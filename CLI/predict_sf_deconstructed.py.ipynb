{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "549ac8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nichrun/miniconda3/envs/data_driven_fep_rel/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for std::vector<double, std::allocator<double> > already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================\n",
      "Sending anonymous Sire usage statistics to http://siremol.org.\n",
      "For more information, see http://siremol.org/analytics\n",
      "To disable, set the environment variable 'SIRE_DONT_PHONEHOME' to 1\n",
      "To see the information sent, set the environment variable \n",
      "SIRE_VERBOSE_PHONEHOME equal to 1. To silence this message, set\n",
      "the environment variable SIRE_SILENT_PHONEHOME to 1.\n",
      "==============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [07:11<00:00, 47.90s/it]\n"
     ]
    }
   ],
   "source": [
    "#!/bin/python\n",
    "\n",
    "# Create the FEPSpace variant of all ligands in an external test set (i.e. congeneric series). \n",
    "# Load the transfer-learned model, predict SEMs. Compare to TRUE SEMs. \n",
    "# Write predictions to file to generate networks with in _04.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import rdmolops, rdMolAlign\n",
    "from rdkit.Chem import Draw, rdFMCS, AllChem, rdmolfiles, Descriptors, rdchem, rdMolDescriptors\n",
    "from rdkit.Chem.AtomPairs import Pairs\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "import BioSimSpace as BSS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import re\n",
    "\n",
    "import time\n",
    "from collections import deque\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from openbabel import pybel\n",
    "\n",
    "import glob\n",
    "import csv\n",
    "import copy\n",
    "import itertools\n",
    "import random\n",
    "# import code to regenerate the twin GCN.\n",
    "import sys\n",
    "sys.path.insert(1, '../ANALYSIS/perturbation_networks/')\n",
    "from _01_twin_gcn import *\n",
    "from _02_transfer_learn_sem import *\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "def CountHAChange(fragment1_mol, fragment2_mol):\n",
    "    \"\"\"Takes in two rdkit fragment molecules, counts heavy atom changes and returns the number.\"\"\"\n",
    "    fragA_smiles = Chem.MolToSmiles(fragment1_mol)\n",
    "    fragB_smiles = Chem.MolToSmiles(fragment2_mol)  \n",
    "    \n",
    "    double_letter_elements = [\"Cl\", \"Br\", \"Si\"]\n",
    "\n",
    "    # assign a score based on n_ha transformed:\n",
    "    transform_score = 0\n",
    "    for frag_A, frag_B in itertools.zip_longest(fragA_smiles.split(\".\"), fragB_smiles.split(\".\")):\n",
    "\n",
    "        # clean up the strings by just retaining letters for easier counting:\n",
    "        if frag_A:\n",
    "            fragA_atoms = ''.join(x for x in frag_A if x.isalpha())\n",
    "        else:\n",
    "            fragA_atoms = \"X\"\n",
    "        if frag_B:\n",
    "            fragB_atoms = ''.join(x for x in frag_B if x.isalpha())\n",
    "        else:\n",
    "            fragB_atoms = \"X\"\n",
    "            \n",
    "        \n",
    "        # a substitution counts as a single-atom change:\n",
    "        if len(fragA_atoms) == len(fragB_atoms):\n",
    "            transform_score += 1\n",
    "        \n",
    "        elif len(fragA_atoms) != len(fragB_atoms):\n",
    "            # add number of heavy atoms changed.\n",
    "            if len(fragA_atoms) > len(fragB_atoms):\n",
    "                transform_score += len(fragA_atoms)\n",
    "            else:\n",
    "                transform_score += len(fragB_atoms)\n",
    "        \n",
    "        # correct for double-letter elements by subtracting 1.\n",
    "        for elem in double_letter_elements:\n",
    "            if elem in fragA_atoms:\n",
    "                transform_score -= 1\n",
    "            if elem in fragB_atoms:\n",
    "                transform_score -= 1\n",
    "            \n",
    "\n",
    "    return transform_score, fragA_smiles, fragB_smiles\n",
    "\n",
    "def constructSmarts(lig_mol, mcs_object):\n",
    "    \"\"\"\n",
    "    Given a ligand and MCS (generated with a second ligand), construct an alternative SMARTS that contains\n",
    "    information on the anchor atom (i.e. the atom in the MCS the perturbed R-group is attached to.)\n",
    "    \n",
    "    Get all neighbour indices of the fragment atoms in the original molecule.  \n",
    "    The (single) index that is in the neighbour indices but not in the fragment \n",
    "    indices (set difference) is the atom we want. Anchor atoms and fragments are \n",
    "    in the same order because of consistent RDKit indexing.\n",
    "    \"\"\"\n",
    "    # get the fragments by subtracting MCS from ligand.\n",
    "    lig_fragments = Chem.ReplaceCore(lig_mol, Chem.MolFromSmarts(mcs_object.smartsString))\n",
    "       \n",
    "    # get the atom indices for the MCS object.\n",
    "    mcs_indices = lig_mol.GetSubstructMatch(Chem.MolFromSmarts(mcs_object.smartsString))\n",
    "\n",
    "    # get all the indices for the ligand.\n",
    "    ligand_indices = set([x for x in range(0, lig_mol.GetNumAtoms())])\n",
    "\n",
    "    # get all the fragment indices.\n",
    "    non_mcs_indices = set(ligand_indices) - set(mcs_indices)\n",
    "\n",
    "    new_smarts = None\n",
    "    anchor_atoms = []\n",
    "    anchor_atoms_idcs = []\n",
    "\n",
    "    for frag_idx in non_mcs_indices:\n",
    "        # get the neighbours for this fragment atom.\n",
    "        nghbrs = lig_mol.GetAtomWithIdx(frag_idx).GetNeighbors()\n",
    "\n",
    "        nghbr_ats = [ lig_mol.GetAtomWithIdx(nghbr.GetIdx()).GetSmarts() for nghbr in nghbrs ] \n",
    "\n",
    "        for nghbr in nghbrs:\n",
    "            # find the set difference.\n",
    "            if not nghbr.GetIdx() in non_mcs_indices:\n",
    "                anchor_atoms.append(lig_mol.GetAtomWithIdx(nghbr.GetIdx()).GetSmarts())\n",
    "                anchor_atoms_idcs.append(nghbr.GetIdx())\n",
    "\n",
    "    # correct an issue with MCS, where e.g. an isopropyl is grafted as two methyls because the MCS \n",
    "    # extends into the base carbon of the isopropyl.\n",
    "    molfrags = Chem.GetMolFrags(lig_fragments, asMols=True, sanitizeFrags=False)\n",
    "\n",
    "    if len(anchor_atoms_idcs) == 3:\n",
    "        if \".\" in Chem.MolToSmiles(lig_fragments): # exclude fused rings.\n",
    "\n",
    "            if anchor_atoms_idcs[0] == anchor_atoms_idcs[1] == anchor_atoms_idcs[2]:\n",
    "                # this will be an isobutyl (-type) R-group. Correct the lig_fragments.\n",
    "                anchor_atom = lig_mol.GetAtomWithIdx(anchor_atoms_idcs[0]).GetSmarts()\n",
    "\n",
    "                fr_0 = Chem.MolToSmiles(lig_fragments).split(\".\")[0].partition(\"]\")[-1]\n",
    "                fr_1 = Chem.MolToSmiles(lig_fragments).split(\".\")[1].partition(\"]\")[-1]\n",
    "                try:\n",
    "                    fr_2 = Chem.MolToSmiles(lig_fragments).split(\".\")[2].partition(\"]\")[-1]\n",
    "                except IndexError:\n",
    "                    new_smarts = f\"{anchor_atom}[1*]({fr_0})({fr_1})\"\n",
    "                    return new_smarts # skips the third fragment if there is none.\n",
    "\n",
    "\n",
    "                new_smarts = f\"{anchor_atom}[1*]({fr_0})({fr_1}){fr_2}\"\n",
    "                return new_smarts\n",
    "    elif len(anchor_atoms_idcs) == 2:\n",
    "        if \".\" in Chem.MolToSmiles(lig_fragments): # exclude fused rings.\n",
    "\n",
    "            if anchor_atoms_idcs[0] == anchor_atoms_idcs[1]:\n",
    "                # this will be an isopropyl (-type) R-group. Correct the lig_fragments.\n",
    "                anchor_atom = lig_mol.GetAtomWithIdx(anchor_atoms_idcs[0]).GetSmarts()\n",
    "                fr_0 = Chem.MolToSmiles(lig_fragments).split(\".\")[0].partition(\"]\")[-1]\n",
    "                fr_1 = Chem.MolToSmiles(lig_fragments).split(\".\")[1].partition(\"]\")[-1]\n",
    "\n",
    "                new_smarts = f\"{anchor_atom}[1*]({fr_0}){fr_1}\"\n",
    "                return new_smarts            \n",
    "\n",
    "    # if no need to correct, just continue as normal, i.e. loop over R-groups.\n",
    "    for anchor, molfrag in zip(anchor_atoms, Chem.GetMolFrags(lig_fragments, asMols=True, sanitizeFrags=False)):\n",
    "        # clean up anchor. We really only care about aromatic vs non-aromatic etc.\n",
    "        anchor = anchor.replace(\"@\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "    \n",
    "        # for each fragment, we construct the smarts as [anchor*]atoms which fits with SMARTS logic.\n",
    "        # Check https://www.daylight.com/dayhtml/doc/theory/theory.smarts.html\n",
    "        # frag_smiles sometimes contains two dummy attachment points (in cases of ring fragments),\n",
    "        # but for our purposes it should be OK to only denote the first dummy with the anchor.\n",
    "        frag_smarts = Chem.MolToSmiles(molfrag)\n",
    "\n",
    "        # we paste the anchor atom in front of the dummy notation in the SMARTS string. We need to retain the dummy\n",
    "        # because this can come in handy when creating R groups on a scaffold (e.g. in case of fused ring perts).\n",
    "        frag_smarts_anchored = anchor+frag_smarts\n",
    "\n",
    "        # build the new SMARTS string. Insert a \".\" when there is already a fragment in the new string.\n",
    "        if not new_smarts:\n",
    "            new_smarts = frag_smarts_anchored\n",
    "        else:\n",
    "            new_smarts += \".\"+frag_smarts_anchored\n",
    "\n",
    "    # sometimes the picked ligand is the actual MCS so there are no pert SMARTS.\n",
    "    if not new_smarts:\n",
    "        new_smarts = \"\"\n",
    "        \n",
    "    return new_smarts\n",
    "\n",
    "def rewriteSMARTS(smarts_string):\n",
    "    \"\"\"Given a SMARTS string with possible multiple fragments, return a valid string where the anchor atom \n",
    "    is the first atom in each fragment, instead of denoted as [x*] (which is not parsable).\"\"\"\n",
    "    \n",
    "    frags_1, frags_2 = smarts_string.split(\"~\")\n",
    "    \n",
    "    def constructPerFrag(frags_smarts):\n",
    "        \"\"\"Splits a ligand's fragments and processes each; puts anchor atom at base of each fragment.\"\"\"\n",
    "        fused_ring = False\n",
    "        frags_whole_rewritten = None\n",
    "\n",
    "        ####### MANUAL REPLACEMENTS\n",
    "        # based on visualising specific outlier perturbations.\n",
    "\n",
    "        # remove some stereo information that we don't need which just makes parsing \n",
    "        # these fragments even more complicated.\n",
    "        if not \":\" in frags_smarts and \"[2*]\" in frags_smarts:\n",
    "            # dealing with a non-fused ring structure. We can replace the attachment\n",
    "            # point with a carbon; just need to determine whether it should be aromatic\n",
    "            # or aliphatic.\n",
    "            if frags_smarts.count(\"c\") < frags_smarts.count(\"C\"):\n",
    "                # there's an edge case here; [2*] is not always a ring structure. these perts are failing now in some cases.\n",
    "                # frags_smarts = frags_smarts.replace(\"[2*]\", \"C1\")\n",
    "                # frags_smarts = frags_smarts[:2]+frags_smarts[2:].replace(\"C\", \"C1\", 1) # set the first-occurring carbon as ring root.\n",
    "                frags_smarts = frags_smarts.replace(\"[2*]\", \"C1\")\n",
    "                frags_smarts = frags_smarts[:2]+frags_smarts[2:].replace(\"C\", \"C1\", 1) # set the first-occurring carbon as ring root.\n",
    "\n",
    "            else:\n",
    "                frags_smarts = frags_smarts.replace(\"[2*]\", \"c1\")\n",
    "                frags_smarts = frags_smarts[:2]+frags_smarts[2:].replace(\"c\", \"c1\", 1) # set the first-occurring carbon as ring root.\n",
    "\n",
    "\n",
    "        replace_queries = [\n",
    "                            [\"CH\", \"C\"],\n",
    "                            [\"C@H\", \"C\"],\n",
    "                            [\"[C@H]\", \"C\"],\n",
    "                            [\"[C]\", \"C\"],\n",
    "                            ]\n",
    "        for source, target in replace_queries:\n",
    "            frags_smarts = frags_smarts.replace(source, target)\n",
    "\n",
    "\n",
    "        # if trihalo, we can merge that into a single R group (i.e. fragment). These are dirty patches, \n",
    "        # protocol should be adjusted in FEP-Space generation.\n",
    "        if \"[C*]F.[C*]F.[C*]F\" in frags_smarts:\n",
    "            frags_smarts = frags_smarts.replace(\"[C*]F.[C*]F.[C*]F\", \"C[1*](F)(F)F\")\n",
    "        elif \"[C*]Cl.[C*]Cl.[C*]Cl\" in frags_smarts:\n",
    "            frags_smarts = frags_smarts.replace(\"[C*]Cl.[C*]Cl.[C*]Cl\", \"C[1*](Cl)(Cl)Cl\")\n",
    "\n",
    "        for idx_a, idx_b, idx_c in itertools.permutations([\"1\", \"2\", \"3\"], 3):\n",
    "            # indices are random; cover all possible orders and replace to isopropyl.\n",
    "            if f\"C[{idx_a}*]C.C[{idx_b}*]C.C[{idx_c}*]C\" in frags_smarts:\n",
    "                frags_smarts = frags_smarts.replace(f\"C[{idx_a}*]C.C[{idx_b}*]C.C[{idx_c}*]C\", \n",
    "                                                        \"C[1*]C(C)(C)C\")\n",
    "        # NB: above conditionals may be obsolete due to isopropyl-type bugfixes in constructSmarts().\n",
    "        \n",
    "        # deal with a special case; R-group is a phenyl. This messes with the grafting algorithm,\n",
    "        # (as the common scaffold is also benzene) so has to be set manually.  \n",
    "        if frags_smarts == \"c[1*]:ccccc:[2*]\":\n",
    "            frags_smarts = \"c[1*]c1ccccc1\"\n",
    "\n",
    "        ####### END OF MANUAL REPLACEMENTS\n",
    "\n",
    "\n",
    "        # now rewrite each fragment.\n",
    "        for frag in frags_smarts.split(\".\"):\n",
    "            frag_parsed = None\n",
    "            if len(frag) == 0:\n",
    "                frag_parsed = anchor_atom = r_group_smarts = \"\"\n",
    "            else: \n",
    "                anchor_atom = frag[0]\n",
    "                r_group_smarts = frag[1:]\n",
    "    \n",
    "            if anchor_atom == \"n\":\n",
    "                # use non-aromatic nitrogen instead.\n",
    "                if frag_parsed:\n",
    "                    frag_parsed += \".N\"+r_group_smarts\n",
    "                else:\n",
    "                    frag_parsed = \"N\"+r_group_smarts \n",
    "            else:\n",
    "                # anchor atom is used between R group and scaffold.\n",
    "                if frag_parsed:\n",
    "                    frag_parsed += \".\"+anchor_atom+r_group_smarts\n",
    "                else:\n",
    "                    frag_parsed = anchor_atom+r_group_smarts \n",
    "\n",
    "            # add the rewritten SMARTS string to the ligand SMARTS string (potentially >1 fragments).      \n",
    "            if frags_whole_rewritten:\n",
    "                frags_whole_rewritten += \".\"+frag_parsed\n",
    "            else:\n",
    "                frags_whole_rewritten = frag_parsed\n",
    "            # record if this fragment contains a fused ring (multiple attachment points).  \n",
    "            if frag_parsed.count(\":\") == 2:\n",
    "                fused_ring = True\n",
    "\n",
    "        # in case the fragments for this ligand contain a fused ring (multiple wildcards), reorder such\n",
    "        # that the fused ring information comes first (simplifies grafting the fragments onto scaffold).\n",
    "        if fused_ring:\n",
    "            # get number of wildcards per sub-fragment.\n",
    "            num_wildcards = [frag_str.count(\"*\") for frag_str in frags_whole_rewritten.split(\".\")]\n",
    "            \n",
    "            # reorder the subfragments by descending number of wildcards (i.e. make fused ring come first).\n",
    "            reordered = [x for _, x in sorted(zip(num_wildcards, frags_whole_rewritten.split(\".\")), reverse=True)]\n",
    "            frags_whole_rewritten = \".\".join(reordered)\n",
    "                  \n",
    "        return frags_whole_rewritten\n",
    "\n",
    "    return constructPerFrag(frags_1), constructPerFrag(frags_2)\n",
    "\n",
    "def graftToScaffold(frag):\n",
    "    \"\"\"Given a SMARTS pattern, create a benzene with R groups corresponding to the fragments in the SMARTS\"\"\"\n",
    "    # start with regular benzene.\n",
    "    main_scaffold = \"c1ccccc1\"\n",
    "    scaffold_mol = Chem.MolFromSmiles(main_scaffold)\n",
    "    \n",
    "    # abort this perturbation if there are two or more fused rings being perturbed.\n",
    "    if frag.count(\".\") == 1 and frag.count(\"*]\") == 4:\n",
    "        #print(\"Aborting this pert --> two or more fused rings being perturbed.\")\n",
    "        return None\n",
    "\n",
    "    # abort this perturbation if there are too many R groups such that the 6 carbons on benzene are not enough.\n",
    "    if frag.count(\".\") >= 5:\n",
    "        #print(\"Aborting this pert --> more than 6 R groups.\")\n",
    "        return None       \n",
    "\n",
    "    # loop over the molecules in this fragment.\n",
    "    for fr in frag.split(\".\"):\n",
    "        # if the fragment is empty, this side of the perturbation is empty. Exit the loop to just keep benzene.\n",
    "        if len(fr) == 0:\n",
    "            break\n",
    "\n",
    "        if fr[0] == \"[\":\n",
    "            # catch rare cases where anchor atom had stereo information.\n",
    "            fr = fr[1]+fr[2:]\n",
    "            \n",
    "        # count the number of wildcards in this set of fragments.\n",
    "        if fr.count(\"*\") <= 1:\n",
    "            # in this case we can simply graft the structure onto benzene.\n",
    "            anchor = fr[0]\n",
    "\n",
    "\n",
    "            if anchor == \"c\":\n",
    "                # removing aromatic anchor will make r_group graft onto benzene directly (making it use the aromatic \n",
    "                # benzene carbon as anchor).\n",
    "                anchor = \"\"\n",
    "            r_group = fr[5:]\n",
    "            \n",
    "            try:\n",
    "                r_group_mol = Chem.MolFromSmiles(\"C\"+anchor+r_group)\n",
    "                scaffold_mol = Chem.ReplaceSubstructs(scaffold_mol, \n",
    "                                         Chem.MolFromSmiles('C'), \n",
    "                                         r_group_mol,\n",
    "                                         replaceAll=False,\n",
    "                                        )[0]\n",
    "            # if no failed r_group, return as None. Next loop iteration will succeed in grafting.\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "\n",
    "        else:\n",
    "            # if >1 wildcards are in the string, we are dealing with a fused ring structure.\n",
    "            # this is considerably more complicated to graft onto benzene. We will rewrite \n",
    "            # the fragment such that it contains the benzene as well; then instead of replacing \n",
    "            # a single carbon in the scaffold we will replace it with the newly generated scaffold.            \n",
    "            new_scaffold = createFusedRingScaffold(fr)\n",
    "            \n",
    "            # several forms of fused rings are being excluded (see createFusedRingScaffold() for rationales).\n",
    "            if new_scaffold is None:\n",
    "                return None\n",
    "            else:\n",
    "                try:\n",
    "                    scaffold_mol = Chem.ReplaceSubstructs(scaffold_mol, \n",
    "                                 Chem.MolFromSmiles(\"c1ccccc1\"), \n",
    "                                 Chem.MolFromSmiles(new_scaffold),\n",
    "                                 replaceAll=False,\n",
    "                                )[0]\n",
    "                except:\n",
    "                    # final error catches. If at this point the fused ring can not be grafted onto the scaffold\n",
    "                    # it can be discarded as brute-forcing it in would substantially alter the chemistry of \n",
    "                    # the benzene scaffold.\n",
    "                    #print(\"Aborting this pert --> miscellaneous fused ring issue.\")\n",
    "                    return None\n",
    "        \n",
    "        # after grafting we need to sanitize.\n",
    "        try:\n",
    "            Chem.SanitizeMol(scaffold_mol)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return scaffold_mol    \n",
    "\n",
    "def createFusedRingScaffold(input_frag):\n",
    "    \"\"\"Given a fragment SMARTS that describes a fused ring, create a canonical smiles notation for benzene\n",
    "    that contains the fused ring.\n",
    "    \"\"\"\n",
    "    # first, verify that the input is indeed a fused ring SMARTS.\n",
    "    if not input_frag.count(\"*\") > 1:\n",
    "        raise Exception(\"Input fragment is not a fused ring SMARTS!\", input_frag)\n",
    "        \n",
    "    # in some cases, fused rings with double bonds will mess with scaffold aromaticity to such a degree that \n",
    "    # building them into our training set becomes complex and introduces noise.\n",
    "    if \"C=[\" in input_frag or \"]=C\" in input_frag:\n",
    "        #print(\"Aborting this pert --> fused ring double bond interrupts scaffold aromaticity.\")\n",
    "        return None\n",
    "    \n",
    "    ########## handle non-aromatic fused rings:\n",
    "    if not input_frag.count(\":\") == 2:\n",
    "        # For our structure, we need everything that is contained within the parentheses of the SMARTS notation.\n",
    "        fused_ring_atoms = input_frag[input_frag.find(\"]\")+len(\"[\"):input_frag.rfind(\"[\")]\n",
    "        \n",
    "        # in case of 5 main cycle atoms, remove 1 'C'. This is due to SMARTS grammar and fixes kekulization errors.\n",
    "        # count the number of atoms in the main cycle of the fused ring.\n",
    "        fused_ring_string = re.sub(r\"\\([^()]*\\)\", \"\", fused_ring_atoms)\n",
    "        fused_ring_size = len(fused_ring_string.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"H\",\"\"))\n",
    "        if fused_ring_size >4:\n",
    "            if \"CCC\" in fused_ring_atoms:\n",
    "                fused_ring_atoms = fused_ring_atoms.replace(\"CCC\", \"CC\", 1)\n",
    "            elif \"CC\" in fused_ring_atoms:\n",
    "                fused_ring_atoms = fused_ring_atoms.replace(\"CC\", \"C\", 1)\n",
    "        \n",
    "        # create the new scaffold string.\n",
    "        new_scaffold = f\"c1cccc2c1{fused_ring_atoms}2\"\n",
    "        \n",
    "        return new_scaffold\n",
    "    ########## handle aromatic fused rings:\n",
    "    # this is much more complex.\n",
    "    else:\n",
    "\n",
    "        # we can ignore the anchor atom (assume aromaticity here, accounting for non-aromaticity here would be exceedingly\n",
    "        # complex). For our structure, we need everything that is contained within the colons of the SMARTS notation.\n",
    "        fused_ring_atoms = input_frag[input_frag.find(\":\")+len(\":\"):input_frag.rfind(\":\")]\n",
    "\n",
    "        ##### clean up structure; \n",
    "        #in some cases there will be a trailing closing '('.\n",
    "        if fused_ring_atoms[-1] == \"(\":\n",
    "            fused_ring_atoms = fused_ring_atoms[:-1]\n",
    "        elif fused_ring_atoms[-2:] == \"(2\":\n",
    "            fused_ring_atoms = fused_ring_atoms[:-2]\n",
    "        elif fused_ring_atoms[-3:] == \"(C2\":\n",
    "            fused_ring_atoms = fused_ring_atoms[:-3]\n",
    "        #####\n",
    "        # in case branch notation for this ring is in the shape of [n*]:ring_atoms(:[n*])branch_atoms,\n",
    "        # we have to swap ':[n*]' and 'branch_atoms'. The way this is written depends mostly on stereochemistry \n",
    "        # and messes up the way we parse.\n",
    "        attch_pnt_strings = [f\"(:[{i}*])\" for i in range(10)]\n",
    "\n",
    "        # count the number of atoms in the main cycle of the fused ring.\n",
    "        fused_ring_string = re.sub(r\"\\([^()]*\\)\", \"\", fused_ring_atoms)\n",
    "        fused_ring_size = len(fused_ring_string.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"H\",\"\"))\n",
    "        \n",
    "        # in case of 5 main cycle atoms, remove 1 'c'. This is due to SMARTS grammar and fixes kekulization errors.\n",
    "        if fused_ring_size >4:\n",
    "            if \"ccc\" in fused_ring_atoms:\n",
    "                fused_ring_atoms = fused_ring_atoms.replace(\"ccc\", \"cc\", 1)\n",
    "            elif \"cc\" in fused_ring_atoms:\n",
    "                fused_ring_atoms = fused_ring_atoms.replace(\"cc\", \"c\", 1)\n",
    "         \n",
    "\n",
    "        if any(c.split(\"])\")[-1].isalpha() for c in input_frag) and any(x in input_frag for x in attch_pnt_strings):\n",
    "            branch_structure = input_frag.split(\"])\")[-1]\n",
    "            fused_ring_atoms += f\"({input_frag.split('])')[-1]})\"\n",
    "            \n",
    "        # create the new scaffold string.\n",
    "        new_scaffold = f\"c1cccc2c1{fused_ring_atoms}2\"\n",
    "\n",
    "        return new_scaffold\n",
    "               \n",
    "def loadEnsemble(len_k, path_to_weights, input_model):\n",
    "    \"\"\"Loads k weights into k copies of input tf.keras model given weights path.\"\"\"\n",
    "    models_collections = []\n",
    "    model_paths = glob(path_to_weights+\"*.data*\")\n",
    "\n",
    "    replicates = [ int(path.split(\"_\")[3]) for path in model_paths ]\n",
    "    n_replicates = max(replicates)\n",
    "\n",
    "    for rep in range(n_replicates):\n",
    "        rep_model_basepath = f\"{path_to_weights}_{rep}_*\"\n",
    "\n",
    "        models_collection = []\n",
    "        \n",
    "        for k in range(len_k):\n",
    "            k_model_path = rep_model_basepath.replace(\"*\", str(k))\n",
    "                   \n",
    "            k_model = tf.keras.models.clone_model(input_model)\n",
    "            try:\n",
    "                k_model.load_weights(k_model_path)\n",
    "                models_collection.append(k_model)\n",
    "            except tf.errors.NotFoundError:\n",
    "                pass # in rare cases some model training fails; see training code.\n",
    "\n",
    "\n",
    "        models_collections.append(models_collection)\n",
    "\n",
    "    #print(f\"Loaded a total of {len(models_collection)} models; {len_k} CV folds.\")\n",
    "\n",
    "    return models_collections\n",
    "\n",
    "def predictEnsemble(ensemble, test_dataset):\n",
    "    \"\"\"Given an ensemble of tf.keras models with loaded weights and a test set, \n",
    "    make k predictions and return mean and std of the predictions.\"\"\"\n",
    "    preds = []\n",
    "\n",
    "    for model in ensemble:\n",
    "\n",
    "        pred_sem_values = np.ravel(model.predict(test_dataset))\n",
    "        preds.append(pred_sem_values)\n",
    "\n",
    "    # return the mean and std for each perturbation.\n",
    "    return np.mean(preds, axis=0), np.std(preds, axis=0)\n",
    "\n",
    "def RDKitToBSSMol(mol):\n",
    "    \"\"\"Uses a .pdb intermediate to convert an rdkit molecule object to a BSS mol object.\n",
    "    \"\"\"\n",
    "    #mol = Chem.AddHs(mol) \n",
    "    AllChem.EmbedMolecule(mol) # need 3D coordinates for BSS to align molecules better.\n",
    "    Chem.MolToPDBFile(mol, \"tmp_mol.pdb\")\n",
    "    bss_mol = BSS.IO.readPDB(\"tmp_mol.pdb\")[0]\n",
    "    os.remove(\"tmp_mol.pdb\")  \n",
    "    return bss_mol  \n",
    "\n",
    "def reloadLigand(ligand_smiles):\n",
    "    \"\"\"Loads a SMILES entry into RDKit, attempts to clean the structure and returns \n",
    "    a re-shuffled SMILES equivalent of the processed input. \n",
    "    \"\"\"\n",
    "    # use rdkit to write alternative SMILES.\n",
    "    tmpmol = Chem.MolFromSmiles(ligand_smiles)\n",
    "\n",
    "    # attempt to clean the structure.\n",
    "    Chem.SanitizeMol(tmpmol)\n",
    "    tmpmol.ClearComputedProps()\n",
    "    tmpmol.UpdatePropertyCache()\n",
    "\n",
    "    # reload through PDB.\n",
    "    AllChem.EmbedMolecule(tmpmol) # adding 3D coordinates to the ligand helps with OFF processing.\n",
    "    Chem.MolToPDBFile(tmpmol, \"tmp/mol.pdb\")\n",
    "    bss_mol = BSS.IO.readPDB(\"tmp/mol.pdb\")[0]\n",
    "\n",
    "    return Chem.MolToSmiles(tmpmol, doRandom=True), bss_mol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mapAtoms(mol1, mol2, forced_mcs_mapp=False):\n",
    "    \"\"\"\n",
    "    Aligns and merges two BSS molecules; returns the atom mapping, merged molecule and a nested\n",
    "    list describing the atom type changes.\n",
    "    \"\"\"\n",
    "    if forced_mcs_mapp:\n",
    "        mapp = BSS.Align.matchAtoms(mol1, mol2, prematch=forced_mcs_mapp)\n",
    "    else:\n",
    "        mapp = BSS.Align.matchAtoms(mol1, mol2)\n",
    "\n",
    "    try:\n",
    "        merged = BSS.Align.merge(mol1, mol2, mapp,\n",
    "                                allow_ring_breaking=True,\n",
    "                                allow_ring_size_change=True,\n",
    "                                )\n",
    "    except BSS._Exceptions.IncompatibleError:\n",
    "        try:\n",
    "            merged = BSS.Align.merge(mol1, mol2, mapp,\n",
    "                                allow_ring_breaking=True,\n",
    "                                allow_ring_size_change=True,\n",
    "                                force=True\n",
    "                                )\n",
    "        except BSS._Exceptions.IncompatibleError:      \n",
    "            # this mapping creates a very funky perturbation; discard.\n",
    "            return {}, None, [[]]\n",
    "\n",
    "    # # Get indices of perturbed atoms.\n",
    "    idxs = merged._getPerturbationIndices()\n",
    "\n",
    "    # For each atom in the merged molecule, get the lambda 0 and 1 amber atom type.\n",
    "    atom_type_changes = [[merged.getAtoms()[idx]._sire_object.property(\"ambertype0\"),  \\\n",
    "                 merged.getAtoms()[idx]._sire_object.property(\"ambertype1\")] \\\n",
    "                 for idx in idxs]\n",
    "\n",
    "    # Keep only changing atoms.\n",
    "    atom_type_changes = [at_ch for at_ch in atom_type_changes if at_ch[0] != at_ch[1] ]\n",
    "\n",
    "    return mapp, merged, atom_type_changes\n",
    "\n",
    "def getBenzeneScaffoldIndices(molecule):\n",
    "    \"\"\"For a given RDKit molecule, return the atom indices for a benzene scaffold\"\"\"\n",
    "    patt = Chem.MolFromSmiles('c1ccccc1')\n",
    "    hit_ats = list(molecule.GetSubstructMatch(patt))\n",
    "    return hit_ats, Chem.AddHs(molecule)\n",
    "\n",
    "def rotate_values(my_dict):\n",
    "    values_deque = deque(my_dict.values())\n",
    "    values_deque.rotate(1)\n",
    "    return dict(zip(my_dict.keys(), values_deque))\n",
    "\n",
    "def getMapping(ligA, ligB, ori_mcs, abstract_mol_1, abstract_mol_2):\n",
    "    \"\"\"\n",
    "    Given input (parameterised) original ligands A and B, their MCSresult and \n",
    "    the generated FEP-Space derivatives 1/2 in RDKit molecule object format,\n",
    "    find the FEP-Space derivative atom-mapping that matches the original ligands' MCS.\n",
    "\n",
    "    In its current form this step is prohibitively rate-limiting. Even with gasteiger-charge based\n",
    "    parameterisation this protocol requires further speed-up. See https://github.com/michellab/BioSimSpace/issues/249.\n",
    "    Potentially this could be solved by refactoring FEP-Space training set setup:\n",
    "    - robustly graft R-groups onto benzene such that we keep track of the R-group indices that are perturbed\n",
    "    - insert a reference R-group at e.g. idx 5 (e.g. -cc(At)c-)\n",
    "    - featurise with standard mapping {0:0, 1:1, ..}\n",
    "    - remove reference R-group\n",
    "\n",
    "    alternatively, instead of feeding a mapping array into the NN, the amber atom-type changes \n",
    "    could be featurised directly through e.g. one-hot encoding.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    !!!!!!!!!!!!!!\n",
    "    FOR THE CLI PROTOTYPE NO MAPPING CALCULATION IS DONE AS IT IS TOO EXPENSIVE\n",
    "    RETURNING THE DEFAULT MAPPING INSTEAD\n",
    "    THIS FUNCTION IS NOT EXECUTED\n",
    "    IF AT SOME POINT THIS FUNCTION HAS BE EXECUTED THE INPUT LIGANDS MUST BE \n",
    "    PARAMETERISED BSS OBJECTS!!\n",
    "    \"\"\"\n",
    "    return {0:0, 1:1, 2:2, 3:3, 4:4, 5:5} # remove this line if want to unlock mapping computation.\n",
    "\n",
    "\n",
    "    # get the atom type changes for the original perturbation (i.e. input ligand).\n",
    "    _, _, ori_atom_type_changes = mapAtoms(ligA, ligB)\n",
    "\n",
    "\n",
    "    abs_lig_1, _ = parameteriseLigand(Chem.MolToSmiles(abstract_mol_1))\n",
    "    abs_lig_2, _ = parameteriseLigand(Chem.MolToSmiles(abstract_mol_2))\n",
    "\n",
    "    if not abs_lig_1 or not abs_lig_2:\n",
    "        # ligands are not parameterisable due to SMILES inconsistencies. Will be discarded downstream.\n",
    "        return {0:0, 1:1, 2:2, 3:3, 4:4, 5:5}\n",
    "\n",
    "    # use RDKit to find the benzene atom indices. These are conserved between RDKit and BSS.\n",
    "    lig_1_benzene_indices, lig_1_rdkit = getBenzeneScaffoldIndices(abstract_mol_1)\n",
    "    lig_2_benzene_indices, lig_2_rdkit = getBenzeneScaffoldIndices(abstract_mol_2)\n",
    "\n",
    "\n",
    "    # with these benzene indices make an initial forced mapping. \n",
    "    forced_mapping = {}\n",
    "    for at1, at2 in zip(lig_1_benzene_indices, lig_2_benzene_indices):\n",
    "        forced_mapping[at1] = at2\n",
    "\n",
    "    # now find the correct mapping for the FEP-Space derivatives.\n",
    "    correct_mapping = None\n",
    "    mapping_highscore = -1\n",
    "\n",
    "    for rotat in range(6):\n",
    "        # rotate along the benzene MCS. \n",
    "        forced_mapping = rotate_values(forced_mapping)\n",
    "\n",
    "        # use BSS to map the ligands together using the forced mapping.\n",
    "        mapping, _, abs_atom_type_changes = mapAtoms(abs_lig_1, abs_lig_2, forced_mcs_mapp=forced_mapping)\n",
    "\n",
    "        # compare the original and the current abstract atom type change lists.\n",
    "        # the mapping with the highest number of matches will be the correct mapping.\n",
    "        counter = 0\n",
    "        for at_ch in abs_atom_type_changes:\n",
    "            if at_ch in ori_atom_type_changes:\n",
    "                counter += 1\n",
    "\n",
    "        # set the new mapping as the correct mapping if it outperforms previous ones.\n",
    "        if counter > mapping_highscore:\n",
    "            correct_mapping = mapping\n",
    "            mapping_highscore = counter\n",
    "\n",
    "    return correct_mapping\n",
    "\n",
    "\n",
    "def calcFPSimilarity(lig1, lig2):\n",
    "    \"\"\"computes molecular similarity using RDKit's standard approach\"\"\"\n",
    "\n",
    "    # Compute ECFP6 (6 is diameter, in rdkit radius 3).\n",
    "    fps = [ AllChem.GetMorganFingerprintAsBitVect(m,3,nBits=1024) for m in [lig1, lig2] ]\n",
    "\n",
    "    # compute tanimoto similarity.\n",
    "    fp_simi = DataStructs.FingerprintSimilarity(fps[0],fps[1], metric=DataStructs.DiceSimilarity)\n",
    "    return fp_simi\n",
    "\n",
    "def GetArrayOfPertMappings(perts):\n",
    "    mapping_array = {0:0, 1:1, 2:2, 3:3, 4:4, 5:5}# !!!!!!!!!!!!! IN EVERY CASE THE MAPPING IN THIS!!!!!!!!\n",
    "    pert_mappings.append(featuriseMapping(mapping_array))#This is the same for every molecules pair\n",
    "    return pert_mappings\n",
    "\n",
    "\n",
    "\n",
    "def createTestDataset(perts_featurised, pert_mappings=None):\n",
    "    \"\"\"Creates a tf.dataset from a nested list of perturbations containing the smiles \n",
    "    for each ligand in shape [[lig_1, lig2], [],[]]\"\"\"\n",
    "    \n",
    "    ligA_features = [pert[0] for pert in perts_featurised]\n",
    "    ligB_features = [pert[1] for pert in perts_featurised]\n",
    "\n",
    "    # we have to use a placeholder y label. Model.predict() will predict the actual y_test values.\n",
    "    y_test = list(range(len(perts_featurised)))\n",
    "\n",
    "    ligA_graph = graphs_from_smiles(ligA_features)\n",
    "    ligB_graph = graphs_from_smiles(ligB_features)\n",
    "\n",
    "    # make a 'batch graph' of this perturbation. Use a batch size that fits (number doesn't really matter\n",
    "    # in testing phase).\n",
    "    \n",
    "    \n",
    "    #Edit this code so pert_mappings is hard coded when pert_mappings=None\n",
    "    if pert_mappings:\n",
    "        series_dataset = MPNNDataset(ligA_graph, ligB_graph, pert_mappings, y_test, batch_size=1)\n",
    "    else:\n",
    "        raise(\"series_dataset, pert_mappings default not supported\")\n",
    "\n",
    "    return series_dataset\n",
    "\n",
    "def loadPostProcessors(basepath_to_input):\n",
    "    \"\"\"\n",
    "    Loads statistical summaries to postprocess features for test datapoints. Any test feature array\n",
    "    must be normalized/PCAd in the same way that the training data was in order for predictions to \n",
    "    be sensible.\n",
    "    \"\"\"\n",
    "    apfp_stats = pd.read_csv(basepath_to_input+\"stats_apfp.csv\")\n",
    "    ecfp_stats = pd.read_csv(basepath_to_input+\"stats_ecfp.csv\")\n",
    "    props_stats = pd.read_csv(basepath_to_input+\"stats_props.csv\")\n",
    "\n",
    "    apfp_pca_obj = pickle.load(open(basepath_to_input+\"pca_apfp.pkl\",\"rb\"))\n",
    "    ecfp_pca_obj = pickle.load(open(basepath_to_input+\"pca_ecfp.pkl\",\"rb\"))\n",
    "    props_pca_obj = pickle.load(open(basepath_to_input+\"pca_props.pkl\",\"rb\"))\n",
    "\n",
    "    rf_apfp = pickle.load(open(basepath_to_input+\"fit_rf_apfp.pkl\",\"rb\")) \n",
    "    rf_ecfp = pickle.load(open(basepath_to_input+\"fit_rf_ecfp.pkl\",\"rb\")) \n",
    "    rf_props = pickle.load(open(basepath_to_input+\"fit_rf_props.pkl\",\"rb\")) \n",
    "\n",
    "    svr_apfp = pickle.load(open(basepath_to_input+\"fit_svr_apfp.pkl\",\"rb\")) \n",
    "    svr_ecfp = pickle.load(open(basepath_to_input+\"fit_svr_ecfp.pkl\",\"rb\")) \n",
    "    svr_props = pickle.load(open(basepath_to_input+\"fit_svr_props.pkl\",\"rb\"))\n",
    "\n",
    "    # return a dict to simplify parsing this function's output.\n",
    "    return_dict = {\n",
    "                \"apfp_stats\" : apfp_stats,\n",
    "                \"ecfp_stats\" : ecfp_stats,\n",
    "                \"props_stats\" : props_stats,\n",
    "                \"apfp_pca_obj\" : apfp_pca_obj,\n",
    "                \"ecfp_pca_obj\" : ecfp_pca_obj,\n",
    "                \"props_pca_obj\" : props_pca_obj,\n",
    "                \"rf_apfp\" : rf_apfp,\n",
    "                \"rf_ecfp\" : rf_ecfp,\n",
    "                \"rf_props\" : rf_props,\n",
    "                \"svr_apfp\" : svr_apfp,\n",
    "                \"svr_ecfp\" : svr_ecfp,\n",
    "                \"svr_props\" : svr_props\n",
    "                }\n",
    "    return return_dict\n",
    "\n",
    "def normaliseTestFeats(feats, stat):\n",
    "    \"\"\"Given an array of features,\n",
    "    Returns a normalised DataFrame and stats for test set scaling.\"\"\"\n",
    "\n",
    "    feats_df = pd.DataFrame.from_records(feats)\n",
    "\n",
    "    def norm(x):\n",
    "        return (x - stat['mean']) / stat['std']\n",
    "\n",
    "    # Normalise and return separately.\n",
    "    normed_data = norm(feats_df).fillna(0).replace([np.inf, -np.inf], 0.0)\n",
    "    \n",
    "    return normed_data \n",
    "\n",
    "def reduceTestFeatures(feats, pca):\n",
    "    \"\"\"Given a pd dataframe of normalised features, reduce\n",
    "    to 100 dimensions using the provided PCA object that has been\n",
    "    pre-fit.\"\"\"\n",
    "    return pca.transform(feats)\n",
    "\n",
    "def predictWithModel(feats, model1, model2):\n",
    "    \"\"\"Given an array of pre-processed features, predict the y label using the\n",
    "    provided pre-trained models\"\"\"\n",
    "    return model1.predict(feats)[0], model2.predict(feats)[0]\n",
    "\n",
    "def predictBaseModels(perts):\n",
    "    \"\"\"\n",
    "    Given a list of perturbations where each item in each list is a path to an SDF file,\n",
    "    - load both ligands as rdkit mol objects\n",
    "    - featurise as during training\n",
    "    - predict the SEM using each method & return arrays\n",
    "    \"\"\"\n",
    "    print(\"Predicting using base models..\")\n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "\n",
    "    # load all statistics and PCA objects required for pre-processing the fingerprints.\n",
    "    pp_dict = loadPostProcessors(\"process/base_models/\")\n",
    "\n",
    "    apfp_rf_preds, apfp_svr_preds,  ecfp_rf_preds, ecfp_svr_preds, \\\n",
    "    props_rf_preds, props_svr_preds = [], [], [], [], [], []\n",
    "\n",
    "    for liga, ligb in tqdm(perts):\n",
    "        liga = Chem.SDMolSupplier(liga)[0]\n",
    "        ligb = Chem.SDMolSupplier(ligb)[0]\n",
    "\n",
    "        ####### ATOM-PAIR FPs\n",
    "        apfp = list(rdMolDescriptors.GetHashedAtomPairFingerprint(liga, 256))\n",
    "        for bit in list(rdMolDescriptors.GetHashedAtomPairFingerprint(ligb, 256)):\n",
    "            apfp.append(bit)\n",
    "        apfp_normed = normaliseTestFeats([apfp], pp_dict[\"apfp_stats\"])\n",
    "        apfp_postprocessed = reduceTestFeatures(apfp_normed, pp_dict[\"apfp_pca_obj\"])\n",
    "        rf_pred, svr_pred = predictWithModel(apfp_postprocessed, \n",
    "                        pp_dict[\"rf_apfp\"], pp_dict[\"svr_apfp\"])\n",
    "        apfp_rf_preds.append(rf_pred)\n",
    "        apfp_svr_preds.append(svr_pred)\n",
    "\n",
    "\n",
    "        ####### EXTENDED CONNECTIVITY FPs\n",
    "        ecfp = list(AllChem.GetMorganFingerprintAsBitVect(liga,1,nBits=1024))\n",
    "        for bit in list(AllChem.GetMorganFingerprintAsBitVect(ligb,1,nBits=1024)):\n",
    "            ecfp.append(bit)\n",
    "        ecfp_normed = normaliseTestFeats([ecfp], pp_dict[\"ecfp_stats\"])\n",
    "        ecfp_postprocessed = reduceTestFeatures(ecfp_normed, pp_dict[\"ecfp_pca_obj\"])\n",
    "        rf_pred, svr_pred = predictWithModel(ecfp_postprocessed, \n",
    "                        pp_dict[\"rf_ecfp\"], pp_dict[\"svr_ecfp\"])\n",
    "        ecfp_rf_preds.append(rf_pred)\n",
    "        ecfp_svr_preds.append(svr_pred)\n",
    "\n",
    "\n",
    "        ####### MOLECULAR PROPERTIES\n",
    "        liga_props = calc(liga).fill_missing(value=0)\n",
    "        ligb_props = calc(ligb).fill_missing(value=0)\n",
    "        dProps = np.array(list(ligb_props.values())) - np.array(list(liga_props.values()))\n",
    "        #dProps_col_names = ligb_props.keys()\n",
    "        props_normed = normaliseTestFeats([dProps], pp_dict[\"props_stats\"])\n",
    "        props_postprocessed = reduceTestFeatures(props_normed, pp_dict[\"props_pca_obj\"])\n",
    "        rf_pred, svr_pred = predictWithModel(props_postprocessed, \n",
    "                        pp_dict[\"rf_props\"], pp_dict[\"svr_props\"])\n",
    "        props_rf_preds.append(rf_pred)\n",
    "        props_svr_preds.append(svr_pred)\n",
    "\n",
    "    return apfp_rf_preds, apfp_svr_preds,  ecfp_rf_preds, ecfp_svr_preds, props_rf_preds, props_svr_preds\n",
    "\n",
    "def writeBaselModelPreds(preds, pert_paths, output_pathbase):\n",
    "    \"\"\"\n",
    "    writes a nested list of SEM predictions to files. See the return format in predictBaseModels().\n",
    "    \"\"\"\n",
    "    print(f\"Writing predictions to {output_pathbase}..\")\n",
    "    pred_methods = [\"apfp_rf_preds\", \"apfp_svr_preds\",  \n",
    "                    \"ecfp_rf_preds\", \"ecfp_svr_preds\", \n",
    "                    \"props_rf_preds\", \"props_svr_preds\"]\n",
    "    pert_names = [ pert[0].split(\"/\")[-1].replace(\".sdf\",\"\")+\"~\"+pert[1].split(\"/\")[-1].replace(\".sdf\",\"\") \\\n",
    "                    for pert in pert_paths ]\n",
    "\n",
    "    for pred, method in zip(preds, pred_methods):\n",
    "\n",
    "        # write the predictions file for parsing during analysis.\n",
    "        with open(output_pathbase+\"_\"+method, \"w\") as writefile:\n",
    "            writer = csv.writer(writefile)\n",
    "            writer.writerow([\"pert_name\", \"pred_sem_base\"])\n",
    "\n",
    "            for pred_sem, pert_name in zip(pred, pert_names):\n",
    "                inv_pert_name = f\"{pert_name.split('~')[1]}~{pert_name.split('~')[0]}\"\n",
    "                writer.writerow([pert_name, pred_sem])\n",
    "                writer.writerow([inv_pert_name, pred_sem])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57977543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################\n",
    "##############################################\n",
    "##############################################\n",
    "# catch input and output file paths from CLI.\n",
    "\n",
    "\"\"\"\n",
    "# catch the CLI flags. This is a quick argparse fix, could do with optimisation of course.\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"-i\", help=\"Path to input CSV file containing input pairs of ligands to predict SEMs on. Example line: input_files_example/jmc_27.sdf,input_files_example/ejm_31.sdf\",\n",
    "                type=str)\n",
    "\n",
    "parser.add_argument(\"-o\", help=\"Path to output CSV file that will contain pairs of ligands with predicted SEMs.\",\n",
    "                type=str)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#input_file = \"networks/cls-22-06-28/cls1/cluster_pairs.csv\"\n",
    "#output_file = \"networks/cls-22-06-28/cls1/cluster_pair_preds.csv\"\n",
    "\n",
    "input_file = \"clustering/pairs.csv\"\n",
    "output_file = \"clustering/Test_output\"\n",
    "\n",
    "if input_file == None or output_file == None:\n",
    "    raise Exception(\"Provide both -i and -o flags to the CLI. See python predict_sd.py -h for info.\")\n",
    "\n",
    "##############################################\n",
    "##############################################\n",
    "##############################################\n",
    "# with the input files, make predictions.\n",
    "\n",
    "##### MODEL LOADING  \n",
    "# 1) Load SEM predictor.\n",
    "# First, build the network architecture based on reference graph inputs from training.\n",
    "fepspace_df = pd.read_csv(\"../ANALYSIS/perturbation_networks/process/fepspace_smiles_per_sem.csv\", nrows=1)\n",
    "x_ref_0 = graphs_from_smiles(fepspace_df.ligand1_smiles)\n",
    "x_ref_1 = graphs_from_smiles(fepspace_df.ligand2_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "767f1e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model..\n"
     ]
    }
   ],
   "source": [
    "# 2) Build the lambda 0 and 1 legs (both are individual MPNNs).\n",
    "print(\"\\nBuilding model..\")\n",
    "fepnn = MPNNModel(\n",
    "    atom_dim_0=x_ref_0[0][0][0].shape[0], bond_dim_0=x_ref_0[1][0][0].shape[0],\n",
    "    atom_dim_1=x_ref_1[0][0][0].shape[0], bond_dim_1=x_ref_1[1][0][0].shape[0],\n",
    "    r_group_mapping_dim=50 # fixed value\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59c94567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_features_0 (InputLayer)    [(None, 29)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_features_0 (InputLayer)    [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pair_indices_0 (InputLayer)     [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_features_1 (InputLayer)    [(None, 29)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_features_1 (InputLayer)    [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pair_indices_1 (InputLayer)     [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "message_passing (MessagePassing (None, 64)           57728       atom_features_0[0][0]            \n",
      "                                                                 bond_features_0[0][0]            \n",
      "                                                                 pair_indices_0[0][0]             \n",
      "                                                                 atom_features_1[0][0]            \n",
      "                                                                 bond_features_1[0][0]            \n",
      "                                                                 pair_indices_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "atom_partition_indices_0 (Input [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_partition_indices_1 (Input [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "partition_padding (PartitionPad (None, None, 64)     0           message_passing[0][0]            \n",
      "                                                                 atom_partition_indices_0[0][0]   \n",
      "                                                                 message_passing[1][0]            \n",
      "                                                                 atom_partition_indices_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 64)     0           partition_padding[0][0]          \n",
      "                                                                 partition_padding[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder (Transforme (None, None, 64)     199040      masking[0][0]                    \n",
      "                                                                 masking[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "r_group_mapping (InputLayer)    [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           transformer_encoder[0][0]        \n",
      "                                                                 transformer_encoder[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           510         r_group_mapping[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          33280       global_average_pooling1d[0][0]   \n",
      "                                                                 global_average_pooling1d[1][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           110         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 450)          230850      dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5)            55          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 905)          0           dense_3[0][0]                    \n",
      "                                                                 dense_3[1][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 700)          634200      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 560)          392560      dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 373)          209253      dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 187)          69938       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            188         dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,827,712\n",
      "Trainable params: 671,939\n",
      "Non-trainable params: 1,155,773\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) extend the model with the transfer-learned weight architecture (_02).\n",
    "fepnn = modelTransfer(fepnn, 4, 4) # adjust parameters if changes them in _02.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e60da564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights from rbfenn_weights/weights_finetuned_*..\n"
     ]
    }
   ],
   "source": [
    "# 4) now load in pre-trained weights for all five folds of all 10 replicates.\n",
    "weights_path = \"rbfenn_weights/weights_finetuned\"\n",
    "print(f\"Loading model weights from {weights_path}_*..\")\n",
    "fepnn_ensembles = loadEnsemble(5, weights_path, fepnn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db5388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> steps 1-3 basically reproduce steps taken during training; step 4 adds trained weights.\n",
    "\n",
    "#### LOAD TRANSFORMATIONS AND LIGANDS\n",
    "\"\"\"\n",
    "#Array of path pairs to sdf of molecule transformation (1) --> (2)\n",
    "query_transformations = []\n",
    "\n",
    "#Dictionary of ligand sdf to smiles\n",
    "input_ligands = {}\n",
    "with open(input_file, \"r\") as readfile:\n",
    "    reader = csv.reader(readfile)\n",
    "    for row in reader:\n",
    "        query_transformations.append(row)\n",
    "\n",
    "        # also load ligands as SMILES\n",
    "        for lig_path in row:\n",
    "            if not lig_path in input_ligands:\n",
    "                input_ligands[lig_path] = Chem.MolToSmiles(\n",
    "                    Chem.SDMolSupplier(lig_path)[0])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1e4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#get the original smiles of the transformations too.\n",
    "#Pairs of smiles strings for transformation (1) --> (2)\n",
    "query_smiles = []\n",
    "for a, b in query_transformations:\n",
    "    a_smiles = Chem.MolToSmiles(Chem.SDMolSupplier(a)[0])\n",
    "    b_smiles = Chem.MolToSmiles(Chem.SDMolSupplier(b)[0])\n",
    "    query_smiles.append([a_smiles, b_smiles])\n",
    "\n",
    "# # CLI NOTE: we don't parameterise because we don't attempt to get the atom mapping.\n",
    "# # these two steps are currently very time-consuming and not fit for the current project.\n",
    "# # here is the original code though:\n",
    "# param_dict = {}\n",
    "# for lig_path in tqdm(ligs, total=len(ligs)):\n",
    "#     #lig = BSS.IO.readMolecules(lig_path.replace(\".sdf\", \".mol2\"))[0]\n",
    "#     lig = Chem.MolToSmiles(Chem.SDMolSupplier(lig_path)[0])\n",
    "#     #lig, _ = parameteriseLigand(lig)\n",
    "#     param_dict[lig_path] = lig\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a12390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef41daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### PREDICTIONS    \n",
    "\"\"\"\n",
    "print(\"\\nComputing features for all perturbations in the set (MCS + graphs).\") \n",
    "# 2) graft all requested transformations onto benzene       \n",
    "perts_featurised, perts_names, pert_mappings, \\\n",
    "ha_change_counts, fp_simis = featurisePerturbations(query_transformations, \n",
    "                                    input_ligands)\n",
    "\n",
    "#perts_featurised = transformations grafted to benzene (array of array pairs)\n",
    "#perts_names = names of molecules being transformed (array of pairs)\n",
    "#pert_mappings = np.array(), not sure of contents, but needed for tensorflow!!!!!!!! \n",
    "#ha_change_counts = array, not sure. This is not called again. Probably used in analysis. \n",
    "#fp_simis = fingerprint similarities (not needed)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e260dc3",
   "metadata": {},
   "source": [
    "# From pre-processed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f0625f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_smiles_pairs = []\n",
    "pert_names = []\n",
    "perts_featurised = []\n",
    "\n",
    "with open(input_file,\"r\") as file:\n",
    "    for line in file.readlines()[1:]:\n",
    "        line=line.split()\n",
    "        list_of_smiles_pairs.append([line[2],line[3]])\n",
    "        pert_name = line[0]+\"~\"+line[1]\n",
    "        \n",
    "        pert_names.append(pert_name)\n",
    "        perts_featurised.append([line[2],line[3]])\n",
    "        \n",
    "mapping_array = {0:0, 1:1, 2:2, 3:3, 4:4, 5:5}# !!!!!!!!!!!!! IN EVERY CASE THE MAPPING IN THIS!!!!!!!!\n",
    "pert_mapping_standard = featuriseMapping(mapping_array)#This is the same for every molecules pair\n",
    "pert_mappings = [pert_mapping_standard]*len(perts_featurised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6132f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) create a test set, i.e. transform the input features such that it has\n",
    "# the training set format.\n",
    "\n",
    "perts_dataset = createTestDataset(perts_featurised, pert_mappings=pert_mappings)#Replace in feauture with default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af2a2fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.ParallelMapDataset"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(perts_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "209e11d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting SFs per siamese GNN model in the ensemble (n=9).\n"
     ]
    }
   ],
   "source": [
    "# 4) make predictions per ensemble.\n",
    "#fepnn_ensembles is define earlier, from tensor flow\n",
    "#Need perts_dataset!!!!!\n",
    "sf_predictions = []\n",
    "print(f\"\\nPredicting SFs per siamese GNN model in the ensemble (n={len(fepnn_ensembles)}).\")\n",
    "for fepnn_ensemble in tqdm(fepnn_ensembles):\n",
    "      #make the SEM predictions for this replicate.\n",
    "      pred_sem_values_mean, pred_sem_values_std = predictEnsemble(fepnn_ensemble, perts_dataset)\n",
    "      sf_predictions.append(pred_sem_values_mean)\n",
    "\n",
    "# get the mean prediction (i.e. mean of mean predictions as each ensemble is 5 \n",
    "# model predictions because of cross validation scheme)\n",
    "sf_predictions = np.mean(sf_predictions, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4559a767",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Make sure this is useful format\n",
    "\n",
    "with open(output_file, \"w\") as writefile:\n",
    "    writer = csv.writer(writefile)\n",
    "\n",
    "    writer.writerow([\"pert_name\", \"graft1\", \"graft2\", \"sf_prediction\"])\n",
    "\n",
    "    for name, (g1, g2), sf in zip(pert_names, list_of_smiles_pairs, sf_predictions):\n",
    "        writer.writerow([name, g1, g2, sf])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
