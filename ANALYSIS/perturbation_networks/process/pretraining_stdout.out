[22;0t]0;IPython: ANALYSIS/perturbation_networksLoading input data..

Generating graphs from SMILES..
Training set..
Validation set..

Building model..

Compiling..
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing (MessagePassing (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding (PartitionPad (None, None, 64)     0           message_passing[0][0]            
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing[1][0]            
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking (Masking)               (None, None, 64)     0           partition_padding[0][0]          
                                                                 partition_padding[1][0]          
__________________________________________________________________________________________________
transformer_encoder (Transforme (None, None, 64)     199040      masking[0][0]                    
                                                                 masking[1][0]                    
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 64)           0           transformer_encoder[0][0]        
                                                                 transformer_encoder[1][0]        
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 512)          33280       global_average_pooling1d[0][0]   
                                                                 global_average_pooling1d[1][0]   
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 10)           110         dense_4[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 450)          230850      dense_2[0][0]                    
                                                                 dense_2[1][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 5)            55          dense_5[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 905)          0           dense_3[0][0]                    
                                                                 dense_3[1][0]                    
                                                                 dense_6[0][0]                    
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 700)          634200      concatenate[0][0]                
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 450)          315450      dense_7[0][0]                    
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 100)          45100       dense_8[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 1)            101         dense_9[0][0]                    
==================================================================================================
Total params: 1,516,424
Trainable params: 1,516,424
Non-trainable params: 0
__________________________________________________________________________________________________
None

Fitting..
Epoch 1/98
16000/16000 - 380s - loss: 0.1883 - mae: 0.5035 - val_loss: 0.0999 - val_mae: 0.3376
Epoch 2/98
16000/16000 - 371s - loss: 0.0614 - mae: 0.2482 - val_loss: 0.0480 - val_mae: 0.2139
Epoch 3/98
16000/16000 - 371s - loss: 0.0290 - mae: 0.1586 - val_loss: 0.0242 - val_mae: 0.1425
Epoch 4/98
16000/16000 - 371s - loss: 0.0160 - mae: 0.1124 - val_loss: 0.0144 - val_mae: 0.1103
Epoch 5/98
16000/16000 - 371s - loss: 0.0098 - mae: 0.0881 - val_loss: 0.0093 - val_mae: 0.0896
Epoch 6/98
16000/16000 - 371s - loss: 0.0062 - mae: 0.0707 - val_loss: 0.0065 - val_mae: 0.0737
Epoch 7/98
16000/16000 - 371s - loss: 0.0040 - mae: 0.0569 - val_loss: 0.0048 - val_mae: 0.0621
Epoch 8/98
16000/16000 - 371s - loss: 0.0027 - mae: 0.0463 - val_loss: 0.0036 - val_mae: 0.0526
Epoch 9/98
16000/16000 - 364s - loss: 0.0019 - mae: 0.0384 - val_loss: 0.0029 - val_mae: 0.0456
Epoch 10/98
16000/16000 - 362s - loss: 0.0013 - mae: 0.0325 - val_loss: 0.0024 - val_mae: 0.0402
Epoch 11/98
16000/16000 - 362s - loss: 9.5646e-04 - mae: 0.0279 - val_loss: 0.0021 - val_mae: 0.0362
Epoch 12/98
16000/16000 - 371s - loss: 6.9920e-04 - mae: 0.0242 - val_loss: 0.0019 - val_mae: 0.0332
Epoch 13/98
16000/16000 - 371s - loss: 5.1982e-04 - mae: 0.0214 - val_loss: 0.0017 - val_mae: 0.0309
Epoch 14/98
16000/16000 - 371s - loss: 3.9404e-04 - mae: 0.0190 - val_loss: 0.0016 - val_mae: 0.0290
Epoch 15/98
16000/16000 - 372s - loss: 3.0384e-04 - mae: 0.0171 - val_loss: 0.0015 - val_mae: 0.0274
Epoch 16/98
16000/16000 - 371s - loss: 2.3820e-04 - mae: 0.0155 - val_loss: 0.0014 - val_mae: 0.0260
Epoch 17/98
16000/16000 - 371s - loss: 1.9123e-04 - mae: 0.0141 - val_loss: 0.0014 - val_mae: 0.0249
Epoch 18/98
16000/16000 - 372s - loss: 1.5727e-04 - mae: 0.0130 - val_loss: 0.0014 - val_mae: 0.0242
Epoch 19/98
16000/16000 - 371s - loss: 1.3228e-04 - mae: 0.0120 - val_loss: 0.0013 - val_mae: 0.0236
Epoch 20/98
16000/16000 - 371s - loss: 1.1353e-04 - mae: 0.0112 - val_loss: 0.0013 - val_mae: 0.0231
Epoch 21/98
16000/16000 - 371s - loss: 9.9308e-05 - mae: 0.0105 - val_loss: 0.0013 - val_mae: 0.0224
Epoch 22/98
16000/16000 - 372s - loss: 8.8291e-05 - mae: 0.0100 - val_loss: 0.0013 - val_mae: 0.0218
Epoch 23/98
16000/16000 - 371s - loss: 7.9591e-05 - mae: 0.0095 - val_loss: 0.0013 - val_mae: 0.0212
Epoch 24/98
16000/16000 - 371s - loss: 7.2523e-05 - mae: 0.0091 - val_loss: 0.0013 - val_mae: 0.0207
Epoch 25/98
16000/16000 - 371s - loss: 6.6670e-05 - mae: 0.0087 - val_loss: 0.0012 - val_mae: 0.0202
Epoch 26/98
16000/16000 - 372s - loss: 6.1706e-05 - mae: 0.0084 - val_loss: 0.0012 - val_mae: 0.0197
Epoch 27/98
16000/16000 - 371s - loss: 5.7489e-05 - mae: 0.0081 - val_loss: 0.0012 - val_mae: 0.0193
Epoch 28/98
16000/16000 - 371s - loss: 5.3842e-05 - mae: 0.0079 - val_loss: 0.0012 - val_mae: 0.0189
Epoch 29/98
16000/16000 - 371s - loss: 5.0646e-05 - mae: 0.0076 - val_loss: 0.0012 - val_mae: 0.0185
Epoch 30/98
16000/16000 - 371s - loss: 4.7827e-05 - mae: 0.0074 - val_loss: 0.0012 - val_mae: 0.0183
Epoch 31/98
16000/16000 - 371s - loss: 4.5306e-05 - mae: 0.0072 - val_loss: 0.0012 - val_mae: 0.0180
Epoch 32/98
16000/16000 - 371s - loss: 4.3037e-05 - mae: 0.0070 - val_loss: 0.0012 - val_mae: 0.0178
Epoch 33/98
16000/16000 - 371s - loss: 4.0974e-05 - mae: 0.0069 - val_loss: 0.0012 - val_mae: 0.0176
Epoch 34/98
16000/16000 - 372s - loss: 3.9091e-05 - mae: 0.0067 - val_loss: 0.0012 - val_mae: 0.0174
Epoch 35/98
16000/16000 - 372s - loss: 3.7360e-05 - mae: 0.0065 - val_loss: 0.0012 - val_mae: 0.0172
Epoch 36/98
16000/16000 - 371s - loss: 3.5781e-05 - mae: 0.0064 - val_loss: 0.0012 - val_mae: 0.0171
Epoch 37/98
16000/16000 - 371s - loss: 3.4337e-05 - mae: 0.0063 - val_loss: 0.0012 - val_mae: 0.0169
Epoch 38/98
16000/16000 - 371s - loss: 3.3008e-05 - mae: 0.0062 - val_loss: 0.0012 - val_mae: 0.0168
Epoch 39/98
16000/16000 - 371s - loss: 3.1780e-05 - mae: 0.0060 - val_loss: 0.0012 - val_mae: 0.0167
Epoch 40/98
16000/16000 - 371s - loss: 3.0643e-05 - mae: 0.0059 - val_loss: 0.0012 - val_mae: 0.0166
Epoch 41/98
16000/16000 - 372s - loss: 2.9581e-05 - mae: 0.0058 - val_loss: 0.0012 - val_mae: 0.0165
Epoch 42/98
16000/16000 - 371s - loss: 2.8592e-05 - mae: 0.0057 - val_loss: 0.0012 - val_mae: 0.0164
Epoch 43/98
16000/16000 - 372s - loss: 2.7667e-05 - mae: 0.0056 - val_loss: 0.0012 - val_mae: 0.0163
Epoch 44/98
16000/16000 - 371s - loss: 2.6801e-05 - mae: 0.0055 - val_loss: 0.0011 - val_mae: 0.0163
Epoch 45/98
16000/16000 - 372s - loss: 2.5985e-05 - mae: 0.0055 - val_loss: 0.0011 - val_mae: 0.0162
Epoch 46/98
16000/16000 - 371s - loss: 2.5214e-05 - mae: 0.0054 - val_loss: 0.0011 - val_mae: 0.0161
Epoch 47/98
16000/16000 - 372s - loss: 2.4486e-05 - mae: 0.0053 - val_loss: 0.0011 - val_mae: 0.0160
Epoch 48/98
16000/16000 - 371s - loss: 2.3798e-05 - mae: 0.0052 - val_loss: 0.0011 - val_mae: 0.0160
Epoch 49/98
16000/16000 - 371s - loss: 2.3146e-05 - mae: 0.0051 - val_loss: 0.0011 - val_mae: 0.0159
Epoch 50/98
16000/16000 - 371s - loss: 2.2530e-05 - mae: 0.0051 - val_loss: 0.0011 - val_mae: 0.0158
Epoch 51/98
16000/16000 - 371s - loss: 2.1949e-05 - mae: 0.0050 - val_loss: 0.0011 - val_mae: 0.0157
Epoch 52/98
16000/16000 - 372s - loss: 2.1395e-05 - mae: 0.0049 - val_loss: 0.0011 - val_mae: 0.0157
Epoch 53/98
16000/16000 - 371s - loss: 2.0864e-05 - mae: 0.0049 - val_loss: 0.0011 - val_mae: 0.0156
Epoch 54/98
16000/16000 - 371s - loss: 2.0358e-05 - mae: 0.0048 - val_loss: 0.0011 - val_mae: 0.0155
Epoch 55/98
16000/16000 - 372s - loss: 1.9876e-05 - mae: 0.0048 - val_loss: 0.0011 - val_mae: 0.0154
Epoch 56/98
16000/16000 - 371s - loss: 1.9417e-05 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0153
Epoch 57/98
16000/16000 - 372s - loss: 1.8976e-05 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0152
Epoch 58/98
16000/16000 - 371s - loss: 1.8554e-05 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0152
Epoch 59/98
16000/16000 - 372s - loss: 1.8151e-05 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0151
Epoch 60/98
16000/16000 - 371s - loss: 1.7765e-05 - mae: 0.0045 - val_loss: 0.0011 - val_mae: 0.0150
Epoch 61/98
16000/16000 - 371s - loss: 1.7396e-05 - mae: 0.0045 - val_loss: 0.0011 - val_mae: 0.0149
Epoch 62/98
16000/16000 - 371s - loss: 1.7042e-05 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0149
Epoch 63/98
16000/16000 - 371s - loss: 1.6702e-05 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0148
Epoch 64/98
16000/16000 - 371s - loss: 1.6373e-05 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0147
Epoch 65/98
16000/16000 - 371s - loss: 1.6056e-05 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0147
Epoch 66/98
16000/16000 - 372s - loss: 1.5753e-05 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0146
Epoch 67/98
16000/16000 - 372s - loss: 1.5460e-05 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0146
Epoch 68/98
16000/16000 - 372s - loss: 1.5176e-05 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0145
Epoch 69/98
16000/16000 - 371s - loss: 1.4905e-05 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0145
Epoch 70/98
16000/16000 - 371s - loss: 1.4643e-05 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0144
Epoch 71/98
16000/16000 - 372s - loss: 1.4388e-05 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0144
Epoch 72/98
16000/16000 - 371s - loss: 1.4144e-05 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0143
Epoch 73/98
16000/16000 - 372s - loss: 1.3907e-05 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0143
Epoch 74/98
16000/16000 - 371s - loss: 1.3676e-05 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0142
Epoch 75/98
16000/16000 - 372s - loss: 1.3453e-05 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0142
Epoch 76/98
16000/16000 - 372s - loss: 1.3236e-05 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0142
Epoch 77/98
16000/16000 - 372s - loss: 1.3026e-05 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0142
Epoch 78/98
16000/16000 - 371s - loss: 1.2821e-05 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0141
Epoch 79/98
16000/16000 - 372s - loss: 1.2622e-05 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0141
Epoch 80/98
16000/16000 - 372s - loss: 1.2431e-05 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0141
Epoch 81/98
16000/16000 - 372s - loss: 1.2243e-05 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0141
Epoch 82/98
16000/16000 - 371s - loss: 1.2061e-05 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0141
Epoch 83/98
16000/16000 - 372s - loss: 1.1884e-05 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0141
Epoch 84/98
16000/16000 - 371s - loss: 1.1712e-05 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0140
Epoch 85/98
16000/16000 - 372s - loss: 1.1544e-05 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0140
Epoch 86/98
16000/16000 - 371s - loss: 1.1382e-05 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0140
Epoch 87/98
16000/16000 - 371s - loss: 1.1225e-05 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0140
Epoch 88/98
16000/16000 - 371s - loss: 1.1071e-05 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0140
Epoch 89/98
16000/16000 - 372s - loss: 1.0920e-05 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0139
Epoch 90/98
16000/16000 - 372s - loss: 1.0774e-05 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0139
Epoch 91/98
16000/16000 - 372s - loss: 1.0631e-05 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0139
Epoch 92/98
16000/16000 - 372s - loss: 1.0493e-05 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0139
Epoch 93/98
16000/16000 - 371s - loss: 1.0358e-05 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0139
Epoch 94/98
16000/16000 - 371s - loss: 1.0225e-05 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0138
Epoch 95/98
16000/16000 - 372s - loss: 1.0095e-05 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0138
Epoch 96/98
16000/16000 - 371s - loss: 9.9682e-06 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0138
Epoch 97/98
16000/16000 - 372s - loss: 9.8444e-06 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0137
Epoch 98/98
16000/16000 - 371s - loss: 9.7243e-06 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0137
Saving training information..
Saving model weights to process/trained_model_weights/weights..

Done.
