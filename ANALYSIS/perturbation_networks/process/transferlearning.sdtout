Writing FEP-Space results..
Found 2286 SMILES references; unable to find 17.
Written file: process/fepspace_smiles_per_sem.csv
Computing FPs for base models..
100%|█████████████████████████████████████████████████████████████████████████| 2286/2286 [07:03<00:00,  5.40it/s]
Training base models:
apfp..
ecfp..
props..
Retrieving FEP atom-mappings..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 0

Generating graphs from SMILES..

Setting up training set.
Size: 1828

Setting up validation set.
Size: 458

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing (MessagePassing (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding (PartitionPad (None, None, 64)     0           message_passing[0][0]            
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing[1][0]            
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking (Masking)               (None, None, 64)     0           partition_padding[0][0]          
                                                                 partition_padding[1][0]          
__________________________________________________________________________________________________
transformer_encoder (Transforme (None, None, 64)     199040      masking[0][0]                    
                                                                 masking[1][0]                    
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 64)           0           transformer_encoder[0][0]        
                                                                 transformer_encoder[1][0]        
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 512)          33280       global_average_pooling1d[0][0]   
                                                                 global_average_pooling1d[1][0]   
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 10)           110         dense_4[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 450)          230850      dense_2[0][0]                    
                                                                 dense_2[1][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 5)            55          dense_5[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 905)          0           dense_3[0][0]                    
                                                                 dense_3[1][0]                    
                                                                 dense_6[0][0]                    
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 700)          634200      concatenate[0][0]                
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 560)          392560      dense_7[0][0]                    
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 373)          209253      dense_11[0][0]                   
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 187)          69938       dense_12[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1)            188         dense_13[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
36/36 - 7s - loss: 0.2902 - mae: 0.5980 - val_loss: 0.2094 - val_mae: 0.5283
Epoch 2/5000
36/36 - 1s - loss: 0.1588 - mae: 0.4059 - val_loss: 0.2026 - val_mae: 0.5138
Epoch 3/5000
36/36 - 1s - loss: 0.1554 - mae: 0.3989 - val_loss: 0.1960 - val_mae: 0.4918
Epoch 4/5000
36/36 - 1s - loss: 0.1539 - mae: 0.3952 - val_loss: 0.1965 - val_mae: 0.4959
Epoch 5/5000
36/36 - 1s - loss: 0.1528 - mae: 0.3933 - val_loss: 0.1937 - val_mae: 0.4859
Epoch 6/5000
36/36 - 1s - loss: 0.1514 - mae: 0.3905 - val_loss: 0.1895 - val_mae: 0.4714
Epoch 7/5000
36/36 - 1s - loss: 0.1503 - mae: 0.3884 - val_loss: 0.1887 - val_mae: 0.4654
Epoch 8/5000
36/36 - 1s - loss: 0.1499 - mae: 0.3869 - val_loss: 0.1848 - val_mae: 0.4514
Epoch 9/5000
36/36 - 1s - loss: 0.1517 - mae: 0.3896 - val_loss: 0.1944 - val_mae: 0.4933
Epoch 10/5000
36/36 - 1s - loss: 0.1490 - mae: 0.3847 - val_loss: 0.1844 - val_mae: 0.4570
Epoch 11/5000
36/36 - 1s - loss: 0.1463 - mae: 0.3792 - val_loss: 0.1838 - val_mae: 0.4537
Epoch 12/5000
36/36 - 1s - loss: 0.1475 - mae: 0.3812 - val_loss: 0.1813 - val_mae: 0.4342
Epoch 13/5000
36/36 - 1s - loss: 0.1485 - mae: 0.3812 - val_loss: 0.1784 - val_mae: 0.4138
Epoch 14/5000
36/36 - 1s - loss: 0.1446 - mae: 0.3731 - val_loss: 0.1783 - val_mae: 0.4235
Epoch 15/5000
36/36 - 1s - loss: 0.1450 - mae: 0.3747 - val_loss: 0.1775 - val_mae: 0.4136
Epoch 16/5000
36/36 - 1s - loss: 0.1425 - mae: 0.3683 - val_loss: 0.1767 - val_mae: 0.4171
Epoch 17/5000
36/36 - 1s - loss: 0.1429 - mae: 0.3693 - val_loss: 0.1763 - val_mae: 0.4081
Epoch 18/5000
36/36 - 1s - loss: 0.1414 - mae: 0.3660 - val_loss: 0.1756 - val_mae: 0.4122
Epoch 19/5000
36/36 - 1s - loss: 0.1407 - mae: 0.3640 - val_loss: 0.1745 - val_mae: 0.4073
Epoch 20/5000
36/36 - 1s - loss: 0.1402 - mae: 0.3630 - val_loss: 0.1740 - val_mae: 0.4107
Epoch 21/5000
36/36 - 1s - loss: 0.1401 - mae: 0.3635 - val_loss: 0.1727 - val_mae: 0.4003
Epoch 22/5000
36/36 - 1s - loss: 0.1382 - mae: 0.3580 - val_loss: 0.1741 - val_mae: 0.4116
Epoch 23/5000
36/36 - 1s - loss: 0.1389 - mae: 0.3606 - val_loss: 0.1706 - val_mae: 0.3987
Epoch 24/5000
36/36 - 1s - loss: 0.1377 - mae: 0.3585 - val_loss: 0.1724 - val_mae: 0.4081
Epoch 25/5000
36/36 - 1s - loss: 0.1374 - mae: 0.3582 - val_loss: 0.1716 - val_mae: 0.4102
Epoch 26/5000
36/36 - 1s - loss: 0.1373 - mae: 0.3575 - val_loss: 0.1735 - val_mae: 0.4266
Epoch 27/5000
36/36 - 1s - loss: 0.1373 - mae: 0.3566 - val_loss: 0.1781 - val_mae: 0.4503
Epoch 28/5000
36/36 - 1s - loss: 0.1369 - mae: 0.3562 - val_loss: 0.1702 - val_mae: 0.4097
Epoch 29/5000
36/36 - 1s - loss: 0.1372 - mae: 0.3553 - val_loss: 0.1761 - val_mae: 0.4400
Epoch 30/5000
36/36 - 1s - loss: 0.1373 - mae: 0.3564 - val_loss: 0.1719 - val_mae: 0.4236
Epoch 31/5000
36/36 - 1s - loss: 0.1389 - mae: 0.3593 - val_loss: 0.1731 - val_mae: 0.4295
Epoch 32/5000
36/36 - 1s - loss: 0.1378 - mae: 0.3565 - val_loss: 0.1735 - val_mae: 0.4290
Epoch 33/5000
36/36 - 1s - loss: 0.1366 - mae: 0.3551 - val_loss: 0.1799 - val_mae: 0.4538
Epoch 34/5000
36/36 - 1s - loss: 0.1352 - mae: 0.3514 - val_loss: 0.1715 - val_mae: 0.4236
Epoch 35/5000
36/36 - 1s - loss: 0.1337 - mae: 0.3459 - val_loss: 0.1728 - val_mae: 0.4247
Epoch 36/5000
36/36 - 1s - loss: 0.1344 - mae: 0.3482 - val_loss: 0.1655 - val_mae: 0.3790
Epoch 37/5000
36/36 - 1s - loss: 0.1330 - mae: 0.3438 - val_loss: 0.1681 - val_mae: 0.4086
Epoch 38/5000
36/36 - 1s - loss: 0.1341 - mae: 0.3483 - val_loss: 0.1705 - val_mae: 0.4244
Epoch 39/5000
36/36 - 1s - loss: 0.1336 - mae: 0.3457 - val_loss: 0.1798 - val_mae: 0.4541
Epoch 40/5000
36/36 - 1s - loss: 0.1353 - mae: 0.3515 - val_loss: 0.1791 - val_mae: 0.4547
Epoch 41/5000
36/36 - 1s - loss: 0.1342 - mae: 0.3490 - val_loss: 0.1772 - val_mae: 0.4454
Epoch 42/5000
36/36 - 1s - loss: 0.1336 - mae: 0.3470 - val_loss: 0.1698 - val_mae: 0.4162
Epoch 43/5000
36/36 - 1s - loss: 0.1321 - mae: 0.3442 - val_loss: 0.1753 - val_mae: 0.4407
Epoch 44/5000
36/36 - 1s - loss: 0.1343 - mae: 0.3485 - val_loss: 0.1795 - val_mae: 0.4501
Epoch 45/5000
36/36 - 1s - loss: 0.1338 - mae: 0.3474 - val_loss: 0.1788 - val_mae: 0.4459
Epoch 46/5000
36/36 - 1s - loss: 0.1334 - mae: 0.3442 - val_loss: 0.1965 - val_mae: 0.4961
Epoch 47/5000
36/36 - 1s - loss: 0.1373 - mae: 0.3550 - val_loss: 0.1688 - val_mae: 0.4155
Epoch 48/5000
36/36 - 1s - loss: 0.1282 - mae: 0.3316 - val_loss: 0.1695 - val_mae: 0.4217
Epoch 49/5000
36/36 - 1s - loss: 0.1286 - mae: 0.3348 - val_loss: 0.1753 - val_mae: 0.4345
Epoch 50/5000
36/36 - 1s - loss: 0.1327 - mae: 0.3441 - val_loss: 0.1828 - val_mae: 0.4638
Epoch 51/5000
36/36 - 1s - loss: 0.1322 - mae: 0.3408 - val_loss: 0.1727 - val_mae: 0.4320
Epoch 52/5000
36/36 - 1s - loss: 0.1284 - mae: 0.3338 - val_loss: 0.1813 - val_mae: 0.4549
Epoch 53/5000
36/36 - 1s - loss: 0.1306 - mae: 0.3380 - val_loss: 0.1815 - val_mae: 0.4533
Epoch 54/5000
36/36 - 1s - loss: 0.1315 - mae: 0.3403 - val_loss: 0.1656 - val_mae: 0.3958
Epoch 55/5000
36/36 - 1s - loss: 0.1253 - mae: 0.3249 - val_loss: 0.1728 - val_mae: 0.4305
Epoch 56/5000
36/36 - 1s - loss: 0.1288 - mae: 0.3357 - val_loss: 0.1839 - val_mae: 0.4583
Epoch 57/5000
36/36 - 1s - loss: 0.1326 - mae: 0.3425 - val_loss: 0.1648 - val_mae: 0.3934
Epoch 58/5000
36/36 - 1s - loss: 0.1250 - mae: 0.3257 - val_loss: 0.1730 - val_mae: 0.4286
Epoch 59/5000
36/36 - 1s - loss: 0.1284 - mae: 0.3332 - val_loss: 0.1899 - val_mae: 0.4704
Epoch 60/5000
36/36 - 1s - loss: 0.1313 - mae: 0.3396 - val_loss: 0.1713 - val_mae: 0.4208
Epoch 61/5000
36/36 - 1s - loss: 0.1260 - mae: 0.3280 - val_loss: 0.1808 - val_mae: 0.4504
Epoch 62/5000
36/36 - 1s - loss: 0.1299 - mae: 0.3364 - val_loss: 0.1667 - val_mae: 0.3986
Epoch 63/5000
36/36 - 1s - loss: 0.1242 - mae: 0.3229 - val_loss: 0.1768 - val_mae: 0.4377
Epoch 64/5000
36/36 - 1s - loss: 0.1281 - mae: 0.3337 - val_loss: 0.1771 - val_mae: 0.4369
Epoch 65/5000
36/36 - 1s - loss: 0.1284 - mae: 0.3319 - val_loss: 0.1748 - val_mae: 0.4343
Epoch 66/5000
36/36 - 1s - loss: 0.1259 - mae: 0.3269 - val_loss: 0.1815 - val_mae: 0.4521
Epoch 67/5000
36/36 - 1s - loss: 0.1282 - mae: 0.3315 - val_loss: 0.1635 - val_mae: 0.3880
Epoch 68/5000
36/36 - 1s - loss: 0.1226 - mae: 0.3199 - val_loss: 0.1733 - val_mae: 0.4234
Epoch 69/5000
36/36 - 1s - loss: 0.1260 - mae: 0.3277 - val_loss: 0.1820 - val_mae: 0.4509
Epoch 70/5000
36/36 - 1s - loss: 0.1293 - mae: 0.3350 - val_loss: 0.1643 - val_mae: 0.3908
Epoch 71/5000
36/36 - 1s - loss: 0.1222 - mae: 0.3186 - val_loss: 0.1755 - val_mae: 0.4288
Epoch 72/5000
36/36 - 1s - loss: 0.1261 - mae: 0.3284 - val_loss: 0.1828 - val_mae: 0.4484
Epoch 73/5000
36/36 - 1s - loss: 0.1271 - mae: 0.3295 - val_loss: 0.1777 - val_mae: 0.4363
Epoch 74/5000
36/36 - 1s - loss: 0.1261 - mae: 0.3268 - val_loss: 0.1727 - val_mae: 0.4213
Epoch 75/5000
36/36 - 1s - loss: 0.1241 - mae: 0.3215 - val_loss: 0.1757 - val_mae: 0.4350
Epoch 76/5000
36/36 - 1s - loss: 0.1242 - mae: 0.3213 - val_loss: 0.1740 - val_mae: 0.4234
Epoch 77/5000
36/36 - 1s - loss: 0.1233 - mae: 0.3192 - val_loss: 0.1755 - val_mae: 0.4289
Epoch 78/5000
36/36 - 1s - loss: 0.1224 - mae: 0.3175 - val_loss: 0.1792 - val_mae: 0.4382
Epoch 79/5000
36/36 - 1s - loss: 0.1246 - mae: 0.3220 - val_loss: 0.1715 - val_mae: 0.4154
Epoch 80/5000
36/36 - 1s - loss: 0.1225 - mae: 0.3178 - val_loss: 0.1760 - val_mae: 0.4309
Epoch 81/5000
36/36 - 1s - loss: 0.1216 - mae: 0.3156 - val_loss: 0.1768 - val_mae: 0.4316
Epoch 82/5000
36/36 - 1s - loss: 0.1219 - mae: 0.3160 - val_loss: 0.1750 - val_mae: 0.4232
Epoch 83/5000
36/36 - 1s - loss: 0.1217 - mae: 0.3169 - val_loss: 0.1820 - val_mae: 0.4421
Epoch 84/5000
36/36 - 1s - loss: 0.1227 - mae: 0.3184 - val_loss: 0.1783 - val_mae: 0.4319
Epoch 85/5000
36/36 - 1s - loss: 0.1235 - mae: 0.3205 - val_loss: 0.1687 - val_mae: 0.3980
Epoch 86/5000
36/36 - 1s - loss: 0.1196 - mae: 0.3122 - val_loss: 0.1789 - val_mae: 0.4316
Epoch 87/5000
36/36 - 1s - loss: 0.1220 - mae: 0.3175 - val_loss: 0.1815 - val_mae: 0.4412
Epoch 88/5000
36/36 - 1s - loss: 0.1237 - mae: 0.3211 - val_loss: 0.1657 - val_mae: 0.3853
Epoch 89/5000
36/36 - 1s - loss: 0.1188 - mae: 0.3116 - val_loss: 0.1798 - val_mae: 0.4317
Epoch 90/5000
36/36 - 1s - loss: 0.1227 - mae: 0.3200 - val_loss: 0.1766 - val_mae: 0.4323
Epoch 91/5000
36/36 - 1s - loss: 0.1233 - mae: 0.3225 - val_loss: 0.1650 - val_mae: 0.3779
Epoch 92/5000
36/36 - 1s - loss: 0.1186 - mae: 0.3108 - val_loss: 0.1749 - val_mae: 0.4121
Epoch 93/5000
36/36 - 1s - loss: 0.1220 - mae: 0.3174 - val_loss: 0.1792 - val_mae: 0.4305
Epoch 94/5000
36/36 - 1s - loss: 0.1231 - mae: 0.3212 - val_loss: 0.1653 - val_mae: 0.3835
Epoch 95/5000
36/36 - 1s - loss: 0.1187 - mae: 0.3104 - val_loss: 0.1771 - val_mae: 0.4283
Epoch 96/5000
36/36 - 1s - loss: 0.1215 - mae: 0.3189 - val_loss: 0.1716 - val_mae: 0.4019
Epoch 97/5000
36/36 - 1s - loss: 0.1204 - mae: 0.3151 - val_loss: 0.1828 - val_mae: 0.4335
Epoch 98/5000
36/36 - 1s - loss: 0.1194 - mae: 0.3128 - val_loss: 0.1851 - val_mae: 0.4399
Epoch 99/5000
36/36 - 1s - loss: 0.1209 - mae: 0.3155 - val_loss: 0.1884 - val_mae: 0.4615
Epoch 100/5000
36/36 - 1s - loss: 0.1246 - mae: 0.3247 - val_loss: 0.1626 - val_mae: 0.3670
Epoch 101/5000
36/36 - 1s - loss: 0.1169 - mae: 0.3073 - val_loss: 0.1801 - val_mae: 0.4337
Epoch 102/5000
36/36 - 1s - loss: 0.1216 - mae: 0.3168 - val_loss: 0.1745 - val_mae: 0.4181
Epoch 103/5000
36/36 - 1s - loss: 0.1198 - mae: 0.3131 - val_loss: 0.1719 - val_mae: 0.4096
Epoch 104/5000
36/36 - 1s - loss: 0.1182 - mae: 0.3095 - val_loss: 0.1703 - val_mae: 0.4093
Epoch 105/5000
36/36 - 1s - loss: 0.1164 - mae: 0.3049 - val_loss: 0.1728 - val_mae: 0.4114
Epoch 106/5000
36/36 - 1s - loss: 0.1175 - mae: 0.3068 - val_loss: 0.1753 - val_mae: 0.4226
Epoch 107/5000
36/36 - 1s - loss: 0.1177 - mae: 0.3089 - val_loss: 0.1767 - val_mae: 0.4214
Epoch 108/5000
36/36 - 1s - loss: 0.1177 - mae: 0.3075 - val_loss: 0.1725 - val_mae: 0.4108
Epoch 109/5000
36/36 - 1s - loss: 0.1162 - mae: 0.3040 - val_loss: 0.1773 - val_mae: 0.4272
Epoch 110/5000
36/36 - 1s - loss: 0.1169 - mae: 0.3048 - val_loss: 0.1738 - val_mae: 0.4173
Epoch 111/5000
36/36 - 1s - loss: 0.1170 - mae: 0.3059 - val_loss: 0.1781 - val_mae: 0.4280
Epoch 112/5000
36/36 - 1s - loss: 0.1183 - mae: 0.3088 - val_loss: 0.1678 - val_mae: 0.3946
Epoch 113/5000
36/36 - 1s - loss: 0.1168 - mae: 0.3068 - val_loss: 0.1719 - val_mae: 0.4075
Epoch 114/5000
36/36 - 1s - loss: 0.1161 - mae: 0.3049 - val_loss: 0.1730 - val_mae: 0.4072
Epoch 115/5000
36/36 - 1s - loss: 0.1164 - mae: 0.3048 - val_loss: 0.1677 - val_mae: 0.3896
Epoch 116/5000
36/36 - 1s - loss: 0.1140 - mae: 0.3004 - val_loss: 0.1696 - val_mae: 0.3943
Epoch 117/5000
36/36 - 1s - loss: 0.1156 - mae: 0.3031 - val_loss: 0.1687 - val_mae: 0.3913
Epoch 118/5000
36/36 - 1s - loss: 0.1146 - mae: 0.3012 - val_loss: 0.1707 - val_mae: 0.4002
Epoch 119/5000
36/36 - 1s - loss: 0.1149 - mae: 0.3017 - val_loss: 0.1738 - val_mae: 0.4072
Epoch 120/5000
36/36 - 1s - loss: 0.1196 - mae: 0.3124 - val_loss: 0.1626 - val_mae: 0.3638
Epoch 121/5000
36/36 - 1s - loss: 0.1170 - mae: 0.3077 - val_loss: 0.1653 - val_mae: 0.3874
Epoch 122/5000
36/36 - 1s - loss: 0.1156 - mae: 0.3033 - val_loss: 0.1781 - val_mae: 0.4254
Epoch 123/5000
36/36 - 1s - loss: 0.1181 - mae: 0.3101 - val_loss: 0.1676 - val_mae: 0.3884
Epoch 124/5000
36/36 - 1s - loss: 0.1170 - mae: 0.3063 - val_loss: 0.1601 - val_mae: 0.3631
Epoch 125/5000
36/36 - 1s - loss: 0.1198 - mae: 0.3129 - val_loss: 0.1599 - val_mae: 0.3623
Epoch 126/5000
36/36 - 1s - loss: 0.1161 - mae: 0.3037 - val_loss: 0.1618 - val_mae: 0.3747
Epoch 127/5000
36/36 - 1s - loss: 0.1146 - mae: 0.3016 - val_loss: 0.1676 - val_mae: 0.3928
Epoch 128/5000
36/36 - 1s - loss: 0.1152 - mae: 0.3035 - val_loss: 0.1647 - val_mae: 0.3794
Epoch 129/5000
36/36 - 1s - loss: 0.1165 - mae: 0.3049 - val_loss: 0.1596 - val_mae: 0.3617
Epoch 130/5000
36/36 - 1s - loss: 0.1161 - mae: 0.3067 - val_loss: 0.1584 - val_mae: 0.3545
Epoch 131/5000
36/36 - 1s - loss: 0.1181 - mae: 0.3098 - val_loss: 0.1618 - val_mae: 0.3558
Epoch 132/5000
36/36 - 1s - loss: 0.1140 - mae: 0.3027 - val_loss: 0.1645 - val_mae: 0.3840
Epoch 133/5000
36/36 - 1s - loss: 0.1148 - mae: 0.3031 - val_loss: 0.1650 - val_mae: 0.3894
Epoch 134/5000
36/36 - 1s - loss: 0.1151 - mae: 0.3029 - val_loss: 0.1640 - val_mae: 0.3795
Epoch 135/5000
36/36 - 1s - loss: 0.1156 - mae: 0.3039 - val_loss: 0.1653 - val_mae: 0.3920
Epoch 136/5000
36/36 - 1s - loss: 0.1153 - mae: 0.3052 - val_loss: 0.1695 - val_mae: 0.4039
Epoch 137/5000
36/36 - 1s - loss: 0.1154 - mae: 0.3037 - val_loss: 0.1688 - val_mae: 0.3928
Epoch 138/5000
36/36 - 1s - loss: 0.1161 - mae: 0.3074 - val_loss: 0.1627 - val_mae: 0.3818
Epoch 139/5000
36/36 - 1s - loss: 0.1151 - mae: 0.3050 - val_loss: 0.1629 - val_mae: 0.3675
Epoch 140/5000
36/36 - 1s - loss: 0.1147 - mae: 0.3016 - val_loss: 0.1700 - val_mae: 0.3919
Epoch 141/5000
36/36 - 1s - loss: 0.1156 - mae: 0.3047 - val_loss: 0.1642 - val_mae: 0.3673
Epoch 142/5000
36/36 - 1s - loss: 0.1186 - mae: 0.3113 - val_loss: 0.1677 - val_mae: 0.3659
Epoch 143/5000
36/36 - 1s - loss: 0.1155 - mae: 0.3083 - val_loss: 0.1682 - val_mae: 0.3894
Epoch 144/5000
36/36 - 1s - loss: 0.1203 - mae: 0.3130 - val_loss: 0.1629 - val_mae: 0.3636
Epoch 145/5000
36/36 - 1s - loss: 0.1133 - mae: 0.3018 - val_loss: 0.1631 - val_mae: 0.3789
Epoch 146/5000
36/36 - 1s - loss: 0.1127 - mae: 0.2973 - val_loss: 0.1623 - val_mae: 0.3725
Epoch 147/5000
36/36 - 1s - loss: 0.1162 - mae: 0.3067 - val_loss: 0.1618 - val_mae: 0.3563
Epoch 148/5000
36/36 - 1s - loss: 0.1121 - mae: 0.2978 - val_loss: 0.1644 - val_mae: 0.3824
Epoch 149/5000
36/36 - 1s - loss: 0.1173 - mae: 0.3082 - val_loss: 0.1696 - val_mae: 0.3827
Epoch 150/5000
36/36 - 1s - loss: 0.1153 - mae: 0.3083 - val_loss: 0.1712 - val_mae: 0.4000
Epoch 151/5000
36/36 - 1s - loss: 0.1133 - mae: 0.2998 - val_loss: 0.1663 - val_mae: 0.3883
Epoch 152/5000
36/36 - 1s - loss: 0.1102 - mae: 0.2902 - val_loss: 0.1639 - val_mae: 0.3806
Epoch 153/5000
36/36 - 1s - loss: 0.1092 - mae: 0.2882 - val_loss: 0.1658 - val_mae: 0.3856
Epoch 154/5000
36/36 - 1s - loss: 0.1087 - mae: 0.2862 - val_loss: 0.1620 - val_mae: 0.3735
Epoch 155/5000
36/36 - 1s - loss: 0.1085 - mae: 0.2862 - val_loss: 0.1616 - val_mae: 0.3659
Epoch 156/5000
36/36 - 1s - loss: 0.1079 - mae: 0.2831 - val_loss: 0.1646 - val_mae: 0.3815
Epoch 157/5000
36/36 - 1s - loss: 0.1094 - mae: 0.2884 - val_loss: 0.1702 - val_mae: 0.4022
Epoch 158/5000
36/36 - 1s - loss: 0.1121 - mae: 0.2958 - val_loss: 0.1617 - val_mae: 0.3660
Epoch 159/5000
36/36 - 1s - loss: 0.1107 - mae: 0.2924 - val_loss: 0.1670 - val_mae: 0.3872
Epoch 160/5000
36/36 - 1s - loss: 0.1091 - mae: 0.2894 - val_loss: 0.1694 - val_mae: 0.3852
Epoch 161/5000
36/36 - 1s - loss: 0.1083 - mae: 0.2852 - val_loss: 0.1583 - val_mae: 0.3533
Epoch 162/5000
36/36 - 1s - loss: 0.1116 - mae: 0.2956 - val_loss: 0.1631 - val_mae: 0.3801
Epoch 163/5000
36/36 - 1s - loss: 0.1102 - mae: 0.2923 - val_loss: 0.1655 - val_mae: 0.3814
Epoch 164/5000
36/36 - 1s - loss: 0.1059 - mae: 0.2810 - val_loss: 0.1574 - val_mae: 0.3477
Epoch 165/5000
36/36 - 1s - loss: 0.1146 - mae: 0.3003 - val_loss: 0.1618 - val_mae: 0.3523
Epoch 166/5000
36/36 - 1s - loss: 0.1178 - mae: 0.3095 - val_loss: 0.1666 - val_mae: 0.3632
Epoch 167/5000
36/36 - 1s - loss: 0.1124 - mae: 0.2992 - val_loss: 0.1618 - val_mae: 0.3535
Epoch 168/5000
36/36 - 1s - loss: 0.1098 - mae: 0.2906 - val_loss: 0.1569 - val_mae: 0.3591
Epoch 169/5000
36/36 - 1s - loss: 0.1076 - mae: 0.2843 - val_loss: 0.1600 - val_mae: 0.3559
Epoch 170/5000
36/36 - 1s - loss: 0.1092 - mae: 0.2875 - val_loss: 0.1633 - val_mae: 0.3792
Epoch 171/5000
36/36 - 1s - loss: 0.1074 - mae: 0.2834 - val_loss: 0.1591 - val_mae: 0.3549
Epoch 172/5000
36/36 - 1s - loss: 0.1137 - mae: 0.3004 - val_loss: 0.1632 - val_mae: 0.3613
Epoch 173/5000
36/36 - 1s - loss: 0.1175 - mae: 0.3037 - val_loss: 0.1675 - val_mae: 0.4014
Epoch 174/5000
36/36 - 1s - loss: 0.1114 - mae: 0.2982 - val_loss: 0.1568 - val_mae: 0.3481
Epoch 175/5000
36/36 - 1s - loss: 0.1075 - mae: 0.2869 - val_loss: 0.1585 - val_mae: 0.3704
Epoch 176/5000
36/36 - 1s - loss: 0.1057 - mae: 0.2826 - val_loss: 0.1600 - val_mae: 0.3527
Epoch 177/5000
36/36 - 1s - loss: 0.1079 - mae: 0.2866 - val_loss: 0.1609 - val_mae: 0.3604
Epoch 178/5000
36/36 - 1s - loss: 0.1057 - mae: 0.2808 - val_loss: 0.1613 - val_mae: 0.3646
Epoch 179/5000
36/36 - 1s - loss: 0.1044 - mae: 0.2766 - val_loss: 0.1616 - val_mae: 0.3632
Epoch 180/5000
36/36 - 1s - loss: 0.1058 - mae: 0.2808 - val_loss: 0.1669 - val_mae: 0.3946
Epoch 181/5000
36/36 - 1s - loss: 0.1052 - mae: 0.2804 - val_loss: 0.1621 - val_mae: 0.3674
Epoch 182/5000
36/36 - 1s - loss: 0.1039 - mae: 0.2765 - val_loss: 0.1571 - val_mae: 0.3467
Epoch 183/5000
36/36 - 1s - loss: 0.1050 - mae: 0.2791 - val_loss: 0.1552 - val_mae: 0.3436
Epoch 184/5000
36/36 - 1s - loss: 0.1057 - mae: 0.2817 - val_loss: 0.1574 - val_mae: 0.3502
Epoch 185/5000
36/36 - 1s - loss: 0.1035 - mae: 0.2745 - val_loss: 0.1614 - val_mae: 0.3633
Epoch 186/5000
36/36 - 1s - loss: 0.1027 - mae: 0.2742 - val_loss: 0.1615 - val_mae: 0.3520
Epoch 187/5000
36/36 - 1s - loss: 0.1056 - mae: 0.2805 - val_loss: 0.1587 - val_mae: 0.3523
Epoch 188/5000
36/36 - 1s - loss: 0.1075 - mae: 0.2858 - val_loss: 0.1721 - val_mae: 0.4001
Epoch 189/5000
36/36 - 1s - loss: 0.1040 - mae: 0.2781 - val_loss: 0.1626 - val_mae: 0.3588
Epoch 190/5000
36/36 - 1s - loss: 0.1031 - mae: 0.2769 - val_loss: 0.1609 - val_mae: 0.3548
Epoch 191/5000
36/36 - 1s - loss: 0.1030 - mae: 0.2741 - val_loss: 0.1653 - val_mae: 0.3663
Epoch 192/5000
36/36 - 1s - loss: 0.1019 - mae: 0.2705 - val_loss: 0.1589 - val_mae: 0.3563
Epoch 193/5000
36/36 - 1s - loss: 0.1025 - mae: 0.2736 - val_loss: 0.1543 - val_mae: 0.3408
Epoch 194/5000
36/36 - 1s - loss: 0.1020 - mae: 0.2706 - val_loss: 0.1609 - val_mae: 0.3555
Epoch 195/5000
36/36 - 1s - loss: 0.1079 - mae: 0.2864 - val_loss: 0.1610 - val_mae: 0.3817
Epoch 196/5000
36/36 - 1s - loss: 0.1047 - mae: 0.2793 - val_loss: 0.1626 - val_mae: 0.3650
Epoch 197/5000
36/36 - 1s - loss: 0.1027 - mae: 0.2764 - val_loss: 0.1645 - val_mae: 0.3606
Epoch 198/5000
36/36 - 1s - loss: 0.1015 - mae: 0.2716 - val_loss: 0.1584 - val_mae: 0.3492
Epoch 199/5000
36/36 - 1s - loss: 0.1033 - mae: 0.2769 - val_loss: 0.1562 - val_mae: 0.3488
Epoch 200/5000
36/36 - 1s - loss: 0.1050 - mae: 0.2798 - val_loss: 0.1665 - val_mae: 0.3820
Epoch 201/5000
36/36 - 1s - loss: 0.1004 - mae: 0.2695 - val_loss: 0.1625 - val_mae: 0.3585
Epoch 202/5000
36/36 - 1s - loss: 0.1009 - mae: 0.2687 - val_loss: 0.1596 - val_mae: 0.3501
Epoch 203/5000
36/36 - 1s - loss: 0.1035 - mae: 0.2763 - val_loss: 0.1606 - val_mae: 0.3414
Epoch 204/5000
36/36 - 1s - loss: 0.1030 - mae: 0.2750 - val_loss: 0.1690 - val_mae: 0.3862
Epoch 205/5000
36/36 - 1s - loss: 0.1039 - mae: 0.2783 - val_loss: 0.1712 - val_mae: 0.4020
Epoch 206/5000
36/36 - 1s - loss: 0.1028 - mae: 0.2772 - val_loss: 0.1667 - val_mae: 0.4003
Epoch 207/5000
36/36 - 1s - loss: 0.1020 - mae: 0.2765 - val_loss: 0.1587 - val_mae: 0.3461
Epoch 208/5000
36/36 - 1s - loss: 0.1006 - mae: 0.2675 - val_loss: 0.1534 - val_mae: 0.3444
Epoch 209/5000
36/36 - 1s - loss: 0.0995 - mae: 0.2699 - val_loss: 0.1624 - val_mae: 0.3703
Epoch 210/5000
36/36 - 1s - loss: 0.0990 - mae: 0.2652 - val_loss: 0.1604 - val_mae: 0.3676
Epoch 211/5000
36/36 - 1s - loss: 0.1002 - mae: 0.2689 - val_loss: 0.1568 - val_mae: 0.3484
Epoch 212/5000
36/36 - 1s - loss: 0.1037 - mae: 0.2772 - val_loss: 0.1555 - val_mae: 0.3461
Epoch 213/5000
36/36 - 1s - loss: 0.1038 - mae: 0.2780 - val_loss: 0.1545 - val_mae: 0.3529
Epoch 214/5000
36/36 - 1s - loss: 0.1046 - mae: 0.2805 - val_loss: 0.1662 - val_mae: 0.3772
Epoch 215/5000
36/36 - 1s - loss: 0.0997 - mae: 0.2673 - val_loss: 0.1616 - val_mae: 0.3561
Epoch 216/5000
36/36 - 1s - loss: 0.0974 - mae: 0.2646 - val_loss: 0.1634 - val_mae: 0.3712
Epoch 217/5000
36/36 - 1s - loss: 0.0969 - mae: 0.2640 - val_loss: 0.1651 - val_mae: 0.3794
Epoch 218/5000
36/36 - 1s - loss: 0.0977 - mae: 0.2628 - val_loss: 0.1685 - val_mae: 0.3727
Epoch 219/5000
36/36 - 1s - loss: 0.0979 - mae: 0.2634 - val_loss: 0.1663 - val_mae: 0.3708
Epoch 220/5000
36/36 - 1s - loss: 0.0973 - mae: 0.2636 - val_loss: 0.1664 - val_mae: 0.3657
Epoch 221/5000
36/36 - 1s - loss: 0.0961 - mae: 0.2598 - val_loss: 0.1585 - val_mae: 0.3517
Epoch 222/5000
36/36 - 1s - loss: 0.0963 - mae: 0.2595 - val_loss: 0.1564 - val_mae: 0.3483
Epoch 223/5000
36/36 - 1s - loss: 0.0952 - mae: 0.2563 - val_loss: 0.1560 - val_mae: 0.3496
Epoch 224/5000
36/36 - 1s - loss: 0.0951 - mae: 0.2590 - val_loss: 0.1621 - val_mae: 0.3606
Epoch 225/5000
36/36 - 1s - loss: 0.0962 - mae: 0.2597 - val_loss: 0.1554 - val_mae: 0.3491
Epoch 226/5000
36/36 - 1s - loss: 0.0972 - mae: 0.2646 - val_loss: 0.1586 - val_mae: 0.3445
Epoch 227/5000
36/36 - 1s - loss: 0.0952 - mae: 0.2582 - val_loss: 0.1652 - val_mae: 0.3762
Epoch 228/5000
36/36 - 1s - loss: 0.0986 - mae: 0.2682 - val_loss: 0.1652 - val_mae: 0.3815
Epoch 229/5000
36/36 - 1s - loss: 0.1041 - mae: 0.2811 - val_loss: 0.1603 - val_mae: 0.3590
Epoch 230/5000
36/36 - 1s - loss: 0.0991 - mae: 0.2690 - val_loss: 0.1626 - val_mae: 0.3689
Epoch 231/5000
36/36 - 1s - loss: 0.0951 - mae: 0.2575 - val_loss: 0.1598 - val_mae: 0.3628
Epoch 232/5000
36/36 - 1s - loss: 0.0949 - mae: 0.2569 - val_loss: 0.1582 - val_mae: 0.3585
Epoch 233/5000
36/36 - 1s - loss: 0.0950 - mae: 0.2598 - val_loss: 0.1572 - val_mae: 0.3430
Epoch 234/5000
36/36 - 1s - loss: 0.0952 - mae: 0.2586 - val_loss: 0.1680 - val_mae: 0.3791
Epoch 235/5000
36/36 - 1s - loss: 0.0927 - mae: 0.2524 - val_loss: 0.1613 - val_mae: 0.3599
Epoch 236/5000
36/36 - 1s - loss: 0.0920 - mae: 0.2513 - val_loss: 0.1587 - val_mae: 0.3529
Epoch 237/5000
36/36 - 1s - loss: 0.0937 - mae: 0.2576 - val_loss: 0.1567 - val_mae: 0.3511
Epoch 238/5000
36/36 - 1s - loss: 0.0963 - mae: 0.2665 - val_loss: 0.1605 - val_mae: 0.3630
Epoch 239/5000
36/36 - 1s - loss: 0.0999 - mae: 0.2699 - val_loss: 0.1677 - val_mae: 0.3660
Epoch 240/5000
36/36 - 1s - loss: 0.1055 - mae: 0.2845 - val_loss: 0.1633 - val_mae: 0.3655
Epoch 241/5000
36/36 - 1s - loss: 0.1000 - mae: 0.2736 - val_loss: 0.1613 - val_mae: 0.3641
Epoch 242/5000
36/36 - 1s - loss: 0.0990 - mae: 0.2683 - val_loss: 0.1681 - val_mae: 0.3839
Epoch 243/5000
36/36 - 1s - loss: 0.0992 - mae: 0.2697 - val_loss: 0.1655 - val_mae: 0.3718
Epoch 244/5000
36/36 - 1s - loss: 0.1031 - mae: 0.2776 - val_loss: 0.1589 - val_mae: 0.3461
Epoch 245/5000
36/36 - 1s - loss: 0.1043 - mae: 0.2789 - val_loss: 0.1595 - val_mae: 0.3592
Epoch 246/5000
36/36 - 1s - loss: 0.1052 - mae: 0.2879 - val_loss: 0.1637 - val_mae: 0.3506
Epoch 247/5000
36/36 - 1s - loss: 0.0992 - mae: 0.2684 - val_loss: 0.1627 - val_mae: 0.3434
Epoch 248/5000
36/36 - 1s - loss: 0.0995 - mae: 0.2694 - val_loss: 0.1569 - val_mae: 0.3391
Epoch 249/5000
36/36 - 1s - loss: 0.0962 - mae: 0.2627 - val_loss: 0.1602 - val_mae: 0.3415
Epoch 250/5000
36/36 - 1s - loss: 0.0927 - mae: 0.2554 - val_loss: 0.1583 - val_mae: 0.3502
Epoch 251/5000
36/36 - 1s - loss: 0.0936 - mae: 0.2551 - val_loss: 0.1620 - val_mae: 0.3687
Epoch 252/5000
36/36 - 1s - loss: 0.0983 - mae: 0.2683 - val_loss: 0.1567 - val_mae: 0.3300
Epoch 253/5000
36/36 - 1s - loss: 0.0952 - mae: 0.2584 - val_loss: 0.1624 - val_mae: 0.3421
Epoch 254/5000
36/36 - 1s - loss: 0.0960 - mae: 0.2607 - val_loss: 0.1644 - val_mae: 0.3605
Epoch 255/5000
36/36 - 1s - loss: 0.1022 - mae: 0.2771 - val_loss: 0.1543 - val_mae: 0.3415
Epoch 256/5000
36/36 - 1s - loss: 0.0955 - mae: 0.2574 - val_loss: 0.1567 - val_mae: 0.3474
Epoch 257/5000
36/36 - 1s - loss: 0.0952 - mae: 0.2541 - val_loss: 0.1617 - val_mae: 0.3562
Epoch 258/5000
36/36 - 1s - loss: 0.0940 - mae: 0.2602 - val_loss: 0.1569 - val_mae: 0.3475
Epoch 259/5000
36/36 - 1s - loss: 0.0925 - mae: 0.2556 - val_loss: 0.1618 - val_mae: 0.3626
Epoch 260/5000
36/36 - 1s - loss: 0.1011 - mae: 0.2737 - val_loss: 0.1589 - val_mae: 0.3432
Epoch 261/5000
36/36 - 1s - loss: 0.0995 - mae: 0.2686 - val_loss: 0.1644 - val_mae: 0.3517
Epoch 262/5000
36/36 - 1s - loss: 0.1004 - mae: 0.2726 - val_loss: 0.1571 - val_mae: 0.3538
Epoch 263/5000
36/36 - 1s - loss: 0.1015 - mae: 0.2769 - val_loss: 0.1612 - val_mae: 0.3593
Epoch 264/5000
36/36 - 1s - loss: 0.1006 - mae: 0.2718 - val_loss: 0.1605 - val_mae: 0.3493
Epoch 265/5000
36/36 - 1s - loss: 0.1039 - mae: 0.2803 - val_loss: 0.1595 - val_mae: 0.3543
Epoch 266/5000
36/36 - 1s - loss: 0.1033 - mae: 0.2766 - val_loss: 0.1560 - val_mae: 0.3515
Epoch 267/5000
36/36 - 1s - loss: 0.0995 - mae: 0.2690 - val_loss: 0.1576 - val_mae: 0.3507
Epoch 268/5000
36/36 - 1s - loss: 0.0990 - mae: 0.2648 - val_loss: 0.1608 - val_mae: 0.3450
Epoch 269/5000
36/36 - 1s - loss: 0.0929 - mae: 0.2548 - val_loss: 0.1595 - val_mae: 0.3533
Epoch 270/5000
36/36 - 1s - loss: 0.0961 - mae: 0.2609 - val_loss: 0.1564 - val_mae: 0.3431
Epoch 271/5000
36/36 - 1s - loss: 0.1030 - mae: 0.2779 - val_loss: 0.1623 - val_mae: 0.3551
Epoch 272/5000
36/36 - 1s - loss: 0.1046 - mae: 0.2893 - val_loss: 0.1623 - val_mae: 0.3565
Epoch 273/5000
36/36 - 1s - loss: 0.0997 - mae: 0.2696 - val_loss: 0.1577 - val_mae: 0.3420
Epoch 274/5000
36/36 - 1s - loss: 0.1177 - mae: 0.3067 - val_loss: 0.2124 - val_mae: 0.5136
Epoch 275/5000
36/36 - 1s - loss: 0.1092 - mae: 0.2971 - val_loss: 0.1881 - val_mae: 0.4600
Epoch 276/5000
36/36 - 1s - loss: 0.1035 - mae: 0.2844 - val_loss: 0.1813 - val_mae: 0.4426
Epoch 277/5000
36/36 - 1s - loss: 0.1052 - mae: 0.2856 - val_loss: 0.1960 - val_mae: 0.4728
Epoch 278/5000
36/36 - 1s - loss: 0.1059 - mae: 0.2858 - val_loss: 0.2217 - val_mae: 0.5363
Epoch 279/5000
36/36 - 1s - loss: 0.1108 - mae: 0.2970 - val_loss: 0.2256 - val_mae: 0.5406
Epoch 280/5000
36/36 - 1s - loss: 0.1118 - mae: 0.3036 - val_loss: 0.1641 - val_mae: 0.3969
Epoch 281/5000
36/36 - 1s - loss: 0.0983 - mae: 0.2730 - val_loss: 0.1978 - val_mae: 0.4827
Epoch 282/5000
36/36 - 1s - loss: 0.1003 - mae: 0.2723 - val_loss: 0.1986 - val_mae: 0.4870
Epoch 283/5000
36/36 - 1s - loss: 0.1041 - mae: 0.2835 - val_loss: 0.1964 - val_mae: 0.4843
Epoch 284/5000
36/36 - 1s - loss: 0.1025 - mae: 0.2811 - val_loss: 0.1874 - val_mae: 0.4554
Epoch 285/5000
36/36 - 1s - loss: 0.0948 - mae: 0.2625 - val_loss: 0.1791 - val_mae: 0.4161
Epoch 286/5000
36/36 - 1s - loss: 0.0902 - mae: 0.2516 - val_loss: 0.1823 - val_mae: 0.4196
Epoch 287/5000
36/36 - 1s - loss: 0.0889 - mae: 0.2488 - val_loss: 0.1725 - val_mae: 0.4001
Epoch 288/5000
36/36 - 1s - loss: 0.0884 - mae: 0.2472 - val_loss: 0.1905 - val_mae: 0.4438
Epoch 289/5000
36/36 - 1s - loss: 0.0920 - mae: 0.2534 - val_loss: 0.1963 - val_mae: 0.4574
Epoch 290/5000
36/36 - 1s - loss: 0.0920 - mae: 0.2582 - val_loss: 0.1884 - val_mae: 0.4575
Epoch 291/5000
36/36 - 1s - loss: 0.0942 - mae: 0.2595 - val_loss: 0.1846 - val_mae: 0.4308
Epoch 292/5000
36/36 - 1s - loss: 0.1039 - mae: 0.2774 - val_loss: 0.2535 - val_mae: 0.6014
Epoch 293/5000
36/36 - 1s - loss: 0.1263 - mae: 0.3298 - val_loss: 0.1681 - val_mae: 0.4132
Epoch 294/5000
36/36 - 1s - loss: 0.1015 - mae: 0.2734 - val_loss: 0.1990 - val_mae: 0.4800
Epoch 295/5000
36/36 - 1s - loss: 0.1031 - mae: 0.2798 - val_loss: 0.2116 - val_mae: 0.5067
Epoch 296/5000
36/36 - 1s - loss: 0.1053 - mae: 0.2844 - val_loss: 0.2001 - val_mae: 0.4872
Epoch 297/5000
36/36 - 1s - loss: 0.1022 - mae: 0.2799 - val_loss: 0.1718 - val_mae: 0.4150
Epoch 298/5000
36/36 - 1s - loss: 0.0984 - mae: 0.2716 - val_loss: 0.1973 - val_mae: 0.4790
Epoch 299/5000
36/36 - 1s - loss: 0.0957 - mae: 0.2621 - val_loss: 0.2089 - val_mae: 0.4949
Epoch 300/5000
36/36 - 1s - loss: 0.0998 - mae: 0.2688 - val_loss: 0.2050 - val_mae: 0.5125
Epoch 301/5000
36/36 - 1s - loss: 0.1095 - mae: 0.3019 - val_loss: 0.1716 - val_mae: 0.4069
Epoch 302/5000
36/36 - 1s - loss: 0.0939 - mae: 0.2610 - val_loss: 0.1814 - val_mae: 0.4460
Epoch 303/5000
36/36 - 1s - loss: 0.0949 - mae: 0.2676 - val_loss: 0.1699 - val_mae: 0.4024
Epoch 304/5000
36/36 - 1s - loss: 0.0922 - mae: 0.2592 - val_loss: 0.1693 - val_mae: 0.4015
Epoch 305/5000
36/36 - 1s - loss: 0.0961 - mae: 0.2694 - val_loss: 0.1658 - val_mae: 0.3879
Epoch 306/5000
36/36 - 1s - loss: 0.0922 - mae: 0.2538 - val_loss: 0.1920 - val_mae: 0.4586
Epoch 307/5000
36/36 - 1s - loss: 0.0891 - mae: 0.2515 - val_loss: 0.1717 - val_mae: 0.4062
Epoch 308/5000
36/36 - 1s - loss: 0.0916 - mae: 0.2597 - val_loss: 0.1693 - val_mae: 0.3919
Epoch 309/5000
36/36 - 1s - loss: 0.0902 - mae: 0.2552 - val_loss: 0.1763 - val_mae: 0.4063
Epoch 310/5000
36/36 - 1s - loss: 0.0876 - mae: 0.2476 - val_loss: 0.1952 - val_mae: 0.4637
Epoch 311/5000
36/36 - 1s - loss: 0.0896 - mae: 0.2527 - val_loss: 0.1821 - val_mae: 0.4382
Epoch 312/5000
36/36 - 1s - loss: 0.0907 - mae: 0.2542 - val_loss: 0.2143 - val_mae: 0.5055
Epoch 313/5000
36/36 - 1s - loss: 0.0911 - mae: 0.2548 - val_loss: 0.1623 - val_mae: 0.3851
Epoch 314/5000
36/36 - 1s - loss: 0.0896 - mae: 0.2519 - val_loss: 0.1861 - val_mae: 0.4448
Epoch 315/5000
36/36 - 1s - loss: 0.0913 - mae: 0.2550 - val_loss: 0.1926 - val_mae: 0.4583
Epoch 316/5000
36/36 - 1s - loss: 0.0938 - mae: 0.2597 - val_loss: 0.1780 - val_mae: 0.4289
Epoch 317/5000
36/36 - 1s - loss: 0.1045 - mae: 0.2936 - val_loss: 0.1596 - val_mae: 0.3592
Epoch 318/5000
36/36 - 1s - loss: 0.1060 - mae: 0.2887 - val_loss: 0.1811 - val_mae: 0.4332
Epoch 319/5000
36/36 - 1s - loss: 0.0985 - mae: 0.2711 - val_loss: 0.1660 - val_mae: 0.3790
Epoch 320/5000
36/36 - 1s - loss: 0.0956 - mae: 0.2641 - val_loss: 0.1820 - val_mae: 0.4401
Epoch 321/5000
36/36 - 1s - loss: 0.0935 - mae: 0.2620 - val_loss: 0.1649 - val_mae: 0.3841
Epoch 322/5000
36/36 - 1s - loss: 0.0894 - mae: 0.2522 - val_loss: 0.1665 - val_mae: 0.3817
Epoch 323/5000
36/36 - 1s - loss: 0.0924 - mae: 0.2568 - val_loss: 0.1675 - val_mae: 0.3964
Epoch 324/5000
36/36 - 1s - loss: 0.0898 - mae: 0.2536 - val_loss: 0.1799 - val_mae: 0.4165
Epoch 325/5000
36/36 - 1s - loss: 0.0903 - mae: 0.2547 - val_loss: 0.1875 - val_mae: 0.4489
Epoch 326/5000
36/36 - 1s - loss: 0.0888 - mae: 0.2543 - val_loss: 0.1818 - val_mae: 0.4266
Epoch 327/5000
36/36 - 1s - loss: 0.0910 - mae: 0.2571 - val_loss: 0.1698 - val_mae: 0.4023
Epoch 328/5000
36/36 - 1s - loss: 0.0895 - mae: 0.2536 - val_loss: 0.1620 - val_mae: 0.3690
Epoch 329/5000
36/36 - 1s - loss: 0.0968 - mae: 0.2729 - val_loss: 0.1603 - val_mae: 0.3640
Epoch 330/5000
36/36 - 1s - loss: 0.0981 - mae: 0.2710 - val_loss: 0.1715 - val_mae: 0.4019
Epoch 331/5000
36/36 - 1s - loss: 0.0916 - mae: 0.2570 - val_loss: 0.1703 - val_mae: 0.3994
Epoch 332/5000
36/36 - 1s - loss: 0.0944 - mae: 0.2655 - val_loss: 0.1613 - val_mae: 0.3631
Epoch 333/5000
36/36 - 1s - loss: 0.0940 - mae: 0.2612 - val_loss: 0.1569 - val_mae: 0.3465
Epoch 334/5000
36/36 - 1s - loss: 0.0958 - mae: 0.2658 - val_loss: 0.1647 - val_mae: 0.3851
Epoch 335/5000
36/36 - 1s - loss: 0.0928 - mae: 0.2640 - val_loss: 0.1738 - val_mae: 0.4031
Epoch 336/5000
36/36 - 1s - loss: 0.0898 - mae: 0.2545 - val_loss: 0.1741 - val_mae: 0.4048
Epoch 337/5000
36/36 - 1s - loss: 0.0885 - mae: 0.2526 - val_loss: 0.1646 - val_mae: 0.3757
Epoch 338/5000
36/36 - 1s - loss: 0.0874 - mae: 0.2453 - val_loss: 0.1763 - val_mae: 0.4169
Epoch 339/5000
36/36 - 1s - loss: 0.0875 - mae: 0.2510 - val_loss: 0.1627 - val_mae: 0.3852
Epoch 340/5000
36/36 - 1s - loss: 0.0908 - mae: 0.2574 - val_loss: 0.1691 - val_mae: 0.3866
Epoch 341/5000
36/36 - 1s - loss: 0.0890 - mae: 0.2550 - val_loss: 0.1573 - val_mae: 0.3650
Epoch 342/5000
36/36 - 1s - loss: 0.0898 - mae: 0.2576 - val_loss: 0.1605 - val_mae: 0.3727
Epoch 343/5000
36/36 - 1s - loss: 0.0869 - mae: 0.2468 - val_loss: 0.1622 - val_mae: 0.3741
Epoch 344/5000
36/36 - 1s - loss: 0.0852 - mae: 0.2448 - val_loss: 0.1574 - val_mae: 0.3615
Epoch 345/5000
36/36 - 1s - loss: 0.0838 - mae: 0.2402 - val_loss: 0.1612 - val_mae: 0.3632
Epoch 346/5000
36/36 - 1s - loss: 0.0862 - mae: 0.2439 - val_loss: 0.1678 - val_mae: 0.3954
Epoch 347/5000
36/36 - 1s - loss: 0.0877 - mae: 0.2475 - val_loss: 0.1666 - val_mae: 0.3860
Epoch 348/5000
36/36 - 1s - loss: 0.0878 - mae: 0.2497 - val_loss: 0.1651 - val_mae: 0.3735
Epoch 349/5000
36/36 - 1s - loss: 0.0866 - mae: 0.2467 - val_loss: 0.1596 - val_mae: 0.3544
Epoch 350/5000
36/36 - 1s - loss: 0.0826 - mae: 0.2390 - val_loss: 0.1751 - val_mae: 0.4037
Epoch 351/5000
36/36 - 1s - loss: 0.0813 - mae: 0.2361 - val_loss: 0.1625 - val_mae: 0.3721
Epoch 352/5000
36/36 - 1s - loss: 0.0827 - mae: 0.2368 - val_loss: 0.1680 - val_mae: 0.3858
Epoch 353/5000
36/36 - 1s - loss: 0.0834 - mae: 0.2396 - val_loss: 0.1728 - val_mae: 0.3927
Restoring model weights from the end of the best epoch.
Epoch 00353: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_0..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing (MessagePassing (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding (PartitionPad (None, None, 64)     0           message_passing[0][0]            
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing[1][0]            
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking (Masking)               (None, None, 64)     0           partition_padding[0][0]          
                                                                 partition_padding[1][0]          
__________________________________________________________________________________________________
transformer_encoder (Transforme (None, None, 64)     199040      masking[0][0]                    
                                                                 masking[1][0]                    
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 64)           0           transformer_encoder[0][0]        
                                                                 transformer_encoder[1][0]        
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 512)          33280       global_average_pooling1d[0][0]   
                                                                 global_average_pooling1d[1][0]   
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 10)           110         dense_4[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 450)          230850      dense_2[0][0]                    
                                                                 dense_2[1][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 5)            55          dense_5[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 905)          0           dense_3[0][0]                    
                                                                 dense_3[1][0]                    
                                                                 dense_6[0][0]                    
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 700)          634200      concatenate[0][0]                
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 560)          392560      dense_7[0][0]                    
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 373)          209253      dense_11[0][0]                   
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 187)          69938       dense_12[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1)            188         dense_13[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
36/36 - 6s - loss: 0.1133 - mae: 0.2941 - val_loss: 0.1725 - val_mae: 0.3931
Epoch 2/5000
36/36 - 1s - loss: 0.0956 - mae: 0.2650 - val_loss: 0.1572 - val_mae: 0.3648
Epoch 3/5000
36/36 - 1s - loss: 0.0963 - mae: 0.2618 - val_loss: 0.2103 - val_mae: 0.4887
Epoch 4/5000
36/36 - 1s - loss: 0.0960 - mae: 0.2637 - val_loss: 0.1888 - val_mae: 0.4311
Epoch 5/5000
36/36 - 1s - loss: 0.0882 - mae: 0.2452 - val_loss: 0.1818 - val_mae: 0.4264
Epoch 6/5000
36/36 - 1s - loss: 0.0851 - mae: 0.2376 - val_loss: 0.1691 - val_mae: 0.3998
Epoch 7/5000
36/36 - 1s - loss: 0.0822 - mae: 0.2300 - val_loss: 0.1705 - val_mae: 0.4010
Epoch 8/5000
36/36 - 1s - loss: 0.0810 - mae: 0.2271 - val_loss: 0.1715 - val_mae: 0.4066
Epoch 9/5000
36/36 - 1s - loss: 0.0799 - mae: 0.2242 - val_loss: 0.1713 - val_mae: 0.3983
Epoch 10/5000
36/36 - 1s - loss: 0.0803 - mae: 0.2255 - val_loss: 0.1636 - val_mae: 0.3869
Epoch 11/5000
36/36 - 1s - loss: 0.0771 - mae: 0.2156 - val_loss: 0.1667 - val_mae: 0.3906
Epoch 12/5000
36/36 - 1s - loss: 0.0763 - mae: 0.2176 - val_loss: 0.1594 - val_mae: 0.3684
Epoch 13/5000
36/36 - 1s - loss: 0.0747 - mae: 0.2121 - val_loss: 0.1608 - val_mae: 0.3707
Epoch 14/5000
36/36 - 1s - loss: 0.0750 - mae: 0.2139 - val_loss: 0.1552 - val_mae: 0.3550
Epoch 15/5000
36/36 - 1s - loss: 0.0774 - mae: 0.2182 - val_loss: 0.1644 - val_mae: 0.3742
Epoch 16/5000
36/36 - 1s - loss: 0.0788 - mae: 0.2229 - val_loss: 0.2002 - val_mae: 0.4578
Epoch 17/5000
36/36 - 1s - loss: 0.0808 - mae: 0.2304 - val_loss: 0.2116 - val_mae: 0.4947
Epoch 18/5000
36/36 - 1s - loss: 0.0816 - mae: 0.2305 - val_loss: 0.1697 - val_mae: 0.3965
Epoch 19/5000
36/36 - 1s - loss: 0.0843 - mae: 0.2379 - val_loss: 0.1577 - val_mae: 0.3661
Epoch 20/5000
36/36 - 1s - loss: 0.0828 - mae: 0.2349 - val_loss: 0.1805 - val_mae: 0.4212
Epoch 21/5000
36/36 - 1s - loss: 0.0818 - mae: 0.2318 - val_loss: 0.1654 - val_mae: 0.3856
Epoch 22/5000
36/36 - 1s - loss: 0.0877 - mae: 0.2443 - val_loss: 0.1491 - val_mae: 0.3304
Epoch 23/5000
36/36 - 1s - loss: 0.0954 - mae: 0.2594 - val_loss: 0.1520 - val_mae: 0.3257
Epoch 24/5000
36/36 - 1s - loss: 0.0907 - mae: 0.2512 - val_loss: 0.1537 - val_mae: 0.3295
Epoch 25/5000
36/36 - 1s - loss: 0.0802 - mae: 0.2277 - val_loss: 0.1507 - val_mae: 0.3210
Epoch 26/5000
36/36 - 1s - loss: 0.0749 - mae: 0.2144 - val_loss: 0.1476 - val_mae: 0.3239
Epoch 27/5000
36/36 - 1s - loss: 0.0710 - mae: 0.2027 - val_loss: 0.1455 - val_mae: 0.3182
Epoch 28/5000
36/36 - 1s - loss: 0.0688 - mae: 0.1980 - val_loss: 0.1441 - val_mae: 0.3114
Epoch 29/5000
36/36 - 1s - loss: 0.0676 - mae: 0.1954 - val_loss: 0.1439 - val_mae: 0.3089
Epoch 30/5000
36/36 - 1s - loss: 0.0666 - mae: 0.1937 - val_loss: 0.1421 - val_mae: 0.3063
Epoch 31/5000
36/36 - 1s - loss: 0.0661 - mae: 0.1912 - val_loss: 0.1426 - val_mae: 0.3100
Epoch 32/5000
36/36 - 1s - loss: 0.0656 - mae: 0.1911 - val_loss: 0.1422 - val_mae: 0.3066
Epoch 33/5000
36/36 - 1s - loss: 0.0646 - mae: 0.1886 - val_loss: 0.1446 - val_mae: 0.3085
Epoch 34/5000
36/36 - 1s - loss: 0.0638 - mae: 0.1890 - val_loss: 0.1412 - val_mae: 0.3052
Epoch 35/5000
36/36 - 1s - loss: 0.0626 - mae: 0.1840 - val_loss: 0.1427 - val_mae: 0.3051
Epoch 36/5000
36/36 - 1s - loss: 0.0616 - mae: 0.1834 - val_loss: 0.1453 - val_mae: 0.3050
Epoch 37/5000
36/36 - 1s - loss: 0.0605 - mae: 0.1803 - val_loss: 0.1440 - val_mae: 0.3050
Epoch 38/5000
36/36 - 1s - loss: 0.0599 - mae: 0.1795 - val_loss: 0.1423 - val_mae: 0.3042
Epoch 39/5000
36/36 - 1s - loss: 0.0607 - mae: 0.1816 - val_loss: 0.1435 - val_mae: 0.3028
Epoch 40/5000
36/36 - 1s - loss: 0.0591 - mae: 0.1786 - val_loss: 0.1452 - val_mae: 0.3039
Epoch 41/5000
36/36 - 1s - loss: 0.0590 - mae: 0.1778 - val_loss: 0.1429 - val_mae: 0.3034
Epoch 42/5000
36/36 - 1s - loss: 0.0602 - mae: 0.1831 - val_loss: 0.1461 - val_mae: 0.3060
Epoch 43/5000
36/36 - 1s - loss: 0.0603 - mae: 0.1834 - val_loss: 0.1454 - val_mae: 0.3088
Epoch 44/5000
36/36 - 1s - loss: 0.0606 - mae: 0.1866 - val_loss: 0.1451 - val_mae: 0.3044
Epoch 45/5000
36/36 - 1s - loss: 0.0612 - mae: 0.1893 - val_loss: 0.1467 - val_mae: 0.3112
Epoch 46/5000
36/36 - 1s - loss: 0.0640 - mae: 0.1973 - val_loss: 0.1489 - val_mae: 0.3199
Epoch 47/5000
36/36 - 1s - loss: 0.0677 - mae: 0.2051 - val_loss: 0.1581 - val_mae: 0.3525
Epoch 48/5000
36/36 - 1s - loss: 0.0684 - mae: 0.2078 - val_loss: 0.1742 - val_mae: 0.3878
Epoch 49/5000
36/36 - 1s - loss: 0.0648 - mae: 0.2002 - val_loss: 0.1713 - val_mae: 0.3811
Epoch 50/5000
36/36 - 1s - loss: 0.0601 - mae: 0.1862 - val_loss: 0.1583 - val_mae: 0.3558
Epoch 51/5000
36/36 - 1s - loss: 0.0595 - mae: 0.1834 - val_loss: 0.1473 - val_mae: 0.3235
Epoch 52/5000
36/36 - 1s - loss: 0.0563 - mae: 0.1737 - val_loss: 0.1456 - val_mae: 0.3145
Epoch 53/5000
36/36 - 1s - loss: 0.0540 - mae: 0.1668 - val_loss: 0.1442 - val_mae: 0.3106
Epoch 54/5000
36/36 - 1s - loss: 0.0519 - mae: 0.1626 - val_loss: 0.1464 - val_mae: 0.3126
Epoch 55/5000
36/36 - 1s - loss: 0.0525 - mae: 0.1659 - val_loss: 0.1483 - val_mae: 0.3177
Epoch 56/5000
36/36 - 1s - loss: 0.0521 - mae: 0.1661 - val_loss: 0.1497 - val_mae: 0.3203
Epoch 57/5000
36/36 - 1s - loss: 0.0515 - mae: 0.1657 - val_loss: 0.1562 - val_mae: 0.3372
Epoch 58/5000
36/36 - 1s - loss: 0.0505 - mae: 0.1643 - val_loss: 0.1596 - val_mae: 0.3483
Epoch 59/5000
36/36 - 1s - loss: 0.0496 - mae: 0.1607 - val_loss: 0.1621 - val_mae: 0.3589
Epoch 60/5000
36/36 - 1s - loss: 0.0490 - mae: 0.1609 - val_loss: 0.1623 - val_mae: 0.3594
Epoch 61/5000
36/36 - 1s - loss: 0.0477 - mae: 0.1564 - val_loss: 0.1697 - val_mae: 0.3769
Epoch 62/5000
36/36 - 1s - loss: 0.0500 - mae: 0.1639 - val_loss: 0.1617 - val_mae: 0.3570
Epoch 63/5000
36/36 - 1s - loss: 0.0504 - mae: 0.1664 - val_loss: 0.1657 - val_mae: 0.3655
Epoch 64/5000
36/36 - 1s - loss: 0.0494 - mae: 0.1607 - val_loss: 0.1621 - val_mae: 0.3575
Epoch 65/5000
36/36 - 1s - loss: 0.0508 - mae: 0.1674 - val_loss: 0.1519 - val_mae: 0.3297
Epoch 66/5000
36/36 - 1s - loss: 0.0546 - mae: 0.1780 - val_loss: 0.1587 - val_mae: 0.3481
Epoch 67/5000
36/36 - 1s - loss: 0.0562 - mae: 0.1751 - val_loss: 0.1438 - val_mae: 0.3090
Epoch 68/5000
36/36 - 1s - loss: 0.0575 - mae: 0.1855 - val_loss: 0.1459 - val_mae: 0.3108
Epoch 69/5000
36/36 - 1s - loss: 0.0560 - mae: 0.1799 - val_loss: 0.1505 - val_mae: 0.3147
Epoch 70/5000
36/36 - 1s - loss: 0.0549 - mae: 0.1798 - val_loss: 0.1521 - val_mae: 0.3163
Epoch 71/5000
36/36 - 1s - loss: 0.0538 - mae: 0.1759 - val_loss: 0.1518 - val_mae: 0.3217
Epoch 72/5000
36/36 - 1s - loss: 0.0456 - mae: 0.1523 - val_loss: 0.1582 - val_mae: 0.3407
Epoch 73/5000
36/36 - 1s - loss: 0.0443 - mae: 0.1518 - val_loss: 0.1568 - val_mae: 0.3354
Epoch 74/5000
36/36 - 1s - loss: 0.0442 - mae: 0.1472 - val_loss: 0.1546 - val_mae: 0.3321
Epoch 75/5000
36/36 - 1s - loss: 0.0416 - mae: 0.1438 - val_loss: 0.1539 - val_mae: 0.3267
Epoch 76/5000
36/36 - 1s - loss: 0.0398 - mae: 0.1373 - val_loss: 0.1517 - val_mae: 0.3235
Epoch 77/5000
36/36 - 1s - loss: 0.0389 - mae: 0.1367 - val_loss: 0.1533 - val_mae: 0.3201
Epoch 78/5000
36/36 - 1s - loss: 0.0381 - mae: 0.1355 - val_loss: 0.1517 - val_mae: 0.3168
Epoch 79/5000
36/36 - 1s - loss: 0.0365 - mae: 0.1305 - val_loss: 0.1552 - val_mae: 0.3296
Epoch 80/5000
36/36 - 1s - loss: 0.0376 - mae: 0.1339 - val_loss: 0.1550 - val_mae: 0.3244
Epoch 81/5000
36/36 - 1s - loss: 0.0367 - mae: 0.1329 - val_loss: 0.1502 - val_mae: 0.3155
Epoch 82/5000
36/36 - 1s - loss: 0.0380 - mae: 0.1379 - val_loss: 0.1549 - val_mae: 0.3260
Epoch 83/5000
36/36 - 1s - loss: 0.0396 - mae: 0.1447 - val_loss: 0.1524 - val_mae: 0.3231
Epoch 84/5000
36/36 - 1s - loss: 0.0377 - mae: 0.1376 - val_loss: 0.1611 - val_mae: 0.3469
Epoch 85/5000
36/36 - 1s - loss: 0.0371 - mae: 0.1380 - val_loss: 0.1722 - val_mae: 0.3701
Epoch 86/5000
36/36 - 1s - loss: 0.0439 - mae: 0.1597 - val_loss: 0.1603 - val_mae: 0.3457
Epoch 87/5000
36/36 - 1s - loss: 0.0399 - mae: 0.1453 - val_loss: 0.1873 - val_mae: 0.4071
Epoch 88/5000
36/36 - 1s - loss: 0.0426 - mae: 0.1548 - val_loss: 0.1796 - val_mae: 0.4035
Epoch 89/5000
36/36 - 1s - loss: 0.0418 - mae: 0.1487 - val_loss: 0.1845 - val_mae: 0.4087
Epoch 90/5000
36/36 - 1s - loss: 0.0447 - mae: 0.1585 - val_loss: 0.1662 - val_mae: 0.3722
Epoch 91/5000
36/36 - 1s - loss: 0.0473 - mae: 0.1629 - val_loss: 0.1532 - val_mae: 0.3397
Epoch 92/5000
36/36 - 1s - loss: 0.0470 - mae: 0.1619 - val_loss: 0.1411 - val_mae: 0.3098
Epoch 93/5000
36/36 - 1s - loss: 0.0540 - mae: 0.1789 - val_loss: 0.1410 - val_mae: 0.3075
Epoch 94/5000
36/36 - 1s - loss: 0.0426 - mae: 0.1492 - val_loss: 0.1435 - val_mae: 0.3111
Epoch 95/5000
36/36 - 1s - loss: 0.0356 - mae: 0.1322 - val_loss: 0.1531 - val_mae: 0.3387
Epoch 96/5000
36/36 - 1s - loss: 0.0328 - mae: 0.1238 - val_loss: 0.1552 - val_mae: 0.3453
Epoch 97/5000
36/36 - 1s - loss: 0.0331 - mae: 0.1247 - val_loss: 0.1547 - val_mae: 0.3443
Epoch 98/5000
36/36 - 1s - loss: 0.0349 - mae: 0.1296 - val_loss: 0.1495 - val_mae: 0.3279
Epoch 99/5000
36/36 - 1s - loss: 0.0334 - mae: 0.1271 - val_loss: 0.1446 - val_mae: 0.3070
Epoch 100/5000
36/36 - 1s - loss: 0.0328 - mae: 0.1236 - val_loss: 0.1477 - val_mae: 0.3209
Epoch 101/5000
36/36 - 1s - loss: 0.0309 - mae: 0.1184 - val_loss: 0.1470 - val_mae: 0.3157
Epoch 102/5000
36/36 - 1s - loss: 0.0295 - mae: 0.1146 - val_loss: 0.1542 - val_mae: 0.3381
Epoch 103/5000
36/36 - 1s - loss: 0.0288 - mae: 0.1117 - val_loss: 0.1593 - val_mae: 0.3466
Epoch 104/5000
36/36 - 1s - loss: 0.0297 - mae: 0.1161 - val_loss: 0.1605 - val_mae: 0.3525
Epoch 105/5000
36/36 - 1s - loss: 0.0289 - mae: 0.1122 - val_loss: 0.1637 - val_mae: 0.3664
Epoch 106/5000
36/36 - 1s - loss: 0.0311 - mae: 0.1194 - val_loss: 0.1644 - val_mae: 0.3622
Epoch 107/5000
36/36 - 1s - loss: 0.0302 - mae: 0.1163 - val_loss: 0.1669 - val_mae: 0.3720
Epoch 108/5000
36/36 - 1s - loss: 0.0320 - mae: 0.1205 - val_loss: 0.1505 - val_mae: 0.3295
Epoch 109/5000
36/36 - 1s - loss: 0.0318 - mae: 0.1220 - val_loss: 0.1497 - val_mae: 0.3290
Epoch 110/5000
36/36 - 1s - loss: 0.0311 - mae: 0.1212 - val_loss: 0.1435 - val_mae: 0.3121
Epoch 111/5000
36/36 - 1s - loss: 0.0350 - mae: 0.1336 - val_loss: 0.1455 - val_mae: 0.3110
Epoch 112/5000
36/36 - 1s - loss: 0.0356 - mae: 0.1352 - val_loss: 0.1453 - val_mae: 0.3135
Epoch 113/5000
36/36 - 1s - loss: 0.0373 - mae: 0.1399 - val_loss: 0.1468 - val_mae: 0.3170
Epoch 114/5000
36/36 - 1s - loss: 0.0326 - mae: 0.1271 - val_loss: 0.1442 - val_mae: 0.3094
Epoch 115/5000
36/36 - 1s - loss: 0.0325 - mae: 0.1284 - val_loss: 0.1450 - val_mae: 0.3080
Epoch 116/5000
36/36 - 1s - loss: 0.0369 - mae: 0.1437 - val_loss: 0.1582 - val_mae: 0.3497
Epoch 117/5000
36/36 - 1s - loss: 0.0342 - mae: 0.1352 - val_loss: 0.1701 - val_mae: 0.3780
Epoch 118/5000
36/36 - 1s - loss: 0.0334 - mae: 0.1270 - val_loss: 0.1687 - val_mae: 0.3650
Epoch 119/5000
36/36 - 1s - loss: 0.0288 - mae: 0.1142 - val_loss: 0.1610 - val_mae: 0.3550
Epoch 120/5000
36/36 - 1s - loss: 0.0296 - mae: 0.1166 - val_loss: 0.1470 - val_mae: 0.3152
Epoch 121/5000
36/36 - 1s - loss: 0.0288 - mae: 0.1133 - val_loss: 0.1432 - val_mae: 0.3117
Epoch 122/5000
36/36 - 1s - loss: 0.0269 - mae: 0.1070 - val_loss: 0.1483 - val_mae: 0.3237
Epoch 123/5000
36/36 - 1s - loss: 0.0264 - mae: 0.1037 - val_loss: 0.1469 - val_mae: 0.3209
Epoch 124/5000
36/36 - 1s - loss: 0.0257 - mae: 0.1000 - val_loss: 0.1460 - val_mae: 0.3154
Epoch 125/5000
36/36 - 1s - loss: 0.0264 - mae: 0.1032 - val_loss: 0.1468 - val_mae: 0.3205
Epoch 126/5000
36/36 - 1s - loss: 0.0257 - mae: 0.1009 - val_loss: 0.1445 - val_mae: 0.3115
Epoch 127/5000
36/36 - 1s - loss: 0.0258 - mae: 0.1014 - val_loss: 0.1467 - val_mae: 0.3176
Epoch 128/5000
36/36 - 1s - loss: 0.0262 - mae: 0.1026 - val_loss: 0.1449 - val_mae: 0.3121
Epoch 129/5000
36/36 - 1s - loss: 0.0263 - mae: 0.1036 - val_loss: 0.1471 - val_mae: 0.3184
Epoch 130/5000
36/36 - 1s - loss: 0.0262 - mae: 0.1029 - val_loss: 0.1457 - val_mae: 0.3147
Epoch 131/5000
36/36 - 1s - loss: 0.0257 - mae: 0.1010 - val_loss: 0.1477 - val_mae: 0.3199
Epoch 132/5000
36/36 - 1s - loss: 0.0265 - mae: 0.1049 - val_loss: 0.1442 - val_mae: 0.3147
Epoch 133/5000
36/36 - 1s - loss: 0.0258 - mae: 0.1012 - val_loss: 0.1454 - val_mae: 0.3161
Epoch 134/5000
36/36 - 1s - loss: 0.0253 - mae: 0.1004 - val_loss: 0.1427 - val_mae: 0.3114
Epoch 135/5000
36/36 - 1s - loss: 0.0249 - mae: 0.0989 - val_loss: 0.1430 - val_mae: 0.3082
Epoch 136/5000
36/36 - 1s - loss: 0.0266 - mae: 0.1033 - val_loss: 0.1472 - val_mae: 0.3176
Epoch 137/5000
36/36 - 1s - loss: 0.0245 - mae: 0.0959 - val_loss: 0.1442 - val_mae: 0.3093
Epoch 138/5000
36/36 - 1s - loss: 0.0265 - mae: 0.1044 - val_loss: 0.1484 - val_mae: 0.3197
Epoch 139/5000
36/36 - 1s - loss: 0.0293 - mae: 0.1184 - val_loss: 0.1522 - val_mae: 0.3305
Epoch 140/5000
36/36 - 1s - loss: 0.0267 - mae: 0.1097 - val_loss: 0.1563 - val_mae: 0.3436
Restoring model weights from the end of the best epoch.
Epoch 00140: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_0..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 1

Generating graphs from SMILES..

Setting up training set.
Size: 1829

Setting up validation set.
Size: 457

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_9"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_1 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_1 (PartitionP (None, None, 64)     0           message_passing_1[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_1[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_1 (Masking)             (None, None, 64)     0           partition_padding_1[0][0]        
                                                                 partition_padding_1[1][0]        
__________________________________________________________________________________________________
transformer_encoder_1 (Transfor (None, None, 64)     199040      masking_1[0][0]                  
                                                                 masking_1[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_1 (Glo (None, 64)           0           transformer_encoder_1[0][0]      
                                                                 transformer_encoder_1[1][0]      
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 512)          33280       global_average_pooling1d_1[0][0] 
                                                                 global_average_pooling1d_1[1][0] 
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 10)           110         dense_21[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 450)          230850      dense_19[0][0]                   
                                                                 dense_19[1][0]                   
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 5)            55          dense_22[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 905)          0           dense_20[0][0]                   
                                                                 dense_20[1][0]                   
                                                                 dense_23[0][0]                   
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 700)          634200      concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 560)          392560      dense_24[0][0]                   
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 373)          209253      dense_28[0][0]                   
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 187)          69938       dense_29[0][0]                   
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 1)            188         dense_30[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
36/36 - 5s - loss: 0.3061 - mae: 0.6133 - val_loss: 0.1756 - val_mae: 0.4954
Epoch 2/5000
36/36 - 1s - loss: 0.1654 - mae: 0.4106 - val_loss: 0.1678 - val_mae: 0.4736
Epoch 3/5000
36/36 - 1s - loss: 0.1617 - mae: 0.4037 - val_loss: 0.1576 - val_mae: 0.4393
Epoch 4/5000
36/36 - 1s - loss: 0.1590 - mae: 0.3991 - val_loss: 0.1589 - val_mae: 0.4464
Epoch 5/5000
36/36 - 1s - loss: 0.1602 - mae: 0.4005 - val_loss: 0.1533 - val_mae: 0.4212
Epoch 6/5000
36/36 - 1s - loss: 0.1574 - mae: 0.3944 - val_loss: 0.1538 - val_mae: 0.4266
Epoch 7/5000
36/36 - 1s - loss: 0.1572 - mae: 0.3918 - val_loss: 0.1604 - val_mae: 0.4522
Epoch 8/5000
36/36 - 1s - loss: 0.1590 - mae: 0.3951 - val_loss: 0.1510 - val_mae: 0.4183
Epoch 9/5000
36/36 - 1s - loss: 0.1545 - mae: 0.3868 - val_loss: 0.1548 - val_mae: 0.4354
Epoch 10/5000
36/36 - 1s - loss: 0.1556 - mae: 0.3862 - val_loss: 0.1582 - val_mae: 0.4473
Epoch 11/5000
36/36 - 1s - loss: 0.1561 - mae: 0.3891 - val_loss: 0.1465 - val_mae: 0.4000
Epoch 12/5000
36/36 - 1s - loss: 0.1513 - mae: 0.3776 - val_loss: 0.1477 - val_mae: 0.4101
Epoch 13/5000
36/36 - 1s - loss: 0.1531 - mae: 0.3802 - val_loss: 0.1425 - val_mae: 0.3816
Epoch 14/5000
36/36 - 1s - loss: 0.1511 - mae: 0.3765 - val_loss: 0.1422 - val_mae: 0.3839
Epoch 15/5000
36/36 - 1s - loss: 0.1506 - mae: 0.3740 - val_loss: 0.1420 - val_mae: 0.3866
Epoch 16/5000
36/36 - 1s - loss: 0.1495 - mae: 0.3711 - val_loss: 0.1440 - val_mae: 0.3994
Epoch 17/5000
36/36 - 1s - loss: 0.1491 - mae: 0.3704 - val_loss: 0.1527 - val_mae: 0.4333
Epoch 18/5000
36/36 - 1s - loss: 0.1502 - mae: 0.3760 - val_loss: 0.1444 - val_mae: 0.3988
Epoch 19/5000
36/36 - 1s - loss: 0.1475 - mae: 0.3684 - val_loss: 0.1486 - val_mae: 0.4175
Epoch 20/5000
36/36 - 1s - loss: 0.1471 - mae: 0.3684 - val_loss: 0.1448 - val_mae: 0.4036
Epoch 21/5000
36/36 - 1s - loss: 0.1460 - mae: 0.3654 - val_loss: 0.1439 - val_mae: 0.4001
Epoch 22/5000
36/36 - 1s - loss: 0.1453 - mae: 0.3630 - val_loss: 0.1441 - val_mae: 0.4017
Epoch 23/5000
36/36 - 1s - loss: 0.1447 - mae: 0.3621 - val_loss: 0.1430 - val_mae: 0.3991
Epoch 24/5000
36/36 - 1s - loss: 0.1457 - mae: 0.3654 - val_loss: 0.1506 - val_mae: 0.4263
Epoch 25/5000
36/36 - 1s - loss: 0.1453 - mae: 0.3665 - val_loss: 0.1369 - val_mae: 0.3629
Epoch 26/5000
36/36 - 1s - loss: 0.1418 - mae: 0.3547 - val_loss: 0.1415 - val_mae: 0.3940
Epoch 27/5000
36/36 - 1s - loss: 0.1435 - mae: 0.3578 - val_loss: 0.1400 - val_mae: 0.3859
Epoch 28/5000
36/36 - 1s - loss: 0.1420 - mae: 0.3552 - val_loss: 0.1415 - val_mae: 0.3932
Epoch 29/5000
36/36 - 1s - loss: 0.1417 - mae: 0.3537 - val_loss: 0.1431 - val_mae: 0.3963
Epoch 30/5000
36/36 - 1s - loss: 0.1409 - mae: 0.3513 - val_loss: 0.1385 - val_mae: 0.3810
Epoch 31/5000
36/36 - 1s - loss: 0.1404 - mae: 0.3518 - val_loss: 0.1380 - val_mae: 0.3734
Epoch 32/5000
36/36 - 1s - loss: 0.1404 - mae: 0.3520 - val_loss: 0.1422 - val_mae: 0.3927
Epoch 33/5000
36/36 - 1s - loss: 0.1408 - mae: 0.3532 - val_loss: 0.1391 - val_mae: 0.3785
Epoch 34/5000
36/36 - 1s - loss: 0.1398 - mae: 0.3503 - val_loss: 0.1375 - val_mae: 0.3726
Epoch 35/5000
36/36 - 1s - loss: 0.1395 - mae: 0.3499 - val_loss: 0.1347 - val_mae: 0.3487
Epoch 36/5000
36/36 - 1s - loss: 0.1385 - mae: 0.3454 - val_loss: 0.1458 - val_mae: 0.4039
Epoch 37/5000
36/36 - 1s - loss: 0.1406 - mae: 0.3502 - val_loss: 0.1329 - val_mae: 0.3491
Epoch 38/5000
36/36 - 1s - loss: 0.1360 - mae: 0.3391 - val_loss: 0.1391 - val_mae: 0.3808
Epoch 39/5000
36/36 - 1s - loss: 0.1376 - mae: 0.3416 - val_loss: 0.1369 - val_mae: 0.3668
Epoch 40/5000
36/36 - 1s - loss: 0.1370 - mae: 0.3405 - val_loss: 0.1358 - val_mae: 0.3588
Epoch 41/5000
36/36 - 1s - loss: 0.1360 - mae: 0.3394 - val_loss: 0.1352 - val_mae: 0.3553
Epoch 42/5000
36/36 - 1s - loss: 0.1345 - mae: 0.3347 - val_loss: 0.1357 - val_mae: 0.3606
Epoch 43/5000
36/36 - 1s - loss: 0.1384 - mae: 0.3444 - val_loss: 0.1385 - val_mae: 0.3814
Epoch 44/5000
36/36 - 1s - loss: 0.1360 - mae: 0.3392 - val_loss: 0.1370 - val_mae: 0.3712
Epoch 45/5000
36/36 - 1s - loss: 0.1365 - mae: 0.3391 - val_loss: 0.1372 - val_mae: 0.3639
Epoch 46/5000
36/36 - 1s - loss: 0.1355 - mae: 0.3371 - val_loss: 0.1327 - val_mae: 0.3512
Epoch 47/5000
36/36 - 1s - loss: 0.1345 - mae: 0.3344 - val_loss: 0.1330 - val_mae: 0.3493
Epoch 48/5000
36/36 - 1s - loss: 0.1318 - mae: 0.3267 - val_loss: 0.1385 - val_mae: 0.3653
Epoch 49/5000
36/36 - 1s - loss: 0.1345 - mae: 0.3320 - val_loss: 0.1361 - val_mae: 0.3675
Epoch 50/5000
36/36 - 1s - loss: 0.1402 - mae: 0.3470 - val_loss: 0.1498 - val_mae: 0.4212
Epoch 51/5000
36/36 - 1s - loss: 0.1436 - mae: 0.3552 - val_loss: 0.1547 - val_mae: 0.4500
Epoch 52/5000
36/36 - 1s - loss: 0.1377 - mae: 0.3494 - val_loss: 0.1369 - val_mae: 0.3779
Epoch 53/5000
36/36 - 1s - loss: 0.1378 - mae: 0.3421 - val_loss: 0.1635 - val_mae: 0.4622
Epoch 54/5000
36/36 - 1s - loss: 0.1357 - mae: 0.3399 - val_loss: 0.1362 - val_mae: 0.3720
Epoch 55/5000
36/36 - 1s - loss: 0.1351 - mae: 0.3376 - val_loss: 0.1408 - val_mae: 0.3928
Epoch 56/5000
36/36 - 1s - loss: 0.1355 - mae: 0.3395 - val_loss: 0.1373 - val_mae: 0.3699
Epoch 57/5000
36/36 - 1s - loss: 0.1320 - mae: 0.3295 - val_loss: 0.1341 - val_mae: 0.3514
Epoch 58/5000
36/36 - 1s - loss: 0.1316 - mae: 0.3271 - val_loss: 0.1351 - val_mae: 0.3552
Epoch 59/5000
36/36 - 1s - loss: 0.1333 - mae: 0.3304 - val_loss: 0.1497 - val_mae: 0.4080
Epoch 60/5000
36/36 - 1s - loss: 0.1405 - mae: 0.3505 - val_loss: 0.1409 - val_mae: 0.3909
Epoch 61/5000
36/36 - 1s - loss: 0.1332 - mae: 0.3357 - val_loss: 0.1312 - val_mae: 0.3456
Epoch 62/5000
36/36 - 1s - loss: 0.1340 - mae: 0.3304 - val_loss: 0.1790 - val_mae: 0.4906
Epoch 63/5000
36/36 - 1s - loss: 0.1379 - mae: 0.3468 - val_loss: 0.1377 - val_mae: 0.3744
Epoch 64/5000
36/36 - 1s - loss: 0.1363 - mae: 0.3348 - val_loss: 0.1656 - val_mae: 0.4597
Epoch 65/5000
36/36 - 1s - loss: 0.1373 - mae: 0.3452 - val_loss: 0.1499 - val_mae: 0.4076
Epoch 66/5000
36/36 - 1s - loss: 0.1368 - mae: 0.3424 - val_loss: 0.1589 - val_mae: 0.4365
Epoch 67/5000
36/36 - 1s - loss: 0.1370 - mae: 0.3416 - val_loss: 0.1531 - val_mae: 0.4303
Epoch 68/5000
36/36 - 1s - loss: 0.1342 - mae: 0.3382 - val_loss: 0.1611 - val_mae: 0.4372
Epoch 69/5000
36/36 - 1s - loss: 0.1362 - mae: 0.3389 - val_loss: 0.1666 - val_mae: 0.4633
Epoch 70/5000
36/36 - 1s - loss: 0.1389 - mae: 0.3432 - val_loss: 0.1554 - val_mae: 0.4206
Epoch 71/5000
36/36 - 1s - loss: 0.1390 - mae: 0.3479 - val_loss: 0.1886 - val_mae: 0.5124
Epoch 72/5000
36/36 - 1s - loss: 0.1394 - mae: 0.3513 - val_loss: 0.1532 - val_mae: 0.4242
Epoch 73/5000
36/36 - 1s - loss: 0.1316 - mae: 0.3303 - val_loss: 0.1495 - val_mae: 0.4087
Epoch 74/5000
36/36 - 1s - loss: 0.1307 - mae: 0.3259 - val_loss: 0.1486 - val_mae: 0.4072
Epoch 75/5000
36/36 - 1s - loss: 0.1297 - mae: 0.3233 - val_loss: 0.1561 - val_mae: 0.4252
Epoch 76/5000
36/36 - 1s - loss: 0.1361 - mae: 0.3375 - val_loss: 0.1684 - val_mae: 0.4657
Epoch 77/5000
36/36 - 1s - loss: 0.1374 - mae: 0.3420 - val_loss: 0.1797 - val_mae: 0.4800
Epoch 78/5000
36/36 - 1s - loss: 0.1365 - mae: 0.3373 - val_loss: 0.1662 - val_mae: 0.4533
Epoch 79/5000
36/36 - 1s - loss: 0.1354 - mae: 0.3379 - val_loss: 0.1644 - val_mae: 0.4525
Epoch 80/5000
36/36 - 1s - loss: 0.1332 - mae: 0.3305 - val_loss: 0.1591 - val_mae: 0.4246
Epoch 81/5000
36/36 - 1s - loss: 0.1342 - mae: 0.3337 - val_loss: 0.1577 - val_mae: 0.4344
Epoch 82/5000
36/36 - 1s - loss: 0.1328 - mae: 0.3300 - val_loss: 0.1588 - val_mae: 0.4301
Epoch 83/5000
36/36 - 1s - loss: 0.1334 - mae: 0.3325 - val_loss: 0.1563 - val_mae: 0.4292
Epoch 84/5000
36/36 - 1s - loss: 0.1336 - mae: 0.3328 - val_loss: 0.1729 - val_mae: 0.4598
Epoch 85/5000
36/36 - 1s - loss: 0.1354 - mae: 0.3384 - val_loss: 0.1431 - val_mae: 0.3828
Epoch 86/5000
36/36 - 1s - loss: 0.1263 - mae: 0.3149 - val_loss: 0.1601 - val_mae: 0.4238
Epoch 87/5000
36/36 - 1s - loss: 0.1327 - mae: 0.3276 - val_loss: 0.1567 - val_mae: 0.4341
Epoch 88/5000
36/36 - 1s - loss: 0.1326 - mae: 0.3312 - val_loss: 0.1611 - val_mae: 0.4315
Epoch 89/5000
36/36 - 1s - loss: 0.1324 - mae: 0.3284 - val_loss: 0.1502 - val_mae: 0.4117
Epoch 90/5000
36/36 - 1s - loss: 0.1287 - mae: 0.3221 - val_loss: 0.1582 - val_mae: 0.4260
Epoch 91/5000
36/36 - 1s - loss: 0.1281 - mae: 0.3195 - val_loss: 0.1625 - val_mae: 0.4339
Epoch 92/5000
36/36 - 1s - loss: 0.1291 - mae: 0.3218 - val_loss: 0.1696 - val_mae: 0.4564
Epoch 93/5000
36/36 - 1s - loss: 0.1311 - mae: 0.3246 - val_loss: 0.1638 - val_mae: 0.4368
Epoch 94/5000
36/36 - 1s - loss: 0.1337 - mae: 0.3327 - val_loss: 0.1424 - val_mae: 0.3836
Epoch 95/5000
36/36 - 1s - loss: 0.1257 - mae: 0.3158 - val_loss: 0.1743 - val_mae: 0.4558
Epoch 96/5000
36/36 - 1s - loss: 0.1290 - mae: 0.3208 - val_loss: 0.1651 - val_mae: 0.4406
Epoch 97/5000
36/36 - 1s - loss: 0.1310 - mae: 0.3242 - val_loss: 0.1644 - val_mae: 0.4440
Epoch 98/5000
36/36 - 1s - loss: 0.1332 - mae: 0.3365 - val_loss: 0.1561 - val_mae: 0.4142
Epoch 99/5000
36/36 - 1s - loss: 0.1256 - mae: 0.3155 - val_loss: 0.1734 - val_mae: 0.4500
Epoch 100/5000
36/36 - 1s - loss: 0.1303 - mae: 0.3212 - val_loss: 0.1604 - val_mae: 0.4277
Epoch 101/5000
36/36 - 1s - loss: 0.1304 - mae: 0.3248 - val_loss: 0.1604 - val_mae: 0.4274
Epoch 102/5000
36/36 - 1s - loss: 0.1300 - mae: 0.3241 - val_loss: 0.1644 - val_mae: 0.4378
Epoch 103/5000
36/36 - 1s - loss: 0.1306 - mae: 0.3264 - val_loss: 0.1512 - val_mae: 0.4027
Epoch 104/5000
36/36 - 1s - loss: 0.1275 - mae: 0.3169 - val_loss: 0.1620 - val_mae: 0.4302
Epoch 105/5000
36/36 - 1s - loss: 0.1304 - mae: 0.3287 - val_loss: 0.1572 - val_mae: 0.4125
Epoch 106/5000
36/36 - 1s - loss: 0.1240 - mae: 0.3101 - val_loss: 0.1780 - val_mae: 0.4615
Epoch 107/5000
36/36 - 1s - loss: 0.1267 - mae: 0.3157 - val_loss: 0.1687 - val_mae: 0.4526
Epoch 108/5000
36/36 - 1s - loss: 0.1292 - mae: 0.3197 - val_loss: 0.1658 - val_mae: 0.4374
Epoch 109/5000
36/36 - 1s - loss: 0.1313 - mae: 0.3287 - val_loss: 0.1480 - val_mae: 0.3882
Epoch 110/5000
36/36 - 1s - loss: 0.1234 - mae: 0.3101 - val_loss: 0.1702 - val_mae: 0.4426
Epoch 111/5000
36/36 - 1s - loss: 0.1250 - mae: 0.3112 - val_loss: 0.1784 - val_mae: 0.4698
Epoch 112/5000
36/36 - 1s - loss: 0.1310 - mae: 0.3269 - val_loss: 0.1438 - val_mae: 0.3842
Epoch 113/5000
36/36 - 1s - loss: 0.1255 - mae: 0.3132 - val_loss: 0.1690 - val_mae: 0.4442
Epoch 114/5000
36/36 - 1s - loss: 0.1287 - mae: 0.3211 - val_loss: 0.1493 - val_mae: 0.3948
Epoch 115/5000
36/36 - 1s - loss: 0.1231 - mae: 0.3083 - val_loss: 0.1801 - val_mae: 0.4678
Epoch 116/5000
36/36 - 1s - loss: 0.1284 - mae: 0.3186 - val_loss: 0.1401 - val_mae: 0.3718
Epoch 117/5000
36/36 - 1s - loss: 0.1298 - mae: 0.3263 - val_loss: 0.1435 - val_mae: 0.3802
Epoch 118/5000
36/36 - 1s - loss: 0.1223 - mae: 0.3049 - val_loss: 0.1590 - val_mae: 0.4241
Epoch 119/5000
36/36 - 1s - loss: 0.1265 - mae: 0.3148 - val_loss: 0.1589 - val_mae: 0.4211
Epoch 120/5000
36/36 - 1s - loss: 0.1268 - mae: 0.3167 - val_loss: 0.1568 - val_mae: 0.4153
Epoch 121/5000
36/36 - 1s - loss: 0.1283 - mae: 0.3216 - val_loss: 0.1425 - val_mae: 0.3658
Epoch 122/5000
36/36 - 1s - loss: 0.1240 - mae: 0.3098 - val_loss: 0.1669 - val_mae: 0.4385
Epoch 123/5000
36/36 - 1s - loss: 0.1283 - mae: 0.3209 - val_loss: 0.1414 - val_mae: 0.3625
Epoch 124/5000
36/36 - 1s - loss: 0.1238 - mae: 0.3099 - val_loss: 0.1495 - val_mae: 0.3895
Epoch 125/5000
36/36 - 1s - loss: 0.1317 - mae: 0.3296 - val_loss: 0.1387 - val_mae: 0.3645
Epoch 126/5000
36/36 - 1s - loss: 0.1276 - mae: 0.3226 - val_loss: 0.1505 - val_mae: 0.4005
Epoch 127/5000
36/36 - 1s - loss: 0.1271 - mae: 0.3187 - val_loss: 0.1490 - val_mae: 0.3944
Epoch 128/5000
36/36 - 1s - loss: 0.1231 - mae: 0.3072 - val_loss: 0.1471 - val_mae: 0.3914
Epoch 129/5000
36/36 - 1s - loss: 0.1226 - mae: 0.3072 - val_loss: 0.1617 - val_mae: 0.4236
Epoch 130/5000
36/36 - 1s - loss: 0.1208 - mae: 0.3046 - val_loss: 0.1719 - val_mae: 0.4425
Epoch 131/5000
36/36 - 1s - loss: 0.1219 - mae: 0.3054 - val_loss: 0.1554 - val_mae: 0.4094
Epoch 132/5000
36/36 - 1s - loss: 0.1211 - mae: 0.3036 - val_loss: 0.1742 - val_mae: 0.4504
Epoch 133/5000
36/36 - 1s - loss: 0.1271 - mae: 0.3162 - val_loss: 0.1384 - val_mae: 0.3633
Epoch 134/5000
36/36 - 1s - loss: 0.1294 - mae: 0.3262 - val_loss: 0.1524 - val_mae: 0.3987
Epoch 135/5000
36/36 - 1s - loss: 0.1206 - mae: 0.3025 - val_loss: 0.1671 - val_mae: 0.4392
Epoch 136/5000
36/36 - 1s - loss: 0.1249 - mae: 0.3129 - val_loss: 0.1526 - val_mae: 0.4067
Epoch 137/5000
36/36 - 1s - loss: 0.1229 - mae: 0.3102 - val_loss: 0.1496 - val_mae: 0.3871
Epoch 138/5000
36/36 - 1s - loss: 0.1199 - mae: 0.3019 - val_loss: 0.1730 - val_mae: 0.4447
Epoch 139/5000
36/36 - 1s - loss: 0.1198 - mae: 0.3013 - val_loss: 0.1681 - val_mae: 0.4334
Epoch 140/5000
36/36 - 1s - loss: 0.1216 - mae: 0.3048 - val_loss: 0.1457 - val_mae: 0.3823
Epoch 141/5000
36/36 - 1s - loss: 0.1295 - mae: 0.3243 - val_loss: 0.1505 - val_mae: 0.4033
Epoch 142/5000
36/36 - 1s - loss: 0.1252 - mae: 0.3171 - val_loss: 0.1524 - val_mae: 0.3962
Epoch 143/5000
36/36 - 1s - loss: 0.1203 - mae: 0.3054 - val_loss: 0.1636 - val_mae: 0.4295
Epoch 144/5000
36/36 - 1s - loss: 0.1218 - mae: 0.3075 - val_loss: 0.1535 - val_mae: 0.4094
Epoch 145/5000
36/36 - 1s - loss: 0.1192 - mae: 0.3021 - val_loss: 0.1581 - val_mae: 0.4170
Epoch 146/5000
36/36 - 1s - loss: 0.1197 - mae: 0.3017 - val_loss: 0.1621 - val_mae: 0.4260
Epoch 147/5000
36/36 - 1s - loss: 0.1200 - mae: 0.3045 - val_loss: 0.1618 - val_mae: 0.4205
Epoch 148/5000
36/36 - 1s - loss: 0.1190 - mae: 0.3013 - val_loss: 0.1769 - val_mae: 0.4562
Epoch 149/5000
36/36 - 1s - loss: 0.1283 - mae: 0.3217 - val_loss: 0.1509 - val_mae: 0.4025
Epoch 150/5000
36/36 - 1s - loss: 0.1249 - mae: 0.3142 - val_loss: 0.1399 - val_mae: 0.3670
Epoch 151/5000
36/36 - 1s - loss: 0.1279 - mae: 0.3203 - val_loss: 0.1360 - val_mae: 0.3558
Epoch 152/5000
36/36 - 1s - loss: 0.1205 - mae: 0.3031 - val_loss: 0.1526 - val_mae: 0.4051
Epoch 153/5000
36/36 - 1s - loss: 0.1216 - mae: 0.3077 - val_loss: 0.1603 - val_mae: 0.4300
Epoch 154/5000
36/36 - 1s - loss: 0.1210 - mae: 0.3102 - val_loss: 0.1582 - val_mae: 0.4255
Epoch 155/5000
36/36 - 1s - loss: 0.1218 - mae: 0.3079 - val_loss: 0.1497 - val_mae: 0.4036
Epoch 156/5000
36/36 - 1s - loss: 0.1219 - mae: 0.3110 - val_loss: 0.1581 - val_mae: 0.4224
Epoch 157/5000
36/36 - 1s - loss: 0.1215 - mae: 0.3083 - val_loss: 0.1500 - val_mae: 0.4001
Epoch 158/5000
36/36 - 1s - loss: 0.1203 - mae: 0.3050 - val_loss: 0.1523 - val_mae: 0.4081
Epoch 159/5000
36/36 - 1s - loss: 0.1212 - mae: 0.3089 - val_loss: 0.1563 - val_mae: 0.4176
Epoch 160/5000
36/36 - 1s - loss: 0.1207 - mae: 0.3045 - val_loss: 0.1498 - val_mae: 0.4000
Epoch 161/5000
36/36 - 1s - loss: 0.1230 - mae: 0.3116 - val_loss: 0.1444 - val_mae: 0.3856
Epoch 162/5000
36/36 - 1s - loss: 0.1275 - mae: 0.3221 - val_loss: 0.1571 - val_mae: 0.4181
Restoring model weights from the end of the best epoch.
Epoch 00162: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_1..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_9"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_1 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_1 (PartitionP (None, None, 64)     0           message_passing_1[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_1[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_1 (Masking)             (None, None, 64)     0           partition_padding_1[0][0]        
                                                                 partition_padding_1[1][0]        
__________________________________________________________________________________________________
transformer_encoder_1 (Transfor (None, None, 64)     199040      masking_1[0][0]                  
                                                                 masking_1[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_1 (Glo (None, 64)           0           transformer_encoder_1[0][0]      
                                                                 transformer_encoder_1[1][0]      
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 512)          33280       global_average_pooling1d_1[0][0] 
                                                                 global_average_pooling1d_1[1][0] 
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 10)           110         dense_21[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 450)          230850      dense_19[0][0]                   
                                                                 dense_19[1][0]                   
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 5)            55          dense_22[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 905)          0           dense_20[0][0]                   
                                                                 dense_20[1][0]                   
                                                                 dense_23[0][0]                   
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 700)          634200      concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 560)          392560      dense_24[0][0]                   
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 373)          209253      dense_28[0][0]                   
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 187)          69938       dense_29[0][0]                   
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 1)            188         dense_30[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
36/36 - 7s - loss: 0.1313 - mae: 0.3237 - val_loss: 0.1499 - val_mae: 0.4210
Epoch 2/5000
36/36 - 1s - loss: 0.1273 - mae: 0.3190 - val_loss: 0.1304 - val_mae: 0.3377
Epoch 3/5000
36/36 - 1s - loss: 0.1212 - mae: 0.3039 - val_loss: 0.1299 - val_mae: 0.3372
Epoch 4/5000
36/36 - 1s - loss: 0.1215 - mae: 0.3059 - val_loss: 0.1300 - val_mae: 0.3103
Epoch 5/5000
36/36 - 1s - loss: 0.1194 - mae: 0.3032 - val_loss: 0.1309 - val_mae: 0.3072
Epoch 6/5000
36/36 - 1s - loss: 0.1134 - mae: 0.2902 - val_loss: 0.1250 - val_mae: 0.3004
Epoch 7/5000
36/36 - 1s - loss: 0.1083 - mae: 0.2775 - val_loss: 0.1260 - val_mae: 0.3168
Epoch 8/5000
36/36 - 1s - loss: 0.1064 - mae: 0.2720 - val_loss: 0.1272 - val_mae: 0.3255
Epoch 9/5000
36/36 - 1s - loss: 0.1053 - mae: 0.2700 - val_loss: 0.1275 - val_mae: 0.3265
Epoch 10/5000
36/36 - 1s - loss: 0.1031 - mae: 0.2660 - val_loss: 0.1279 - val_mae: 0.3320
Epoch 11/5000
36/36 - 1s - loss: 0.1006 - mae: 0.2603 - val_loss: 0.1305 - val_mae: 0.3415
Epoch 12/5000
36/36 - 1s - loss: 0.0983 - mae: 0.2540 - val_loss: 0.1329 - val_mae: 0.3482
Epoch 13/5000
36/36 - 1s - loss: 0.0968 - mae: 0.2501 - val_loss: 0.1395 - val_mae: 0.3635
Epoch 14/5000
36/36 - 1s - loss: 0.0947 - mae: 0.2454 - val_loss: 0.1419 - val_mae: 0.3679
Epoch 15/5000
36/36 - 1s - loss: 0.0928 - mae: 0.2409 - val_loss: 0.1450 - val_mae: 0.3743
Epoch 16/5000
36/36 - 1s - loss: 0.0918 - mae: 0.2385 - val_loss: 0.1434 - val_mae: 0.3686
Epoch 17/5000
36/36 - 1s - loss: 0.0921 - mae: 0.2399 - val_loss: 0.1411 - val_mae: 0.3639
Epoch 18/5000
36/36 - 1s - loss: 0.0957 - mae: 0.2497 - val_loss: 0.1267 - val_mae: 0.3200
Epoch 19/5000
36/36 - 1s - loss: 0.0947 - mae: 0.2511 - val_loss: 0.1246 - val_mae: 0.3203
Epoch 20/5000
36/36 - 1s - loss: 0.0867 - mae: 0.2289 - val_loss: 0.1317 - val_mae: 0.3453
Epoch 21/5000
36/36 - 1s - loss: 0.0840 - mae: 0.2228 - val_loss: 0.1312 - val_mae: 0.3350
Epoch 22/5000
36/36 - 1s - loss: 0.0832 - mae: 0.2201 - val_loss: 0.1349 - val_mae: 0.3485
Epoch 23/5000
36/36 - 1s - loss: 0.0822 - mae: 0.2183 - val_loss: 0.1302 - val_mae: 0.3331
Epoch 24/5000
36/36 - 1s - loss: 0.0812 - mae: 0.2166 - val_loss: 0.1323 - val_mae: 0.3400
Epoch 25/5000
36/36 - 1s - loss: 0.0813 - mae: 0.2171 - val_loss: 0.1311 - val_mae: 0.3376
Epoch 26/5000
36/36 - 1s - loss: 0.0822 - mae: 0.2206 - val_loss: 0.1245 - val_mae: 0.3152
Epoch 27/5000
36/36 - 1s - loss: 0.0857 - mae: 0.2334 - val_loss: 0.1219 - val_mae: 0.3112
Epoch 28/5000
36/36 - 1s - loss: 0.0868 - mae: 0.2365 - val_loss: 0.1278 - val_mae: 0.3367
Epoch 29/5000
36/36 - 1s - loss: 0.0827 - mae: 0.2259 - val_loss: 0.1308 - val_mae: 0.3460
Epoch 30/5000
36/36 - 1s - loss: 0.0823 - mae: 0.2244 - val_loss: 0.1244 - val_mae: 0.3181
Epoch 31/5000
36/36 - 1s - loss: 0.0805 - mae: 0.2190 - val_loss: 0.1237 - val_mae: 0.3167
Epoch 32/5000
36/36 - 1s - loss: 0.0813 - mae: 0.2210 - val_loss: 0.1235 - val_mae: 0.2999
Epoch 33/5000
36/36 - 1s - loss: 0.0910 - mae: 0.2467 - val_loss: 0.1286 - val_mae: 0.2989
Epoch 34/5000
36/36 - 1s - loss: 0.1011 - mae: 0.2630 - val_loss: 0.1259 - val_mae: 0.2986
Epoch 35/5000
36/36 - 1s - loss: 0.0926 - mae: 0.2498 - val_loss: 0.1158 - val_mae: 0.2942
Epoch 36/5000
36/36 - 1s - loss: 0.0816 - mae: 0.2240 - val_loss: 0.1183 - val_mae: 0.3037
Epoch 37/5000
36/36 - 1s - loss: 0.0725 - mae: 0.2005 - val_loss: 0.1197 - val_mae: 0.3046
Epoch 38/5000
36/36 - 1s - loss: 0.0687 - mae: 0.1912 - val_loss: 0.1197 - val_mae: 0.3041
Epoch 39/5000
36/36 - 1s - loss: 0.0669 - mae: 0.1874 - val_loss: 0.1190 - val_mae: 0.3059
Epoch 40/5000
36/36 - 1s - loss: 0.0657 - mae: 0.1854 - val_loss: 0.1206 - val_mae: 0.3123
Epoch 41/5000
36/36 - 1s - loss: 0.0643 - mae: 0.1822 - val_loss: 0.1206 - val_mae: 0.3089
Epoch 42/5000
36/36 - 1s - loss: 0.0640 - mae: 0.1824 - val_loss: 0.1200 - val_mae: 0.3089
Epoch 43/5000
36/36 - 1s - loss: 0.0635 - mae: 0.1810 - val_loss: 0.1188 - val_mae: 0.2997
Epoch 44/5000
36/36 - 1s - loss: 0.0685 - mae: 0.1948 - val_loss: 0.1214 - val_mae: 0.3023
Epoch 45/5000
36/36 - 1s - loss: 0.0724 - mae: 0.2085 - val_loss: 0.1174 - val_mae: 0.2909
Epoch 46/5000
36/36 - 1s - loss: 0.0791 - mae: 0.2242 - val_loss: 0.1171 - val_mae: 0.2977
Epoch 47/5000
36/36 - 1s - loss: 0.0692 - mae: 0.1995 - val_loss: 0.1172 - val_mae: 0.2977
Epoch 48/5000
36/36 - 1s - loss: 0.0649 - mae: 0.1915 - val_loss: 0.1185 - val_mae: 0.2927
Epoch 49/5000
36/36 - 1s - loss: 0.0640 - mae: 0.1905 - val_loss: 0.1144 - val_mae: 0.2857
Epoch 50/5000
36/36 - 1s - loss: 0.0641 - mae: 0.1921 - val_loss: 0.1189 - val_mae: 0.2928
Epoch 51/5000
36/36 - 1s - loss: 0.0730 - mae: 0.2137 - val_loss: 0.1166 - val_mae: 0.2911
Epoch 52/5000
36/36 - 1s - loss: 0.0758 - mae: 0.2212 - val_loss: 0.1302 - val_mae: 0.3463
Epoch 53/5000
36/36 - 1s - loss: 0.0778 - mae: 0.2216 - val_loss: 0.1310 - val_mae: 0.3468
Epoch 54/5000
36/36 - 1s - loss: 0.0807 - mae: 0.2398 - val_loss: 0.1273 - val_mae: 0.3323
Epoch 55/5000
36/36 - 1s - loss: 0.0643 - mae: 0.1949 - val_loss: 0.1434 - val_mae: 0.3749
Epoch 56/5000
36/36 - 1s - loss: 0.0643 - mae: 0.1977 - val_loss: 0.1451 - val_mae: 0.3536
Epoch 57/5000
36/36 - 1s - loss: 0.0603 - mae: 0.1847 - val_loss: 0.1220 - val_mae: 0.2971
Epoch 58/5000
36/36 - 1s - loss: 0.0600 - mae: 0.1857 - val_loss: 0.1334 - val_mae: 0.3338
Epoch 59/5000
36/36 - 1s - loss: 0.0639 - mae: 0.1932 - val_loss: 0.1492 - val_mae: 0.3678
Epoch 60/5000
36/36 - 1s - loss: 0.0742 - mae: 0.2215 - val_loss: 0.1306 - val_mae: 0.3220
Epoch 61/5000
36/36 - 1s - loss: 0.0585 - mae: 0.1807 - val_loss: 0.1357 - val_mae: 0.3302
Epoch 62/5000
36/36 - 1s - loss: 0.0541 - mae: 0.1687 - val_loss: 0.1247 - val_mae: 0.2940
Epoch 63/5000
36/36 - 1s - loss: 0.0536 - mae: 0.1697 - val_loss: 0.1405 - val_mae: 0.3325
Epoch 64/5000
36/36 - 1s - loss: 0.0522 - mae: 0.1678 - val_loss: 0.1277 - val_mae: 0.2958
Epoch 65/5000
36/36 - 1s - loss: 0.0508 - mae: 0.1630 - val_loss: 0.1521 - val_mae: 0.3571
Epoch 66/5000
36/36 - 1s - loss: 0.0494 - mae: 0.1625 - val_loss: 0.1450 - val_mae: 0.3325
Epoch 67/5000
36/36 - 1s - loss: 0.0538 - mae: 0.1731 - val_loss: 0.1497 - val_mae: 0.3510
Epoch 68/5000
36/36 - 1s - loss: 0.0542 - mae: 0.1774 - val_loss: 0.1397 - val_mae: 0.3233
Epoch 69/5000
36/36 - 1s - loss: 0.0562 - mae: 0.1789 - val_loss: 0.1317 - val_mae: 0.3068
Epoch 70/5000
36/36 - 1s - loss: 0.0530 - mae: 0.1721 - val_loss: 0.1263 - val_mae: 0.2944
Epoch 71/5000
36/36 - 1s - loss: 0.0531 - mae: 0.1737 - val_loss: 0.1273 - val_mae: 0.2966
Epoch 72/5000
36/36 - 1s - loss: 0.0517 - mae: 0.1717 - val_loss: 0.1254 - val_mae: 0.2903
Epoch 73/5000
36/36 - 1s - loss: 0.0530 - mae: 0.1799 - val_loss: 0.1246 - val_mae: 0.2932
Epoch 74/5000
36/36 - 1s - loss: 0.0564 - mae: 0.1868 - val_loss: 0.1455 - val_mae: 0.3501
Epoch 75/5000
36/36 - 1s - loss: 0.0561 - mae: 0.1877 - val_loss: 0.1360 - val_mae: 0.3121
Epoch 76/5000
36/36 - 1s - loss: 0.0491 - mae: 0.1666 - val_loss: 0.1315 - val_mae: 0.3071
Epoch 77/5000
36/36 - 1s - loss: 0.0526 - mae: 0.1754 - val_loss: 0.1452 - val_mae: 0.3443
Epoch 78/5000
36/36 - 1s - loss: 0.0574 - mae: 0.1872 - val_loss: 0.1282 - val_mae: 0.2921
Epoch 79/5000
36/36 - 1s - loss: 0.0540 - mae: 0.1784 - val_loss: 0.1308 - val_mae: 0.2984
Epoch 80/5000
36/36 - 1s - loss: 0.0614 - mae: 0.2027 - val_loss: 0.1291 - val_mae: 0.3036
Epoch 81/5000
36/36 - 1s - loss: 0.0611 - mae: 0.1933 - val_loss: 0.1253 - val_mae: 0.2921
Epoch 82/5000
36/36 - 1s - loss: 0.0552 - mae: 0.1901 - val_loss: 0.1216 - val_mae: 0.2905
Epoch 83/5000
36/36 - 1s - loss: 0.0672 - mae: 0.2183 - val_loss: 0.1242 - val_mae: 0.2971
Epoch 84/5000
36/36 - 1s - loss: 0.0582 - mae: 0.1997 - val_loss: 0.1294 - val_mae: 0.3019
Epoch 85/5000
36/36 - 1s - loss: 0.0642 - mae: 0.2199 - val_loss: 0.1347 - val_mae: 0.3132
Epoch 86/5000
36/36 - 1s - loss: 0.0665 - mae: 0.2271 - val_loss: 0.1324 - val_mae: 0.3216
Epoch 87/5000
36/36 - 1s - loss: 0.0715 - mae: 0.2298 - val_loss: 0.1315 - val_mae: 0.3138
Epoch 88/5000
36/36 - 1s - loss: 0.0643 - mae: 0.2143 - val_loss: 0.1616 - val_mae: 0.3681
Epoch 89/5000
36/36 - 1s - loss: 0.0559 - mae: 0.1888 - val_loss: 0.1334 - val_mae: 0.3146
Epoch 90/5000
36/36 - 1s - loss: 0.0479 - mae: 0.1777 - val_loss: 0.1298 - val_mae: 0.3043
Epoch 91/5000
36/36 - 1s - loss: 0.0448 - mae: 0.1690 - val_loss: 0.1273 - val_mae: 0.2978
Epoch 92/5000
36/36 - 1s - loss: 0.0454 - mae: 0.1727 - val_loss: 0.1289 - val_mae: 0.2987
Epoch 93/5000
36/36 - 1s - loss: 0.0459 - mae: 0.1721 - val_loss: 0.1279 - val_mae: 0.3008
Epoch 94/5000
36/36 - 1s - loss: 0.0485 - mae: 0.1823 - val_loss: 0.1328 - val_mae: 0.3061
Epoch 95/5000
36/36 - 1s - loss: 0.0472 - mae: 0.1778 - val_loss: 0.1443 - val_mae: 0.3195
Epoch 96/5000
36/36 - 1s - loss: 0.0514 - mae: 0.1862 - val_loss: 0.1629 - val_mae: 0.3542
Epoch 97/5000
36/36 - 1s - loss: 0.0483 - mae: 0.1791 - val_loss: 0.1910 - val_mae: 0.4091
Epoch 98/5000
36/36 - 1s - loss: 0.0499 - mae: 0.1811 - val_loss: 0.1887 - val_mae: 0.4215
Epoch 99/5000
36/36 - 1s - loss: 0.0523 - mae: 0.1868 - val_loss: 0.1634 - val_mae: 0.3724
Epoch 100/5000
36/36 - 1s - loss: 0.0470 - mae: 0.1722 - val_loss: 0.1376 - val_mae: 0.3103
Epoch 101/5000
36/36 - 1s - loss: 0.0415 - mae: 0.1660 - val_loss: 0.1480 - val_mae: 0.3210
Epoch 102/5000
36/36 - 1s - loss: 0.0359 - mae: 0.1443 - val_loss: 0.1399 - val_mae: 0.3160
Epoch 103/5000
36/36 - 1s - loss: 0.0373 - mae: 0.1506 - val_loss: 0.1401 - val_mae: 0.3090
Epoch 104/5000
36/36 - 1s - loss: 0.0403 - mae: 0.1591 - val_loss: 0.1375 - val_mae: 0.3040
Epoch 105/5000
36/36 - 1s - loss: 0.0350 - mae: 0.1457 - val_loss: 0.1380 - val_mae: 0.2989
Epoch 106/5000
36/36 - 1s - loss: 0.0347 - mae: 0.1480 - val_loss: 0.1345 - val_mae: 0.2977
Epoch 107/5000
36/36 - 1s - loss: 0.0397 - mae: 0.1588 - val_loss: 0.1338 - val_mae: 0.2991
Epoch 108/5000
36/36 - 1s - loss: 0.0369 - mae: 0.1581 - val_loss: 0.1391 - val_mae: 0.3042
Epoch 109/5000
36/36 - 1s - loss: 0.0402 - mae: 0.1645 - val_loss: 0.1529 - val_mae: 0.3324
Epoch 110/5000
36/36 - 1s - loss: 0.0442 - mae: 0.1729 - val_loss: 0.1742 - val_mae: 0.3740
Epoch 111/5000
36/36 - 1s - loss: 0.0383 - mae: 0.1562 - val_loss: 0.1799 - val_mae: 0.3880
Epoch 112/5000
36/36 - 1s - loss: 0.0421 - mae: 0.1606 - val_loss: 0.1897 - val_mae: 0.4153
Epoch 113/5000
36/36 - 1s - loss: 0.0381 - mae: 0.1511 - val_loss: 0.1575 - val_mae: 0.3630
Epoch 114/5000
36/36 - 1s - loss: 0.0363 - mae: 0.1517 - val_loss: 0.1486 - val_mae: 0.3204
Epoch 115/5000
36/36 - 1s - loss: 0.0334 - mae: 0.1472 - val_loss: 0.1370 - val_mae: 0.3025
Epoch 116/5000
36/36 - 1s - loss: 0.0323 - mae: 0.1416 - val_loss: 0.1445 - val_mae: 0.3254
Epoch 117/5000
36/36 - 1s - loss: 0.0305 - mae: 0.1386 - val_loss: 0.1461 - val_mae: 0.3174
Epoch 118/5000
36/36 - 1s - loss: 0.0314 - mae: 0.1409 - val_loss: 0.1400 - val_mae: 0.3027
Epoch 119/5000
36/36 - 1s - loss: 0.0268 - mae: 0.1278 - val_loss: 0.1460 - val_mae: 0.3107
Epoch 120/5000
36/36 - 1s - loss: 0.0279 - mae: 0.1304 - val_loss: 0.1421 - val_mae: 0.3057
Epoch 121/5000
36/36 - 1s - loss: 0.0290 - mae: 0.1365 - val_loss: 0.1524 - val_mae: 0.3236
Epoch 122/5000
36/36 - 1s - loss: 0.0327 - mae: 0.1483 - val_loss: 0.1593 - val_mae: 0.3427
Epoch 123/5000
36/36 - 1s - loss: 0.0371 - mae: 0.1591 - val_loss: 0.1831 - val_mae: 0.4036
Epoch 124/5000
36/36 - 1s - loss: 0.0392 - mae: 0.1612 - val_loss: 0.1958 - val_mae: 0.4307
Epoch 125/5000
36/36 - 1s - loss: 0.0391 - mae: 0.1590 - val_loss: 0.1809 - val_mae: 0.4023
Epoch 126/5000
36/36 - 1s - loss: 0.0335 - mae: 0.1479 - val_loss: 0.1625 - val_mae: 0.3489
Epoch 127/5000
36/36 - 1s - loss: 0.0342 - mae: 0.1472 - val_loss: 0.1389 - val_mae: 0.3159
Epoch 128/5000
36/36 - 1s - loss: 0.0404 - mae: 0.1610 - val_loss: 0.1271 - val_mae: 0.2984
Epoch 129/5000
36/36 - 1s - loss: 0.0369 - mae: 0.1609 - val_loss: 0.1386 - val_mae: 0.3091
Epoch 130/5000
36/36 - 1s - loss: 0.0358 - mae: 0.1528 - val_loss: 0.1439 - val_mae: 0.3191
Epoch 131/5000
36/36 - 1s - loss: 0.0288 - mae: 0.1326 - val_loss: 0.1537 - val_mae: 0.3311
Epoch 132/5000
36/36 - 1s - loss: 0.0257 - mae: 0.1262 - val_loss: 0.1713 - val_mae: 0.3649
Epoch 133/5000
36/36 - 1s - loss: 0.0237 - mae: 0.1189 - val_loss: 0.1608 - val_mae: 0.3596
Epoch 134/5000
36/36 - 1s - loss: 0.0295 - mae: 0.1331 - val_loss: 0.1494 - val_mae: 0.3335
Epoch 135/5000
36/36 - 1s - loss: 0.0317 - mae: 0.1423 - val_loss: 0.1283 - val_mae: 0.2936
Epoch 136/5000
36/36 - 1s - loss: 0.0305 - mae: 0.1408 - val_loss: 0.1466 - val_mae: 0.3125
Epoch 137/5000
36/36 - 1s - loss: 0.0305 - mae: 0.1383 - val_loss: 0.1471 - val_mae: 0.3141
Epoch 138/5000
36/36 - 1s - loss: 0.0255 - mae: 0.1261 - val_loss: 0.1540 - val_mae: 0.3332
Epoch 139/5000
36/36 - 1s - loss: 0.0205 - mae: 0.1104 - val_loss: 0.1637 - val_mae: 0.3515
Epoch 140/5000
36/36 - 1s - loss: 0.0227 - mae: 0.1130 - val_loss: 0.1512 - val_mae: 0.3214
Epoch 141/5000
36/36 - 1s - loss: 0.0211 - mae: 0.1112 - val_loss: 0.1597 - val_mae: 0.3498
Epoch 142/5000
36/36 - 1s - loss: 0.0212 - mae: 0.1104 - val_loss: 0.1576 - val_mae: 0.3362
Epoch 143/5000
36/36 - 1s - loss: 0.0207 - mae: 0.1066 - val_loss: 0.1406 - val_mae: 0.3147
Epoch 144/5000
36/36 - 1s - loss: 0.0212 - mae: 0.1116 - val_loss: 0.1462 - val_mae: 0.3163
Epoch 145/5000
36/36 - 1s - loss: 0.0229 - mae: 0.1150 - val_loss: 0.1379 - val_mae: 0.3015
Epoch 146/5000
36/36 - 1s - loss: 0.0222 - mae: 0.1132 - val_loss: 0.1392 - val_mae: 0.3010
Epoch 147/5000
36/36 - 1s - loss: 0.0213 - mae: 0.1131 - val_loss: 0.1413 - val_mae: 0.3032
Epoch 148/5000
36/36 - 1s - loss: 0.0211 - mae: 0.1108 - val_loss: 0.1437 - val_mae: 0.3108
Epoch 149/5000
36/36 - 1s - loss: 0.0225 - mae: 0.1158 - val_loss: 0.1545 - val_mae: 0.3299
Epoch 150/5000
36/36 - 1s - loss: 0.0226 - mae: 0.1179 - val_loss: 0.1536 - val_mae: 0.3247
Restoring model weights from the end of the best epoch.
Epoch 00150: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_1..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 2

Generating graphs from SMILES..

Setting up training set.
Size: 1829

Setting up validation set.
Size: 457

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_14"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_2 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_2 (PartitionP (None, None, 64)     0           message_passing_2[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_2[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_2 (Masking)             (None, None, 64)     0           partition_padding_2[0][0]        
                                                                 partition_padding_2[1][0]        
__________________________________________________________________________________________________
transformer_encoder_2 (Transfor (None, None, 64)     199040      masking_2[0][0]                  
                                                                 masking_2[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_2 (Glo (None, 64)           0           transformer_encoder_2[0][0]      
                                                                 transformer_encoder_2[1][0]      
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 512)          33280       global_average_pooling1d_2[0][0] 
                                                                 global_average_pooling1d_2[1][0] 
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 10)           110         dense_38[0][0]                   
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 450)          230850      dense_36[0][0]                   
                                                                 dense_36[1][0]                   
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 5)            55          dense_39[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 905)          0           dense_37[0][0]                   
                                                                 dense_37[1][0]                   
                                                                 dense_40[0][0]                   
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 700)          634200      concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 560)          392560      dense_41[0][0]                   
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 373)          209253      dense_45[0][0]                   
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 187)          69938       dense_46[0][0]                   
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 1)            188         dense_47[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
36/36 - 6s - loss: 0.4008 - mae: 0.7449 - val_loss: 0.1502 - val_mae: 0.4542
Epoch 2/5000
36/36 - 1s - loss: 0.1700 - mae: 0.4166 - val_loss: 0.1496 - val_mae: 0.4518
Epoch 3/5000
36/36 - 1s - loss: 0.1691 - mae: 0.4118 - val_loss: 0.1491 - val_mae: 0.4505
Epoch 4/5000
36/36 - 1s - loss: 0.1695 - mae: 0.4128 - val_loss: 0.1600 - val_mae: 0.4844
Epoch 5/5000
36/36 - 1s - loss: 0.1690 - mae: 0.4126 - val_loss: 0.1454 - val_mae: 0.4362
Epoch 6/5000
36/36 - 1s - loss: 0.1648 - mae: 0.4039 - val_loss: 0.1462 - val_mae: 0.4430
Epoch 7/5000
36/36 - 1s - loss: 0.1639 - mae: 0.4019 - val_loss: 0.1465 - val_mae: 0.4439
Epoch 8/5000
36/36 - 1s - loss: 0.1631 - mae: 0.3997 - val_loss: 0.1442 - val_mae: 0.4364
Epoch 9/5000
36/36 - 1s - loss: 0.1626 - mae: 0.3981 - val_loss: 0.1454 - val_mae: 0.4397
Epoch 10/5000
36/36 - 1s - loss: 0.1611 - mae: 0.3964 - val_loss: 0.1449 - val_mae: 0.4373
Epoch 11/5000
36/36 - 1s - loss: 0.1609 - mae: 0.3940 - val_loss: 0.1415 - val_mae: 0.4282
Epoch 12/5000
36/36 - 1s - loss: 0.1598 - mae: 0.3924 - val_loss: 0.1450 - val_mae: 0.4379
Epoch 13/5000
36/36 - 1s - loss: 0.1594 - mae: 0.3922 - val_loss: 0.1440 - val_mae: 0.4329
Epoch 14/5000
36/36 - 1s - loss: 0.1600 - mae: 0.3914 - val_loss: 0.1475 - val_mae: 0.4465
Epoch 15/5000
36/36 - 1s - loss: 0.1581 - mae: 0.3897 - val_loss: 0.1422 - val_mae: 0.4253
Epoch 16/5000
36/36 - 1s - loss: 0.1591 - mae: 0.3899 - val_loss: 0.1579 - val_mae: 0.4753
Epoch 17/5000
36/36 - 1s - loss: 0.1616 - mae: 0.3960 - val_loss: 0.1533 - val_mae: 0.4659
Epoch 18/5000
36/36 - 1s - loss: 0.1583 - mae: 0.3917 - val_loss: 0.1421 - val_mae: 0.4284
Epoch 19/5000
36/36 - 1s - loss: 0.1568 - mae: 0.3846 - val_loss: 0.1432 - val_mae: 0.4259
Epoch 20/5000
36/36 - 1s - loss: 0.1553 - mae: 0.3829 - val_loss: 0.1429 - val_mae: 0.4290
Epoch 21/5000
36/36 - 1s - loss: 0.1551 - mae: 0.3826 - val_loss: 0.1461 - val_mae: 0.4364
Epoch 22/5000
36/36 - 1s - loss: 0.1543 - mae: 0.3817 - val_loss: 0.1432 - val_mae: 0.4335
Epoch 23/5000
36/36 - 1s - loss: 0.1549 - mae: 0.3818 - val_loss: 0.1447 - val_mae: 0.4348
Epoch 24/5000
36/36 - 1s - loss: 0.1543 - mae: 0.3804 - val_loss: 0.1432 - val_mae: 0.4304
Epoch 25/5000
36/36 - 1s - loss: 0.1531 - mae: 0.3776 - val_loss: 0.1478 - val_mae: 0.4403
Epoch 26/5000
36/36 - 1s - loss: 0.1535 - mae: 0.3796 - val_loss: 0.1401 - val_mae: 0.4209
Epoch 27/5000
36/36 - 1s - loss: 0.1530 - mae: 0.3770 - val_loss: 0.1428 - val_mae: 0.4198
Epoch 28/5000
36/36 - 1s - loss: 0.1517 - mae: 0.3741 - val_loss: 0.1565 - val_mae: 0.4579
Epoch 29/5000
36/36 - 1s - loss: 0.1517 - mae: 0.3757 - val_loss: 0.1421 - val_mae: 0.4254
Epoch 30/5000
36/36 - 1s - loss: 0.1512 - mae: 0.3741 - val_loss: 0.1389 - val_mae: 0.4136
Epoch 31/5000
36/36 - 1s - loss: 0.1522 - mae: 0.3772 - val_loss: 0.1405 - val_mae: 0.4110
Epoch 32/5000
36/36 - 1s - loss: 0.1536 - mae: 0.3799 - val_loss: 0.1484 - val_mae: 0.4421
Epoch 33/5000
36/36 - 1s - loss: 0.1526 - mae: 0.3770 - val_loss: 0.1368 - val_mae: 0.4024
Epoch 34/5000
36/36 - 1s - loss: 0.1484 - mae: 0.3654 - val_loss: 0.1416 - val_mae: 0.4183
Epoch 35/5000
36/36 - 1s - loss: 0.1497 - mae: 0.3684 - val_loss: 0.1374 - val_mae: 0.3967
Epoch 36/5000
36/36 - 1s - loss: 0.1445 - mae: 0.3568 - val_loss: 0.1280 - val_mae: 0.3534
Epoch 37/5000
36/36 - 1s - loss: 0.1425 - mae: 0.3512 - val_loss: 0.1256 - val_mae: 0.3534
Epoch 38/5000
36/36 - 1s - loss: 0.1491 - mae: 0.3660 - val_loss: 0.1648 - val_mae: 0.4871
Epoch 39/5000
36/36 - 1s - loss: 0.1492 - mae: 0.3699 - val_loss: 0.1247 - val_mae: 0.3559
Epoch 40/5000
36/36 - 1s - loss: 0.1419 - mae: 0.3499 - val_loss: 0.1285 - val_mae: 0.3521
Epoch 41/5000
36/36 - 1s - loss: 0.1419 - mae: 0.3496 - val_loss: 0.1262 - val_mae: 0.3434
Epoch 42/5000
36/36 - 1s - loss: 0.1403 - mae: 0.3433 - val_loss: 0.1269 - val_mae: 0.3537
Epoch 43/5000
36/36 - 1s - loss: 0.1407 - mae: 0.3467 - val_loss: 0.1221 - val_mae: 0.3366
Epoch 44/5000
36/36 - 1s - loss: 0.1403 - mae: 0.3444 - val_loss: 0.1291 - val_mae: 0.3417
Epoch 45/5000
36/36 - 1s - loss: 0.1390 - mae: 0.3402 - val_loss: 0.1256 - val_mae: 0.3446
Epoch 46/5000
36/36 - 1s - loss: 0.1387 - mae: 0.3411 - val_loss: 0.1288 - val_mae: 0.3416
Epoch 47/5000
36/36 - 1s - loss: 0.1411 - mae: 0.3480 - val_loss: 0.1306 - val_mae: 0.3628
Epoch 48/5000
36/36 - 1s - loss: 0.1493 - mae: 0.3632 - val_loss: 0.1466 - val_mae: 0.4158
Epoch 49/5000
36/36 - 1s - loss: 0.1441 - mae: 0.3620 - val_loss: 0.1205 - val_mae: 0.3332
Epoch 50/5000
36/36 - 1s - loss: 0.1483 - mae: 0.3629 - val_loss: 0.1213 - val_mae: 0.3673
Epoch 51/5000
36/36 - 1s - loss: 0.1426 - mae: 0.3554 - val_loss: 0.1371 - val_mae: 0.4047
Epoch 52/5000
36/36 - 1s - loss: 0.1461 - mae: 0.3599 - val_loss: 0.1293 - val_mae: 0.3629
Epoch 53/5000
36/36 - 1s - loss: 0.1452 - mae: 0.3542 - val_loss: 0.1683 - val_mae: 0.4782
Epoch 54/5000
36/36 - 1s - loss: 0.1466 - mae: 0.3639 - val_loss: 0.1247 - val_mae: 0.3478
Epoch 55/5000
36/36 - 1s - loss: 0.1441 - mae: 0.3513 - val_loss: 0.1436 - val_mae: 0.4196
Epoch 56/5000
36/36 - 1s - loss: 0.1430 - mae: 0.3521 - val_loss: 0.1428 - val_mae: 0.4124
Epoch 57/5000
36/36 - 1s - loss: 0.1422 - mae: 0.3496 - val_loss: 0.1363 - val_mae: 0.4002
Epoch 58/5000
36/36 - 1s - loss: 0.1421 - mae: 0.3475 - val_loss: 0.1549 - val_mae: 0.4344
Epoch 59/5000
36/36 - 1s - loss: 0.1429 - mae: 0.3500 - val_loss: 0.1526 - val_mae: 0.4366
Epoch 60/5000
36/36 - 1s - loss: 0.1412 - mae: 0.3484 - val_loss: 0.1402 - val_mae: 0.4018
Epoch 61/5000
36/36 - 1s - loss: 0.1427 - mae: 0.3460 - val_loss: 0.1347 - val_mae: 0.3961
Epoch 62/5000
36/36 - 1s - loss: 0.1396 - mae: 0.3436 - val_loss: 0.1327 - val_mae: 0.3984
Epoch 63/5000
36/36 - 1s - loss: 0.1413 - mae: 0.3444 - val_loss: 0.1379 - val_mae: 0.4120
Epoch 64/5000
36/36 - 1s - loss: 0.1402 - mae: 0.3430 - val_loss: 0.1278 - val_mae: 0.3806
Epoch 65/5000
36/36 - 1s - loss: 0.1390 - mae: 0.3397 - val_loss: 0.1309 - val_mae: 0.3890
Epoch 66/5000
36/36 - 1s - loss: 0.1395 - mae: 0.3397 - val_loss: 0.1295 - val_mae: 0.3793
Epoch 67/5000
36/36 - 1s - loss: 0.1408 - mae: 0.3383 - val_loss: 0.1322 - val_mae: 0.3913
Epoch 68/5000
36/36 - 1s - loss: 0.1391 - mae: 0.3475 - val_loss: 0.1466 - val_mae: 0.4184
Epoch 69/5000
36/36 - 1s - loss: 0.1418 - mae: 0.3457 - val_loss: 0.1524 - val_mae: 0.4471
Epoch 70/5000
36/36 - 1s - loss: 0.1408 - mae: 0.3446 - val_loss: 0.1321 - val_mae: 0.3778
Epoch 71/5000
36/36 - 1s - loss: 0.1399 - mae: 0.3402 - val_loss: 0.1355 - val_mae: 0.4159
Epoch 72/5000
36/36 - 1s - loss: 0.1399 - mae: 0.3423 - val_loss: 0.1322 - val_mae: 0.3973
Epoch 73/5000
36/36 - 1s - loss: 0.1387 - mae: 0.3371 - val_loss: 0.1270 - val_mae: 0.3843
Epoch 74/5000
36/36 - 1s - loss: 0.1387 - mae: 0.3369 - val_loss: 0.1314 - val_mae: 0.3904
Epoch 75/5000
36/36 - 1s - loss: 0.1376 - mae: 0.3338 - val_loss: 0.1399 - val_mae: 0.4176
Epoch 76/5000
36/36 - 1s - loss: 0.1374 - mae: 0.3355 - val_loss: 0.1278 - val_mae: 0.3730
Epoch 77/5000
36/36 - 1s - loss: 0.1382 - mae: 0.3325 - val_loss: 0.1303 - val_mae: 0.4026
Epoch 78/5000
36/36 - 1s - loss: 0.1376 - mae: 0.3390 - val_loss: 0.1243 - val_mae: 0.3634
Epoch 79/5000
36/36 - 1s - loss: 0.1369 - mae: 0.3339 - val_loss: 0.1250 - val_mae: 0.3762
Epoch 80/5000
36/36 - 1s - loss: 0.1372 - mae: 0.3313 - val_loss: 0.1257 - val_mae: 0.3883
Epoch 81/5000
36/36 - 1s - loss: 0.1371 - mae: 0.3353 - val_loss: 0.1224 - val_mae: 0.3768
Epoch 82/5000
36/36 - 1s - loss: 0.1358 - mae: 0.3297 - val_loss: 0.1239 - val_mae: 0.3756
Epoch 83/5000
36/36 - 1s - loss: 0.1345 - mae: 0.3257 - val_loss: 0.1259 - val_mae: 0.3893
Epoch 84/5000
36/36 - 1s - loss: 0.1355 - mae: 0.3284 - val_loss: 0.1245 - val_mae: 0.3782
Epoch 85/5000
36/36 - 1s - loss: 0.1342 - mae: 0.3256 - val_loss: 0.1221 - val_mae: 0.3723
Epoch 86/5000
36/36 - 1s - loss: 0.1348 - mae: 0.3261 - val_loss: 0.1235 - val_mae: 0.3816
Epoch 87/5000
36/36 - 1s - loss: 0.1349 - mae: 0.3273 - val_loss: 0.1226 - val_mae: 0.3794
Epoch 88/5000
36/36 - 1s - loss: 0.1356 - mae: 0.3293 - val_loss: 0.1224 - val_mae: 0.3765
Epoch 89/5000
36/36 - 1s - loss: 0.1353 - mae: 0.3276 - val_loss: 0.1218 - val_mae: 0.3779
Epoch 90/5000
36/36 - 1s - loss: 0.1334 - mae: 0.3224 - val_loss: 0.1220 - val_mae: 0.3731
Epoch 91/5000
36/36 - 1s - loss: 0.1331 - mae: 0.3212 - val_loss: 0.1260 - val_mae: 0.3951
Epoch 92/5000
36/36 - 1s - loss: 0.1342 - mae: 0.3259 - val_loss: 0.1226 - val_mae: 0.3742
Epoch 93/5000
36/36 - 1s - loss: 0.1319 - mae: 0.3186 - val_loss: 0.1311 - val_mae: 0.4090
Epoch 94/5000
36/36 - 1s - loss: 0.1346 - mae: 0.3283 - val_loss: 0.1261 - val_mae: 0.3730
Epoch 95/5000
36/36 - 1s - loss: 0.1328 - mae: 0.3216 - val_loss: 0.1382 - val_mae: 0.4169
Epoch 96/5000
36/36 - 1s - loss: 0.1354 - mae: 0.3283 - val_loss: 0.1361 - val_mae: 0.4008
Epoch 97/5000
36/36 - 1s - loss: 0.1341 - mae: 0.3250 - val_loss: 0.1258 - val_mae: 0.3726
Epoch 98/5000
36/36 - 1s - loss: 0.1316 - mae: 0.3177 - val_loss: 0.1295 - val_mae: 0.3974
Epoch 99/5000
36/36 - 1s - loss: 0.1331 - mae: 0.3214 - val_loss: 0.1220 - val_mae: 0.3617
Epoch 100/5000
36/36 - 1s - loss: 0.1312 - mae: 0.3160 - val_loss: 0.1391 - val_mae: 0.4299
Epoch 101/5000
36/36 - 1s - loss: 0.1336 - mae: 0.3268 - val_loss: 0.1264 - val_mae: 0.3865
Epoch 102/5000
36/36 - 1s - loss: 0.1327 - mae: 0.3217 - val_loss: 0.1312 - val_mae: 0.3845
Epoch 103/5000
36/36 - 1s - loss: 0.1305 - mae: 0.3144 - val_loss: 0.1260 - val_mae: 0.3900
Epoch 104/5000
36/36 - 1s - loss: 0.1303 - mae: 0.3161 - val_loss: 0.1273 - val_mae: 0.3860
Epoch 105/5000
36/36 - 1s - loss: 0.1308 - mae: 0.3176 - val_loss: 0.1219 - val_mae: 0.3678
Epoch 106/5000
36/36 - 1s - loss: 0.1294 - mae: 0.3136 - val_loss: 0.1231 - val_mae: 0.3770
Epoch 107/5000
36/36 - 1s - loss: 0.1309 - mae: 0.3162 - val_loss: 0.1233 - val_mae: 0.3788
Epoch 108/5000
36/36 - 1s - loss: 0.1302 - mae: 0.3169 - val_loss: 0.1235 - val_mae: 0.3724
Epoch 109/5000
36/36 - 1s - loss: 0.1292 - mae: 0.3122 - val_loss: 0.1329 - val_mae: 0.4071
Epoch 110/5000
36/36 - 1s - loss: 0.1327 - mae: 0.3232 - val_loss: 0.1186 - val_mae: 0.3430
Epoch 111/5000
36/36 - 1s - loss: 0.1308 - mae: 0.3153 - val_loss: 0.1240 - val_mae: 0.3770
Epoch 112/5000
36/36 - 1s - loss: 0.1306 - mae: 0.3191 - val_loss: 0.1279 - val_mae: 0.3832
Epoch 113/5000
36/36 - 1s - loss: 0.1308 - mae: 0.3173 - val_loss: 0.1241 - val_mae: 0.3804
Epoch 114/5000
36/36 - 1s - loss: 0.1293 - mae: 0.3118 - val_loss: 0.1199 - val_mae: 0.3619
Epoch 115/5000
36/36 - 1s - loss: 0.1278 - mae: 0.3104 - val_loss: 0.1249 - val_mae: 0.3791
Epoch 116/5000
36/36 - 1s - loss: 0.1302 - mae: 0.3154 - val_loss: 0.1246 - val_mae: 0.3760
Epoch 117/5000
36/36 - 1s - loss: 0.1275 - mae: 0.3098 - val_loss: 0.1194 - val_mae: 0.3625
Epoch 118/5000
36/36 - 1s - loss: 0.1286 - mae: 0.3122 - val_loss: 0.1447 - val_mae: 0.4333
Epoch 119/5000
36/36 - 1s - loss: 0.1313 - mae: 0.3226 - val_loss: 0.1500 - val_mae: 0.4251
Epoch 120/5000
36/36 - 1s - loss: 0.1307 - mae: 0.3192 - val_loss: 0.1409 - val_mae: 0.4067
Epoch 121/5000
36/36 - 1s - loss: 0.1274 - mae: 0.3090 - val_loss: 0.1407 - val_mae: 0.4162
Epoch 122/5000
36/36 - 1s - loss: 0.1272 - mae: 0.3101 - val_loss: 0.1315 - val_mae: 0.3938
Epoch 123/5000
36/36 - 1s - loss: 0.1261 - mae: 0.3052 - val_loss: 0.1344 - val_mae: 0.4062
Epoch 124/5000
36/36 - 1s - loss: 0.1279 - mae: 0.3121 - val_loss: 0.1267 - val_mae: 0.3723
Epoch 125/5000
36/36 - 1s - loss: 0.1257 - mae: 0.3055 - val_loss: 0.1284 - val_mae: 0.3769
Epoch 126/5000
36/36 - 1s - loss: 0.1269 - mae: 0.3071 - val_loss: 0.1430 - val_mae: 0.4184
Epoch 127/5000
36/36 - 1s - loss: 0.1295 - mae: 0.3184 - val_loss: 0.1224 - val_mae: 0.3617
Epoch 128/5000
36/36 - 1s - loss: 0.1257 - mae: 0.3053 - val_loss: 0.1384 - val_mae: 0.4138
Epoch 129/5000
36/36 - 1s - loss: 0.1291 - mae: 0.3139 - val_loss: 0.1417 - val_mae: 0.4173
Epoch 130/5000
36/36 - 1s - loss: 0.1282 - mae: 0.3141 - val_loss: 0.1316 - val_mae: 0.3867
Epoch 131/5000
36/36 - 1s - loss: 0.1249 - mae: 0.3046 - val_loss: 0.1368 - val_mae: 0.4021
Epoch 132/5000
36/36 - 1s - loss: 0.1275 - mae: 0.3104 - val_loss: 0.1410 - val_mae: 0.4008
Epoch 133/5000
36/36 - 1s - loss: 0.1252 - mae: 0.3048 - val_loss: 0.1440 - val_mae: 0.4229
Epoch 134/5000
36/36 - 1s - loss: 0.1264 - mae: 0.3086 - val_loss: 0.1366 - val_mae: 0.3913
Epoch 135/5000
36/36 - 1s - loss: 0.1232 - mae: 0.2991 - val_loss: 0.1387 - val_mae: 0.3985
Epoch 136/5000
36/36 - 1s - loss: 0.1243 - mae: 0.3036 - val_loss: 0.1473 - val_mae: 0.4200
Epoch 137/5000
36/36 - 1s - loss: 0.1257 - mae: 0.3046 - val_loss: 0.1241 - val_mae: 0.3534
Epoch 138/5000
36/36 - 1s - loss: 0.1216 - mae: 0.2952 - val_loss: 0.1550 - val_mae: 0.4339
Epoch 139/5000
36/36 - 1s - loss: 0.1269 - mae: 0.3094 - val_loss: 0.1366 - val_mae: 0.3883
Epoch 140/5000
36/36 - 1s - loss: 0.1260 - mae: 0.3074 - val_loss: 0.1314 - val_mae: 0.3743
Epoch 141/5000
36/36 - 1s - loss: 0.1240 - mae: 0.3015 - val_loss: 0.1476 - val_mae: 0.4125
Epoch 142/5000
36/36 - 1s - loss: 0.1251 - mae: 0.3057 - val_loss: 0.1438 - val_mae: 0.4075
Epoch 143/5000
36/36 - 1s - loss: 0.1246 - mae: 0.3051 - val_loss: 0.1445 - val_mae: 0.4165
Epoch 144/5000
36/36 - 1s - loss: 0.1263 - mae: 0.3098 - val_loss: 0.1491 - val_mae: 0.4163
Epoch 145/5000
36/36 - 1s - loss: 0.1236 - mae: 0.3030 - val_loss: 0.1521 - val_mae: 0.4300
Epoch 146/5000
36/36 - 1s - loss: 0.1265 - mae: 0.3129 - val_loss: 0.1497 - val_mae: 0.4193
Epoch 147/5000
36/36 - 1s - loss: 0.1230 - mae: 0.3019 - val_loss: 0.1393 - val_mae: 0.3830
Epoch 148/5000
36/36 - 1s - loss: 0.1223 - mae: 0.2992 - val_loss: 0.1412 - val_mae: 0.3917
Epoch 149/5000
36/36 - 1s - loss: 0.1207 - mae: 0.2952 - val_loss: 0.1540 - val_mae: 0.4252
Epoch 150/5000
36/36 - 1s - loss: 0.1259 - mae: 0.3094 - val_loss: 0.1455 - val_mae: 0.4007
Restoring model weights from the end of the best epoch.
Epoch 00150: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_2..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_14"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_2 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_2 (PartitionP (None, None, 64)     0           message_passing_2[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_2[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_2 (Masking)             (None, None, 64)     0           partition_padding_2[0][0]        
                                                                 partition_padding_2[1][0]        
__________________________________________________________________________________________________
transformer_encoder_2 (Transfor (None, None, 64)     199040      masking_2[0][0]                  
                                                                 masking_2[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_2 (Glo (None, 64)           0           transformer_encoder_2[0][0]      
                                                                 transformer_encoder_2[1][0]      
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 512)          33280       global_average_pooling1d_2[0][0] 
                                                                 global_average_pooling1d_2[1][0] 
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 10)           110         dense_38[0][0]                   
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 450)          230850      dense_36[0][0]                   
                                                                 dense_36[1][0]                   
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 5)            55          dense_39[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 905)          0           dense_37[0][0]                   
                                                                 dense_37[1][0]                   
                                                                 dense_40[0][0]                   
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 700)          634200      concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 560)          392560      dense_41[0][0]                   
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 373)          209253      dense_45[0][0]                   
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 187)          69938       dense_46[0][0]                   
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 1)            188         dense_47[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
36/36 - 7s - loss: 0.1421 - mae: 0.3469 - val_loss: 0.1221 - val_mae: 0.3525
Epoch 2/5000
36/36 - 1s - loss: 0.1288 - mae: 0.3157 - val_loss: 0.1133 - val_mae: 0.3333
Epoch 3/5000
36/36 - 1s - loss: 0.1249 - mae: 0.3057 - val_loss: 0.1096 - val_mae: 0.3189
Epoch 4/5000
36/36 - 1s - loss: 0.1214 - mae: 0.2974 - val_loss: 0.1082 - val_mae: 0.3135
Epoch 5/5000
36/36 - 1s - loss: 0.1185 - mae: 0.2910 - val_loss: 0.1076 - val_mae: 0.3111
Epoch 6/5000
36/36 - 1s - loss: 0.1162 - mae: 0.2857 - val_loss: 0.1073 - val_mae: 0.3072
Epoch 7/5000
36/36 - 1s - loss: 0.1140 - mae: 0.2812 - val_loss: 0.1072 - val_mae: 0.3044
Epoch 8/5000
36/36 - 1s - loss: 0.1122 - mae: 0.2771 - val_loss: 0.1076 - val_mae: 0.3055
Epoch 9/5000
36/36 - 1s - loss: 0.1109 - mae: 0.2748 - val_loss: 0.1062 - val_mae: 0.2999
Epoch 10/5000
36/36 - 1s - loss: 0.1093 - mae: 0.2717 - val_loss: 0.1040 - val_mae: 0.2935
Epoch 11/5000
36/36 - 1s - loss: 0.1071 - mae: 0.2661 - val_loss: 0.1033 - val_mae: 0.2897
Epoch 12/5000
36/36 - 1s - loss: 0.1048 - mae: 0.2608 - val_loss: 0.1027 - val_mae: 0.2875
Epoch 13/5000
36/36 - 1s - loss: 0.1029 - mae: 0.2559 - val_loss: 0.1013 - val_mae: 0.2862
Epoch 14/5000
36/36 - 1s - loss: 0.1014 - mae: 0.2526 - val_loss: 0.1016 - val_mae: 0.2886
Epoch 15/5000
36/36 - 1s - loss: 0.1019 - mae: 0.2527 - val_loss: 0.0978 - val_mae: 0.2686
Epoch 16/5000
36/36 - 1s - loss: 0.0987 - mae: 0.2458 - val_loss: 0.0995 - val_mae: 0.2765
Epoch 17/5000
36/36 - 1s - loss: 0.0979 - mae: 0.2438 - val_loss: 0.1003 - val_mae: 0.2788
Epoch 18/5000
36/36 - 1s - loss: 0.0972 - mae: 0.2412 - val_loss: 0.1001 - val_mae: 0.2787
Epoch 19/5000
36/36 - 1s - loss: 0.0969 - mae: 0.2411 - val_loss: 0.1035 - val_mae: 0.2885
Epoch 20/5000
36/36 - 1s - loss: 0.0973 - mae: 0.2420 - val_loss: 0.1020 - val_mae: 0.2840
Epoch 21/5000
36/36 - 1s - loss: 0.0959 - mae: 0.2400 - val_loss: 0.1026 - val_mae: 0.2839
Epoch 22/5000
36/36 - 1s - loss: 0.0933 - mae: 0.2343 - val_loss: 0.1052 - val_mae: 0.2997
Epoch 23/5000
36/36 - 1s - loss: 0.0929 - mae: 0.2325 - val_loss: 0.1039 - val_mae: 0.2945
Epoch 24/5000
36/36 - 1s - loss: 0.0930 - mae: 0.2318 - val_loss: 0.1032 - val_mae: 0.2905
Epoch 25/5000
36/36 - 1s - loss: 0.0928 - mae: 0.2319 - val_loss: 0.1083 - val_mae: 0.2991
Epoch 26/5000
36/36 - 1s - loss: 0.0935 - mae: 0.2328 - val_loss: 0.1084 - val_mae: 0.2982
Epoch 27/5000
36/36 - 1s - loss: 0.0937 - mae: 0.2353 - val_loss: 0.0999 - val_mae: 0.2692
Epoch 28/5000
36/36 - 1s - loss: 0.0893 - mae: 0.2257 - val_loss: 0.1064 - val_mae: 0.2993
Epoch 29/5000
36/36 - 1s - loss: 0.0878 - mae: 0.2226 - val_loss: 0.1136 - val_mae: 0.3183
Epoch 30/5000
36/36 - 1s - loss: 0.0885 - mae: 0.2222 - val_loss: 0.1133 - val_mae: 0.3172
Epoch 31/5000
36/36 - 1s - loss: 0.0891 - mae: 0.2232 - val_loss: 0.1049 - val_mae: 0.2884
Epoch 32/5000
36/36 - 1s - loss: 0.0877 - mae: 0.2208 - val_loss: 0.1044 - val_mae: 0.2851
Epoch 33/5000
36/36 - 1s - loss: 0.0869 - mae: 0.2204 - val_loss: 0.1019 - val_mae: 0.2734
Epoch 34/5000
36/36 - 1s - loss: 0.0853 - mae: 0.2163 - val_loss: 0.1006 - val_mae: 0.2756
Epoch 35/5000
36/36 - 1s - loss: 0.0836 - mae: 0.2114 - val_loss: 0.1023 - val_mae: 0.2872
Epoch 36/5000
36/36 - 1s - loss: 0.0838 - mae: 0.2112 - val_loss: 0.1026 - val_mae: 0.2940
Epoch 37/5000
36/36 - 1s - loss: 0.0859 - mae: 0.2174 - val_loss: 0.1032 - val_mae: 0.2965
Epoch 38/5000
36/36 - 1s - loss: 0.0853 - mae: 0.2168 - val_loss: 0.1158 - val_mae: 0.3319
Epoch 39/5000
36/36 - 1s - loss: 0.0930 - mae: 0.2362 - val_loss: 0.1741 - val_mae: 0.4613
Epoch 40/5000
36/36 - 1s - loss: 0.0976 - mae: 0.2509 - val_loss: 0.1297 - val_mae: 0.3700
Epoch 41/5000
36/36 - 1s - loss: 0.0927 - mae: 0.2403 - val_loss: 0.1061 - val_mae: 0.3072
Epoch 42/5000
36/36 - 1s - loss: 0.0859 - mae: 0.2231 - val_loss: 0.1149 - val_mae: 0.3240
Epoch 43/5000
36/36 - 1s - loss: 0.0826 - mae: 0.2114 - val_loss: 0.1201 - val_mae: 0.3318
Epoch 44/5000
36/36 - 1s - loss: 0.0823 - mae: 0.2114 - val_loss: 0.1214 - val_mae: 0.3360
Epoch 45/5000
36/36 - 1s - loss: 0.0816 - mae: 0.2112 - val_loss: 0.1123 - val_mae: 0.3102
Epoch 46/5000
36/36 - 1s - loss: 0.0814 - mae: 0.2121 - val_loss: 0.1036 - val_mae: 0.2887
Epoch 47/5000
36/36 - 1s - loss: 0.0803 - mae: 0.2076 - val_loss: 0.1003 - val_mae: 0.2788
Epoch 48/5000
36/36 - 1s - loss: 0.0774 - mae: 0.2003 - val_loss: 0.0987 - val_mae: 0.2831
Epoch 49/5000
36/36 - 1s - loss: 0.0751 - mae: 0.1941 - val_loss: 0.1044 - val_mae: 0.2999
Epoch 50/5000
36/36 - 1s - loss: 0.0755 - mae: 0.1947 - val_loss: 0.1014 - val_mae: 0.2958
Epoch 51/5000
36/36 - 1s - loss: 0.0751 - mae: 0.1929 - val_loss: 0.1086 - val_mae: 0.3128
Epoch 52/5000
36/36 - 1s - loss: 0.0742 - mae: 0.1897 - val_loss: 0.1046 - val_mae: 0.2988
Epoch 53/5000
36/36 - 1s - loss: 0.0740 - mae: 0.1903 - val_loss: 0.1019 - val_mae: 0.2889
Epoch 54/5000
36/36 - 1s - loss: 0.0722 - mae: 0.1884 - val_loss: 0.1087 - val_mae: 0.3036
Epoch 55/5000
36/36 - 1s - loss: 0.0713 - mae: 0.1869 - val_loss: 0.1148 - val_mae: 0.3164
Epoch 56/5000
36/36 - 1s - loss: 0.0719 - mae: 0.1891 - val_loss: 0.1086 - val_mae: 0.3047
Epoch 57/5000
36/36 - 1s - loss: 0.0730 - mae: 0.1938 - val_loss: 0.1184 - val_mae: 0.3323
Epoch 58/5000
36/36 - 1s - loss: 0.0738 - mae: 0.1970 - val_loss: 0.1382 - val_mae: 0.3795
Epoch 59/5000
36/36 - 1s - loss: 0.0742 - mae: 0.2005 - val_loss: 0.1543 - val_mae: 0.4044
Epoch 60/5000
36/36 - 1s - loss: 0.0752 - mae: 0.2031 - val_loss: 0.1423 - val_mae: 0.3702
Epoch 61/5000
36/36 - 1s - loss: 0.0818 - mae: 0.2214 - val_loss: 0.1073 - val_mae: 0.2892
Epoch 62/5000
36/36 - 1s - loss: 0.0824 - mae: 0.2213 - val_loss: 0.0907 - val_mae: 0.2477
Epoch 63/5000
36/36 - 1s - loss: 0.0731 - mae: 0.1974 - val_loss: 0.1108 - val_mae: 0.3025
Epoch 64/5000
36/36 - 1s - loss: 0.0682 - mae: 0.1851 - val_loss: 0.1122 - val_mae: 0.3049
Epoch 65/5000
36/36 - 1s - loss: 0.0664 - mae: 0.1817 - val_loss: 0.1169 - val_mae: 0.3107
Epoch 66/5000
36/36 - 1s - loss: 0.0655 - mae: 0.1796 - val_loss: 0.1023 - val_mae: 0.2795
Epoch 67/5000
36/36 - 1s - loss: 0.0645 - mae: 0.1777 - val_loss: 0.0994 - val_mae: 0.2786
Epoch 68/5000
36/36 - 1s - loss: 0.0637 - mae: 0.1788 - val_loss: 0.1009 - val_mae: 0.2885
Epoch 69/5000
36/36 - 1s - loss: 0.0628 - mae: 0.1784 - val_loss: 0.1007 - val_mae: 0.2767
Epoch 70/5000
36/36 - 1s - loss: 0.0622 - mae: 0.1786 - val_loss: 0.1122 - val_mae: 0.3082
Epoch 71/5000
36/36 - 1s - loss: 0.0638 - mae: 0.1845 - val_loss: 0.1273 - val_mae: 0.3326
Epoch 72/5000
36/36 - 1s - loss: 0.0690 - mae: 0.1972 - val_loss: 0.1558 - val_mae: 0.4123
Epoch 73/5000
36/36 - 1s - loss: 0.0748 - mae: 0.2143 - val_loss: 0.1610 - val_mae: 0.4244
Epoch 74/5000
36/36 - 1s - loss: 0.0793 - mae: 0.2248 - val_loss: 0.1047 - val_mae: 0.3083
Epoch 75/5000
36/36 - 1s - loss: 0.0844 - mae: 0.2347 - val_loss: 0.0909 - val_mae: 0.2800
Epoch 76/5000
36/36 - 1s - loss: 0.0838 - mae: 0.2337 - val_loss: 0.0943 - val_mae: 0.2792
Epoch 77/5000
36/36 - 1s - loss: 0.0883 - mae: 0.2390 - val_loss: 0.1150 - val_mae: 0.2979
Epoch 78/5000
36/36 - 1s - loss: 0.1038 - mae: 0.2682 - val_loss: 0.1016 - val_mae: 0.2631
Epoch 79/5000
36/36 - 1s - loss: 0.0905 - mae: 0.2479 - val_loss: 0.1025 - val_mae: 0.2620
Epoch 80/5000
36/36 - 1s - loss: 0.0917 - mae: 0.2421 - val_loss: 0.0964 - val_mae: 0.2634
Epoch 81/5000
36/36 - 1s - loss: 0.0778 - mae: 0.2143 - val_loss: 0.0873 - val_mae: 0.2510
Epoch 82/5000
36/36 - 1s - loss: 0.0656 - mae: 0.1910 - val_loss: 0.0901 - val_mae: 0.2489
Epoch 83/5000
36/36 - 1s - loss: 0.0609 - mae: 0.1804 - val_loss: 0.0904 - val_mae: 0.2539
Epoch 84/5000
36/36 - 1s - loss: 0.0578 - mae: 0.1755 - val_loss: 0.0896 - val_mae: 0.2480
Epoch 85/5000
36/36 - 1s - loss: 0.0570 - mae: 0.1742 - val_loss: 0.0924 - val_mae: 0.2548
Epoch 86/5000
36/36 - 1s - loss: 0.0564 - mae: 0.1733 - val_loss: 0.0910 - val_mae: 0.2493
Epoch 87/5000
36/36 - 1s - loss: 0.0609 - mae: 0.1875 - val_loss: 0.0960 - val_mae: 0.2570
Epoch 88/5000
36/36 - 1s - loss: 0.0644 - mae: 0.1937 - val_loss: 0.0985 - val_mae: 0.2616
Epoch 89/5000
36/36 - 1s - loss: 0.0689 - mae: 0.2039 - val_loss: 0.1082 - val_mae: 0.2718
Epoch 90/5000
36/36 - 1s - loss: 0.0789 - mae: 0.2230 - val_loss: 0.1193 - val_mae: 0.2873
Epoch 91/5000
36/36 - 1s - loss: 0.0955 - mae: 0.2627 - val_loss: 0.0942 - val_mae: 0.2794
Epoch 92/5000
36/36 - 1s - loss: 0.0635 - mae: 0.2038 - val_loss: 0.1059 - val_mae: 0.2739
Epoch 93/5000
36/36 - 1s - loss: 0.0608 - mae: 0.1906 - val_loss: 0.0997 - val_mae: 0.2599
Epoch 94/5000
36/36 - 1s - loss: 0.0621 - mae: 0.1942 - val_loss: 0.1074 - val_mae: 0.2739
Epoch 95/5000
36/36 - 1s - loss: 0.0617 - mae: 0.1919 - val_loss: 0.0975 - val_mae: 0.2579
Epoch 96/5000
36/36 - 1s - loss: 0.0590 - mae: 0.1931 - val_loss: 0.1100 - val_mae: 0.2804
Epoch 97/5000
36/36 - 1s - loss: 0.0612 - mae: 0.1982 - val_loss: 0.1083 - val_mae: 0.2793
Epoch 98/5000
36/36 - 1s - loss: 0.0568 - mae: 0.1861 - val_loss: 0.1018 - val_mae: 0.2664
Epoch 99/5000
36/36 - 1s - loss: 0.0552 - mae: 0.1849 - val_loss: 0.1180 - val_mae: 0.2917
Epoch 100/5000
36/36 - 1s - loss: 0.0576 - mae: 0.1874 - val_loss: 0.1190 - val_mae: 0.2884
Epoch 101/5000
36/36 - 1s - loss: 0.0494 - mae: 0.1672 - val_loss: 0.1358 - val_mae: 0.3136
Epoch 102/5000
36/36 - 1s - loss: 0.0508 - mae: 0.1700 - val_loss: 0.1142 - val_mae: 0.2818
Epoch 103/5000
36/36 - 1s - loss: 0.0480 - mae: 0.1587 - val_loss: 0.0997 - val_mae: 0.2708
Epoch 104/5000
36/36 - 1s - loss: 0.0472 - mae: 0.1561 - val_loss: 0.0864 - val_mae: 0.2518
Epoch 105/5000
36/36 - 1s - loss: 0.0473 - mae: 0.1583 - val_loss: 0.0871 - val_mae: 0.2554
Epoch 106/5000
36/36 - 1s - loss: 0.0439 - mae: 0.1530 - val_loss: 0.0904 - val_mae: 0.2488
Epoch 107/5000
36/36 - 1s - loss: 0.0460 - mae: 0.1587 - val_loss: 0.0909 - val_mae: 0.2497
Epoch 108/5000
36/36 - 1s - loss: 0.0509 - mae: 0.1722 - val_loss: 0.0976 - val_mae: 0.2617
Epoch 109/5000
36/36 - 1s - loss: 0.0601 - mae: 0.1937 - val_loss: 0.0925 - val_mae: 0.2535
Epoch 110/5000
36/36 - 1s - loss: 0.0612 - mae: 0.2031 - val_loss: 0.1443 - val_mae: 0.3221
Epoch 111/5000
36/36 - 1s - loss: 0.0565 - mae: 0.1827 - val_loss: 0.1143 - val_mae: 0.2851
Epoch 112/5000
36/36 - 1s - loss: 0.0423 - mae: 0.1508 - val_loss: 0.1274 - val_mae: 0.2975
Epoch 113/5000
36/36 - 1s - loss: 0.0424 - mae: 0.1487 - val_loss: 0.1192 - val_mae: 0.2844
Epoch 114/5000
36/36 - 1s - loss: 0.0372 - mae: 0.1374 - val_loss: 0.1043 - val_mae: 0.2693
Epoch 115/5000
36/36 - 1s - loss: 0.0359 - mae: 0.1340 - val_loss: 0.1077 - val_mae: 0.2723
Epoch 116/5000
36/36 - 1s - loss: 0.0373 - mae: 0.1397 - val_loss: 0.1062 - val_mae: 0.2716
Epoch 117/5000
36/36 - 1s - loss: 0.0370 - mae: 0.1375 - val_loss: 0.0965 - val_mae: 0.2598
Epoch 118/5000
36/36 - 1s - loss: 0.0399 - mae: 0.1464 - val_loss: 0.0963 - val_mae: 0.2576
Epoch 119/5000
36/36 - 1s - loss: 0.0393 - mae: 0.1441 - val_loss: 0.1387 - val_mae: 0.3163
Epoch 120/5000
36/36 - 1s - loss: 0.0434 - mae: 0.1519 - val_loss: 0.1289 - val_mae: 0.2975
Epoch 121/5000
36/36 - 1s - loss: 0.0368 - mae: 0.1374 - val_loss: 0.1252 - val_mae: 0.2931
Epoch 122/5000
36/36 - 1s - loss: 0.0345 - mae: 0.1318 - val_loss: 0.1372 - val_mae: 0.3035
Epoch 123/5000
36/36 - 1s - loss: 0.0338 - mae: 0.1310 - val_loss: 0.1457 - val_mae: 0.3240
Epoch 124/5000
36/36 - 1s - loss: 0.0393 - mae: 0.1467 - val_loss: 0.2086 - val_mae: 0.4021
Epoch 125/5000
36/36 - 1s - loss: 0.0443 - mae: 0.1583 - val_loss: 0.1303 - val_mae: 0.3085
Epoch 126/5000
36/36 - 1s - loss: 0.0372 - mae: 0.1413 - val_loss: 0.1306 - val_mae: 0.3142
Epoch 127/5000
36/36 - 1s - loss: 0.0382 - mae: 0.1424 - val_loss: 0.1191 - val_mae: 0.2974
Epoch 128/5000
36/36 - 1s - loss: 0.0378 - mae: 0.1454 - val_loss: 0.0939 - val_mae: 0.2582
Epoch 129/5000
36/36 - 1s - loss: 0.0430 - mae: 0.1574 - val_loss: 0.1221 - val_mae: 0.2911
Epoch 130/5000
36/36 - 1s - loss: 0.0377 - mae: 0.1457 - val_loss: 0.1006 - val_mae: 0.2614
Epoch 131/5000
36/36 - 1s - loss: 0.0373 - mae: 0.1417 - val_loss: 0.0853 - val_mae: 0.2452
Epoch 132/5000
36/36 - 1s - loss: 0.0404 - mae: 0.1548 - val_loss: 0.1034 - val_mae: 0.2670
Epoch 133/5000
36/36 - 1s - loss: 0.0383 - mae: 0.1452 - val_loss: 0.1073 - val_mae: 0.2724
Epoch 134/5000
36/36 - 1s - loss: 0.0399 - mae: 0.1482 - val_loss: 0.1003 - val_mae: 0.2645
Epoch 135/5000
36/36 - 1s - loss: 0.0409 - mae: 0.1515 - val_loss: 0.1522 - val_mae: 0.3285
Epoch 136/5000
36/36 - 1s - loss: 0.0440 - mae: 0.1601 - val_loss: 0.1552 - val_mae: 0.3304
Epoch 137/5000
36/36 - 1s - loss: 0.0356 - mae: 0.1361 - val_loss: 0.1390 - val_mae: 0.3171
Epoch 138/5000
36/36 - 1s - loss: 0.0391 - mae: 0.1445 - val_loss: 0.1196 - val_mae: 0.2996
Epoch 139/5000
36/36 - 1s - loss: 0.0373 - mae: 0.1367 - val_loss: 0.0832 - val_mae: 0.2535
Epoch 140/5000
36/36 - 1s - loss: 0.0358 - mae: 0.1394 - val_loss: 0.1173 - val_mae: 0.2867
Epoch 141/5000
36/36 - 1s - loss: 0.0332 - mae: 0.1275 - val_loss: 0.1148 - val_mae: 0.2799
Epoch 142/5000
36/36 - 1s - loss: 0.0342 - mae: 0.1352 - val_loss: 0.1240 - val_mae: 0.2909
Epoch 143/5000
36/36 - 1s - loss: 0.0318 - mae: 0.1303 - val_loss: 0.1376 - val_mae: 0.3087
Epoch 144/5000
36/36 - 1s - loss: 0.0313 - mae: 0.1278 - val_loss: 0.1750 - val_mae: 0.3584
Epoch 145/5000
36/36 - 1s - loss: 0.0342 - mae: 0.1354 - val_loss: 0.1449 - val_mae: 0.3273
Epoch 146/5000
36/36 - 1s - loss: 0.0427 - mae: 0.1559 - val_loss: 0.0894 - val_mae: 0.2519
Epoch 147/5000
36/36 - 1s - loss: 0.0321 - mae: 0.1287 - val_loss: 0.1028 - val_mae: 0.2671
Epoch 148/5000
36/36 - 1s - loss: 0.0300 - mae: 0.1217 - val_loss: 0.1168 - val_mae: 0.2862
Epoch 149/5000
36/36 - 1s - loss: 0.0276 - mae: 0.1143 - val_loss: 0.1230 - val_mae: 0.2883
Epoch 150/5000
36/36 - 1s - loss: 0.0298 - mae: 0.1219 - val_loss: 0.1267 - val_mae: 0.3014
Epoch 151/5000
36/36 - 1s - loss: 0.0281 - mae: 0.1149 - val_loss: 0.1643 - val_mae: 0.3406
Epoch 152/5000
36/36 - 1s - loss: 0.0331 - mae: 0.1266 - val_loss: 0.1207 - val_mae: 0.2960
Epoch 153/5000
36/36 - 1s - loss: 0.0310 - mae: 0.1230 - val_loss: 0.1070 - val_mae: 0.2742
Epoch 154/5000
36/36 - 1s - loss: 0.0295 - mae: 0.1185 - val_loss: 0.1053 - val_mae: 0.2712
Epoch 155/5000
36/36 - 1s - loss: 0.0329 - mae: 0.1278 - val_loss: 0.1167 - val_mae: 0.2857
Epoch 156/5000
36/36 - 1s - loss: 0.0286 - mae: 0.1156 - val_loss: 0.0993 - val_mae: 0.2620
Epoch 157/5000
36/36 - 1s - loss: 0.0296 - mae: 0.1219 - val_loss: 0.1044 - val_mae: 0.2681
Epoch 158/5000
36/36 - 1s - loss: 0.0288 - mae: 0.1173 - val_loss: 0.1099 - val_mae: 0.2739
Epoch 159/5000
36/36 - 1s - loss: 0.0320 - mae: 0.1309 - val_loss: 0.1265 - val_mae: 0.2952
Epoch 160/5000
36/36 - 1s - loss: 0.0320 - mae: 0.1308 - val_loss: 0.1418 - val_mae: 0.3212
Epoch 161/5000
36/36 - 1s - loss: 0.0319 - mae: 0.1272 - val_loss: 0.1404 - val_mae: 0.3232
Epoch 162/5000
36/36 - 1s - loss: 0.0366 - mae: 0.1404 - val_loss: 0.0989 - val_mae: 0.2666
Epoch 163/5000
36/36 - 1s - loss: 0.0392 - mae: 0.1477 - val_loss: 0.1114 - val_mae: 0.2819
Epoch 164/5000
36/36 - 1s - loss: 0.0286 - mae: 0.1151 - val_loss: 0.1098 - val_mae: 0.2776
Epoch 165/5000
36/36 - 1s - loss: 0.0312 - mae: 0.1264 - val_loss: 0.1102 - val_mae: 0.2785
Epoch 166/5000
36/36 - 1s - loss: 0.0346 - mae: 0.1349 - val_loss: 0.1281 - val_mae: 0.3039
Epoch 167/5000
36/36 - 1s - loss: 0.0318 - mae: 0.1269 - val_loss: 0.1750 - val_mae: 0.3566
Epoch 168/5000
36/36 - 1s - loss: 0.0374 - mae: 0.1415 - val_loss: 0.1182 - val_mae: 0.2940
Epoch 169/5000
36/36 - 1s - loss: 0.0317 - mae: 0.1255 - val_loss: 0.1030 - val_mae: 0.2725
Epoch 170/5000
36/36 - 1s - loss: 0.0259 - mae: 0.1064 - val_loss: 0.1100 - val_mae: 0.2794
Epoch 171/5000
36/36 - 1s - loss: 0.0267 - mae: 0.1138 - val_loss: 0.1143 - val_mae: 0.2818
Epoch 172/5000
36/36 - 1s - loss: 0.0266 - mae: 0.1106 - val_loss: 0.1392 - val_mae: 0.3095
Epoch 173/5000
36/36 - 1s - loss: 0.0272 - mae: 0.1084 - val_loss: 0.1353 - val_mae: 0.3160
Epoch 174/5000
36/36 - 1s - loss: 0.0276 - mae: 0.1104 - val_loss: 0.1187 - val_mae: 0.2908
Epoch 175/5000
36/36 - 1s - loss: 0.0272 - mae: 0.1066 - val_loss: 0.1174 - val_mae: 0.2878
Epoch 176/5000
36/36 - 1s - loss: 0.0256 - mae: 0.1077 - val_loss: 0.1119 - val_mae: 0.2795
Epoch 177/5000
36/36 - 1s - loss: 0.0284 - mae: 0.1102 - val_loss: 0.1291 - val_mae: 0.3041
Epoch 178/5000
36/36 - 1s - loss: 0.0260 - mae: 0.1058 - val_loss: 0.1176 - val_mae: 0.2866
Epoch 179/5000
36/36 - 1s - loss: 0.0285 - mae: 0.1142 - val_loss: 0.1181 - val_mae: 0.2905
Epoch 180/5000
36/36 - 1s - loss: 0.0272 - mae: 0.1112 - val_loss: 0.1556 - val_mae: 0.3349
Epoch 181/5000
36/36 - 1s - loss: 0.0271 - mae: 0.1092 - val_loss: 0.1380 - val_mae: 0.3200
Epoch 182/5000
36/36 - 1s - loss: 0.0296 - mae: 0.1164 - val_loss: 0.1238 - val_mae: 0.2984
Epoch 183/5000
36/36 - 1s - loss: 0.0270 - mae: 0.1081 - val_loss: 0.1007 - val_mae: 0.2690
Epoch 184/5000
36/36 - 1s - loss: 0.0251 - mae: 0.1075 - val_loss: 0.1169 - val_mae: 0.2873
Epoch 185/5000
36/36 - 1s - loss: 0.0237 - mae: 0.0964 - val_loss: 0.1092 - val_mae: 0.2756
Epoch 186/5000
36/36 - 1s - loss: 0.0270 - mae: 0.1148 - val_loss: 0.1100 - val_mae: 0.2790
Epoch 187/5000
36/36 - 1s - loss: 0.0255 - mae: 0.1075 - val_loss: 0.1367 - val_mae: 0.3079
Epoch 188/5000
36/36 - 1s - loss: 0.0272 - mae: 0.1131 - val_loss: 0.1316 - val_mae: 0.3087
Epoch 189/5000
36/36 - 1s - loss: 0.0254 - mae: 0.1035 - val_loss: 0.1486 - val_mae: 0.3273
Epoch 190/5000
36/36 - 1s - loss: 0.0263 - mae: 0.1073 - val_loss: 0.1331 - val_mae: 0.3115
Epoch 191/5000
36/36 - 1s - loss: 0.0257 - mae: 0.1062 - val_loss: 0.1127 - val_mae: 0.2825
Epoch 192/5000
36/36 - 1s - loss: 0.0271 - mae: 0.1084 - val_loss: 0.1130 - val_mae: 0.2851
Epoch 193/5000
36/36 - 1s - loss: 0.0254 - mae: 0.1073 - val_loss: 0.1138 - val_mae: 0.2814
Epoch 194/5000
36/36 - 1s - loss: 0.0251 - mae: 0.1056 - val_loss: 0.1075 - val_mae: 0.2755
Epoch 195/5000
36/36 - 1s - loss: 0.0265 - mae: 0.1091 - val_loss: 0.1384 - val_mae: 0.3116
Epoch 196/5000
36/36 - 1s - loss: 0.0248 - mae: 0.1046 - val_loss: 0.1366 - val_mae: 0.3135
Epoch 197/5000
36/36 - 1s - loss: 0.0231 - mae: 0.0971 - val_loss: 0.1512 - val_mae: 0.3343
Epoch 198/5000
36/36 - 1s - loss: 0.0253 - mae: 0.1054 - val_loss: 0.1435 - val_mae: 0.3302
Epoch 199/5000
36/36 - 1s - loss: 0.0244 - mae: 0.1022 - val_loss: 0.1176 - val_mae: 0.2901
Epoch 200/5000
36/36 - 1s - loss: 0.0272 - mae: 0.1090 - val_loss: 0.1110 - val_mae: 0.2844
Epoch 201/5000
36/36 - 1s - loss: 0.0271 - mae: 0.1169 - val_loss: 0.1043 - val_mae: 0.2677
Epoch 202/5000
36/36 - 1s - loss: 0.0267 - mae: 0.1111 - val_loss: 0.1044 - val_mae: 0.2730
Epoch 203/5000
36/36 - 1s - loss: 0.0265 - mae: 0.1146 - val_loss: 0.1214 - val_mae: 0.2924
Epoch 204/5000
36/36 - 1s - loss: 0.0269 - mae: 0.1166 - val_loss: 0.1328 - val_mae: 0.3121
Epoch 205/5000
36/36 - 1s - loss: 0.0244 - mae: 0.1055 - val_loss: 0.1747 - val_mae: 0.3663
Epoch 206/5000
36/36 - 1s - loss: 0.0301 - mae: 0.1203 - val_loss: 0.1245 - val_mae: 0.3030
Epoch 207/5000
36/36 - 1s - loss: 0.0320 - mae: 0.1258 - val_loss: 0.1006 - val_mae: 0.2709
Epoch 208/5000
36/36 - 1s - loss: 0.0260 - mae: 0.1112 - val_loss: 0.1008 - val_mae: 0.2693
Epoch 209/5000
36/36 - 1s - loss: 0.0251 - mae: 0.1052 - val_loss: 0.1155 - val_mae: 0.2829
Epoch 210/5000
36/36 - 1s - loss: 0.0264 - mae: 0.1108 - val_loss: 0.1168 - val_mae: 0.2879
Epoch 211/5000
36/36 - 1s - loss: 0.0279 - mae: 0.1174 - val_loss: 0.1462 - val_mae: 0.3402
Epoch 212/5000
36/36 - 1s - loss: 0.0257 - mae: 0.1130 - val_loss: 0.1457 - val_mae: 0.3313
Epoch 213/5000
36/36 - 1s - loss: 0.0243 - mae: 0.1017 - val_loss: 0.1192 - val_mae: 0.2918
Epoch 214/5000
36/36 - 1s - loss: 0.0257 - mae: 0.1033 - val_loss: 0.1113 - val_mae: 0.2824
Epoch 215/5000
36/36 - 1s - loss: 0.0238 - mae: 0.1002 - val_loss: 0.1107 - val_mae: 0.2805
Epoch 216/5000
36/36 - 1s - loss: 0.0225 - mae: 0.0959 - val_loss: 0.1257 - val_mae: 0.2963
Epoch 217/5000
36/36 - 1s - loss: 0.0235 - mae: 0.1032 - val_loss: 0.1470 - val_mae: 0.3275
Epoch 218/5000
36/36 - 1s - loss: 0.0241 - mae: 0.1008 - val_loss: 0.1431 - val_mae: 0.3394
Epoch 219/5000
36/36 - 1s - loss: 0.0290 - mae: 0.1190 - val_loss: 0.1030 - val_mae: 0.2907
Epoch 220/5000
36/36 - 1s - loss: 0.0290 - mae: 0.1258 - val_loss: 0.0995 - val_mae: 0.2684
Epoch 221/5000
36/36 - 1s - loss: 0.0239 - mae: 0.0980 - val_loss: 0.1112 - val_mae: 0.2771
Epoch 222/5000
36/36 - 1s - loss: 0.0257 - mae: 0.1128 - val_loss: 0.1279 - val_mae: 0.2990
Epoch 223/5000
36/36 - 1s - loss: 0.0235 - mae: 0.1058 - val_loss: 0.1495 - val_mae: 0.3394
Epoch 224/5000
36/36 - 1s - loss: 0.0257 - mae: 0.1061 - val_loss: 0.1088 - val_mae: 0.2940
Epoch 225/5000
36/36 - 1s - loss: 0.0313 - mae: 0.1260 - val_loss: 0.1077 - val_mae: 0.2793
Epoch 226/5000
36/36 - 1s - loss: 0.0232 - mae: 0.1030 - val_loss: 0.1016 - val_mae: 0.2683
Epoch 227/5000
36/36 - 1s - loss: 0.0227 - mae: 0.0981 - val_loss: 0.1318 - val_mae: 0.3107
Epoch 228/5000
36/36 - 1s - loss: 0.0229 - mae: 0.0993 - val_loss: 0.1446 - val_mae: 0.3310
Epoch 229/5000
36/36 - 1s - loss: 0.0228 - mae: 0.0968 - val_loss: 0.1325 - val_mae: 0.3182
Epoch 230/5000
36/36 - 1s - loss: 0.0246 - mae: 0.1027 - val_loss: 0.1235 - val_mae: 0.2994
Epoch 231/5000
36/36 - 1s - loss: 0.0210 - mae: 0.0899 - val_loss: 0.1169 - val_mae: 0.2889
Epoch 232/5000
36/36 - 1s - loss: 0.0215 - mae: 0.0959 - val_loss: 0.1433 - val_mae: 0.3218
Restoring model weights from the end of the best epoch.
Epoch 00232: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_2..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 3

Generating graphs from SMILES..

Setting up training set.
Size: 1829

Setting up validation set.
Size: 457

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_19"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_3 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_3 (PartitionP (None, None, 64)     0           message_passing_3[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_3[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_3 (Masking)             (None, None, 64)     0           partition_padding_3[0][0]        
                                                                 partition_padding_3[1][0]        
__________________________________________________________________________________________________
transformer_encoder_3 (Transfor (None, None, 64)     199040      masking_3[0][0]                  
                                                                 masking_3[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_3 (Glo (None, 64)           0           transformer_encoder_3[0][0]      
                                                                 transformer_encoder_3[1][0]      
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 512)          33280       global_average_pooling1d_3[0][0] 
                                                                 global_average_pooling1d_3[1][0] 
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 10)           110         dense_55[0][0]                   
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 450)          230850      dense_53[0][0]                   
                                                                 dense_53[1][0]                   
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 5)            55          dense_56[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 905)          0           dense_54[0][0]                   
                                                                 dense_54[1][0]                   
                                                                 dense_57[0][0]                   
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 700)          634200      concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 560)          392560      dense_58[0][0]                   
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 373)          209253      dense_62[0][0]                   
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 187)          69938       dense_63[0][0]                   
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 1)            188         dense_64[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
36/36 - 5s - loss: 0.3188 - mae: 0.6395 - val_loss: 0.2127 - val_mae: 0.5315
Epoch 2/5000
36/36 - 1s - loss: 0.1596 - mae: 0.4103 - val_loss: 0.2049 - val_mae: 0.5141
Epoch 3/5000
36/36 - 1s - loss: 0.1567 - mae: 0.4043 - val_loss: 0.2064 - val_mae: 0.5147
Epoch 4/5000
36/36 - 1s - loss: 0.1572 - mae: 0.4055 - val_loss: 0.1907 - val_mae: 0.4745
Epoch 5/5000
36/36 - 1s - loss: 0.1538 - mae: 0.3965 - val_loss: 0.1908 - val_mae: 0.4750
Epoch 6/5000
36/36 - 1s - loss: 0.1526 - mae: 0.3930 - val_loss: 0.1947 - val_mae: 0.4858
Epoch 7/5000
36/36 - 1s - loss: 0.1527 - mae: 0.3924 - val_loss: 0.1932 - val_mae: 0.4820
Epoch 8/5000
36/36 - 1s - loss: 0.1514 - mae: 0.3898 - val_loss: 0.1912 - val_mae: 0.4750
Epoch 9/5000
36/36 - 1s - loss: 0.1506 - mae: 0.3870 - val_loss: 0.1904 - val_mae: 0.4781
Epoch 10/5000
36/36 - 1s - loss: 0.1494 - mae: 0.3843 - val_loss: 0.1870 - val_mae: 0.4670
Epoch 11/5000
36/36 - 1s - loss: 0.1500 - mae: 0.3832 - val_loss: 0.1929 - val_mae: 0.4847
Epoch 12/5000
36/36 - 1s - loss: 0.1484 - mae: 0.3826 - val_loss: 0.1823 - val_mae: 0.4523
Epoch 13/5000
36/36 - 1s - loss: 0.1457 - mae: 0.3763 - val_loss: 0.1894 - val_mae: 0.4760
Epoch 14/5000
36/36 - 1s - loss: 0.1481 - mae: 0.3806 - val_loss: 0.1825 - val_mae: 0.4524
Epoch 15/5000
36/36 - 1s - loss: 0.1450 - mae: 0.3754 - val_loss: 0.1794 - val_mae: 0.4439
Epoch 16/5000
36/36 - 1s - loss: 0.1425 - mae: 0.3690 - val_loss: 0.1793 - val_mae: 0.4426
Epoch 17/5000
36/36 - 1s - loss: 0.1432 - mae: 0.3698 - val_loss: 0.1782 - val_mae: 0.4426
Epoch 18/5000
36/36 - 1s - loss: 0.1418 - mae: 0.3666 - val_loss: 0.1759 - val_mae: 0.4297
Epoch 19/5000
36/36 - 1s - loss: 0.1440 - mae: 0.3721 - val_loss: 0.1989 - val_mae: 0.5005
Epoch 20/5000
36/36 - 1s - loss: 0.1459 - mae: 0.3766 - val_loss: 0.2044 - val_mae: 0.5141
Epoch 21/5000
36/36 - 1s - loss: 0.1451 - mae: 0.3773 - val_loss: 0.1881 - val_mae: 0.4764
Epoch 22/5000
36/36 - 1s - loss: 0.1405 - mae: 0.3655 - val_loss: 0.1891 - val_mae: 0.4712
Epoch 23/5000
36/36 - 1s - loss: 0.1407 - mae: 0.3665 - val_loss: 0.1760 - val_mae: 0.4331
Epoch 24/5000
36/36 - 1s - loss: 0.1371 - mae: 0.3578 - val_loss: 0.1706 - val_mae: 0.4131
Epoch 25/5000
36/36 - 1s - loss: 0.1393 - mae: 0.3613 - val_loss: 0.1858 - val_mae: 0.4655
Epoch 26/5000
36/36 - 1s - loss: 0.1400 - mae: 0.3632 - val_loss: 0.1981 - val_mae: 0.4958
Epoch 27/5000
36/36 - 1s - loss: 0.1402 - mae: 0.3645 - val_loss: 0.1859 - val_mae: 0.4683
Epoch 28/5000
36/36 - 1s - loss: 0.1386 - mae: 0.3595 - val_loss: 0.1964 - val_mae: 0.4926
Epoch 29/5000
36/36 - 1s - loss: 0.1407 - mae: 0.3658 - val_loss: 0.1971 - val_mae: 0.4954
Epoch 30/5000
36/36 - 1s - loss: 0.1377 - mae: 0.3581 - val_loss: 0.1748 - val_mae: 0.4260
Epoch 31/5000
36/36 - 1s - loss: 0.1359 - mae: 0.3518 - val_loss: 0.1950 - val_mae: 0.4886
Epoch 32/5000
36/36 - 1s - loss: 0.1375 - mae: 0.3554 - val_loss: 0.1784 - val_mae: 0.4395
Epoch 33/5000
36/36 - 1s - loss: 0.1341 - mae: 0.3492 - val_loss: 0.1700 - val_mae: 0.4122
Epoch 34/5000
36/36 - 1s - loss: 0.1334 - mae: 0.3468 - val_loss: 0.1631 - val_mae: 0.3846
Epoch 35/5000
36/36 - 1s - loss: 0.1330 - mae: 0.3448 - val_loss: 0.2036 - val_mae: 0.5165
Epoch 36/5000
36/36 - 1s - loss: 0.1359 - mae: 0.3524 - val_loss: 0.1660 - val_mae: 0.3947
Epoch 37/5000
36/36 - 1s - loss: 0.1351 - mae: 0.3491 - val_loss: 0.2134 - val_mae: 0.5343
Epoch 38/5000
36/36 - 1s - loss: 0.1397 - mae: 0.3603 - val_loss: 0.1815 - val_mae: 0.4460
Epoch 39/5000
36/36 - 1s - loss: 0.1342 - mae: 0.3465 - val_loss: 0.1898 - val_mae: 0.4736
Epoch 40/5000
36/36 - 1s - loss: 0.1364 - mae: 0.3519 - val_loss: 0.1962 - val_mae: 0.4917
Epoch 41/5000
36/36 - 1s - loss: 0.1380 - mae: 0.3538 - val_loss: 0.2002 - val_mae: 0.4971
Epoch 42/5000
36/36 - 1s - loss: 0.1370 - mae: 0.3509 - val_loss: 0.1980 - val_mae: 0.4937
Epoch 43/5000
36/36 - 1s - loss: 0.1350 - mae: 0.3505 - val_loss: 0.1710 - val_mae: 0.4194
Epoch 44/5000
36/36 - 1s - loss: 0.1337 - mae: 0.3434 - val_loss: 0.2035 - val_mae: 0.5154
Epoch 45/5000
36/36 - 1s - loss: 0.1375 - mae: 0.3521 - val_loss: 0.1830 - val_mae: 0.4550
Epoch 46/5000
36/36 - 1s - loss: 0.1335 - mae: 0.3440 - val_loss: 0.1793 - val_mae: 0.4400
Epoch 47/5000
36/36 - 1s - loss: 0.1328 - mae: 0.3406 - val_loss: 0.1867 - val_mae: 0.4624
Epoch 48/5000
36/36 - 1s - loss: 0.1313 - mae: 0.3381 - val_loss: 0.1797 - val_mae: 0.4394
Epoch 49/5000
36/36 - 1s - loss: 0.1305 - mae: 0.3370 - val_loss: 0.1787 - val_mae: 0.4298
Epoch 50/5000
36/36 - 1s - loss: 0.1306 - mae: 0.3360 - val_loss: 0.1886 - val_mae: 0.4596
Epoch 51/5000
36/36 - 1s - loss: 0.1328 - mae: 0.3417 - val_loss: 0.1843 - val_mae: 0.4528
Epoch 52/5000
36/36 - 1s - loss: 0.1307 - mae: 0.3363 - val_loss: 0.1895 - val_mae: 0.4653
Epoch 53/5000
36/36 - 1s - loss: 0.1296 - mae: 0.3354 - val_loss: 0.1844 - val_mae: 0.4465
Epoch 54/5000
36/36 - 1s - loss: 0.1303 - mae: 0.3363 - val_loss: 0.1843 - val_mae: 0.4459
Epoch 55/5000
36/36 - 1s - loss: 0.1286 - mae: 0.3310 - val_loss: 0.1819 - val_mae: 0.4350
Epoch 56/5000
36/36 - 1s - loss: 0.1304 - mae: 0.3337 - val_loss: 0.1964 - val_mae: 0.4797
Epoch 57/5000
36/36 - 1s - loss: 0.1332 - mae: 0.3414 - val_loss: 0.1951 - val_mae: 0.4813
Epoch 58/5000
36/36 - 1s - loss: 0.1355 - mae: 0.3468 - val_loss: 0.1767 - val_mae: 0.4352
Epoch 59/5000
36/36 - 1s - loss: 0.1273 - mae: 0.3288 - val_loss: 0.1889 - val_mae: 0.4678
Epoch 60/5000
36/36 - 1s - loss: 0.1307 - mae: 0.3339 - val_loss: 0.1965 - val_mae: 0.4823
Epoch 61/5000
36/36 - 1s - loss: 0.1336 - mae: 0.3408 - val_loss: 0.2036 - val_mae: 0.5000
Epoch 62/5000
36/36 - 1s - loss: 0.1359 - mae: 0.3478 - val_loss: 0.1753 - val_mae: 0.4290
Epoch 63/5000
36/36 - 1s - loss: 0.1277 - mae: 0.3283 - val_loss: 0.1880 - val_mae: 0.4655
Epoch 64/5000
36/36 - 1s - loss: 0.1332 - mae: 0.3429 - val_loss: 0.1712 - val_mae: 0.4156
Epoch 65/5000
36/36 - 1s - loss: 0.1258 - mae: 0.3249 - val_loss: 0.1854 - val_mae: 0.4550
Epoch 66/5000
36/36 - 1s - loss: 0.1301 - mae: 0.3353 - val_loss: 0.1747 - val_mae: 0.4185
Epoch 67/5000
36/36 - 1s - loss: 0.1258 - mae: 0.3237 - val_loss: 0.1881 - val_mae: 0.4668
Epoch 68/5000
36/36 - 1s - loss: 0.1294 - mae: 0.3331 - val_loss: 0.1914 - val_mae: 0.4642
Epoch 69/5000
36/36 - 1s - loss: 0.1306 - mae: 0.3358 - val_loss: 0.1743 - val_mae: 0.4234
Epoch 70/5000
36/36 - 1s - loss: 0.1258 - mae: 0.3222 - val_loss: 0.1908 - val_mae: 0.4718
Epoch 71/5000
36/36 - 1s - loss: 0.1318 - mae: 0.3397 - val_loss: 0.1681 - val_mae: 0.4031
Epoch 72/5000
36/36 - 1s - loss: 0.1239 - mae: 0.3188 - val_loss: 0.1856 - val_mae: 0.4520
Epoch 73/5000
36/36 - 1s - loss: 0.1276 - mae: 0.3280 - val_loss: 0.1923 - val_mae: 0.4651
Epoch 74/5000
36/36 - 1s - loss: 0.1281 - mae: 0.3298 - val_loss: 0.1844 - val_mae: 0.4422
Epoch 75/5000
36/36 - 1s - loss: 0.1253 - mae: 0.3231 - val_loss: 0.1939 - val_mae: 0.4690
Epoch 76/5000
36/36 - 1s - loss: 0.1267 - mae: 0.3274 - val_loss: 0.1851 - val_mae: 0.4435
Epoch 77/5000
36/36 - 1s - loss: 0.1253 - mae: 0.3221 - val_loss: 0.1936 - val_mae: 0.4639
Epoch 78/5000
36/36 - 1s - loss: 0.1259 - mae: 0.3238 - val_loss: 0.1908 - val_mae: 0.4554
Epoch 79/5000
36/36 - 1s - loss: 0.1267 - mae: 0.3259 - val_loss: 0.1890 - val_mae: 0.4577
Epoch 80/5000
36/36 - 1s - loss: 0.1273 - mae: 0.3285 - val_loss: 0.1718 - val_mae: 0.4039
Epoch 81/5000
36/36 - 1s - loss: 0.1233 - mae: 0.3168 - val_loss: 0.1818 - val_mae: 0.4409
Epoch 82/5000
36/36 - 1s - loss: 0.1272 - mae: 0.3288 - val_loss: 0.1690 - val_mae: 0.3987
Epoch 83/5000
36/36 - 1s - loss: 0.1223 - mae: 0.3150 - val_loss: 0.1884 - val_mae: 0.4608
Epoch 84/5000
36/36 - 1s - loss: 0.1247 - mae: 0.3231 - val_loss: 0.1848 - val_mae: 0.4400
Epoch 85/5000
36/36 - 1s - loss: 0.1227 - mae: 0.3164 - val_loss: 0.1917 - val_mae: 0.4596
Epoch 86/5000
36/36 - 1s - loss: 0.1238 - mae: 0.3219 - val_loss: 0.1869 - val_mae: 0.4429
Epoch 87/5000
36/36 - 1s - loss: 0.1215 - mae: 0.3152 - val_loss: 0.1840 - val_mae: 0.4374
Epoch 88/5000
36/36 - 1s - loss: 0.1218 - mae: 0.3160 - val_loss: 0.1854 - val_mae: 0.4412
Epoch 89/5000
36/36 - 1s - loss: 0.1230 - mae: 0.3179 - val_loss: 0.1794 - val_mae: 0.4269
Epoch 90/5000
36/36 - 1s - loss: 0.1219 - mae: 0.3156 - val_loss: 0.1894 - val_mae: 0.4517
Epoch 91/5000
36/36 - 1s - loss: 0.1215 - mae: 0.3143 - val_loss: 0.1852 - val_mae: 0.4368
Epoch 92/5000
36/36 - 1s - loss: 0.1214 - mae: 0.3139 - val_loss: 0.1923 - val_mae: 0.4597
Epoch 93/5000
36/36 - 1s - loss: 0.1239 - mae: 0.3205 - val_loss: 0.1915 - val_mae: 0.4532
Epoch 94/5000
36/36 - 1s - loss: 0.1212 - mae: 0.3128 - val_loss: 0.1818 - val_mae: 0.4296
Epoch 95/5000
36/36 - 1s - loss: 0.1224 - mae: 0.3174 - val_loss: 0.1879 - val_mae: 0.4502
Epoch 96/5000
36/36 - 1s - loss: 0.1228 - mae: 0.3181 - val_loss: 0.1989 - val_mae: 0.4719
Epoch 97/5000
36/36 - 1s - loss: 0.1216 - mae: 0.3142 - val_loss: 0.1956 - val_mae: 0.4606
Epoch 98/5000
36/36 - 1s - loss: 0.1210 - mae: 0.3134 - val_loss: 0.1919 - val_mae: 0.4527
Epoch 99/5000
36/36 - 1s - loss: 0.1201 - mae: 0.3105 - val_loss: 0.1993 - val_mae: 0.4718
Epoch 100/5000
36/36 - 1s - loss: 0.1206 - mae: 0.3137 - val_loss: 0.1944 - val_mae: 0.4606
Epoch 101/5000
36/36 - 1s - loss: 0.1208 - mae: 0.3135 - val_loss: 0.1909 - val_mae: 0.4547
Epoch 102/5000
36/36 - 1s - loss: 0.1223 - mae: 0.3163 - val_loss: 0.1985 - val_mae: 0.4649
Epoch 103/5000
36/36 - 1s - loss: 0.1201 - mae: 0.3111 - val_loss: 0.1905 - val_mae: 0.4461
Epoch 104/5000
36/36 - 1s - loss: 0.1193 - mae: 0.3096 - val_loss: 0.1985 - val_mae: 0.4673
Epoch 105/5000
36/36 - 1s - loss: 0.1205 - mae: 0.3133 - val_loss: 0.2027 - val_mae: 0.4761
Epoch 106/5000
36/36 - 1s - loss: 0.1220 - mae: 0.3160 - val_loss: 0.2049 - val_mae: 0.4840
Epoch 107/5000
36/36 - 1s - loss: 0.1212 - mae: 0.3129 - val_loss: 0.1939 - val_mae: 0.4592
Epoch 108/5000
36/36 - 1s - loss: 0.1209 - mae: 0.3132 - val_loss: 0.1920 - val_mae: 0.4543
Epoch 109/5000
36/36 - 1s - loss: 0.1206 - mae: 0.3132 - val_loss: 0.1997 - val_mae: 0.4733
Epoch 110/5000
36/36 - 1s - loss: 0.1264 - mae: 0.3278 - val_loss: 0.1707 - val_mae: 0.3975
Epoch 111/5000
36/36 - 1s - loss: 0.1180 - mae: 0.3074 - val_loss: 0.1876 - val_mae: 0.4409
Epoch 112/5000
36/36 - 1s - loss: 0.1201 - mae: 0.3147 - val_loss: 0.1938 - val_mae: 0.4568
Epoch 113/5000
36/36 - 1s - loss: 0.1200 - mae: 0.3156 - val_loss: 0.1915 - val_mae: 0.4491
Epoch 114/5000
36/36 - 1s - loss: 0.1189 - mae: 0.3100 - val_loss: 0.1926 - val_mae: 0.4523
Epoch 115/5000
36/36 - 1s - loss: 0.1179 - mae: 0.3085 - val_loss: 0.1887 - val_mae: 0.4415
Epoch 116/5000
36/36 - 1s - loss: 0.1182 - mae: 0.3078 - val_loss: 0.1886 - val_mae: 0.4409
Epoch 117/5000
36/36 - 1s - loss: 0.1173 - mae: 0.3065 - val_loss: 0.1847 - val_mae: 0.4327
Epoch 118/5000
36/36 - 1s - loss: 0.1179 - mae: 0.3080 - val_loss: 0.1906 - val_mae: 0.4510
Epoch 119/5000
36/36 - 1s - loss: 0.1188 - mae: 0.3093 - val_loss: 0.1966 - val_mae: 0.4670
Epoch 120/5000
36/36 - 1s - loss: 0.1199 - mae: 0.3127 - val_loss: 0.1890 - val_mae: 0.4481
Epoch 121/5000
36/36 - 1s - loss: 0.1211 - mae: 0.3154 - val_loss: 0.1892 - val_mae: 0.4458
Epoch 122/5000
36/36 - 1s - loss: 0.1185 - mae: 0.3089 - val_loss: 0.2016 - val_mae: 0.4777
Epoch 123/5000
36/36 - 1s - loss: 0.1192 - mae: 0.3093 - val_loss: 0.1856 - val_mae: 0.4387
Epoch 124/5000
36/36 - 1s - loss: 0.1244 - mae: 0.3231 - val_loss: 0.1685 - val_mae: 0.3972
Epoch 125/5000
36/36 - 1s - loss: 0.1160 - mae: 0.3021 - val_loss: 0.1838 - val_mae: 0.4450
Epoch 126/5000
36/36 - 1s - loss: 0.1166 - mae: 0.3041 - val_loss: 0.1899 - val_mae: 0.4476
Epoch 127/5000
36/36 - 1s - loss: 0.1153 - mae: 0.3008 - val_loss: 0.1966 - val_mae: 0.4736
Epoch 128/5000
36/36 - 1s - loss: 0.1176 - mae: 0.3038 - val_loss: 0.2009 - val_mae: 0.4816
Epoch 129/5000
36/36 - 1s - loss: 0.1226 - mae: 0.3183 - val_loss: 0.1667 - val_mae: 0.3875
Epoch 130/5000
36/36 - 1s - loss: 0.1151 - mae: 0.3009 - val_loss: 0.1946 - val_mae: 0.4702
Epoch 131/5000
36/36 - 1s - loss: 0.1228 - mae: 0.3224 - val_loss: 0.1784 - val_mae: 0.4193
Epoch 132/5000
36/36 - 1s - loss: 0.1166 - mae: 0.3041 - val_loss: 0.1920 - val_mae: 0.4578
Epoch 133/5000
36/36 - 1s - loss: 0.1224 - mae: 0.3202 - val_loss: 0.1714 - val_mae: 0.4113
Epoch 134/5000
36/36 - 1s - loss: 0.1138 - mae: 0.2989 - val_loss: 0.1897 - val_mae: 0.4507
Epoch 135/5000
36/36 - 1s - loss: 0.1170 - mae: 0.3070 - val_loss: 0.1873 - val_mae: 0.4496
Restoring model weights from the end of the best epoch.
Epoch 00135: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_3..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_19"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_3 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_3 (PartitionP (None, None, 64)     0           message_passing_3[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_3[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_3 (Masking)             (None, None, 64)     0           partition_padding_3[0][0]        
                                                                 partition_padding_3[1][0]        
__________________________________________________________________________________________________
transformer_encoder_3 (Transfor (None, None, 64)     199040      masking_3[0][0]                  
                                                                 masking_3[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_3 (Glo (None, 64)           0           transformer_encoder_3[0][0]      
                                                                 transformer_encoder_3[1][0]      
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 512)          33280       global_average_pooling1d_3[0][0] 
                                                                 global_average_pooling1d_3[1][0] 
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 10)           110         dense_55[0][0]                   
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 450)          230850      dense_53[0][0]                   
                                                                 dense_53[1][0]                   
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 5)            55          dense_56[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 905)          0           dense_54[0][0]                   
                                                                 dense_54[1][0]                   
                                                                 dense_57[0][0]                   
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 700)          634200      concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 560)          392560      dense_58[0][0]                   
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 373)          209253      dense_62[0][0]                   
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 187)          69938       dense_63[0][0]                   
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 1)            188         dense_64[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
36/36 - 7s - loss: 0.1291 - mae: 0.3352 - val_loss: 0.1679 - val_mae: 0.4083
Epoch 2/5000
36/36 - 1s - loss: 0.1209 - mae: 0.3152 - val_loss: 0.1664 - val_mae: 0.4072
Epoch 3/5000
36/36 - 1s - loss: 0.1159 - mae: 0.3040 - val_loss: 0.1694 - val_mae: 0.4211
Epoch 4/5000
36/36 - 1s - loss: 0.1134 - mae: 0.2986 - val_loss: 0.1721 - val_mae: 0.4292
Epoch 5/5000
36/36 - 1s - loss: 0.1113 - mae: 0.2935 - val_loss: 0.1762 - val_mae: 0.4402
Epoch 6/5000
36/36 - 1s - loss: 0.1099 - mae: 0.2899 - val_loss: 0.1774 - val_mae: 0.4425
Epoch 7/5000
36/36 - 1s - loss: 0.1128 - mae: 0.2968 - val_loss: 0.1541 - val_mae: 0.3622
Epoch 8/5000
36/36 - 1s - loss: 0.1113 - mae: 0.2945 - val_loss: 0.1493 - val_mae: 0.3248
Epoch 9/5000
36/36 - 1s - loss: 0.1055 - mae: 0.2809 - val_loss: 0.1499 - val_mae: 0.3259
Epoch 10/5000
36/36 - 1s - loss: 0.1013 - mae: 0.2702 - val_loss: 0.1545 - val_mae: 0.3453
Epoch 11/5000
36/36 - 1s - loss: 0.0989 - mae: 0.2645 - val_loss: 0.1593 - val_mae: 0.3644
Epoch 12/5000
36/36 - 1s - loss: 0.0964 - mae: 0.2585 - val_loss: 0.1617 - val_mae: 0.3740
Epoch 13/5000
36/36 - 1s - loss: 0.0945 - mae: 0.2536 - val_loss: 0.1639 - val_mae: 0.3825
Epoch 14/5000
36/36 - 1s - loss: 0.0932 - mae: 0.2506 - val_loss: 0.1659 - val_mae: 0.3872
Epoch 15/5000
36/36 - 1s - loss: 0.0913 - mae: 0.2461 - val_loss: 0.1687 - val_mae: 0.3974
Epoch 16/5000
36/36 - 1s - loss: 0.0897 - mae: 0.2421 - val_loss: 0.1676 - val_mae: 0.3950
Epoch 17/5000
36/36 - 1s - loss: 0.0881 - mae: 0.2375 - val_loss: 0.1716 - val_mae: 0.4076
Epoch 18/5000
36/36 - 1s - loss: 0.0868 - mae: 0.2350 - val_loss: 0.1703 - val_mae: 0.4027
Epoch 19/5000
36/36 - 1s - loss: 0.0859 - mae: 0.2328 - val_loss: 0.1681 - val_mae: 0.3948
Epoch 20/5000
36/36 - 1s - loss: 0.0852 - mae: 0.2314 - val_loss: 0.1667 - val_mae: 0.3886
Epoch 21/5000
36/36 - 1s - loss: 0.0852 - mae: 0.2321 - val_loss: 0.1656 - val_mae: 0.3848
Epoch 22/5000
36/36 - 1s - loss: 0.0847 - mae: 0.2325 - val_loss: 0.1613 - val_mae: 0.3716
Epoch 23/5000
36/36 - 1s - loss: 0.0846 - mae: 0.2313 - val_loss: 0.1628 - val_mae: 0.3754
Epoch 24/5000
36/36 - 1s - loss: 0.0830 - mae: 0.2264 - val_loss: 0.1650 - val_mae: 0.3817
Epoch 25/5000
36/36 - 1s - loss: 0.0805 - mae: 0.2208 - val_loss: 0.1673 - val_mae: 0.3881
Epoch 26/5000
36/36 - 1s - loss: 0.0790 - mae: 0.2177 - val_loss: 0.1677 - val_mae: 0.3860
Epoch 27/5000
36/36 - 1s - loss: 0.0776 - mae: 0.2139 - val_loss: 0.1687 - val_mae: 0.3871
Epoch 28/5000
36/36 - 1s - loss: 0.0769 - mae: 0.2121 - val_loss: 0.1673 - val_mae: 0.3816
Epoch 29/5000
36/36 - 1s - loss: 0.0767 - mae: 0.2118 - val_loss: 0.1719 - val_mae: 0.3946
Epoch 30/5000
36/36 - 1s - loss: 0.0769 - mae: 0.2119 - val_loss: 0.1640 - val_mae: 0.3719
Epoch 31/5000
36/36 - 1s - loss: 0.0759 - mae: 0.2099 - val_loss: 0.1688 - val_mae: 0.3790
Epoch 32/5000
36/36 - 1s - loss: 0.0746 - mae: 0.2067 - val_loss: 0.1587 - val_mae: 0.3503
Epoch 33/5000
36/36 - 1s - loss: 0.0735 - mae: 0.2049 - val_loss: 0.1586 - val_mae: 0.3521
Epoch 34/5000
36/36 - 1s - loss: 0.0722 - mae: 0.2029 - val_loss: 0.1542 - val_mae: 0.3369
Epoch 35/5000
36/36 - 1s - loss: 0.0710 - mae: 0.1991 - val_loss: 0.1582 - val_mae: 0.3463
Epoch 36/5000
36/36 - 1s - loss: 0.0697 - mae: 0.1965 - val_loss: 0.1577 - val_mae: 0.3440
Epoch 37/5000
36/36 - 1s - loss: 0.0691 - mae: 0.1965 - val_loss: 0.1575 - val_mae: 0.3432
Epoch 38/5000
36/36 - 1s - loss: 0.0681 - mae: 0.1939 - val_loss: 0.1562 - val_mae: 0.3359
Epoch 39/5000
36/36 - 1s - loss: 0.0677 - mae: 0.1940 - val_loss: 0.1549 - val_mae: 0.3325
Epoch 40/5000
36/36 - 1s - loss: 0.0674 - mae: 0.1942 - val_loss: 0.1528 - val_mae: 0.3280
Epoch 41/5000
36/36 - 1s - loss: 0.0705 - mae: 0.2036 - val_loss: 0.1534 - val_mae: 0.3331
Epoch 42/5000
36/36 - 1s - loss: 0.0737 - mae: 0.2136 - val_loss: 0.1823 - val_mae: 0.4053
Epoch 43/5000
36/36 - 1s - loss: 0.0720 - mae: 0.2094 - val_loss: 0.1729 - val_mae: 0.3857
Epoch 44/5000
36/36 - 1s - loss: 0.0711 - mae: 0.2143 - val_loss: 0.1593 - val_mae: 0.3440
Epoch 45/5000
36/36 - 1s - loss: 0.0654 - mae: 0.1967 - val_loss: 0.1624 - val_mae: 0.3475
Epoch 46/5000
36/36 - 1s - loss: 0.0616 - mae: 0.1871 - val_loss: 0.1609 - val_mae: 0.3419
Epoch 47/5000
36/36 - 1s - loss: 0.0598 - mae: 0.1817 - val_loss: 0.1683 - val_mae: 0.3588
Epoch 48/5000
36/36 - 1s - loss: 0.0592 - mae: 0.1810 - val_loss: 0.1725 - val_mae: 0.3662
Epoch 49/5000
36/36 - 1s - loss: 0.0586 - mae: 0.1803 - val_loss: 0.1876 - val_mae: 0.3993
Epoch 50/5000
36/36 - 1s - loss: 0.0614 - mae: 0.1902 - val_loss: 0.1744 - val_mae: 0.3757
Epoch 51/5000
36/36 - 1s - loss: 0.0683 - mae: 0.2134 - val_loss: 0.1535 - val_mae: 0.3186
Epoch 52/5000
36/36 - 1s - loss: 0.0688 - mae: 0.2170 - val_loss: 0.1530 - val_mae: 0.3117
Epoch 53/5000
36/36 - 1s - loss: 0.0648 - mae: 0.2044 - val_loss: 0.1558 - val_mae: 0.3140
Epoch 54/5000
36/36 - 1s - loss: 0.0650 - mae: 0.2037 - val_loss: 0.1568 - val_mae: 0.3141
Epoch 55/5000
36/36 - 1s - loss: 0.0644 - mae: 0.2023 - val_loss: 0.1557 - val_mae: 0.3093
Epoch 56/5000
36/36 - 1s - loss: 0.0778 - mae: 0.2290 - val_loss: 0.1732 - val_mae: 0.3697
Epoch 57/5000
36/36 - 1s - loss: 0.0677 - mae: 0.2087 - val_loss: 0.1693 - val_mae: 0.3658
Epoch 58/5000
36/36 - 1s - loss: 0.0639 - mae: 0.1998 - val_loss: 0.1720 - val_mae: 0.3690
Epoch 59/5000
36/36 - 1s - loss: 0.0572 - mae: 0.1827 - val_loss: 0.1833 - val_mae: 0.3899
Epoch 60/5000
36/36 - 1s - loss: 0.0552 - mae: 0.1786 - val_loss: 0.1758 - val_mae: 0.3710
Epoch 61/5000
36/36 - 1s - loss: 0.0537 - mae: 0.1751 - val_loss: 0.1759 - val_mae: 0.3656
Epoch 62/5000
36/36 - 1s - loss: 0.0558 - mae: 0.1807 - val_loss: 0.1707 - val_mae: 0.3523
Epoch 63/5000
36/36 - 1s - loss: 0.0578 - mae: 0.1872 - val_loss: 0.1665 - val_mae: 0.3455
Epoch 64/5000
36/36 - 1s - loss: 0.0596 - mae: 0.1925 - val_loss: 0.1823 - val_mae: 0.3757
Epoch 65/5000
36/36 - 1s - loss: 0.0629 - mae: 0.1993 - val_loss: 0.1968 - val_mae: 0.4013
Epoch 66/5000
36/36 - 1s - loss: 0.0705 - mae: 0.2192 - val_loss: 0.1583 - val_mae: 0.3279
Epoch 67/5000
36/36 - 1s - loss: 0.0629 - mae: 0.2091 - val_loss: 0.1727 - val_mae: 0.3429
Epoch 68/5000
36/36 - 1s - loss: 0.0569 - mae: 0.1878 - val_loss: 0.1859 - val_mae: 0.3749
Epoch 69/5000
36/36 - 1s - loss: 0.0584 - mae: 0.1914 - val_loss: 0.1593 - val_mae: 0.3298
Epoch 70/5000
36/36 - 1s - loss: 0.0523 - mae: 0.1858 - val_loss: 0.1683 - val_mae: 0.3290
Epoch 71/5000
36/36 - 1s - loss: 0.0508 - mae: 0.1774 - val_loss: 0.1656 - val_mae: 0.3299
Epoch 72/5000
36/36 - 1s - loss: 0.0547 - mae: 0.1857 - val_loss: 0.1653 - val_mae: 0.3382
Epoch 73/5000
36/36 - 1s - loss: 0.0561 - mae: 0.1924 - val_loss: 0.1626 - val_mae: 0.3222
Epoch 74/5000
36/36 - 1s - loss: 0.0625 - mae: 0.2120 - val_loss: 0.1635 - val_mae: 0.3199
Epoch 75/5000
36/36 - 1s - loss: 0.0729 - mae: 0.2293 - val_loss: 0.1670 - val_mae: 0.3227
Epoch 76/5000
36/36 - 1s - loss: 0.0774 - mae: 0.2452 - val_loss: 0.1684 - val_mae: 0.3417
Epoch 77/5000
36/36 - 1s - loss: 0.0718 - mae: 0.2305 - val_loss: 0.1671 - val_mae: 0.3279
Epoch 78/5000
36/36 - 1s - loss: 0.0696 - mae: 0.2250 - val_loss: 0.1666 - val_mae: 0.3315
Epoch 79/5000
36/36 - 1s - loss: 0.0638 - mae: 0.2109 - val_loss: 0.1689 - val_mae: 0.3399
Epoch 80/5000
36/36 - 1s - loss: 0.0589 - mae: 0.2034 - val_loss: 0.1670 - val_mae: 0.3401
Epoch 81/5000
36/36 - 1s - loss: 0.0486 - mae: 0.1784 - val_loss: 0.1647 - val_mae: 0.3313
Epoch 82/5000
36/36 - 1s - loss: 0.0436 - mae: 0.1638 - val_loss: 0.1640 - val_mae: 0.3253
Epoch 83/5000
36/36 - 1s - loss: 0.0421 - mae: 0.1607 - val_loss: 0.1636 - val_mae: 0.3228
Epoch 84/5000
36/36 - 1s - loss: 0.0390 - mae: 0.1521 - val_loss: 0.1638 - val_mae: 0.3252
Epoch 85/5000
36/36 - 1s - loss: 0.0395 - mae: 0.1559 - val_loss: 0.1637 - val_mae: 0.3283
Epoch 86/5000
36/36 - 1s - loss: 0.0376 - mae: 0.1525 - val_loss: 0.1634 - val_mae: 0.3298
Epoch 87/5000
36/36 - 1s - loss: 0.0358 - mae: 0.1476 - val_loss: 0.1644 - val_mae: 0.3316
Epoch 88/5000
36/36 - 1s - loss: 0.0419 - mae: 0.1628 - val_loss: 0.1613 - val_mae: 0.3251
Epoch 89/5000
36/36 - 1s - loss: 0.0436 - mae: 0.1660 - val_loss: 0.1610 - val_mae: 0.3181
Epoch 90/5000
36/36 - 1s - loss: 0.0392 - mae: 0.1565 - val_loss: 0.1613 - val_mae: 0.3214
Epoch 91/5000
36/36 - 1s - loss: 0.0372 - mae: 0.1501 - val_loss: 0.1591 - val_mae: 0.3194
Epoch 92/5000
36/36 - 1s - loss: 0.0397 - mae: 0.1594 - val_loss: 0.1582 - val_mae: 0.3171
Epoch 93/5000
36/36 - 1s - loss: 0.0371 - mae: 0.1544 - val_loss: 0.1585 - val_mae: 0.3155
Epoch 94/5000
36/36 - 1s - loss: 0.0349 - mae: 0.1495 - val_loss: 0.1614 - val_mae: 0.3205
Epoch 95/5000
36/36 - 1s - loss: 0.0380 - mae: 0.1582 - val_loss: 0.1627 - val_mae: 0.3245
Epoch 96/5000
36/36 - 1s - loss: 0.0407 - mae: 0.1674 - val_loss: 0.1647 - val_mae: 0.3259
Epoch 97/5000
36/36 - 1s - loss: 0.0432 - mae: 0.1737 - val_loss: 0.1694 - val_mae: 0.3310
Epoch 98/5000
36/36 - 1s - loss: 0.0391 - mae: 0.1634 - val_loss: 0.1677 - val_mae: 0.3326
Epoch 99/5000
36/36 - 1s - loss: 0.0485 - mae: 0.1873 - val_loss: 0.1659 - val_mae: 0.3330
Epoch 100/5000
36/36 - 1s - loss: 0.0467 - mae: 0.1804 - val_loss: 0.1679 - val_mae: 0.3352
Epoch 101/5000
36/36 - 1s - loss: 0.0560 - mae: 0.2022 - val_loss: 0.1655 - val_mae: 0.3334
Epoch 102/5000
36/36 - 1s - loss: 0.0659 - mae: 0.2204 - val_loss: 0.1865 - val_mae: 0.3682
Epoch 103/5000
36/36 - 1s - loss: 0.0615 - mae: 0.2104 - val_loss: 0.1671 - val_mae: 0.3368
Epoch 104/5000
36/36 - 1s - loss: 0.0448 - mae: 0.1731 - val_loss: 0.1640 - val_mae: 0.3254
Epoch 105/5000
36/36 - 1s - loss: 0.0333 - mae: 0.1487 - val_loss: 0.1615 - val_mae: 0.3209
Epoch 106/5000
36/36 - 1s - loss: 0.0323 - mae: 0.1453 - val_loss: 0.1593 - val_mae: 0.3201
Epoch 107/5000
36/36 - 1s - loss: 0.0318 - mae: 0.1453 - val_loss: 0.1601 - val_mae: 0.3240
Epoch 108/5000
36/36 - 1s - loss: 0.0309 - mae: 0.1412 - val_loss: 0.1538 - val_mae: 0.3116
Epoch 109/5000
36/36 - 1s - loss: 0.0279 - mae: 0.1326 - val_loss: 0.1576 - val_mae: 0.3212
Epoch 110/5000
36/36 - 1s - loss: 0.0287 - mae: 0.1320 - val_loss: 0.1603 - val_mae: 0.3197
Epoch 111/5000
36/36 - 1s - loss: 0.0273 - mae: 0.1330 - val_loss: 0.1600 - val_mae: 0.3222
Epoch 112/5000
36/36 - 1s - loss: 0.0249 - mae: 0.1264 - val_loss: 0.1602 - val_mae: 0.3204
Epoch 113/5000
36/36 - 1s - loss: 0.0238 - mae: 0.1240 - val_loss: 0.1594 - val_mae: 0.3177
Epoch 114/5000
36/36 - 1s - loss: 0.0239 - mae: 0.1256 - val_loss: 0.1545 - val_mae: 0.3128
Epoch 115/5000
36/36 - 1s - loss: 0.0223 - mae: 0.1219 - val_loss: 0.1549 - val_mae: 0.3131
Epoch 116/5000
36/36 - 1s - loss: 0.0239 - mae: 0.1263 - val_loss: 0.1541 - val_mae: 0.3116
Epoch 117/5000
36/36 - 1s - loss: 0.0269 - mae: 0.1328 - val_loss: 0.1497 - val_mae: 0.3102
Epoch 118/5000
36/36 - 1s - loss: 0.0282 - mae: 0.1374 - val_loss: 0.1528 - val_mae: 0.3059
Epoch 119/5000
36/36 - 1s - loss: 0.0241 - mae: 0.1248 - val_loss: 0.1542 - val_mae: 0.3093
Epoch 120/5000
36/36 - 1s - loss: 0.0236 - mae: 0.1238 - val_loss: 0.1603 - val_mae: 0.3235
Epoch 121/5000
36/36 - 1s - loss: 0.0257 - mae: 0.1337 - val_loss: 0.1632 - val_mae: 0.3242
Epoch 122/5000
36/36 - 1s - loss: 0.0255 - mae: 0.1323 - val_loss: 0.1654 - val_mae: 0.3315
Epoch 123/5000
36/36 - 1s - loss: 0.0299 - mae: 0.1461 - val_loss: 0.1624 - val_mae: 0.3261
Epoch 124/5000
36/36 - 1s - loss: 0.0362 - mae: 0.1622 - val_loss: 0.1592 - val_mae: 0.3178
Epoch 125/5000
36/36 - 1s - loss: 0.0376 - mae: 0.1658 - val_loss: 0.1585 - val_mae: 0.3177
Epoch 126/5000
36/36 - 1s - loss: 0.0389 - mae: 0.1702 - val_loss: 0.1746 - val_mae: 0.3413
Epoch 127/5000
36/36 - 1s - loss: 0.0560 - mae: 0.2006 - val_loss: 0.1737 - val_mae: 0.3486
Epoch 128/5000
36/36 - 1s - loss: 0.0338 - mae: 0.1550 - val_loss: 0.1558 - val_mae: 0.3192
Epoch 129/5000
36/36 - 1s - loss: 0.0245 - mae: 0.1278 - val_loss: 0.1537 - val_mae: 0.3113
Epoch 130/5000
36/36 - 1s - loss: 0.0202 - mae: 0.1199 - val_loss: 0.1504 - val_mae: 0.3061
Epoch 131/5000
36/36 - 1s - loss: 0.0188 - mae: 0.1182 - val_loss: 0.1496 - val_mae: 0.3043
Epoch 132/5000
36/36 - 1s - loss: 0.0173 - mae: 0.1132 - val_loss: 0.1532 - val_mae: 0.3092
Epoch 133/5000
36/36 - 1s - loss: 0.0207 - mae: 0.1236 - val_loss: 0.1550 - val_mae: 0.3123
Epoch 134/5000
36/36 - 1s - loss: 0.0200 - mae: 0.1206 - val_loss: 0.1529 - val_mae: 0.3110
Epoch 135/5000
36/36 - 1s - loss: 0.0221 - mae: 0.1263 - val_loss: 0.1559 - val_mae: 0.3131
Epoch 136/5000
36/36 - 1s - loss: 0.0211 - mae: 0.1196 - val_loss: 0.1539 - val_mae: 0.3097
Epoch 137/5000
36/36 - 1s - loss: 0.0292 - mae: 0.1443 - val_loss: 0.1594 - val_mae: 0.3229
Epoch 138/5000
36/36 - 1s - loss: 0.0299 - mae: 0.1453 - val_loss: 0.1599 - val_mae: 0.3186
Epoch 139/5000
36/36 - 1s - loss: 0.0229 - mae: 0.1269 - val_loss: 0.1609 - val_mae: 0.3230
Epoch 140/5000
36/36 - 1s - loss: 0.0192 - mae: 0.1167 - val_loss: 0.1552 - val_mae: 0.3122
Epoch 141/5000
36/36 - 1s - loss: 0.0181 - mae: 0.1173 - val_loss: 0.1551 - val_mae: 0.3178
Epoch 142/5000
36/36 - 1s - loss: 0.0173 - mae: 0.1149 - val_loss: 0.1561 - val_mae: 0.3185
Epoch 143/5000
36/36 - 1s - loss: 0.0159 - mae: 0.1108 - val_loss: 0.1578 - val_mae: 0.3243
Epoch 144/5000
36/36 - 1s - loss: 0.0166 - mae: 0.1125 - val_loss: 0.1577 - val_mae: 0.3222
Epoch 145/5000
36/36 - 1s - loss: 0.0168 - mae: 0.1133 - val_loss: 0.1548 - val_mae: 0.3174
Epoch 146/5000
36/36 - 1s - loss: 0.0175 - mae: 0.1143 - val_loss: 0.1526 - val_mae: 0.3076
Epoch 147/5000
36/36 - 1s - loss: 0.0196 - mae: 0.1203 - val_loss: 0.1538 - val_mae: 0.3126
Epoch 148/5000
36/36 - 1s - loss: 0.0251 - mae: 0.1375 - val_loss: 0.1568 - val_mae: 0.3169
Epoch 149/5000
36/36 - 1s - loss: 0.0263 - mae: 0.1387 - val_loss: 0.1483 - val_mae: 0.3015
Epoch 150/5000
36/36 - 1s - loss: 0.0268 - mae: 0.1368 - val_loss: 0.1540 - val_mae: 0.3203
Epoch 151/5000
36/36 - 1s - loss: 0.0320 - mae: 0.1519 - val_loss: 0.1637 - val_mae: 0.3323
Epoch 152/5000
36/36 - 1s - loss: 0.0248 - mae: 0.1363 - val_loss: 0.1577 - val_mae: 0.3251
Epoch 153/5000
36/36 - 1s - loss: 0.0180 - mae: 0.1185 - val_loss: 0.1676 - val_mae: 0.3368
Epoch 154/5000
36/36 - 1s - loss: 0.0181 - mae: 0.1167 - val_loss: 0.1591 - val_mae: 0.3234
Epoch 155/5000
36/36 - 1s - loss: 0.0160 - mae: 0.1122 - val_loss: 0.1582 - val_mae: 0.3252
Epoch 156/5000
36/36 - 1s - loss: 0.0149 - mae: 0.1083 - val_loss: 0.1554 - val_mae: 0.3190
Epoch 157/5000
36/36 - 1s - loss: 0.0164 - mae: 0.1118 - val_loss: 0.1599 - val_mae: 0.3221
Epoch 158/5000
36/36 - 1s - loss: 0.0196 - mae: 0.1223 - val_loss: 0.1441 - val_mae: 0.3009
Epoch 159/5000
36/36 - 1s - loss: 0.0238 - mae: 0.1335 - val_loss: 0.1480 - val_mae: 0.3087
Epoch 160/5000
36/36 - 1s - loss: 0.0233 - mae: 0.1334 - val_loss: 0.1569 - val_mae: 0.3215
Epoch 161/5000
36/36 - 1s - loss: 0.0198 - mae: 0.1232 - val_loss: 0.1628 - val_mae: 0.3337
Epoch 162/5000
36/36 - 1s - loss: 0.0232 - mae: 0.1262 - val_loss: 0.1626 - val_mae: 0.3331
Epoch 163/5000
36/36 - 1s - loss: 0.0230 - mae: 0.1264 - val_loss: 0.1556 - val_mae: 0.3134
Epoch 164/5000
36/36 - 1s - loss: 0.0270 - mae: 0.1352 - val_loss: 0.1443 - val_mae: 0.2918
Epoch 165/5000
36/36 - 1s - loss: 0.0249 - mae: 0.1324 - val_loss: 0.1435 - val_mae: 0.2982
Epoch 166/5000
36/36 - 1s - loss: 0.0260 - mae: 0.1324 - val_loss: 0.1551 - val_mae: 0.3182
Epoch 167/5000
36/36 - 1s - loss: 0.0227 - mae: 0.1218 - val_loss: 0.1640 - val_mae: 0.3359
Epoch 168/5000
36/36 - 1s - loss: 0.0204 - mae: 0.1217 - val_loss: 0.1562 - val_mae: 0.3218
Epoch 169/5000
36/36 - 1s - loss: 0.0172 - mae: 0.1132 - val_loss: 0.1667 - val_mae: 0.3375
Epoch 170/5000
36/36 - 1s - loss: 0.0179 - mae: 0.1189 - val_loss: 0.1739 - val_mae: 0.3492
Epoch 171/5000
36/36 - 1s - loss: 0.0184 - mae: 0.1197 - val_loss: 0.1725 - val_mae: 0.3439
Epoch 172/5000
36/36 - 1s - loss: 0.0172 - mae: 0.1167 - val_loss: 0.1761 - val_mae: 0.3505
Epoch 173/5000
36/36 - 1s - loss: 0.0170 - mae: 0.1185 - val_loss: 0.1927 - val_mae: 0.3769
Epoch 174/5000
36/36 - 1s - loss: 0.0208 - mae: 0.1245 - val_loss: 0.1960 - val_mae: 0.3808
Epoch 175/5000
36/36 - 1s - loss: 0.0213 - mae: 0.1267 - val_loss: 0.1784 - val_mae: 0.3576
Epoch 176/5000
36/36 - 1s - loss: 0.0228 - mae: 0.1295 - val_loss: 0.1877 - val_mae: 0.3734
Epoch 177/5000
36/36 - 1s - loss: 0.0181 - mae: 0.1230 - val_loss: 0.2304 - val_mae: 0.4408
Epoch 178/5000
36/36 - 1s - loss: 0.0254 - mae: 0.1399 - val_loss: 0.1865 - val_mae: 0.3760
Epoch 179/5000
36/36 - 1s - loss: 0.0299 - mae: 0.1499 - val_loss: 0.2042 - val_mae: 0.4099
Epoch 180/5000
36/36 - 1s - loss: 0.0204 - mae: 0.1310 - val_loss: 0.2214 - val_mae: 0.4456
Epoch 181/5000
36/36 - 1s - loss: 0.0253 - mae: 0.1429 - val_loss: 0.2174 - val_mae: 0.4293
Epoch 182/5000
36/36 - 1s - loss: 0.0273 - mae: 0.1440 - val_loss: 0.2365 - val_mae: 0.4774
Epoch 183/5000
36/36 - 1s - loss: 0.0280 - mae: 0.1475 - val_loss: 0.1971 - val_mae: 0.4119
Epoch 184/5000
36/36 - 1s - loss: 0.0277 - mae: 0.1471 - val_loss: 0.1919 - val_mae: 0.4094
Epoch 185/5000
36/36 - 1s - loss: 0.0307 - mae: 0.1557 - val_loss: 0.1896 - val_mae: 0.4075
Epoch 186/5000
36/36 - 1s - loss: 0.0283 - mae: 0.1464 - val_loss: 0.1728 - val_mae: 0.3756
Epoch 187/5000
36/36 - 1s - loss: 0.0273 - mae: 0.1456 - val_loss: 0.1824 - val_mae: 0.3857
Epoch 188/5000
36/36 - 1s - loss: 0.0270 - mae: 0.1370 - val_loss: 0.1776 - val_mae: 0.3727
Epoch 189/5000
36/36 - 1s - loss: 0.0221 - mae: 0.1236 - val_loss: 0.1553 - val_mae: 0.3403
Epoch 190/5000
36/36 - 1s - loss: 0.0231 - mae: 0.1322 - val_loss: 0.1572 - val_mae: 0.3521
Epoch 191/5000
36/36 - 1s - loss: 0.0206 - mae: 0.1284 - val_loss: 0.1583 - val_mae: 0.3480
Epoch 192/5000
36/36 - 1s - loss: 0.0197 - mae: 0.1264 - val_loss: 0.1523 - val_mae: 0.3338
Epoch 193/5000
36/36 - 1s - loss: 0.0184 - mae: 0.1233 - val_loss: 0.1528 - val_mae: 0.3247
Epoch 194/5000
36/36 - 1s - loss: 0.0162 - mae: 0.1139 - val_loss: 0.1542 - val_mae: 0.3171
Epoch 195/5000
36/36 - 1s - loss: 0.0137 - mae: 0.1033 - val_loss: 0.1490 - val_mae: 0.3132
Epoch 196/5000
36/36 - 1s - loss: 0.0124 - mae: 0.0958 - val_loss: 0.1497 - val_mae: 0.3072
Epoch 197/5000
36/36 - 1s - loss: 0.0115 - mae: 0.0948 - val_loss: 0.1471 - val_mae: 0.3058
Epoch 198/5000
36/36 - 1s - loss: 0.0098 - mae: 0.0861 - val_loss: 0.1485 - val_mae: 0.3033
Epoch 199/5000
36/36 - 1s - loss: 0.0092 - mae: 0.0836 - val_loss: 0.1490 - val_mae: 0.3066
Epoch 200/5000
36/36 - 1s - loss: 0.0084 - mae: 0.0777 - val_loss: 0.1480 - val_mae: 0.3056
Epoch 201/5000
36/36 - 1s - loss: 0.0082 - mae: 0.0744 - val_loss: 0.1490 - val_mae: 0.3054
Epoch 202/5000
36/36 - 1s - loss: 0.0078 - mae: 0.0725 - val_loss: 0.1444 - val_mae: 0.2975
Epoch 203/5000
36/36 - 1s - loss: 0.0080 - mae: 0.0754 - val_loss: 0.1503 - val_mae: 0.3109
Epoch 204/5000
36/36 - 1s - loss: 0.0084 - mae: 0.0752 - val_loss: 0.1481 - val_mae: 0.3057
Epoch 205/5000
36/36 - 1s - loss: 0.0072 - mae: 0.0695 - val_loss: 0.1464 - val_mae: 0.3024
Epoch 206/5000
36/36 - 1s - loss: 0.0067 - mae: 0.0663 - val_loss: 0.1463 - val_mae: 0.3055
Epoch 207/5000
36/36 - 1s - loss: 0.0073 - mae: 0.0677 - val_loss: 0.1510 - val_mae: 0.3144
Epoch 208/5000
36/36 - 1s - loss: 0.0078 - mae: 0.0683 - val_loss: 0.1441 - val_mae: 0.2980
Epoch 209/5000
36/36 - 1s - loss: 0.0072 - mae: 0.0678 - val_loss: 0.1477 - val_mae: 0.3062
Epoch 210/5000
36/36 - 1s - loss: 0.0074 - mae: 0.0687 - val_loss: 0.1514 - val_mae: 0.3186
Epoch 211/5000
36/36 - 1s - loss: 0.0079 - mae: 0.0686 - val_loss: 0.1503 - val_mae: 0.3104
Epoch 212/5000
36/36 - 1s - loss: 0.0075 - mae: 0.0668 - val_loss: 0.1430 - val_mae: 0.2972
Epoch 213/5000
36/36 - 1s - loss: 0.0082 - mae: 0.0729 - val_loss: 0.1525 - val_mae: 0.3190
Epoch 214/5000
36/36 - 1s - loss: 0.0089 - mae: 0.0743 - val_loss: 0.1526 - val_mae: 0.3200
Epoch 215/5000
36/36 - 1s - loss: 0.0093 - mae: 0.0752 - val_loss: 0.1448 - val_mae: 0.3009
Epoch 216/5000
36/36 - 1s - loss: 0.0081 - mae: 0.0703 - val_loss: 0.1496 - val_mae: 0.3132
Epoch 217/5000
36/36 - 1s - loss: 0.0074 - mae: 0.0672 - val_loss: 0.1585 - val_mae: 0.3341
Epoch 218/5000
36/36 - 1s - loss: 0.0079 - mae: 0.0684 - val_loss: 0.1489 - val_mae: 0.3101
Epoch 219/5000
36/36 - 1s - loss: 0.0074 - mae: 0.0654 - val_loss: 0.1449 - val_mae: 0.3037
Epoch 220/5000
36/36 - 1s - loss: 0.0071 - mae: 0.0676 - val_loss: 0.1584 - val_mae: 0.3326
Epoch 221/5000
36/36 - 1s - loss: 0.0066 - mae: 0.0629 - val_loss: 0.1523 - val_mae: 0.3195
Epoch 222/5000
36/36 - 1s - loss: 0.0073 - mae: 0.0661 - val_loss: 0.1457 - val_mae: 0.3050
Epoch 223/5000
36/36 - 1s - loss: 0.0075 - mae: 0.0673 - val_loss: 0.1518 - val_mae: 0.3219
Epoch 224/5000
36/36 - 1s - loss: 0.0070 - mae: 0.0642 - val_loss: 0.1516 - val_mae: 0.3217
Epoch 225/5000
36/36 - 1s - loss: 0.0072 - mae: 0.0647 - val_loss: 0.1530 - val_mae: 0.3161
Epoch 226/5000
36/36 - 1s - loss: 0.0063 - mae: 0.0599 - val_loss: 0.1472 - val_mae: 0.3085
Epoch 227/5000
36/36 - 1s - loss: 0.0069 - mae: 0.0634 - val_loss: 0.1595 - val_mae: 0.3333
Epoch 228/5000
36/36 - 1s - loss: 0.0070 - mae: 0.0643 - val_loss: 0.1487 - val_mae: 0.3170
Epoch 229/5000
36/36 - 1s - loss: 0.0068 - mae: 0.0658 - val_loss: 0.1468 - val_mae: 0.3081
Epoch 230/5000
36/36 - 1s - loss: 0.0069 - mae: 0.0636 - val_loss: 0.1461 - val_mae: 0.3042
Epoch 231/5000
36/36 - 1s - loss: 0.0082 - mae: 0.0732 - val_loss: 0.1581 - val_mae: 0.3366
Epoch 232/5000
36/36 - 1s - loss: 0.0085 - mae: 0.0695 - val_loss: 0.1502 - val_mae: 0.3177
Epoch 233/5000
36/36 - 1s - loss: 0.0077 - mae: 0.0676 - val_loss: 0.1480 - val_mae: 0.3066
Epoch 234/5000
36/36 - 1s - loss: 0.0063 - mae: 0.0616 - val_loss: 0.1524 - val_mae: 0.3180
Epoch 235/5000
36/36 - 1s - loss: 0.0062 - mae: 0.0591 - val_loss: 0.1533 - val_mae: 0.3237
Epoch 236/5000
36/36 - 1s - loss: 0.0063 - mae: 0.0569 - val_loss: 0.1460 - val_mae: 0.3091
Epoch 237/5000
36/36 - 1s - loss: 0.0062 - mae: 0.0594 - val_loss: 0.1483 - val_mae: 0.3074
Epoch 238/5000
36/36 - 1s - loss: 0.0067 - mae: 0.0658 - val_loss: 0.1512 - val_mae: 0.3224
Epoch 239/5000
36/36 - 1s - loss: 0.0062 - mae: 0.0616 - val_loss: 0.1508 - val_mae: 0.3178
Epoch 240/5000
36/36 - 1s - loss: 0.0061 - mae: 0.0591 - val_loss: 0.1452 - val_mae: 0.3038
Epoch 241/5000
36/36 - 1s - loss: 0.0061 - mae: 0.0582 - val_loss: 0.1527 - val_mae: 0.3187
Epoch 242/5000
36/36 - 1s - loss: 0.0064 - mae: 0.0602 - val_loss: 0.1484 - val_mae: 0.3178
Epoch 243/5000
36/36 - 1s - loss: 0.0069 - mae: 0.0620 - val_loss: 0.1551 - val_mae: 0.3264
Epoch 244/5000
36/36 - 1s - loss: 0.0067 - mae: 0.0611 - val_loss: 0.1430 - val_mae: 0.3019
Epoch 245/5000
36/36 - 1s - loss: 0.0066 - mae: 0.0619 - val_loss: 0.1529 - val_mae: 0.3183
Epoch 246/5000
36/36 - 1s - loss: 0.0059 - mae: 0.0571 - val_loss: 0.1506 - val_mae: 0.3190
Epoch 247/5000
36/36 - 1s - loss: 0.0059 - mae: 0.0580 - val_loss: 0.1523 - val_mae: 0.3240
Epoch 248/5000
36/36 - 1s - loss: 0.0059 - mae: 0.0567 - val_loss: 0.1449 - val_mae: 0.3044
Epoch 249/5000
36/36 - 1s - loss: 0.0057 - mae: 0.0559 - val_loss: 0.1457 - val_mae: 0.3047
Epoch 250/5000
36/36 - 1s - loss: 0.0061 - mae: 0.0582 - val_loss: 0.1485 - val_mae: 0.3124
Epoch 251/5000
36/36 - 1s - loss: 0.0069 - mae: 0.0632 - val_loss: 0.1542 - val_mae: 0.3248
Epoch 252/5000
36/36 - 1s - loss: 0.0068 - mae: 0.0606 - val_loss: 0.1442 - val_mae: 0.3079
Epoch 253/5000
36/36 - 1s - loss: 0.0067 - mae: 0.0612 - val_loss: 0.1535 - val_mae: 0.3198
Epoch 254/5000
36/36 - 1s - loss: 0.0064 - mae: 0.0604 - val_loss: 0.1463 - val_mae: 0.3070
Epoch 255/5000
36/36 - 1s - loss: 0.0057 - mae: 0.0565 - val_loss: 0.1491 - val_mae: 0.3115
Epoch 256/5000
36/36 - 1s - loss: 0.0052 - mae: 0.0521 - val_loss: 0.1525 - val_mae: 0.3166
Epoch 257/5000
36/36 - 1s - loss: 0.0063 - mae: 0.0617 - val_loss: 0.1515 - val_mae: 0.3257
Epoch 258/5000
36/36 - 1s - loss: 0.0064 - mae: 0.0609 - val_loss: 0.1466 - val_mae: 0.3059
Epoch 259/5000
36/36 - 1s - loss: 0.0061 - mae: 0.0580 - val_loss: 0.1446 - val_mae: 0.3055
Epoch 260/5000
36/36 - 1s - loss: 0.0067 - mae: 0.0612 - val_loss: 0.1478 - val_mae: 0.3050
Epoch 261/5000
36/36 - 1s - loss: 0.0073 - mae: 0.0647 - val_loss: 0.1450 - val_mae: 0.3008
Epoch 262/5000
36/36 - 1s - loss: 0.0078 - mae: 0.0682 - val_loss: 0.1499 - val_mae: 0.3146
Epoch 263/5000
36/36 - 1s - loss: 0.0109 - mae: 0.0815 - val_loss: 0.1605 - val_mae: 0.3420
Epoch 264/5000
36/36 - 1s - loss: 0.0112 - mae: 0.0800 - val_loss: 0.1534 - val_mae: 0.3215
Epoch 265/5000
36/36 - 1s - loss: 0.0107 - mae: 0.0790 - val_loss: 0.1569 - val_mae: 0.3251
Restoring model weights from the end of the best epoch.
Epoch 00265: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_3..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 4

Generating graphs from SMILES..

Setting up training set.
Size: 1829

Setting up validation set.
Size: 457

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_24"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_4 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_4 (PartitionP (None, None, 64)     0           message_passing_4[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_4[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_4 (Masking)             (None, None, 64)     0           partition_padding_4[0][0]        
                                                                 partition_padding_4[1][0]        
__________________________________________________________________________________________________
transformer_encoder_4 (Transfor (None, None, 64)     199040      masking_4[0][0]                  
                                                                 masking_4[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_4 (Glo (None, 64)           0           transformer_encoder_4[0][0]      
                                                                 transformer_encoder_4[1][0]      
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 512)          33280       global_average_pooling1d_4[0][0] 
                                                                 global_average_pooling1d_4[1][0] 
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 10)           110         dense_72[0][0]                   
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 450)          230850      dense_70[0][0]                   
                                                                 dense_70[1][0]                   
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 5)            55          dense_73[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 905)          0           dense_71[0][0]                   
                                                                 dense_71[1][0]                   
                                                                 dense_74[0][0]                   
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 700)          634200      concatenate_4[0][0]              
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 560)          392560      dense_75[0][0]                   
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 373)          209253      dense_79[0][0]                   
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 187)          69938       dense_80[0][0]                   
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 1)            188         dense_81[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
36/36 - 6s - loss: 0.3245 - mae: 0.6287 - val_loss: 0.1598 - val_mae: 0.4735
Epoch 2/5000
36/36 - 1s - loss: 0.1667 - mae: 0.4091 - val_loss: 0.1543 - val_mae: 0.4575
Epoch 3/5000
36/36 - 1s - loss: 0.1649 - mae: 0.4058 - val_loss: 0.1499 - val_mae: 0.4433
Epoch 4/5000
36/36 - 1s - loss: 0.1640 - mae: 0.4045 - val_loss: 0.1457 - val_mae: 0.4248
Epoch 5/5000
36/36 - 1s - loss: 0.1639 - mae: 0.4037 - val_loss: 0.1513 - val_mae: 0.4483
Epoch 6/5000
36/36 - 1s - loss: 0.1614 - mae: 0.3988 - val_loss: 0.1424 - val_mae: 0.4092
Epoch 7/5000
36/36 - 1s - loss: 0.1625 - mae: 0.4004 - val_loss: 0.1464 - val_mae: 0.4272
Epoch 8/5000
36/36 - 1s - loss: 0.1607 - mae: 0.3966 - val_loss: 0.1476 - val_mae: 0.4368
Epoch 9/5000
36/36 - 1s - loss: 0.1593 - mae: 0.3945 - val_loss: 0.1423 - val_mae: 0.4138
Epoch 10/5000
36/36 - 1s - loss: 0.1583 - mae: 0.3923 - val_loss: 0.1378 - val_mae: 0.3828
Epoch 11/5000
36/36 - 1s - loss: 0.1585 - mae: 0.3913 - val_loss: 0.1403 - val_mae: 0.4008
Epoch 12/5000
36/36 - 1s - loss: 0.1558 - mae: 0.3859 - val_loss: 0.1362 - val_mae: 0.3853
Epoch 13/5000
36/36 - 1s - loss: 0.1562 - mae: 0.3866 - val_loss: 0.1379 - val_mae: 0.3925
Epoch 14/5000
36/36 - 1s - loss: 0.1553 - mae: 0.3852 - val_loss: 0.1351 - val_mae: 0.3627
Epoch 15/5000
36/36 - 1s - loss: 0.1527 - mae: 0.3782 - val_loss: 0.1355 - val_mae: 0.3897
Epoch 16/5000
36/36 - 1s - loss: 0.1558 - mae: 0.3853 - val_loss: 0.1364 - val_mae: 0.3851
Epoch 17/5000
36/36 - 1s - loss: 0.1523 - mae: 0.3776 - val_loss: 0.1339 - val_mae: 0.3664
Epoch 18/5000
36/36 - 1s - loss: 0.1509 - mae: 0.3740 - val_loss: 0.1320 - val_mae: 0.3689
Epoch 19/5000
36/36 - 1s - loss: 0.1515 - mae: 0.3760 - val_loss: 0.1386 - val_mae: 0.4073
Epoch 20/5000
36/36 - 1s - loss: 0.1490 - mae: 0.3691 - val_loss: 0.1310 - val_mae: 0.3717
Epoch 21/5000
36/36 - 1s - loss: 0.1506 - mae: 0.3749 - val_loss: 0.1350 - val_mae: 0.3823
Epoch 22/5000
36/36 - 1s - loss: 0.1488 - mae: 0.3704 - val_loss: 0.1297 - val_mae: 0.3632
Epoch 23/5000
36/36 - 1s - loss: 0.1517 - mae: 0.3760 - val_loss: 0.1370 - val_mae: 0.3904
Epoch 24/5000
36/36 - 1s - loss: 0.1459 - mae: 0.3611 - val_loss: 0.1378 - val_mae: 0.4007
Epoch 25/5000
36/36 - 1s - loss: 0.1542 - mae: 0.3814 - val_loss: 0.1488 - val_mae: 0.4440
Epoch 26/5000
36/36 - 1s - loss: 0.1463 - mae: 0.3632 - val_loss: 0.1293 - val_mae: 0.3622
Epoch 27/5000
36/36 - 1s - loss: 0.1517 - mae: 0.3750 - val_loss: 0.1490 - val_mae: 0.4437
Epoch 28/5000
36/36 - 1s - loss: 0.1455 - mae: 0.3605 - val_loss: 0.1263 - val_mae: 0.3399
Epoch 29/5000
36/36 - 1s - loss: 0.1460 - mae: 0.3612 - val_loss: 0.1287 - val_mae: 0.3591
Epoch 30/5000
36/36 - 1s - loss: 0.1428 - mae: 0.3543 - val_loss: 0.1266 - val_mae: 0.3541
Epoch 31/5000
36/36 - 1s - loss: 0.1478 - mae: 0.3636 - val_loss: 0.1406 - val_mae: 0.4172
Epoch 32/5000
36/36 - 1s - loss: 0.1461 - mae: 0.3593 - val_loss: 0.1298 - val_mae: 0.3590
Epoch 33/5000
36/36 - 1s - loss: 0.1431 - mae: 0.3542 - val_loss: 0.1324 - val_mae: 0.3859
Epoch 34/5000
36/36 - 1s - loss: 0.1448 - mae: 0.3572 - val_loss: 0.1520 - val_mae: 0.4570
Epoch 35/5000
36/36 - 1s - loss: 0.1468 - mae: 0.3640 - val_loss: 0.1519 - val_mae: 0.4487
Epoch 36/5000
36/36 - 1s - loss: 0.1421 - mae: 0.3537 - val_loss: 0.1339 - val_mae: 0.3726
Epoch 37/5000
36/36 - 1s - loss: 0.1423 - mae: 0.3512 - val_loss: 0.1238 - val_mae: 0.3452
Epoch 38/5000
36/36 - 1s - loss: 0.1514 - mae: 0.3651 - val_loss: 0.1573 - val_mae: 0.4141
Epoch 39/5000
36/36 - 1s - loss: 0.1464 - mae: 0.3711 - val_loss: 0.1260 - val_mae: 0.3641
Epoch 40/5000
36/36 - 1s - loss: 0.1407 - mae: 0.3498 - val_loss: 0.1241 - val_mae: 0.3538
Epoch 41/5000
36/36 - 1s - loss: 0.1426 - mae: 0.3530 - val_loss: 0.1484 - val_mae: 0.4454
Epoch 42/5000
36/36 - 1s - loss: 0.1442 - mae: 0.3539 - val_loss: 0.1612 - val_mae: 0.4607
Epoch 43/5000
36/36 - 1s - loss: 0.1458 - mae: 0.3643 - val_loss: 0.1598 - val_mae: 0.4740
Epoch 44/5000
36/36 - 1s - loss: 0.1407 - mae: 0.3511 - val_loss: 0.1288 - val_mae: 0.3585
Epoch 45/5000
36/36 - 1s - loss: 0.1415 - mae: 0.3465 - val_loss: 0.1934 - val_mae: 0.5495
Epoch 46/5000
36/36 - 1s - loss: 0.1497 - mae: 0.3698 - val_loss: 0.1275 - val_mae: 0.3559
Epoch 47/5000
36/36 - 1s - loss: 0.1438 - mae: 0.3571 - val_loss: 0.1540 - val_mae: 0.4475
Epoch 48/5000
36/36 - 1s - loss: 0.1475 - mae: 0.3587 - val_loss: 0.1643 - val_mae: 0.4612
Epoch 49/5000
36/36 - 1s - loss: 0.1521 - mae: 0.3777 - val_loss: 0.1665 - val_mae: 0.5034
Epoch 50/5000
36/36 - 1s - loss: 0.1454 - mae: 0.3591 - val_loss: 0.1866 - val_mae: 0.5302
Epoch 51/5000
36/36 - 1s - loss: 0.1514 - mae: 0.3732 - val_loss: 0.1424 - val_mae: 0.4230
Epoch 52/5000
36/36 - 1s - loss: 0.1395 - mae: 0.3480 - val_loss: 0.1273 - val_mae: 0.3503
Epoch 53/5000
36/36 - 1s - loss: 0.1374 - mae: 0.3398 - val_loss: 0.1300 - val_mae: 0.3602
Epoch 54/5000
36/36 - 1s - loss: 0.1390 - mae: 0.3426 - val_loss: 0.1477 - val_mae: 0.4276
Epoch 55/5000
36/36 - 1s - loss: 0.1433 - mae: 0.3496 - val_loss: 0.1736 - val_mae: 0.4843
Epoch 56/5000
36/36 - 1s - loss: 0.1445 - mae: 0.3622 - val_loss: 0.1625 - val_mae: 0.4758
Epoch 57/5000
36/36 - 1s - loss: 0.1403 - mae: 0.3509 - val_loss: 0.1359 - val_mae: 0.3932
Epoch 58/5000
36/36 - 1s - loss: 0.1477 - mae: 0.3545 - val_loss: 0.1484 - val_mae: 0.3709
Epoch 59/5000
36/36 - 1s - loss: 0.1510 - mae: 0.3733 - val_loss: 0.1393 - val_mae: 0.3745
Epoch 60/5000
36/36 - 1s - loss: 0.1416 - mae: 0.3542 - val_loss: 0.1799 - val_mae: 0.5096
Epoch 61/5000
36/36 - 1s - loss: 0.1453 - mae: 0.3628 - val_loss: 0.1331 - val_mae: 0.3640
Epoch 62/5000
36/36 - 1s - loss: 0.1388 - mae: 0.3422 - val_loss: 0.1591 - val_mae: 0.4605
Epoch 63/5000
36/36 - 1s - loss: 0.1414 - mae: 0.3485 - val_loss: 0.1683 - val_mae: 0.4755
Epoch 64/5000
36/36 - 1s - loss: 0.1438 - mae: 0.3494 - val_loss: 0.1730 - val_mae: 0.4596
Epoch 65/5000
36/36 - 1s - loss: 0.1499 - mae: 0.3695 - val_loss: 0.1445 - val_mae: 0.4433
Epoch 66/5000
36/36 - 1s - loss: 0.1406 - mae: 0.3500 - val_loss: 0.1639 - val_mae: 0.4692
Epoch 67/5000
36/36 - 1s - loss: 0.1432 - mae: 0.3490 - val_loss: 0.1815 - val_mae: 0.4972
Epoch 68/5000
36/36 - 1s - loss: 0.1501 - mae: 0.3706 - val_loss: 0.1308 - val_mae: 0.3914
Epoch 69/5000
36/36 - 1s - loss: 0.1410 - mae: 0.3485 - val_loss: 0.1712 - val_mae: 0.4900
Epoch 70/5000
36/36 - 1s - loss: 0.1485 - mae: 0.3633 - val_loss: 0.1546 - val_mae: 0.4521
Epoch 71/5000
36/36 - 1s - loss: 0.1485 - mae: 0.3650 - val_loss: 0.1417 - val_mae: 0.3992
Epoch 72/5000
36/36 - 1s - loss: 0.1401 - mae: 0.3455 - val_loss: 0.1633 - val_mae: 0.4778
Epoch 73/5000
36/36 - 1s - loss: 0.1427 - mae: 0.3496 - val_loss: 0.1631 - val_mae: 0.4767
Epoch 74/5000
36/36 - 1s - loss: 0.1425 - mae: 0.3514 - val_loss: 0.1772 - val_mae: 0.5085
Epoch 75/5000
36/36 - 1s - loss: 0.1444 - mae: 0.3559 - val_loss: 0.1506 - val_mae: 0.4336
Epoch 76/5000
36/36 - 1s - loss: 0.1432 - mae: 0.3501 - val_loss: 0.1414 - val_mae: 0.4049
Epoch 77/5000
36/36 - 1s - loss: 0.1425 - mae: 0.3472 - val_loss: 0.1393 - val_mae: 0.3815
Epoch 78/5000
36/36 - 1s - loss: 0.1446 - mae: 0.3532 - val_loss: 0.1339 - val_mae: 0.3432
Epoch 79/5000
36/36 - 1s - loss: 0.1435 - mae: 0.3590 - val_loss: 0.1290 - val_mae: 0.3732
Epoch 80/5000
36/36 - 1s - loss: 0.1371 - mae: 0.3379 - val_loss: 0.1581 - val_mae: 0.4602
Epoch 81/5000
36/36 - 1s - loss: 0.1371 - mae: 0.3386 - val_loss: 0.1774 - val_mae: 0.4960
Epoch 82/5000
36/36 - 1s - loss: 0.1415 - mae: 0.3461 - val_loss: 0.1343 - val_mae: 0.3786
Epoch 83/5000
36/36 - 1s - loss: 0.1417 - mae: 0.3461 - val_loss: 0.1339 - val_mae: 0.3614
Epoch 84/5000
36/36 - 1s - loss: 0.1438 - mae: 0.3565 - val_loss: 0.1248 - val_mae: 0.3536
Epoch 85/5000
36/36 - 1s - loss: 0.1369 - mae: 0.3357 - val_loss: 0.1319 - val_mae: 0.3810
Epoch 86/5000
36/36 - 1s - loss: 0.1429 - mae: 0.3501 - val_loss: 0.1285 - val_mae: 0.3426
Epoch 87/5000
36/36 - 1s - loss: 0.1432 - mae: 0.3588 - val_loss: 0.1296 - val_mae: 0.3846
Epoch 88/5000
36/36 - 1s - loss: 0.1364 - mae: 0.3331 - val_loss: 0.1313 - val_mae: 0.3808
Epoch 89/5000
36/36 - 1s - loss: 0.1462 - mae: 0.3550 - val_loss: 0.1426 - val_mae: 0.3491
Epoch 90/5000
36/36 - 1s - loss: 0.1443 - mae: 0.3609 - val_loss: 0.1319 - val_mae: 0.3854
Epoch 91/5000
36/36 - 1s - loss: 0.1418 - mae: 0.3469 - val_loss: 0.1230 - val_mae: 0.3304
Epoch 92/5000
36/36 - 1s - loss: 0.1419 - mae: 0.3552 - val_loss: 0.1338 - val_mae: 0.3964
Epoch 93/5000
36/36 - 1s - loss: 0.1418 - mae: 0.3420 - val_loss: 0.1381 - val_mae: 0.3348
Epoch 94/5000
36/36 - 1s - loss: 0.1397 - mae: 0.3539 - val_loss: 0.1426 - val_mae: 0.4135
Epoch 95/5000
36/36 - 1s - loss: 0.1377 - mae: 0.3315 - val_loss: 0.1275 - val_mae: 0.3526
Epoch 96/5000
36/36 - 1s - loss: 0.1417 - mae: 0.3531 - val_loss: 0.1239 - val_mae: 0.3389
Epoch 97/5000
36/36 - 1s - loss: 0.1403 - mae: 0.3419 - val_loss: 0.1348 - val_mae: 0.3282
Epoch 98/5000
36/36 - 1s - loss: 0.1396 - mae: 0.3518 - val_loss: 0.1335 - val_mae: 0.3873
Epoch 99/5000
36/36 - 1s - loss: 0.1355 - mae: 0.3318 - val_loss: 0.1373 - val_mae: 0.3781
Epoch 100/5000
36/36 - 1s - loss: 0.1412 - mae: 0.3428 - val_loss: 0.1403 - val_mae: 0.3363
Epoch 101/5000
36/36 - 1s - loss: 0.1403 - mae: 0.3548 - val_loss: 0.1486 - val_mae: 0.4266
Epoch 102/5000
36/36 - 1s - loss: 0.1375 - mae: 0.3337 - val_loss: 0.1252 - val_mae: 0.3447
Epoch 103/5000
36/36 - 1s - loss: 0.1403 - mae: 0.3438 - val_loss: 0.1335 - val_mae: 0.3238
Epoch 104/5000
36/36 - 1s - loss: 0.1389 - mae: 0.3466 - val_loss: 0.1431 - val_mae: 0.4149
Epoch 105/5000
36/36 - 1s - loss: 0.1381 - mae: 0.3335 - val_loss: 0.1302 - val_mae: 0.3353
Epoch 106/5000
36/36 - 1s - loss: 0.1391 - mae: 0.3470 - val_loss: 0.1255 - val_mae: 0.3550
Epoch 107/5000
36/36 - 1s - loss: 0.1380 - mae: 0.3337 - val_loss: 0.1330 - val_mae: 0.3321
Epoch 108/5000
36/36 - 1s - loss: 0.1386 - mae: 0.3520 - val_loss: 0.1397 - val_mae: 0.4092
Epoch 109/5000
36/36 - 1s - loss: 0.1376 - mae: 0.3319 - val_loss: 0.1285 - val_mae: 0.3288
Epoch 110/5000
36/36 - 1s - loss: 0.1394 - mae: 0.3455 - val_loss: 0.1205 - val_mae: 0.3358
Epoch 111/5000
36/36 - 1s - loss: 0.1361 - mae: 0.3335 - val_loss: 0.1249 - val_mae: 0.3216
Epoch 112/5000
36/36 - 1s - loss: 0.1367 - mae: 0.3414 - val_loss: 0.1314 - val_mae: 0.3759
Epoch 113/5000
36/36 - 1s - loss: 0.1370 - mae: 0.3309 - val_loss: 0.1337 - val_mae: 0.3279
Epoch 114/5000
36/36 - 1s - loss: 0.1376 - mae: 0.3455 - val_loss: 0.1426 - val_mae: 0.4090
Epoch 115/5000
36/36 - 1s - loss: 0.1354 - mae: 0.3259 - val_loss: 0.1275 - val_mae: 0.3240
Epoch 116/5000
36/36 - 1s - loss: 0.1373 - mae: 0.3432 - val_loss: 0.1317 - val_mae: 0.3771
Epoch 117/5000
36/36 - 1s - loss: 0.1345 - mae: 0.3266 - val_loss: 0.1323 - val_mae: 0.3296
Epoch 118/5000
36/36 - 1s - loss: 0.1377 - mae: 0.3450 - val_loss: 0.1405 - val_mae: 0.4010
Epoch 119/5000
36/36 - 1s - loss: 0.1366 - mae: 0.3290 - val_loss: 0.1334 - val_mae: 0.3382
Epoch 120/5000
36/36 - 1s - loss: 0.1363 - mae: 0.3425 - val_loss: 0.1480 - val_mae: 0.4138
Epoch 121/5000
36/36 - 1s - loss: 0.1364 - mae: 0.3284 - val_loss: 0.1297 - val_mae: 0.3220
Epoch 122/5000
36/36 - 1s - loss: 0.1364 - mae: 0.3437 - val_loss: 0.1373 - val_mae: 0.3911
Epoch 123/5000
36/36 - 1s - loss: 0.1368 - mae: 0.3289 - val_loss: 0.1340 - val_mae: 0.3272
Epoch 124/5000
36/36 - 1s - loss: 0.1377 - mae: 0.3454 - val_loss: 0.1406 - val_mae: 0.4038
Epoch 125/5000
36/36 - 1s - loss: 0.1364 - mae: 0.3283 - val_loss: 0.1328 - val_mae: 0.3270
Epoch 126/5000
36/36 - 1s - loss: 0.1388 - mae: 0.3485 - val_loss: 0.1339 - val_mae: 0.3781
Epoch 127/5000
36/36 - 1s - loss: 0.1349 - mae: 0.3286 - val_loss: 0.1302 - val_mae: 0.3212
Epoch 128/5000
36/36 - 1s - loss: 0.1368 - mae: 0.3419 - val_loss: 0.1333 - val_mae: 0.3811
Epoch 129/5000
36/36 - 1s - loss: 0.1346 - mae: 0.3263 - val_loss: 0.1329 - val_mae: 0.3263
Epoch 130/5000
36/36 - 1s - loss: 0.1388 - mae: 0.3466 - val_loss: 0.1290 - val_mae: 0.3639
Epoch 131/5000
36/36 - 1s - loss: 0.1351 - mae: 0.3274 - val_loss: 0.1333 - val_mae: 0.3287
Epoch 132/5000
36/36 - 1s - loss: 0.1415 - mae: 0.3535 - val_loss: 0.1247 - val_mae: 0.3245
Epoch 133/5000
36/36 - 1s - loss: 0.1347 - mae: 0.3323 - val_loss: 0.1262 - val_mae: 0.3172
Epoch 134/5000
36/36 - 1s - loss: 0.1345 - mae: 0.3372 - val_loss: 0.1450 - val_mae: 0.4088
Epoch 135/5000
36/36 - 1s - loss: 0.1364 - mae: 0.3293 - val_loss: 0.1282 - val_mae: 0.3210
Epoch 136/5000
36/36 - 1s - loss: 0.1354 - mae: 0.3400 - val_loss: 0.1307 - val_mae: 0.3760
Epoch 137/5000
36/36 - 1s - loss: 0.1336 - mae: 0.3234 - val_loss: 0.1286 - val_mae: 0.3191
Epoch 138/5000
36/36 - 1s - loss: 0.1344 - mae: 0.3371 - val_loss: 0.1500 - val_mae: 0.4215
Epoch 139/5000
36/36 - 1s - loss: 0.1350 - mae: 0.3260 - val_loss: 0.1294 - val_mae: 0.3202
Epoch 140/5000
36/36 - 1s - loss: 0.1355 - mae: 0.3392 - val_loss: 0.1349 - val_mae: 0.3896
Epoch 141/5000
36/36 - 1s - loss: 0.1332 - mae: 0.3214 - val_loss: 0.1295 - val_mae: 0.3196
Epoch 142/5000
36/36 - 1s - loss: 0.1392 - mae: 0.3456 - val_loss: 0.1220 - val_mae: 0.3256
Epoch 143/5000
36/36 - 1s - loss: 0.1334 - mae: 0.3278 - val_loss: 0.1284 - val_mae: 0.3206
Epoch 144/5000
36/36 - 1s - loss: 0.1377 - mae: 0.3442 - val_loss: 0.1230 - val_mae: 0.3277
Epoch 145/5000
36/36 - 1s - loss: 0.1334 - mae: 0.3277 - val_loss: 0.1243 - val_mae: 0.3185
Epoch 146/5000
36/36 - 1s - loss: 0.1328 - mae: 0.3326 - val_loss: 0.1280 - val_mae: 0.3570
Epoch 147/5000
36/36 - 1s - loss: 0.1329 - mae: 0.3230 - val_loss: 0.1270 - val_mae: 0.3244
Epoch 148/5000
36/36 - 1s - loss: 0.1343 - mae: 0.3378 - val_loss: 0.1395 - val_mae: 0.3860
Epoch 149/5000
36/36 - 1s - loss: 0.1327 - mae: 0.3249 - val_loss: 0.1211 - val_mae: 0.3304
Epoch 150/5000
36/36 - 1s - loss: 0.1319 - mae: 0.3280 - val_loss: 0.1196 - val_mae: 0.3268
Epoch 151/5000
36/36 - 1s - loss: 0.1292 - mae: 0.3208 - val_loss: 0.1201 - val_mae: 0.3225
Epoch 152/5000
36/36 - 1s - loss: 0.1303 - mae: 0.3249 - val_loss: 0.1193 - val_mae: 0.3269
Epoch 153/5000
36/36 - 1s - loss: 0.1293 - mae: 0.3227 - val_loss: 0.1210 - val_mae: 0.3342
Epoch 154/5000
36/36 - 1s - loss: 0.1277 - mae: 0.3173 - val_loss: 0.1227 - val_mae: 0.3380
Epoch 155/5000
36/36 - 1s - loss: 0.1312 - mae: 0.3199 - val_loss: 0.1252 - val_mae: 0.3233
Epoch 156/5000
36/36 - 1s - loss: 0.1336 - mae: 0.3334 - val_loss: 0.1300 - val_mae: 0.3709
Epoch 157/5000
36/36 - 1s - loss: 0.1318 - mae: 0.3238 - val_loss: 0.1251 - val_mae: 0.3183
Epoch 158/5000
36/36 - 1s - loss: 0.1344 - mae: 0.3335 - val_loss: 0.1272 - val_mae: 0.3633
Epoch 159/5000
36/36 - 1s - loss: 0.1295 - mae: 0.3201 - val_loss: 0.1225 - val_mae: 0.3222
Epoch 160/5000
36/36 - 1s - loss: 0.1311 - mae: 0.3272 - val_loss: 0.1296 - val_mae: 0.3634
Epoch 161/5000
36/36 - 1s - loss: 0.1315 - mae: 0.3221 - val_loss: 0.1291 - val_mae: 0.3237
Epoch 162/5000
36/36 - 1s - loss: 0.1406 - mae: 0.3469 - val_loss: 0.1244 - val_mae: 0.3482
Epoch 163/5000
36/36 - 1s - loss: 0.1305 - mae: 0.3217 - val_loss: 0.1213 - val_mae: 0.3238
Epoch 164/5000
36/36 - 1s - loss: 0.1310 - mae: 0.3279 - val_loss: 0.1278 - val_mae: 0.3551
Epoch 165/5000
36/36 - 1s - loss: 0.1285 - mae: 0.3138 - val_loss: 0.1233 - val_mae: 0.3265
Epoch 166/5000
36/36 - 1s - loss: 0.1314 - mae: 0.3306 - val_loss: 0.1355 - val_mae: 0.3853
Epoch 167/5000
36/36 - 1s - loss: 0.1313 - mae: 0.3220 - val_loss: 0.1259 - val_mae: 0.3195
Epoch 168/5000
36/36 - 1s - loss: 0.1378 - mae: 0.3426 - val_loss: 0.1238 - val_mae: 0.3195
Epoch 169/5000
36/36 - 1s - loss: 0.1287 - mae: 0.3218 - val_loss: 0.1314 - val_mae: 0.3690
Epoch 170/5000
36/36 - 1s - loss: 0.1281 - mae: 0.3181 - val_loss: 0.1327 - val_mae: 0.3692
Epoch 171/5000
36/36 - 1s - loss: 0.1278 - mae: 0.3118 - val_loss: 0.1221 - val_mae: 0.3283
Epoch 172/5000
36/36 - 1s - loss: 0.1315 - mae: 0.3238 - val_loss: 0.1370 - val_mae: 0.3995
Epoch 173/5000
36/36 - 1s - loss: 0.1287 - mae: 0.3216 - val_loss: 0.1207 - val_mae: 0.3259
Epoch 174/5000
36/36 - 1s - loss: 0.1267 - mae: 0.3166 - val_loss: 0.1300 - val_mae: 0.3606
Epoch 175/5000
36/36 - 1s - loss: 0.1298 - mae: 0.3192 - val_loss: 0.1298 - val_mae: 0.3720
Epoch 176/5000
36/36 - 1s - loss: 0.1290 - mae: 0.3221 - val_loss: 0.1361 - val_mae: 0.3732
Epoch 177/5000
36/36 - 1s - loss: 0.1286 - mae: 0.3145 - val_loss: 0.1229 - val_mae: 0.3303
Epoch 178/5000
36/36 - 1s - loss: 0.1356 - mae: 0.3352 - val_loss: 0.1377 - val_mae: 0.3914
Epoch 179/5000
36/36 - 1s - loss: 0.1289 - mae: 0.3202 - val_loss: 0.1228 - val_mae: 0.3353
Epoch 180/5000
36/36 - 1s - loss: 0.1273 - mae: 0.3187 - val_loss: 0.1344 - val_mae: 0.3684
Epoch 181/5000
36/36 - 1s - loss: 0.1265 - mae: 0.3120 - val_loss: 0.1309 - val_mae: 0.3625
Epoch 182/5000
36/36 - 1s - loss: 0.1241 - mae: 0.3065 - val_loss: 0.1216 - val_mae: 0.3404
Epoch 183/5000
36/36 - 1s - loss: 0.1235 - mae: 0.3119 - val_loss: 0.1286 - val_mae: 0.3533
Epoch 184/5000
36/36 - 1s - loss: 0.1247 - mae: 0.3076 - val_loss: 0.1233 - val_mae: 0.3433
Epoch 185/5000
36/36 - 1s - loss: 0.1233 - mae: 0.3098 - val_loss: 0.1243 - val_mae: 0.3423
Epoch 186/5000
36/36 - 1s - loss: 0.1246 - mae: 0.3091 - val_loss: 0.1306 - val_mae: 0.3548
Epoch 187/5000
36/36 - 1s - loss: 0.1235 - mae: 0.3049 - val_loss: 0.1260 - val_mae: 0.3487
Epoch 188/5000
36/36 - 1s - loss: 0.1239 - mae: 0.3090 - val_loss: 0.1278 - val_mae: 0.3486
Epoch 189/5000
36/36 - 1s - loss: 0.1225 - mae: 0.3038 - val_loss: 0.1340 - val_mae: 0.3688
Epoch 190/5000
36/36 - 1s - loss: 0.1237 - mae: 0.3069 - val_loss: 0.1291 - val_mae: 0.3557
Epoch 191/5000
36/36 - 1s - loss: 0.1219 - mae: 0.3016 - val_loss: 0.1225 - val_mae: 0.3451
Epoch 192/5000
36/36 - 1s - loss: 0.1286 - mae: 0.3202 - val_loss: 0.1350 - val_mae: 0.3911
Epoch 193/5000
36/36 - 1s - loss: 0.1379 - mae: 0.3318 - val_loss: 0.1321 - val_mae: 0.3658
Epoch 194/5000
36/36 - 1s - loss: 0.1313 - mae: 0.3234 - val_loss: 0.1288 - val_mae: 0.3497
Epoch 195/5000
36/36 - 1s - loss: 0.1271 - mae: 0.3214 - val_loss: 0.1268 - val_mae: 0.3543
Epoch 196/5000
36/36 - 1s - loss: 0.1253 - mae: 0.3115 - val_loss: 0.1289 - val_mae: 0.3508
Epoch 197/5000
36/36 - 1s - loss: 0.1259 - mae: 0.3141 - val_loss: 0.1329 - val_mae: 0.3607
Epoch 198/5000
36/36 - 1s - loss: 0.1276 - mae: 0.3150 - val_loss: 0.1486 - val_mae: 0.4180
Epoch 199/5000
36/36 - 1s - loss: 0.1247 - mae: 0.3095 - val_loss: 0.1294 - val_mae: 0.3574
Epoch 200/5000
36/36 - 1s - loss: 0.1212 - mae: 0.3024 - val_loss: 0.1279 - val_mae: 0.3606
Epoch 201/5000
36/36 - 1s - loss: 0.1239 - mae: 0.3100 - val_loss: 0.1269 - val_mae: 0.3445
Epoch 202/5000
36/36 - 1s - loss: 0.1210 - mae: 0.3023 - val_loss: 0.1312 - val_mae: 0.3564
Epoch 203/5000
36/36 - 1s - loss: 0.1209 - mae: 0.3000 - val_loss: 0.1405 - val_mae: 0.3869
Epoch 204/5000
36/36 - 1s - loss: 0.1202 - mae: 0.2998 - val_loss: 0.1388 - val_mae: 0.3870
Epoch 205/5000
36/36 - 1s - loss: 0.1194 - mae: 0.2996 - val_loss: 0.1342 - val_mae: 0.3742
Epoch 206/5000
36/36 - 1s - loss: 0.1199 - mae: 0.2999 - val_loss: 0.1318 - val_mae: 0.3660
Epoch 207/5000
36/36 - 1s - loss: 0.1219 - mae: 0.3027 - val_loss: 0.1327 - val_mae: 0.3644
Epoch 208/5000
36/36 - 1s - loss: 0.1193 - mae: 0.2974 - val_loss: 0.1284 - val_mae: 0.3603
Epoch 209/5000
36/36 - 1s - loss: 0.1278 - mae: 0.3160 - val_loss: 0.1259 - val_mae: 0.3487
Epoch 210/5000
36/36 - 1s - loss: 0.1274 - mae: 0.3181 - val_loss: 0.1335 - val_mae: 0.3646
Epoch 211/5000
36/36 - 1s - loss: 0.1237 - mae: 0.3044 - val_loss: 0.1452 - val_mae: 0.3940
Epoch 212/5000
36/36 - 1s - loss: 0.1201 - mae: 0.2982 - val_loss: 0.1431 - val_mae: 0.3939
Epoch 213/5000
36/36 - 1s - loss: 0.1189 - mae: 0.2968 - val_loss: 0.1317 - val_mae: 0.3731
Epoch 214/5000
36/36 - 1s - loss: 0.1233 - mae: 0.3067 - val_loss: 0.1290 - val_mae: 0.3680
Epoch 215/5000
36/36 - 1s - loss: 0.1368 - mae: 0.3269 - val_loss: 0.1293 - val_mae: 0.3666
Epoch 216/5000
36/36 - 1s - loss: 0.1301 - mae: 0.3244 - val_loss: 0.1324 - val_mae: 0.3762
Epoch 217/5000
36/36 - 1s - loss: 0.1258 - mae: 0.3150 - val_loss: 0.1408 - val_mae: 0.3967
Epoch 218/5000
36/36 - 1s - loss: 0.1228 - mae: 0.3057 - val_loss: 0.1331 - val_mae: 0.3639
Epoch 219/5000
36/36 - 1s - loss: 0.1184 - mae: 0.2956 - val_loss: 0.1541 - val_mae: 0.4333
Epoch 220/5000
36/36 - 1s - loss: 0.1233 - mae: 0.3061 - val_loss: 0.1361 - val_mae: 0.3770
Epoch 221/5000
36/36 - 1s - loss: 0.1174 - mae: 0.2925 - val_loss: 0.1393 - val_mae: 0.3755
Epoch 222/5000
36/36 - 1s - loss: 0.1183 - mae: 0.2926 - val_loss: 0.1366 - val_mae: 0.3848
Epoch 223/5000
36/36 - 1s - loss: 0.1203 - mae: 0.2994 - val_loss: 0.1278 - val_mae: 0.3564
Epoch 224/5000
36/36 - 1s - loss: 0.1206 - mae: 0.2990 - val_loss: 0.1258 - val_mae: 0.3575
Epoch 225/5000
36/36 - 1s - loss: 0.1251 - mae: 0.3089 - val_loss: 0.1389 - val_mae: 0.3955
Epoch 226/5000
36/36 - 1s - loss: 0.1257 - mae: 0.3101 - val_loss: 0.1399 - val_mae: 0.4019
Epoch 227/5000
36/36 - 1s - loss: 0.1304 - mae: 0.3196 - val_loss: 0.1314 - val_mae: 0.3759
Epoch 228/5000
36/36 - 1s - loss: 0.1351 - mae: 0.3304 - val_loss: 0.1270 - val_mae: 0.3467
Epoch 229/5000
36/36 - 1s - loss: 0.1369 - mae: 0.3403 - val_loss: 0.1315 - val_mae: 0.3372
Epoch 230/5000
36/36 - 1s - loss: 0.1354 - mae: 0.3345 - val_loss: 0.1243 - val_mae: 0.3146
Epoch 231/5000
36/36 - 1s - loss: 0.1286 - mae: 0.3215 - val_loss: 0.1280 - val_mae: 0.3446
Epoch 232/5000
36/36 - 1s - loss: 0.1246 - mae: 0.3091 - val_loss: 0.1445 - val_mae: 0.4119
Epoch 233/5000
36/36 - 1s - loss: 0.1200 - mae: 0.3018 - val_loss: 0.1262 - val_mae: 0.3447
Epoch 234/5000
36/36 - 1s - loss: 0.1176 - mae: 0.2961 - val_loss: 0.1417 - val_mae: 0.3906
Epoch 235/5000
36/36 - 1s - loss: 0.1156 - mae: 0.2900 - val_loss: 0.1420 - val_mae: 0.3863
Epoch 236/5000
36/36 - 1s - loss: 0.1158 - mae: 0.2888 - val_loss: 0.1266 - val_mae: 0.3586
Epoch 237/5000
36/36 - 1s - loss: 0.1188 - mae: 0.2963 - val_loss: 0.1244 - val_mae: 0.3472
Epoch 238/5000
36/36 - 1s - loss: 0.1243 - mae: 0.3096 - val_loss: 0.1454 - val_mae: 0.4165
Epoch 239/5000
36/36 - 1s - loss: 0.1201 - mae: 0.3007 - val_loss: 0.1343 - val_mae: 0.3634
Epoch 240/5000
36/36 - 1s - loss: 0.1170 - mae: 0.2914 - val_loss: 0.1312 - val_mae: 0.3692
Epoch 241/5000
36/36 - 1s - loss: 0.1195 - mae: 0.2998 - val_loss: 0.1424 - val_mae: 0.3895
Epoch 242/5000
36/36 - 1s - loss: 0.1172 - mae: 0.2934 - val_loss: 0.1469 - val_mae: 0.3882
Epoch 243/5000
36/36 - 1s - loss: 0.1149 - mae: 0.2898 - val_loss: 0.1364 - val_mae: 0.3668
Epoch 244/5000
36/36 - 1s - loss: 0.1146 - mae: 0.2885 - val_loss: 0.1429 - val_mae: 0.3947
Epoch 245/5000
36/36 - 1s - loss: 0.1172 - mae: 0.2929 - val_loss: 0.1299 - val_mae: 0.3539
Epoch 246/5000
36/36 - 1s - loss: 0.1160 - mae: 0.2915 - val_loss: 0.1386 - val_mae: 0.3779
Epoch 247/5000
36/36 - 1s - loss: 0.1156 - mae: 0.2918 - val_loss: 0.1321 - val_mae: 0.3619
Epoch 248/5000
36/36 - 1s - loss: 0.1156 - mae: 0.2918 - val_loss: 0.1296 - val_mae: 0.3592
Epoch 249/5000
36/36 - 1s - loss: 0.1156 - mae: 0.2914 - val_loss: 0.1293 - val_mae: 0.3566
Epoch 250/5000
36/36 - 1s - loss: 0.1202 - mae: 0.3050 - val_loss: 0.1326 - val_mae: 0.3635
Epoch 251/5000
36/36 - 1s - loss: 0.1269 - mae: 0.3139 - val_loss: 0.1398 - val_mae: 0.3876
Epoch 252/5000
36/36 - 1s - loss: 0.1315 - mae: 0.3240 - val_loss: 0.1411 - val_mae: 0.4076
Epoch 253/5000
36/36 - 1s - loss: 0.1347 - mae: 0.3306 - val_loss: 0.1297 - val_mae: 0.3463
Epoch 254/5000
36/36 - 1s - loss: 0.1341 - mae: 0.3343 - val_loss: 0.1230 - val_mae: 0.3253
Epoch 255/5000
36/36 - 1s - loss: 0.1300 - mae: 0.3224 - val_loss: 0.1272 - val_mae: 0.3244
Epoch 256/5000
36/36 - 1s - loss: 0.1306 - mae: 0.3228 - val_loss: 0.1233 - val_mae: 0.3249
Epoch 257/5000
36/36 - 1s - loss: 0.1315 - mae: 0.3248 - val_loss: 0.1252 - val_mae: 0.3095
Epoch 258/5000
36/36 - 1s - loss: 0.1361 - mae: 0.3327 - val_loss: 0.1242 - val_mae: 0.3198
Epoch 259/5000
36/36 - 1s - loss: 0.1215 - mae: 0.3012 - val_loss: 0.1239 - val_mae: 0.3315
Epoch 260/5000
36/36 - 1s - loss: 0.1248 - mae: 0.3100 - val_loss: 0.1262 - val_mae: 0.3432
Epoch 261/5000
36/36 - 1s - loss: 0.1236 - mae: 0.3094 - val_loss: 0.1341 - val_mae: 0.3617
Epoch 262/5000
36/36 - 1s - loss: 0.1165 - mae: 0.2919 - val_loss: 0.1347 - val_mae: 0.3660
Epoch 263/5000
36/36 - 1s - loss: 0.1171 - mae: 0.2956 - val_loss: 0.1402 - val_mae: 0.3782
Epoch 264/5000
36/36 - 1s - loss: 0.1137 - mae: 0.2863 - val_loss: 0.1424 - val_mae: 0.3793
Epoch 265/5000
36/36 - 1s - loss: 0.1137 - mae: 0.2868 - val_loss: 0.1438 - val_mae: 0.3977
Epoch 266/5000
36/36 - 1s - loss: 0.1192 - mae: 0.2985 - val_loss: 0.1220 - val_mae: 0.3256
Epoch 267/5000
36/36 - 1s - loss: 0.1285 - mae: 0.3217 - val_loss: 0.1250 - val_mae: 0.3216
Epoch 268/5000
36/36 - 1s - loss: 0.1309 - mae: 0.3237 - val_loss: 0.1256 - val_mae: 0.3232
Epoch 269/5000
36/36 - 1s - loss: 0.1290 - mae: 0.3171 - val_loss: 0.1232 - val_mae: 0.3181
Epoch 270/5000
36/36 - 1s - loss: 0.1290 - mae: 0.3193 - val_loss: 0.1238 - val_mae: 0.3202
Epoch 271/5000
36/36 - 1s - loss: 0.1274 - mae: 0.3151 - val_loss: 0.1240 - val_mae: 0.3099
Epoch 272/5000
36/36 - 1s - loss: 0.1258 - mae: 0.3116 - val_loss: 0.1251 - val_mae: 0.3291
Epoch 273/5000
36/36 - 1s - loss: 0.1306 - mae: 0.3212 - val_loss: 0.1248 - val_mae: 0.3173
Epoch 274/5000
36/36 - 1s - loss: 0.1292 - mae: 0.3188 - val_loss: 0.1251 - val_mae: 0.3183
Epoch 275/5000
36/36 - 1s - loss: 0.1269 - mae: 0.3178 - val_loss: 0.1271 - val_mae: 0.3107
Epoch 276/5000
36/36 - 1s - loss: 0.1328 - mae: 0.3279 - val_loss: 0.1254 - val_mae: 0.3087
Epoch 277/5000
36/36 - 1s - loss: 0.1252 - mae: 0.3091 - val_loss: 0.1237 - val_mae: 0.3144
Epoch 278/5000
36/36 - 1s - loss: 0.1245 - mae: 0.3110 - val_loss: 0.1247 - val_mae: 0.3122
Epoch 279/5000
36/36 - 1s - loss: 0.1261 - mae: 0.3082 - val_loss: 0.1281 - val_mae: 0.3175
Epoch 280/5000
36/36 - 1s - loss: 0.1229 - mae: 0.3053 - val_loss: 0.1274 - val_mae: 0.3159
Epoch 281/5000
36/36 - 1s - loss: 0.1246 - mae: 0.3088 - val_loss: 0.1238 - val_mae: 0.3067
Epoch 282/5000
36/36 - 1s - loss: 0.1235 - mae: 0.3066 - val_loss: 0.1258 - val_mae: 0.3116
Epoch 283/5000
36/36 - 1s - loss: 0.1282 - mae: 0.3162 - val_loss: 0.1263 - val_mae: 0.3195
Epoch 284/5000
36/36 - 1s - loss: 0.1214 - mae: 0.3021 - val_loss: 0.1262 - val_mae: 0.3146
Epoch 285/5000
36/36 - 1s - loss: 0.1243 - mae: 0.3090 - val_loss: 0.1260 - val_mae: 0.3123
Epoch 286/5000
36/36 - 1s - loss: 0.1209 - mae: 0.3006 - val_loss: 0.1241 - val_mae: 0.3219
Epoch 287/5000
36/36 - 1s - loss: 0.1183 - mae: 0.2933 - val_loss: 0.1248 - val_mae: 0.3163
Epoch 288/5000
36/36 - 1s - loss: 0.1157 - mae: 0.2902 - val_loss: 0.1262 - val_mae: 0.3225
Epoch 289/5000
36/36 - 1s - loss: 0.1122 - mae: 0.2820 - val_loss: 0.1249 - val_mae: 0.3296
Epoch 290/5000
36/36 - 1s - loss: 0.1109 - mae: 0.2793 - val_loss: 0.1249 - val_mae: 0.3275
Epoch 291/5000
36/36 - 1s - loss: 0.1123 - mae: 0.2791 - val_loss: 0.1254 - val_mae: 0.3324
Epoch 292/5000
36/36 - 1s - loss: 0.1106 - mae: 0.2805 - val_loss: 0.1252 - val_mae: 0.3353
Epoch 293/5000
36/36 - 1s - loss: 0.1097 - mae: 0.2753 - val_loss: 0.1260 - val_mae: 0.3420
Epoch 294/5000
36/36 - 1s - loss: 0.1109 - mae: 0.2805 - val_loss: 0.1261 - val_mae: 0.3265
Epoch 295/5000
36/36 - 1s - loss: 0.1123 - mae: 0.2803 - val_loss: 0.1260 - val_mae: 0.3365
Epoch 296/5000
36/36 - 1s - loss: 0.1128 - mae: 0.2839 - val_loss: 0.1252 - val_mae: 0.3235
Epoch 297/5000
36/36 - 1s - loss: 0.1103 - mae: 0.2760 - val_loss: 0.1249 - val_mae: 0.3239
Epoch 298/5000
36/36 - 1s - loss: 0.1148 - mae: 0.2893 - val_loss: 0.1268 - val_mae: 0.3218
Epoch 299/5000
36/36 - 1s - loss: 0.1141 - mae: 0.2871 - val_loss: 0.1256 - val_mae: 0.3178
Epoch 300/5000
36/36 - 1s - loss: 0.1115 - mae: 0.2784 - val_loss: 0.1220 - val_mae: 0.3138
Epoch 301/5000
36/36 - 1s - loss: 0.1103 - mae: 0.2779 - val_loss: 0.1237 - val_mae: 0.3215
Epoch 302/5000
36/36 - 1s - loss: 0.1084 - mae: 0.2733 - val_loss: 0.1289 - val_mae: 0.3413
Epoch 303/5000
36/36 - 1s - loss: 0.1113 - mae: 0.2766 - val_loss: 0.1237 - val_mae: 0.3307
Epoch 304/5000
36/36 - 1s - loss: 0.1093 - mae: 0.2745 - val_loss: 0.1281 - val_mae: 0.3432
Epoch 305/5000
36/36 - 1s - loss: 0.1063 - mae: 0.2725 - val_loss: 0.1271 - val_mae: 0.3402
Epoch 306/5000
36/36 - 1s - loss: 0.1080 - mae: 0.2736 - val_loss: 0.1264 - val_mae: 0.3358
Epoch 307/5000
36/36 - 1s - loss: 0.1089 - mae: 0.2769 - val_loss: 0.1330 - val_mae: 0.3587
Epoch 308/5000
36/36 - 1s - loss: 0.1093 - mae: 0.2759 - val_loss: 0.1261 - val_mae: 0.3410
Epoch 309/5000
36/36 - 1s - loss: 0.1108 - mae: 0.2809 - val_loss: 0.1279 - val_mae: 0.3373
Epoch 310/5000
36/36 - 1s - loss: 0.1066 - mae: 0.2699 - val_loss: 0.1308 - val_mae: 0.3511
Epoch 311/5000
36/36 - 1s - loss: 0.1054 - mae: 0.2687 - val_loss: 0.1251 - val_mae: 0.3329
Epoch 312/5000
36/36 - 1s - loss: 0.1074 - mae: 0.2756 - val_loss: 0.1295 - val_mae: 0.3383
Epoch 313/5000
36/36 - 1s - loss: 0.1065 - mae: 0.2740 - val_loss: 0.1299 - val_mae: 0.3349
Epoch 314/5000
36/36 - 1s - loss: 0.1084 - mae: 0.2757 - val_loss: 0.1271 - val_mae: 0.3243
Epoch 315/5000
36/36 - 1s - loss: 0.1097 - mae: 0.2821 - val_loss: 0.1276 - val_mae: 0.3191
Epoch 316/5000
36/36 - 1s - loss: 0.1207 - mae: 0.3006 - val_loss: 0.1286 - val_mae: 0.3438
Epoch 317/5000
36/36 - 1s - loss: 0.1103 - mae: 0.2817 - val_loss: 0.1310 - val_mae: 0.3294
Epoch 318/5000
36/36 - 1s - loss: 0.1153 - mae: 0.2892 - val_loss: 0.1292 - val_mae: 0.3264
Epoch 319/5000
36/36 - 1s - loss: 0.1142 - mae: 0.2894 - val_loss: 0.1308 - val_mae: 0.3446
Epoch 320/5000
36/36 - 1s - loss: 0.1093 - mae: 0.2781 - val_loss: 0.1232 - val_mae: 0.3257
Epoch 321/5000
36/36 - 1s - loss: 0.1130 - mae: 0.2866 - val_loss: 0.1279 - val_mae: 0.3363
Epoch 322/5000
36/36 - 1s - loss: 0.1129 - mae: 0.2833 - val_loss: 0.1253 - val_mae: 0.3284
Epoch 323/5000
36/36 - 1s - loss: 0.1123 - mae: 0.2854 - val_loss: 0.1342 - val_mae: 0.3514
Epoch 324/5000
36/36 - 1s - loss: 0.1094 - mae: 0.2782 - val_loss: 0.1331 - val_mae: 0.3520
Epoch 325/5000
36/36 - 1s - loss: 0.1078 - mae: 0.2736 - val_loss: 0.1253 - val_mae: 0.3252
Epoch 326/5000
36/36 - 1s - loss: 0.1061 - mae: 0.2732 - val_loss: 0.1253 - val_mae: 0.3225
Epoch 327/5000
36/36 - 1s - loss: 0.1099 - mae: 0.2835 - val_loss: 0.1249 - val_mae: 0.3267
Epoch 328/5000
36/36 - 1s - loss: 0.1108 - mae: 0.2752 - val_loss: 0.1281 - val_mae: 0.3249
Epoch 329/5000
36/36 - 1s - loss: 0.1166 - mae: 0.2916 - val_loss: 0.1266 - val_mae: 0.3325
Epoch 330/5000
36/36 - 1s - loss: 0.1096 - mae: 0.2759 - val_loss: 0.1278 - val_mae: 0.3212
Epoch 331/5000
36/36 - 1s - loss: 0.1140 - mae: 0.2881 - val_loss: 0.1318 - val_mae: 0.3489
Epoch 332/5000
36/36 - 1s - loss: 0.1058 - mae: 0.2696 - val_loss: 0.1287 - val_mae: 0.3261
Epoch 333/5000
36/36 - 1s - loss: 0.1078 - mae: 0.2781 - val_loss: 0.1274 - val_mae: 0.3261
Epoch 334/5000
36/36 - 1s - loss: 0.1076 - mae: 0.2751 - val_loss: 0.1299 - val_mae: 0.3393
Epoch 335/5000
36/36 - 1s - loss: 0.1039 - mae: 0.2669 - val_loss: 0.1227 - val_mae: 0.3219
Epoch 336/5000
36/36 - 1s - loss: 0.1037 - mae: 0.2672 - val_loss: 0.1238 - val_mae: 0.3164
Epoch 337/5000
36/36 - 1s - loss: 0.1093 - mae: 0.2796 - val_loss: 0.1259 - val_mae: 0.3220
Epoch 338/5000
36/36 - 1s - loss: 0.1025 - mae: 0.2671 - val_loss: 0.1287 - val_mae: 0.3280
Epoch 339/5000
36/36 - 1s - loss: 0.1029 - mae: 0.2679 - val_loss: 0.1245 - val_mae: 0.3129
Epoch 340/5000
36/36 - 1s - loss: 0.1048 - mae: 0.2704 - val_loss: 0.1276 - val_mae: 0.3286
Epoch 341/5000
36/36 - 1s - loss: 0.1037 - mae: 0.2682 - val_loss: 0.1250 - val_mae: 0.3304
Epoch 342/5000
36/36 - 1s - loss: 0.1090 - mae: 0.2751 - val_loss: 0.1239 - val_mae: 0.3293
Epoch 343/5000
36/36 - 1s - loss: 0.1040 - mae: 0.2702 - val_loss: 0.1233 - val_mae: 0.3191
Epoch 344/5000
36/36 - 1s - loss: 0.1043 - mae: 0.2710 - val_loss: 0.1244 - val_mae: 0.3298
Epoch 345/5000
36/36 - 1s - loss: 0.1047 - mae: 0.2703 - val_loss: 0.1257 - val_mae: 0.3353
Epoch 346/5000
36/36 - 1s - loss: 0.1068 - mae: 0.2753 - val_loss: 0.1261 - val_mae: 0.3368
Epoch 347/5000
36/36 - 1s - loss: 0.1076 - mae: 0.2801 - val_loss: 0.1260 - val_mae: 0.3243
Epoch 348/5000
36/36 - 1s - loss: 0.1075 - mae: 0.2797 - val_loss: 0.1253 - val_mae: 0.3250
Epoch 349/5000
36/36 - 1s - loss: 0.1043 - mae: 0.2759 - val_loss: 0.1230 - val_mae: 0.3240
Epoch 350/5000
36/36 - 1s - loss: 0.1086 - mae: 0.2806 - val_loss: 0.1280 - val_mae: 0.3351
Epoch 351/5000
36/36 - 1s - loss: 0.1118 - mae: 0.2900 - val_loss: 0.1291 - val_mae: 0.3286
Epoch 352/5000
36/36 - 1s - loss: 0.1071 - mae: 0.2782 - val_loss: 0.1257 - val_mae: 0.3152
Epoch 353/5000
36/36 - 1s - loss: 0.1099 - mae: 0.2849 - val_loss: 0.1257 - val_mae: 0.3253
Epoch 354/5000
36/36 - 1s - loss: 0.1076 - mae: 0.2816 - val_loss: 0.1261 - val_mae: 0.3180
Epoch 355/5000
36/36 - 1s - loss: 0.1121 - mae: 0.2893 - val_loss: 0.1276 - val_mae: 0.3253
Epoch 356/5000
36/36 - 1s - loss: 0.1311 - mae: 0.3230 - val_loss: 0.1280 - val_mae: 0.3221
Epoch 357/5000
36/36 - 1s - loss: 0.1213 - mae: 0.3072 - val_loss: 0.1268 - val_mae: 0.3163
Epoch 358/5000
36/36 - 1s - loss: 0.1112 - mae: 0.2851 - val_loss: 0.1261 - val_mae: 0.3117
Epoch 359/5000
36/36 - 1s - loss: 0.1063 - mae: 0.2776 - val_loss: 0.1257 - val_mae: 0.3080
Epoch 360/5000
36/36 - 1s - loss: 0.1163 - mae: 0.2952 - val_loss: 0.1275 - val_mae: 0.3119
Epoch 361/5000
36/36 - 1s - loss: 0.1153 - mae: 0.2906 - val_loss: 0.1275 - val_mae: 0.3216
Epoch 362/5000
36/36 - 1s - loss: 0.1068 - mae: 0.2766 - val_loss: 0.1288 - val_mae: 0.3112
Epoch 363/5000
36/36 - 1s - loss: 0.1130 - mae: 0.2857 - val_loss: 0.1251 - val_mae: 0.3200
Epoch 364/5000
36/36 - 1s - loss: 0.1237 - mae: 0.3065 - val_loss: 0.1304 - val_mae: 0.3184
Epoch 365/5000
36/36 - 1s - loss: 0.1137 - mae: 0.2898 - val_loss: 0.1273 - val_mae: 0.3162
Epoch 366/5000
36/36 - 1s - loss: 0.1202 - mae: 0.3000 - val_loss: 0.1280 - val_mae: 0.3238
Epoch 367/5000
36/36 - 1s - loss: 0.1131 - mae: 0.2856 - val_loss: 0.1261 - val_mae: 0.3119
Epoch 368/5000
36/36 - 1s - loss: 0.1150 - mae: 0.2921 - val_loss: 0.1284 - val_mae: 0.3178
Epoch 369/5000
36/36 - 1s - loss: 0.1149 - mae: 0.2949 - val_loss: 0.1373 - val_mae: 0.3203
Epoch 370/5000
36/36 - 1s - loss: 0.1174 - mae: 0.3003 - val_loss: 0.1266 - val_mae: 0.3150
Epoch 371/5000
36/36 - 1s - loss: 0.1146 - mae: 0.2911 - val_loss: 0.1306 - val_mae: 0.3201
Epoch 372/5000
36/36 - 1s - loss: 0.1041 - mae: 0.2712 - val_loss: 0.1295 - val_mae: 0.3242
Epoch 373/5000
36/36 - 1s - loss: 0.1042 - mae: 0.2718 - val_loss: 0.1272 - val_mae: 0.3169
Epoch 374/5000
36/36 - 1s - loss: 0.1089 - mae: 0.2813 - val_loss: 0.1343 - val_mae: 0.3204
Epoch 375/5000
36/36 - 1s - loss: 0.1062 - mae: 0.2753 - val_loss: 0.1274 - val_mae: 0.3184
Epoch 376/5000
36/36 - 1s - loss: 0.1043 - mae: 0.2699 - val_loss: 0.1279 - val_mae: 0.3191
Epoch 377/5000
36/36 - 1s - loss: 0.1038 - mae: 0.2674 - val_loss: 0.1280 - val_mae: 0.3144
Epoch 378/5000
36/36 - 1s - loss: 0.1016 - mae: 0.2636 - val_loss: 0.1293 - val_mae: 0.3204
Epoch 379/5000
36/36 - 1s - loss: 0.1036 - mae: 0.2673 - val_loss: 0.1259 - val_mae: 0.3180
Epoch 380/5000
36/36 - 1s - loss: 0.1057 - mae: 0.2668 - val_loss: 0.1330 - val_mae: 0.3209
Epoch 381/5000
36/36 - 1s - loss: 0.1055 - mae: 0.2770 - val_loss: 0.1264 - val_mae: 0.3122
Epoch 382/5000
36/36 - 1s - loss: 0.0985 - mae: 0.2610 - val_loss: 0.1266 - val_mae: 0.3084
Restoring model weights from the end of the best epoch.
Epoch 00382: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_4..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_24"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_4 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_4 (PartitionP (None, None, 64)     0           message_passing_4[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_4[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_4 (Masking)             (None, None, 64)     0           partition_padding_4[0][0]        
                                                                 partition_padding_4[1][0]        
__________________________________________________________________________________________________
transformer_encoder_4 (Transfor (None, None, 64)     199040      masking_4[0][0]                  
                                                                 masking_4[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_4 (Glo (None, 64)           0           transformer_encoder_4[0][0]      
                                                                 transformer_encoder_4[1][0]      
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 512)          33280       global_average_pooling1d_4[0][0] 
                                                                 global_average_pooling1d_4[1][0] 
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 10)           110         dense_72[0][0]                   
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 450)          230850      dense_70[0][0]                   
                                                                 dense_70[1][0]                   
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 5)            55          dense_73[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 905)          0           dense_71[0][0]                   
                                                                 dense_71[1][0]                   
                                                                 dense_74[0][0]                   
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 700)          634200      concatenate_4[0][0]              
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 560)          392560      dense_75[0][0]                   
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 373)          209253      dense_79[0][0]                   
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 187)          69938       dense_80[0][0]                   
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 1)            188         dense_81[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
36/36 - 7s - loss: 0.1186 - mae: 0.2965 - val_loss: 0.1217 - val_mae: 0.3239
Epoch 2/5000
36/36 - 1s - loss: 0.1079 - mae: 0.2730 - val_loss: 0.1216 - val_mae: 0.3294
Epoch 3/5000
36/36 - 1s - loss: 0.1079 - mae: 0.2711 - val_loss: 0.1199 - val_mae: 0.3115
Epoch 4/5000
36/36 - 1s - loss: 0.1096 - mae: 0.2774 - val_loss: 0.1266 - val_mae: 0.3054
Epoch 5/5000
36/36 - 1s - loss: 0.1113 - mae: 0.2831 - val_loss: 0.1204 - val_mae: 0.2963
Epoch 6/5000
36/36 - 1s - loss: 0.1048 - mae: 0.2685 - val_loss: 0.1166 - val_mae: 0.2979
Epoch 7/5000
36/36 - 1s - loss: 0.0981 - mae: 0.2539 - val_loss: 0.1173 - val_mae: 0.2948
Epoch 8/5000
36/36 - 1s - loss: 0.0959 - mae: 0.2499 - val_loss: 0.1165 - val_mae: 0.2955
Epoch 9/5000
36/36 - 1s - loss: 0.0923 - mae: 0.2440 - val_loss: 0.1141 - val_mae: 0.2934
Epoch 10/5000
36/36 - 1s - loss: 0.0908 - mae: 0.2413 - val_loss: 0.1134 - val_mae: 0.2935
Epoch 11/5000
36/36 - 1s - loss: 0.0904 - mae: 0.2419 - val_loss: 0.1133 - val_mae: 0.2880
Epoch 12/5000
36/36 - 1s - loss: 0.0902 - mae: 0.2423 - val_loss: 0.1152 - val_mae: 0.3081
Epoch 13/5000
36/36 - 1s - loss: 0.0882 - mae: 0.2399 - val_loss: 0.1101 - val_mae: 0.2863
Epoch 14/5000
36/36 - 1s - loss: 0.0893 - mae: 0.2406 - val_loss: 0.1128 - val_mae: 0.2917
Epoch 15/5000
36/36 - 1s - loss: 0.0887 - mae: 0.2418 - val_loss: 0.1144 - val_mae: 0.2980
Epoch 16/5000
36/36 - 1s - loss: 0.0954 - mae: 0.2529 - val_loss: 0.1259 - val_mae: 0.3015
Epoch 17/5000
36/36 - 1s - loss: 0.1107 - mae: 0.2852 - val_loss: 0.1311 - val_mae: 0.3079
Epoch 18/5000
36/36 - 1s - loss: 0.1137 - mae: 0.2890 - val_loss: 0.1161 - val_mae: 0.3042
Epoch 19/5000
36/36 - 1s - loss: 0.1019 - mae: 0.2673 - val_loss: 0.1249 - val_mae: 0.2993
Epoch 20/5000
36/36 - 1s - loss: 0.0992 - mae: 0.2624 - val_loss: 0.1196 - val_mae: 0.2898
Epoch 21/5000
36/36 - 1s - loss: 0.0913 - mae: 0.2478 - val_loss: 0.1157 - val_mae: 0.2867
Epoch 22/5000
36/36 - 1s - loss: 0.0911 - mae: 0.2476 - val_loss: 0.1145 - val_mae: 0.2860
Epoch 23/5000
36/36 - 1s - loss: 0.0861 - mae: 0.2377 - val_loss: 0.1140 - val_mae: 0.2869
Epoch 24/5000
36/36 - 1s - loss: 0.0813 - mae: 0.2267 - val_loss: 0.1140 - val_mae: 0.2857
Epoch 25/5000
36/36 - 1s - loss: 0.0775 - mae: 0.2182 - val_loss: 0.1097 - val_mae: 0.2821
Epoch 26/5000
36/36 - 1s - loss: 0.0750 - mae: 0.2124 - val_loss: 0.1106 - val_mae: 0.2776
Epoch 27/5000
36/36 - 1s - loss: 0.0733 - mae: 0.2086 - val_loss: 0.1081 - val_mae: 0.2765
Epoch 28/5000
36/36 - 1s - loss: 0.0733 - mae: 0.2076 - val_loss: 0.1093 - val_mae: 0.2765
Epoch 29/5000
36/36 - 1s - loss: 0.0717 - mae: 0.2037 - val_loss: 0.1116 - val_mae: 0.2762
Epoch 30/5000
36/36 - 1s - loss: 0.0710 - mae: 0.2018 - val_loss: 0.1101 - val_mae: 0.2744
Epoch 31/5000
36/36 - 1s - loss: 0.0738 - mae: 0.2091 - val_loss: 0.1137 - val_mae: 0.2773
Epoch 32/5000
36/36 - 1s - loss: 0.0732 - mae: 0.2085 - val_loss: 0.1113 - val_mae: 0.2749
Epoch 33/5000
36/36 - 1s - loss: 0.0751 - mae: 0.2112 - val_loss: 0.1144 - val_mae: 0.2788
Epoch 34/5000
36/36 - 1s - loss: 0.0761 - mae: 0.2150 - val_loss: 0.1144 - val_mae: 0.2776
Epoch 35/5000
36/36 - 1s - loss: 0.0800 - mae: 0.2227 - val_loss: 0.1141 - val_mae: 0.2800
Epoch 36/5000
36/36 - 1s - loss: 0.0791 - mae: 0.2217 - val_loss: 0.1097 - val_mae: 0.2747
Epoch 37/5000
36/36 - 1s - loss: 0.0778 - mae: 0.2196 - val_loss: 0.1087 - val_mae: 0.2762
Epoch 38/5000
36/36 - 1s - loss: 0.0770 - mae: 0.2168 - val_loss: 0.1104 - val_mae: 0.2773
Epoch 39/5000
36/36 - 1s - loss: 0.0770 - mae: 0.2206 - val_loss: 0.1080 - val_mae: 0.2853
Epoch 40/5000
36/36 - 1s - loss: 0.0720 - mae: 0.2081 - val_loss: 0.1109 - val_mae: 0.2884
Epoch 41/5000
36/36 - 1s - loss: 0.0736 - mae: 0.2127 - val_loss: 0.1151 - val_mae: 0.2945
Epoch 42/5000
36/36 - 1s - loss: 0.0699 - mae: 0.2058 - val_loss: 0.1074 - val_mae: 0.2875
Epoch 43/5000
36/36 - 1s - loss: 0.0666 - mae: 0.1956 - val_loss: 0.1083 - val_mae: 0.2853
Epoch 44/5000
36/36 - 1s - loss: 0.0638 - mae: 0.1859 - val_loss: 0.1060 - val_mae: 0.2805
Epoch 45/5000
36/36 - 1s - loss: 0.0626 - mae: 0.1847 - val_loss: 0.1060 - val_mae: 0.2836
Epoch 46/5000
36/36 - 1s - loss: 0.0614 - mae: 0.1819 - val_loss: 0.1094 - val_mae: 0.2930
Epoch 47/5000
36/36 - 1s - loss: 0.0606 - mae: 0.1800 - val_loss: 0.1069 - val_mae: 0.2875
Epoch 48/5000
36/36 - 1s - loss: 0.0598 - mae: 0.1791 - val_loss: 0.1133 - val_mae: 0.2997
Epoch 49/5000
36/36 - 1s - loss: 0.0596 - mae: 0.1801 - val_loss: 0.1067 - val_mae: 0.2809
Epoch 50/5000
36/36 - 1s - loss: 0.0588 - mae: 0.1800 - val_loss: 0.1125 - val_mae: 0.2906
Epoch 51/5000
36/36 - 1s - loss: 0.0594 - mae: 0.1793 - val_loss: 0.1049 - val_mae: 0.2752
Epoch 52/5000
36/36 - 1s - loss: 0.0577 - mae: 0.1767 - val_loss: 0.1084 - val_mae: 0.2813
Epoch 53/5000
36/36 - 1s - loss: 0.0598 - mae: 0.1773 - val_loss: 0.1085 - val_mae: 0.2755
Epoch 54/5000
36/36 - 1s - loss: 0.0605 - mae: 0.1843 - val_loss: 0.1104 - val_mae: 0.2770
Epoch 55/5000
36/36 - 1s - loss: 0.0606 - mae: 0.1833 - val_loss: 0.1096 - val_mae: 0.2741
Epoch 56/5000
36/36 - 1s - loss: 0.0619 - mae: 0.1851 - val_loss: 0.1229 - val_mae: 0.2848
Epoch 57/5000
36/36 - 1s - loss: 0.0707 - mae: 0.2053 - val_loss: 0.1212 - val_mae: 0.2899
Epoch 58/5000
36/36 - 1s - loss: 0.0720 - mae: 0.2107 - val_loss: 0.1206 - val_mae: 0.2851
Epoch 59/5000
36/36 - 1s - loss: 0.0740 - mae: 0.2130 - val_loss: 0.1194 - val_mae: 0.2867
Epoch 60/5000
36/36 - 1s - loss: 0.0756 - mae: 0.2154 - val_loss: 0.1107 - val_mae: 0.2759
Epoch 61/5000
36/36 - 1s - loss: 0.0641 - mae: 0.1960 - val_loss: 0.1150 - val_mae: 0.2970
Epoch 62/5000
36/36 - 1s - loss: 0.0587 - mae: 0.1859 - val_loss: 0.1112 - val_mae: 0.2910
Epoch 63/5000
36/36 - 1s - loss: 0.0538 - mae: 0.1715 - val_loss: 0.1118 - val_mae: 0.2818
Epoch 64/5000
36/36 - 1s - loss: 0.0509 - mae: 0.1629 - val_loss: 0.1154 - val_mae: 0.2940
Epoch 65/5000
36/36 - 1s - loss: 0.0502 - mae: 0.1603 - val_loss: 0.1114 - val_mae: 0.2882
Epoch 66/5000
36/36 - 1s - loss: 0.0486 - mae: 0.1600 - val_loss: 0.1161 - val_mae: 0.2895
Epoch 67/5000
36/36 - 1s - loss: 0.0473 - mae: 0.1547 - val_loss: 0.1088 - val_mae: 0.2774
Epoch 68/5000
36/36 - 1s - loss: 0.0524 - mae: 0.1710 - val_loss: 0.1151 - val_mae: 0.2824
Epoch 69/5000
36/36 - 1s - loss: 0.0504 - mae: 0.1706 - val_loss: 0.1131 - val_mae: 0.2868
Epoch 70/5000
36/36 - 1s - loss: 0.0535 - mae: 0.1766 - val_loss: 0.1117 - val_mae: 0.2808
Epoch 71/5000
36/36 - 1s - loss: 0.0508 - mae: 0.1728 - val_loss: 0.1095 - val_mae: 0.2823
Epoch 72/5000
36/36 - 1s - loss: 0.0518 - mae: 0.1742 - val_loss: 0.1162 - val_mae: 0.2852
Epoch 73/5000
36/36 - 1s - loss: 0.0628 - mae: 0.1960 - val_loss: 0.1165 - val_mae: 0.2781
Epoch 74/5000
36/36 - 1s - loss: 0.0728 - mae: 0.2147 - val_loss: 0.1193 - val_mae: 0.2887
Epoch 75/5000
36/36 - 1s - loss: 0.0557 - mae: 0.1873 - val_loss: 0.1091 - val_mae: 0.2793
Epoch 76/5000
36/36 - 1s - loss: 0.0554 - mae: 0.1846 - val_loss: 0.1166 - val_mae: 0.2867
Epoch 77/5000
36/36 - 1s - loss: 0.0512 - mae: 0.1737 - val_loss: 0.1212 - val_mae: 0.3142
Epoch 78/5000
36/36 - 1s - loss: 0.0490 - mae: 0.1711 - val_loss: 0.1080 - val_mae: 0.2816
Epoch 79/5000
36/36 - 1s - loss: 0.0476 - mae: 0.1608 - val_loss: 0.1098 - val_mae: 0.2815
Epoch 80/5000
36/36 - 1s - loss: 0.0450 - mae: 0.1548 - val_loss: 0.1074 - val_mae: 0.2728
Epoch 81/5000
36/36 - 1s - loss: 0.0458 - mae: 0.1614 - val_loss: 0.1098 - val_mae: 0.2809
Epoch 82/5000
36/36 - 1s - loss: 0.0424 - mae: 0.1499 - val_loss: 0.1205 - val_mae: 0.3012
Epoch 83/5000
36/36 - 1s - loss: 0.0412 - mae: 0.1488 - val_loss: 0.1101 - val_mae: 0.2886
Epoch 84/5000
36/36 - 1s - loss: 0.0406 - mae: 0.1442 - val_loss: 0.1216 - val_mae: 0.2989
Epoch 85/5000
36/36 - 1s - loss: 0.0411 - mae: 0.1475 - val_loss: 0.1109 - val_mae: 0.2872
Epoch 86/5000
36/36 - 1s - loss: 0.0415 - mae: 0.1456 - val_loss: 0.1174 - val_mae: 0.2892
Epoch 87/5000
36/36 - 1s - loss: 0.0403 - mae: 0.1436 - val_loss: 0.1112 - val_mae: 0.2906
Epoch 88/5000
36/36 - 1s - loss: 0.0425 - mae: 0.1527 - val_loss: 0.1120 - val_mae: 0.2884
Epoch 89/5000
36/36 - 1s - loss: 0.0405 - mae: 0.1448 - val_loss: 0.1218 - val_mae: 0.2960
Epoch 90/5000
36/36 - 1s - loss: 0.0417 - mae: 0.1517 - val_loss: 0.1109 - val_mae: 0.2886
Epoch 91/5000
36/36 - 1s - loss: 0.0385 - mae: 0.1400 - val_loss: 0.1199 - val_mae: 0.2958
Epoch 92/5000
36/36 - 1s - loss: 0.0403 - mae: 0.1490 - val_loss: 0.1138 - val_mae: 0.2973
Epoch 93/5000
36/36 - 1s - loss: 0.0420 - mae: 0.1480 - val_loss: 0.1167 - val_mae: 0.3014
Epoch 94/5000
36/36 - 1s - loss: 0.0411 - mae: 0.1500 - val_loss: 0.1123 - val_mae: 0.2931
Epoch 95/5000
36/36 - 1s - loss: 0.0414 - mae: 0.1484 - val_loss: 0.1159 - val_mae: 0.2927
Epoch 96/5000
36/36 - 1s - loss: 0.0401 - mae: 0.1469 - val_loss: 0.1211 - val_mae: 0.3115
Epoch 97/5000
36/36 - 1s - loss: 0.0391 - mae: 0.1435 - val_loss: 0.1139 - val_mae: 0.2798
Epoch 98/5000
36/36 - 1s - loss: 0.0423 - mae: 0.1493 - val_loss: 0.1121 - val_mae: 0.2843
Epoch 99/5000
36/36 - 1s - loss: 0.0394 - mae: 0.1421 - val_loss: 0.1120 - val_mae: 0.2840
Epoch 100/5000
36/36 - 1s - loss: 0.0413 - mae: 0.1448 - val_loss: 0.1094 - val_mae: 0.2839
Epoch 101/5000
36/36 - 1s - loss: 0.0375 - mae: 0.1366 - val_loss: 0.1088 - val_mae: 0.2810
Epoch 102/5000
36/36 - 1s - loss: 0.0370 - mae: 0.1341 - val_loss: 0.1075 - val_mae: 0.2810
Epoch 103/5000
36/36 - 1s - loss: 0.0370 - mae: 0.1351 - val_loss: 0.1089 - val_mae: 0.2764
Epoch 104/5000
36/36 - 1s - loss: 0.0383 - mae: 0.1398 - val_loss: 0.1082 - val_mae: 0.2754
Epoch 105/5000
36/36 - 1s - loss: 0.0366 - mae: 0.1337 - val_loss: 0.1115 - val_mae: 0.2875
Epoch 106/5000
36/36 - 1s - loss: 0.0375 - mae: 0.1372 - val_loss: 0.1082 - val_mae: 0.2783
Epoch 107/5000
36/36 - 1s - loss: 0.0367 - mae: 0.1327 - val_loss: 0.1090 - val_mae: 0.2782
Epoch 108/5000
36/36 - 1s - loss: 0.0345 - mae: 0.1316 - val_loss: 0.1163 - val_mae: 0.2940
Epoch 109/5000
36/36 - 1s - loss: 0.0348 - mae: 0.1286 - val_loss: 0.1108 - val_mae: 0.2765
Epoch 110/5000
36/36 - 1s - loss: 0.0359 - mae: 0.1351 - val_loss: 0.1111 - val_mae: 0.2878
Epoch 111/5000
36/36 - 1s - loss: 0.0338 - mae: 0.1250 - val_loss: 0.1120 - val_mae: 0.2920
Epoch 112/5000
36/36 - 1s - loss: 0.0349 - mae: 0.1312 - val_loss: 0.1227 - val_mae: 0.3060
Epoch 113/5000
36/36 - 1s - loss: 0.0338 - mae: 0.1265 - val_loss: 0.1182 - val_mae: 0.2914
Epoch 114/5000
36/36 - 1s - loss: 0.0367 - mae: 0.1353 - val_loss: 0.1111 - val_mae: 0.2839
Epoch 115/5000
36/36 - 1s - loss: 0.0355 - mae: 0.1290 - val_loss: 0.1101 - val_mae: 0.2789
Epoch 116/5000
36/36 - 1s - loss: 0.0336 - mae: 0.1261 - val_loss: 0.1113 - val_mae: 0.2856
Epoch 117/5000
36/36 - 1s - loss: 0.0368 - mae: 0.1325 - val_loss: 0.1141 - val_mae: 0.2887
Epoch 118/5000
36/36 - 1s - loss: 0.0343 - mae: 0.1269 - val_loss: 0.1082 - val_mae: 0.2781
Epoch 119/5000
36/36 - 1s - loss: 0.0353 - mae: 0.1279 - val_loss: 0.1152 - val_mae: 0.2865
Epoch 120/5000
36/36 - 1s - loss: 0.0338 - mae: 0.1254 - val_loss: 0.1153 - val_mae: 0.2913
Epoch 121/5000
36/36 - 1s - loss: 0.0327 - mae: 0.1226 - val_loss: 0.1140 - val_mae: 0.2891
Epoch 122/5000
36/36 - 1s - loss: 0.0324 - mae: 0.1219 - val_loss: 0.1201 - val_mae: 0.2970
Epoch 123/5000
36/36 - 1s - loss: 0.0324 - mae: 0.1229 - val_loss: 0.1205 - val_mae: 0.2935
Epoch 124/5000
36/36 - 1s - loss: 0.0316 - mae: 0.1179 - val_loss: 0.1149 - val_mae: 0.2830
Epoch 125/5000
36/36 - 1s - loss: 0.0310 - mae: 0.1184 - val_loss: 0.1200 - val_mae: 0.2974
Epoch 126/5000
36/36 - 1s - loss: 0.0314 - mae: 0.1183 - val_loss: 0.1157 - val_mae: 0.2863
Epoch 127/5000
36/36 - 1s - loss: 0.0306 - mae: 0.1169 - val_loss: 0.1153 - val_mae: 0.2923
Epoch 128/5000
36/36 - 1s - loss: 0.0305 - mae: 0.1150 - val_loss: 0.1152 - val_mae: 0.2825
Epoch 129/5000
36/36 - 1s - loss: 0.0296 - mae: 0.1131 - val_loss: 0.1204 - val_mae: 0.2985
Epoch 130/5000
36/36 - 1s - loss: 0.0296 - mae: 0.1125 - val_loss: 0.1125 - val_mae: 0.2771
Epoch 131/5000
36/36 - 1s - loss: 0.0297 - mae: 0.1137 - val_loss: 0.1148 - val_mae: 0.2878
Epoch 132/5000
36/36 - 1s - loss: 0.0286 - mae: 0.1092 - val_loss: 0.1175 - val_mae: 0.2880
Epoch 133/5000
36/36 - 1s - loss: 0.0298 - mae: 0.1124 - val_loss: 0.1191 - val_mae: 0.2922
Epoch 134/5000
36/36 - 1s - loss: 0.0321 - mae: 0.1198 - val_loss: 0.1173 - val_mae: 0.2896
Epoch 135/5000
36/36 - 1s - loss: 0.0325 - mae: 0.1211 - val_loss: 0.1203 - val_mae: 0.2909
Epoch 136/5000
36/36 - 1s - loss: 0.0331 - mae: 0.1239 - val_loss: 0.1187 - val_mae: 0.2940
Epoch 137/5000
36/36 - 1s - loss: 0.0325 - mae: 0.1226 - val_loss: 0.1193 - val_mae: 0.2896
Epoch 138/5000
36/36 - 1s - loss: 0.0329 - mae: 0.1208 - val_loss: 0.1165 - val_mae: 0.2893
Epoch 139/5000
36/36 - 1s - loss: 0.0329 - mae: 0.1249 - val_loss: 0.1215 - val_mae: 0.2986
Epoch 140/5000
36/36 - 1s - loss: 0.0328 - mae: 0.1215 - val_loss: 0.1210 - val_mae: 0.2995
Epoch 141/5000
36/36 - 1s - loss: 0.0296 - mae: 0.1142 - val_loss: 0.1220 - val_mae: 0.3012
Epoch 142/5000
36/36 - 1s - loss: 0.0303 - mae: 0.1149 - val_loss: 0.1236 - val_mae: 0.3008
Epoch 143/5000
36/36 - 1s - loss: 0.0307 - mae: 0.1178 - val_loss: 0.1271 - val_mae: 0.3077
Epoch 144/5000
36/36 - 1s - loss: 0.0301 - mae: 0.1146 - val_loss: 0.1284 - val_mae: 0.3065
Epoch 145/5000
36/36 - 1s - loss: 0.0309 - mae: 0.1187 - val_loss: 0.1344 - val_mae: 0.3202
Epoch 146/5000
36/36 - 1s - loss: 0.0289 - mae: 0.1143 - val_loss: 0.1302 - val_mae: 0.3114
Epoch 147/5000
36/36 - 1s - loss: 0.0313 - mae: 0.1229 - val_loss: 0.1401 - val_mae: 0.3286
Epoch 148/5000
36/36 - 1s - loss: 0.0309 - mae: 0.1220 - val_loss: 0.1390 - val_mae: 0.3272
Epoch 149/5000
36/36 - 1s - loss: 0.0339 - mae: 0.1322 - val_loss: 0.1375 - val_mae: 0.3219
Epoch 150/5000
36/36 - 1s - loss: 0.0313 - mae: 0.1243 - val_loss: 0.1156 - val_mae: 0.2933
Epoch 151/5000
36/36 - 1s - loss: 0.0352 - mae: 0.1338 - val_loss: 0.1161 - val_mae: 0.2912
Epoch 152/5000
36/36 - 1s - loss: 0.0371 - mae: 0.1402 - val_loss: 0.1161 - val_mae: 0.2918
Epoch 153/5000
36/36 - 1s - loss: 0.0363 - mae: 0.1395 - val_loss: 0.1178 - val_mae: 0.2881
Epoch 154/5000
36/36 - 1s - loss: 0.0416 - mae: 0.1537 - val_loss: 0.1189 - val_mae: 0.2865
Epoch 155/5000
36/36 - 1s - loss: 0.0482 - mae: 0.1676 - val_loss: 0.1202 - val_mae: 0.2919
Epoch 156/5000
36/36 - 1s - loss: 0.0365 - mae: 0.1368 - val_loss: 0.1241 - val_mae: 0.3095
Epoch 157/5000
36/36 - 1s - loss: 0.0334 - mae: 0.1305 - val_loss: 0.1186 - val_mae: 0.2970
Epoch 158/5000
36/36 - 1s - loss: 0.0317 - mae: 0.1250 - val_loss: 0.1202 - val_mae: 0.2908
Epoch 159/5000
36/36 - 1s - loss: 0.0303 - mae: 0.1171 - val_loss: 0.1170 - val_mae: 0.2944
Epoch 160/5000
36/36 - 1s - loss: 0.0284 - mae: 0.1145 - val_loss: 0.1231 - val_mae: 0.3006
Epoch 161/5000
36/36 - 1s - loss: 0.0287 - mae: 0.1132 - val_loss: 0.1177 - val_mae: 0.2938
Epoch 162/5000
36/36 - 1s - loss: 0.0279 - mae: 0.1118 - val_loss: 0.1202 - val_mae: 0.2979
Epoch 163/5000
36/36 - 1s - loss: 0.0329 - mae: 0.1235 - val_loss: 0.1194 - val_mae: 0.3094
Epoch 164/5000
36/36 - 1s - loss: 0.0280 - mae: 0.1138 - val_loss: 0.1222 - val_mae: 0.2927
Epoch 165/5000
36/36 - 1s - loss: 0.0251 - mae: 0.1036 - val_loss: 0.1198 - val_mae: 0.2976
Epoch 166/5000
36/36 - 1s - loss: 0.0264 - mae: 0.1054 - val_loss: 0.1234 - val_mae: 0.2956
Epoch 167/5000
36/36 - 1s - loss: 0.0255 - mae: 0.1033 - val_loss: 0.1214 - val_mae: 0.3033
Epoch 168/5000
36/36 - 1s - loss: 0.0259 - mae: 0.1059 - val_loss: 0.1146 - val_mae: 0.2844
Epoch 169/5000
36/36 - 1s - loss: 0.0258 - mae: 0.1084 - val_loss: 0.1193 - val_mae: 0.2966
Epoch 170/5000
36/36 - 1s - loss: 0.0245 - mae: 0.1021 - val_loss: 0.1180 - val_mae: 0.2903
Epoch 171/5000
36/36 - 1s - loss: 0.0241 - mae: 0.1018 - val_loss: 0.1217 - val_mae: 0.3021
Epoch 172/5000
36/36 - 1s - loss: 0.0236 - mae: 0.0970 - val_loss: 0.1168 - val_mae: 0.2923
Epoch 173/5000
36/36 - 1s - loss: 0.0225 - mae: 0.0961 - val_loss: 0.1197 - val_mae: 0.2972
Epoch 174/5000
36/36 - 1s - loss: 0.0227 - mae: 0.0946 - val_loss: 0.1185 - val_mae: 0.2938
Epoch 175/5000
36/36 - 1s - loss: 0.0228 - mae: 0.0956 - val_loss: 0.1250 - val_mae: 0.3040
Epoch 176/5000
36/36 - 1s - loss: 0.0230 - mae: 0.0928 - val_loss: 0.1173 - val_mae: 0.2929
Epoch 177/5000
36/36 - 1s - loss: 0.0223 - mae: 0.0936 - val_loss: 0.1159 - val_mae: 0.2861
Epoch 178/5000
36/36 - 1s - loss: 0.0224 - mae: 0.0962 - val_loss: 0.1223 - val_mae: 0.3035
Epoch 179/5000
36/36 - 1s - loss: 0.0218 - mae: 0.0920 - val_loss: 0.1147 - val_mae: 0.2829
Epoch 180/5000
36/36 - 1s - loss: 0.0239 - mae: 0.1014 - val_loss: 0.1219 - val_mae: 0.3027
Epoch 181/5000
36/36 - 1s - loss: 0.0235 - mae: 0.0996 - val_loss: 0.1141 - val_mae: 0.2846
Restoring model weights from the end of the best epoch.
Epoch 00181: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_4..

Done.
(data_driven_fep_rel) jscheen@yoko:perturbation_networks$ ll
total 2648
drwxrwxr-x 10 jscheen jscheen    4096 Dec  2 22:39 ./
drwxrwxr-x  5 jscheen jscheen    4096 Nov 12 09:08 ../
-rw-rw-r--  1 jscheen jscheen    4405 Oct 26 11:22 _00_fepspace_esol.py
-rw-rw-r--  1 jscheen jscheen   21391 Nov 30 09:56 _01_twin_gcn.py
-rw-rw-r--  1 jscheen jscheen   17748 Dec  2 14:35 _02_transfer_learn_sem.py
-rw-rw-r--  1 jscheen jscheen  385504 Nov 24 16:28 _03_analyse_training_losses.ipynb
-rw-rw-r--  1 jscheen jscheen    8860 Nov 16 09:37 _042_all_series_networks.py
-rw-rw-r--  1 jscheen jscheen   41383 Dec  2 14:02 _04_external_test_all_series.py
-rw-rw-r--  1 jscheen jscheen  535428 Nov 30 15:56 _05_generate_perturbation_networks.ipynb
drwxrwxr-x  3 jscheen jscheen    4096 Nov 22 09:48 input/
drwxrwxr-x  2 jscheen jscheen    4096 Nov 30 12:44 .ipynb_checkpoints/
-rw-------  1 jscheen jscheen   16858 Dec  3 09:22 nohup.out
drwxrwxr-x  3 jscheen jscheen    4096 Oct 27 15:29 output/
drwxrwxr-x  6 jscheen jscheen    4096 Dec  1 15:41 process/
drwxrwxr-x  2 jscheen jscheen    4096 Dec  2 12:24 __pycache__/
drwxrwxr-x  2 jscheen jscheen    4096 Nov  4 15:57 tmp/
-rw-rw-r--  1 jscheen jscheen 1612529 Oct 25 14:45 tmp_compare_ntwx_all_series.ipynb
drwxrwxr-x  2 jscheen jscheen    4096 Nov 15 10:58 tmp_images/
drwxrwxr-x  2 jscheen jscheen    4096 Oct 20 11:55 variations/
(data_driven_fep_rel) jscheen@yoko:perturbation_networks$ rmate _01_twin_gcn.py 
(data_driven_fep_rel) jscheen@yoko:perturbation_networks$ ll
total 2648
drwxrwxr-x 10 jscheen jscheen    4096 Dec  2 22:39 ./
drwxrwxr-x  5 jscheen jscheen    4096 Nov 12 09:08 ../
-rw-rw-r--  1 jscheen jscheen    4405 Oct 26 11:22 _00_fepspace_esol.py
-rw-rw-r--  1 jscheen jscheen   21391 Nov 30 09:56 _01_twin_gcn.py
-rw-rw-r--  1 jscheen jscheen   17748 Dec  2 14:35 _02_transfer_learn_sem.py
-rw-rw-r--  1 jscheen jscheen  385504 Nov 24 16:28 _03_analyse_training_losses.ipynb
-rw-rw-r--  1 jscheen jscheen    8860 Nov 16 09:37 _042_all_series_networks.py
-rw-rw-r--  1 jscheen jscheen   41383 Dec  2 14:02 _04_external_test_all_series.py
-rw-rw-r--  1 jscheen jscheen  535428 Nov 30 15:56 _05_generate_perturbation_networks.ipynb
drwxrwxr-x  3 jscheen jscheen    4096 Nov 22 09:48 input/
drwxrwxr-x  2 jscheen jscheen    4096 Nov 30 12:44 .ipynb_checkpoints/
-rw-------  1 jscheen jscheen   16858 Dec  3 09:22 nohup.out
drwxrwxr-x  3 jscheen jscheen    4096 Oct 27 15:29 output/
drwxrwxr-x  6 jscheen jscheen    4096 Dec  1 15:41 process/
drwxrwxr-x  2 jscheen jscheen    4096 Dec  2 12:24 __pycache__/
drwxrwxr-x  2 jscheen jscheen    4096 Nov  4 15:57 tmp/
-rw-rw-r--  1 jscheen jscheen 1612529 Oct 25 14:45 tmp_compare_ntwx_all_series.ipynb
drwxrwxr-x  2 jscheen jscheen    4096 Nov 15 10:58 tmp_images/
drwxrwxr-x  2 jscheen jscheen    4096 Oct 20 11:55 variations/
(data_driven_fep_rel) jscheen@yoko:perturbation_networks$ cd process/
(data_driven_fep_rel) jscheen@yoko:process$ ll
total 2392
drwxrwxr-x  6 jscheen jscheen   4096 Dec  1 15:41 ./
drwxrwxr-x 10 jscheen jscheen   4096 Dec  2 22:39 ../
drwxrwxr-x  2 jscheen jscheen   4096 Dec  2 11:50 base_models/
-rw-rw-r--  1 jscheen jscheen 174348 Dec  3 09:47 fepspace_smiles_per_sem.csv
drwxrwxr-x  2 jscheen jscheen   4096 Oct 19 22:00 inputs/
drwxrwxr-x  4 jscheen jscheen   4096 Nov 30 15:25 lomap/
-rw-rw-r--  1 jscheen jscheen   8710 Dec  3 09:22 pretraining_history.csv
-rw-rw-r--  1 jscheen jscheen  20900 Dec  3 09:22 pretraining_history_plot.png
-rw-rw-r--  1 jscheen jscheen  16858 Oct 27 09:40 pretraining_stdout.out
drwxr-xr-x  2 jscheen jscheen   4096 Dec  3 10:30 trained_model_weights/
-rw-rw-r--  1 jscheen jscheen  11507 Dec  3 10:03 training_history_finetuned_0.csv
-rw-rw-r--  1 jscheen jscheen  12343 Dec  3 10:08 training_history_finetuned_1.csv
-rw-rw-r--  1 jscheen jscheen  19198 Dec  3 10:14 training_history_finetuned_2.csv
-rw-rw-r--  1 jscheen jscheen  22038 Dec  3 10:21 training_history_finetuned_3.csv
-rw-rw-r--  1 jscheen jscheen  14980 Dec  3 10:30 training_history_finetuned_4.csv
-rw-rw-r--  1 jscheen jscheen  21865 Oct 27 16:40 training_history_finetuned_5.csv
-rw-rw-r--  1 jscheen jscheen  16543 Oct 27 16:46 training_history_finetuned_6.csv
-rw-rw-r--  1 jscheen jscheen  26966 Oct 27 16:56 training_history_finetuned_7.csv
-rw-rw-r--  1 jscheen jscheen  11359 Oct 27 17:01 training_history_finetuned_8.csv
-rw-rw-r--  1 jscheen jscheen  17930 Oct 27 17:08 training_history_finetuned_9.csv
-rw-rw-r--  1 jscheen jscheen  46001 Dec  3 10:03 training_history_plot_finetuned_0.png
-rw-rw-r--  1 jscheen jscheen  52085 Dec  3 10:08 training_history_plot_finetuned_1.png
-rw-rw-r--  1 jscheen jscheen  56560 Dec  3 10:14 training_history_plot_finetuned_2.png
-rw-rw-r--  1 jscheen jscheen  46833 Dec  3 10:21 training_history_plot_finetuned_3.png
-rw-rw-r--  1 jscheen jscheen  47806 Dec  3 10:30 training_history_plot_finetuned_4.png
-rw-rw-r--  1 jscheen jscheen  55903 Oct 27 16:40 training_history_plot_finetuned_5.png
-rw-rw-r--  1 jscheen jscheen  50505 Oct 27 16:46 training_history_plot_finetuned_6.png
-rw-rw-r--  1 jscheen jscheen  62582 Oct 27 16:56 training_history_plot_finetuned_7.png
-rw-rw-r--  1 jscheen jscheen  45583 Oct 27 17:01 training_history_plot_finetuned_8.png
-rw-rw-r--  1 jscheen jscheen  56195 Oct 27 17:08 training_history_plot_finetuned_9.png
-rw-rw-r--  1 jscheen jscheen  58665 Dec  3 10:00 training_history_plot_transfer_0.png
-rw-rw-r--  1 jscheen jscheen  56843 Dec  3 10:05 training_history_plot_transfer_1.png
-rw-rw-r--  1 jscheen jscheen  43829 Dec  3 10:10 training_history_plot_transfer_2.png
-rw-rw-r--  1 jscheen jscheen  52865 Dec  3 10:16 training_history_plot_transfer_3.png
-rw-rw-r--  1 jscheen jscheen  55415 Dec  3 10:26 training_history_plot_transfer_4.png
-rw-rw-r--  1 jscheen jscheen  61708 Oct 27 16:35 training_history_plot_transfer_5.png
-rw-rw-r--  1 jscheen jscheen  57948 Oct 27 16:42 training_history_plot_transfer_6.png
-rw-rw-r--  1 jscheen jscheen  56131 Oct 27 16:49 training_history_plot_transfer_7.png
-rw-rw-r--  1 jscheen jscheen  58186 Oct 27 16:58 training_history_plot_transfer_8.png
-rw-rw-r--  1 jscheen jscheen  58175 Oct 27 17:04 training_history_plot_transfer_9.png
-rw-rw-r--  1 jscheen jscheen  28951 Dec  3 10:00 training_history_transfer_0.csv
-rw-rw-r--  1 jscheen jscheen  13251 Dec  3 10:05 training_history_transfer_1.csv
-rw-rw-r--  1 jscheen jscheen  12238 Dec  3 10:10 training_history_transfer_2.csv
-rw-rw-r--  1 jscheen jscheen  11001 Dec  3 10:16 training_history_transfer_3.csv
-rw-rw-r--  1 jscheen jscheen  31336 Dec  3 10:26 training_history_transfer_4.csv
-rw-rw-r--  1 jscheen jscheen  12969 Oct 27 16:35 training_history_transfer_5.csv
-rw-rw-r--  1 jscheen jscheen  12882 Oct 27 16:42 training_history_transfer_6.csv
-rw-rw-r--  1 jscheen jscheen  15550 Oct 27 16:49 training_history_transfer_7.csv
-rw-rw-r--  1 jscheen jscheen  13505 Oct 27 16:58 training_history_transfer_8.csv
-rw-rw-r--  1 jscheen jscheen  17598 Oct 27 17:04 training_history_transfer_9.csv
-rw-rw-r--  1 jscheen jscheen 498080 Oct 27 17:08 transferlearning_stdout.out
-rw-rw-r--  1 jscheen jscheen 170191 Dec  2 23:15 twin_model.png
-rw-rw-r--  1 jscheen jscheen     72 Nov 30 09:37 walltime_ml_pred_per_tgt.csv
(data_driven_fep_rel) jscheen@yoko:process$ cd trained_model_weights/^C
(data_driven_fep_rel) jscheen@yoko:process$ ll
total 2392
drwxrwxr-x  6 jscheen jscheen   4096 Dec  1 15:41 ./
drwxrwxr-x 10 jscheen jscheen   4096 Dec  2 22:39 ../
drwxrwxr-x  2 jscheen jscheen   4096 Dec  2 11:50 base_models/
-rw-rw-r--  1 jscheen jscheen 174348 Dec  3 09:47 fepspace_smiles_per_sem.csv
drwxrwxr-x  2 jscheen jscheen   4096 Oct 19 22:00 inputs/
drwxrwxr-x  4 jscheen jscheen   4096 Nov 30 15:25 lomap/
-rw-rw-r--  1 jscheen jscheen   8710 Dec  3 09:22 pretraining_history.csv
-rw-rw-r--  1 jscheen jscheen  20900 Dec  3 09:22 pretraining_history_plot.png
-rw-rw-r--  1 jscheen jscheen  16858 Oct 27 09:40 pretraining_stdout.out
drwxr-xr-x  2 jscheen jscheen   4096 Dec  3 10:30 trained_model_weights/
-rw-rw-r--  1 jscheen jscheen  11507 Dec  3 10:03 training_history_finetuned_0.csv
-rw-rw-r--  1 jscheen jscheen  12343 Dec  3 10:08 training_history_finetuned_1.csv
-rw-rw-r--  1 jscheen jscheen  19198 Dec  3 10:14 training_history_finetuned_2.csv
-rw-rw-r--  1 jscheen jscheen  22038 Dec  3 10:21 training_history_finetuned_3.csv
-rw-rw-r--  1 jscheen jscheen  14980 Dec  3 10:30 training_history_finetuned_4.csv
-rw-rw-r--  1 jscheen jscheen  21865 Oct 27 16:40 training_history_finetuned_5.csv
-rw-rw-r--  1 jscheen jscheen  16543 Oct 27 16:46 training_history_finetuned_6.csv
-rw-rw-r--  1 jscheen jscheen  26966 Oct 27 16:56 training_history_finetuned_7.csv
-rw-rw-r--  1 jscheen jscheen  11359 Oct 27 17:01 training_history_finetuned_8.csv
-rw-rw-r--  1 jscheen jscheen  17930 Oct 27 17:08 training_history_finetuned_9.csv
-rw-rw-r--  1 jscheen jscheen  46001 Dec  3 10:03 training_history_plot_finetuned_0.png
-rw-rw-r--  1 jscheen jscheen  52085 Dec  3 10:08 training_history_plot_finetuned_1.png
-rw-rw-r--  1 jscheen jscheen  56560 Dec  3 10:14 training_history_plot_finetuned_2.png
-rw-rw-r--  1 jscheen jscheen  46833 Dec  3 10:21 training_history_plot_finetuned_3.png
-rw-rw-r--  1 jscheen jscheen  47806 Dec  3 10:30 training_history_plot_finetuned_4.png
-rw-rw-r--  1 jscheen jscheen  55903 Oct 27 16:40 training_history_plot_finetuned_5.png
-rw-rw-r--  1 jscheen jscheen  50505 Oct 27 16:46 training_history_plot_finetuned_6.png
-rw-rw-r--  1 jscheen jscheen  62582 Oct 27 16:56 training_history_plot_finetuned_7.png
-rw-rw-r--  1 jscheen jscheen  45583 Oct 27 17:01 training_history_plot_finetuned_8.png
-rw-rw-r--  1 jscheen jscheen  56195 Oct 27 17:08 training_history_plot_finetuned_9.png
-rw-rw-r--  1 jscheen jscheen  58665 Dec  3 10:00 training_history_plot_transfer_0.png
-rw-rw-r--  1 jscheen jscheen  56843 Dec  3 10:05 training_history_plot_transfer_1.png
-rw-rw-r--  1 jscheen jscheen  43829 Dec  3 10:10 training_history_plot_transfer_2.png
-rw-rw-r--  1 jscheen jscheen  52865 Dec  3 10:16 training_history_plot_transfer_3.png
-rw-rw-r--  1 jscheen jscheen  55415 Dec  3 10:26 training_history_plot_transfer_4.png
-rw-rw-r--  1 jscheen jscheen  61708 Oct 27 16:35 training_history_plot_transfer_5.png
-rw-rw-r--  1 jscheen jscheen  57948 Oct 27 16:42 training_history_plot_transfer_6.png
-rw-rw-r--  1 jscheen jscheen  56131 Oct 27 16:49 training_history_plot_transfer_7.png
-rw-rw-r--  1 jscheen jscheen  58186 Oct 27 16:58 training_history_plot_transfer_8.png
-rw-rw-r--  1 jscheen jscheen  58175 Oct 27 17:04 training_history_plot_transfer_9.png
-rw-rw-r--  1 jscheen jscheen  28951 Dec  3 10:00 training_history_transfer_0.csv
-rw-rw-r--  1 jscheen jscheen  13251 Dec  3 10:05 training_history_transfer_1.csv
-rw-rw-r--  1 jscheen jscheen  12238 Dec  3 10:10 training_history_transfer_2.csv
-rw-rw-r--  1 jscheen jscheen  11001 Dec  3 10:16 training_history_transfer_3.csv
-rw-rw-r--  1 jscheen jscheen  31336 Dec  3 10:26 training_history_transfer_4.csv
-rw-rw-r--  1 jscheen jscheen  12969 Oct 27 16:35 training_history_transfer_5.csv
-rw-rw-r--  1 jscheen jscheen  12882 Oct 27 16:42 training_history_transfer_6.csv
-rw-rw-r--  1 jscheen jscheen  15550 Oct 27 16:49 training_history_transfer_7.csv
-rw-rw-r--  1 jscheen jscheen  13505 Oct 27 16:58 training_history_transfer_8.csv
-rw-rw-r--  1 jscheen jscheen  17598 Oct 27 17:04 training_history_transfer_9.csv
-rw-rw-r--  1 jscheen jscheen 498080 Oct 27 17:08 transferlearning_stdout.out
-rw-rw-r--  1 jscheen jscheen 170191 Dec  2 23:15 twin_model.png
-rw-rw-r--  1 jscheen jscheen     72 Nov 30 09:37 walltime_ml_pred_per_tgt.csv
(data_driven_fep_rel) jscheen@yoko:process$ for i in {5..9}; do rm training_history_transfer_$i.csv; done
(data_driven_fep_rel) jscheen@yoko:process$ ll
total 2308
drwxrwxr-x  6 jscheen jscheen   4096 Dec  3 10:34 ./
drwxrwxr-x 10 jscheen jscheen   4096 Dec  3 10:33 ../
drwxrwxr-x  2 jscheen jscheen   4096 Dec  2 11:50 base_models/
-rw-rw-r--  1 jscheen jscheen 174348 Dec  3 09:47 fepspace_smiles_per_sem.csv
drwxrwxr-x  2 jscheen jscheen   4096 Oct 19 22:00 inputs/
drwxrwxr-x  4 jscheen jscheen   4096 Nov 30 15:25 lomap/
-rw-rw-r--  1 jscheen jscheen   8710 Dec  3 09:22 pretraining_history.csv
-rw-rw-r--  1 jscheen jscheen  20900 Dec  3 09:22 pretraining_history_plot.png
-rw-rw-r--  1 jscheen jscheen  16858 Oct 27 09:40 pretraining_stdout.out
drwxr-xr-x  2 jscheen jscheen   4096 Dec  3 10:30 trained_model_weights/
-rw-rw-r--  1 jscheen jscheen  11507 Dec  3 10:03 training_history_finetuned_0.csv
-rw-rw-r--  1 jscheen jscheen  12343 Dec  3 10:08 training_history_finetuned_1.csv
-rw-rw-r--  1 jscheen jscheen  19198 Dec  3 10:14 training_history_finetuned_2.csv
-rw-rw-r--  1 jscheen jscheen  22038 Dec  3 10:21 training_history_finetuned_3.csv
-rw-rw-r--  1 jscheen jscheen  14980 Dec  3 10:30 training_history_finetuned_4.csv
-rw-rw-r--  1 jscheen jscheen  21865 Oct 27 16:40 training_history_finetuned_5.csv
-rw-rw-r--  1 jscheen jscheen  16543 Oct 27 16:46 training_history_finetuned_6.csv
-rw-rw-r--  1 jscheen jscheen  26966 Oct 27 16:56 training_history_finetuned_7.csv
-rw-rw-r--  1 jscheen jscheen  11359 Oct 27 17:01 training_history_finetuned_8.csv
-rw-rw-r--  1 jscheen jscheen  17930 Oct 27 17:08 training_history_finetuned_9.csv
-rw-rw-r--  1 jscheen jscheen  46001 Dec  3 10:03 training_history_plot_finetuned_0.png
-rw-rw-r--  1 jscheen jscheen  52085 Dec  3 10:08 training_history_plot_finetuned_1.png
-rw-rw-r--  1 jscheen jscheen  56560 Dec  3 10:14 training_history_plot_finetuned_2.png
-rw-rw-r--  1 jscheen jscheen  46833 Dec  3 10:21 training_history_plot_finetuned_3.png
-rw-rw-r--  1 jscheen jscheen  47806 Dec  3 10:30 training_history_plot_finetuned_4.png
-rw-rw-r--  1 jscheen jscheen  55903 Oct 27 16:40 training_history_plot_finetuned_5.png
-rw-rw-r--  1 jscheen jscheen  50505 Oct 27 16:46 training_history_plot_finetuned_6.png
-rw-rw-r--  1 jscheen jscheen  62582 Oct 27 16:56 training_history_plot_finetuned_7.png
-rw-rw-r--  1 jscheen jscheen  45583 Oct 27 17:01 training_history_plot_finetuned_8.png
-rw-rw-r--  1 jscheen jscheen  56195 Oct 27 17:08 training_history_plot_finetuned_9.png
-rw-rw-r--  1 jscheen jscheen  58665 Dec  3 10:00 training_history_plot_transfer_0.png
-rw-rw-r--  1 jscheen jscheen  56843 Dec  3 10:05 training_history_plot_transfer_1.png
-rw-rw-r--  1 jscheen jscheen  43829 Dec  3 10:10 training_history_plot_transfer_2.png
-rw-rw-r--  1 jscheen jscheen  52865 Dec  3 10:16 training_history_plot_transfer_3.png
-rw-rw-r--  1 jscheen jscheen  55415 Dec  3 10:26 training_history_plot_transfer_4.png
-rw-rw-r--  1 jscheen jscheen  61708 Oct 27 16:35 training_history_plot_transfer_5.png
-rw-rw-r--  1 jscheen jscheen  57948 Oct 27 16:42 training_history_plot_transfer_6.png
-rw-rw-r--  1 jscheen jscheen  56131 Oct 27 16:49 training_history_plot_transfer_7.png
-rw-rw-r--  1 jscheen jscheen  58186 Oct 27 16:58 training_history_plot_transfer_8.png
-rw-rw-r--  1 jscheen jscheen  58175 Oct 27 17:04 training_history_plot_transfer_9.png
-rw-rw-r--  1 jscheen jscheen  28951 Dec  3 10:00 training_history_transfer_0.csv
-rw-rw-r--  1 jscheen jscheen  13251 Dec  3 10:05 training_history_transfer_1.csv
-rw-rw-r--  1 jscheen jscheen  12238 Dec  3 10:10 training_history_transfer_2.csv
-rw-rw-r--  1 jscheen jscheen  11001 Dec  3 10:16 training_history_transfer_3.csv
-rw-rw-r--  1 jscheen jscheen  31336 Dec  3 10:26 training_history_transfer_4.csv
-rw-rw-r--  1 jscheen jscheen 498080 Oct 27 17:08 transferlearning_stdout.out
-rw-rw-r--  1 jscheen jscheen 170191 Dec  2 23:15 twin_model.png
-rw-rw-r--  1 jscheen jscheen     72 Nov 30 09:37 walltime_ml_pred_per_tgt.csv
(data_driven_fep_rel) jscheen@yoko:process$ for i in {5..9}; do rm training_history_plot_transfer_$i.png; done
(data_driven_fep_rel) jscheen@yoko:process$ for i in {5..9}; do rm training_history_plot_finetuned_$i.png; done
(data_driven_fep_rel) jscheen@yoko:process$ ll
total 1732
drwxrwxr-x  6 jscheen jscheen   4096 Dec  3 10:34 ./
drwxrwxr-x 10 jscheen jscheen   4096 Dec  3 10:33 ../
drwxrwxr-x  2 jscheen jscheen   4096 Dec  2 11:50 base_models/
-rw-rw-r--  1 jscheen jscheen 174348 Dec  3 09:47 fepspace_smiles_per_sem.csv
drwxrwxr-x  2 jscheen jscheen   4096 Oct 19 22:00 inputs/
drwxrwxr-x  4 jscheen jscheen   4096 Nov 30 15:25 lomap/
-rw-rw-r--  1 jscheen jscheen   8710 Dec  3 09:22 pretraining_history.csv
-rw-rw-r--  1 jscheen jscheen  20900 Dec  3 09:22 pretraining_history_plot.png
-rw-rw-r--  1 jscheen jscheen  16858 Oct 27 09:40 pretraining_stdout.out
drwxr-xr-x  2 jscheen jscheen   4096 Dec  3 10:30 trained_model_weights/
-rw-rw-r--  1 jscheen jscheen  11507 Dec  3 10:03 training_history_finetuned_0.csv
-rw-rw-r--  1 jscheen jscheen  12343 Dec  3 10:08 training_history_finetuned_1.csv
-rw-rw-r--  1 jscheen jscheen  19198 Dec  3 10:14 training_history_finetuned_2.csv
-rw-rw-r--  1 jscheen jscheen  22038 Dec  3 10:21 training_history_finetuned_3.csv
-rw-rw-r--  1 jscheen jscheen  14980 Dec  3 10:30 training_history_finetuned_4.csv
-rw-rw-r--  1 jscheen jscheen  21865 Oct 27 16:40 training_history_finetuned_5.csv
-rw-rw-r--  1 jscheen jscheen  16543 Oct 27 16:46 training_history_finetuned_6.csv
-rw-rw-r--  1 jscheen jscheen  26966 Oct 27 16:56 training_history_finetuned_7.csv
-rw-rw-r--  1 jscheen jscheen  11359 Oct 27 17:01 training_history_finetuned_8.csv
-rw-rw-r--  1 jscheen jscheen  17930 Oct 27 17:08 training_history_finetuned_9.csv
-rw-rw-r--  1 jscheen jscheen  46001 Dec  3 10:03 training_history_plot_finetuned_0.png
-rw-rw-r--  1 jscheen jscheen  52085 Dec  3 10:08 training_history_plot_finetuned_1.png
-rw-rw-r--  1 jscheen jscheen  56560 Dec  3 10:14 training_history_plot_finetuned_2.png
-rw-rw-r--  1 jscheen jscheen  46833 Dec  3 10:21 training_history_plot_finetuned_3.png
-rw-rw-r--  1 jscheen jscheen  47806 Dec  3 10:30 training_history_plot_finetuned_4.png
-rw-rw-r--  1 jscheen jscheen  58665 Dec  3 10:00 training_history_plot_transfer_0.png
-rw-rw-r--  1 jscheen jscheen  56843 Dec  3 10:05 training_history_plot_transfer_1.png
-rw-rw-r--  1 jscheen jscheen  43829 Dec  3 10:10 training_history_plot_transfer_2.png
-rw-rw-r--  1 jscheen jscheen  52865 Dec  3 10:16 training_history_plot_transfer_3.png
-rw-rw-r--  1 jscheen jscheen  55415 Dec  3 10:26 training_history_plot_transfer_4.png
-rw-rw-r--  1 jscheen jscheen  28951 Dec  3 10:00 training_history_transfer_0.csv
-rw-rw-r--  1 jscheen jscheen  13251 Dec  3 10:05 training_history_transfer_1.csv
-rw-rw-r--  1 jscheen jscheen  12238 Dec  3 10:10 training_history_transfer_2.csv
-rw-rw-r--  1 jscheen jscheen  11001 Dec  3 10:16 training_history_transfer_3.csv
-rw-rw-r--  1 jscheen jscheen  31336 Dec  3 10:26 training_history_transfer_4.csv
-rw-rw-r--  1 jscheen jscheen 498080 Oct 27 17:08 transferlearning_stdout.out
-rw-rw-r--  1 jscheen jscheen 170191 Dec  2 23:15 twin_model.png
-rw-rw-r--  1 jscheen jscheen     72 Nov 30 09:37 walltime_ml_pred_per_tgt.csv
(data_driven_fep_rel) jscheen@yoko:process$ for i in {5..9}; do rm training_history_finetuned_$i.csv; done
(data_driven_fep_rel) jscheen@yoko:process$ ll
total 1628
drwxrwxr-x  6 jscheen jscheen   4096 Dec  3 10:34 ./
drwxrwxr-x 10 jscheen jscheen   4096 Dec  3 10:33 ../
drwxrwxr-x  2 jscheen jscheen   4096 Dec  2 11:50 base_models/
-rw-rw-r--  1 jscheen jscheen 174348 Dec  3 09:47 fepspace_smiles_per_sem.csv
drwxrwxr-x  2 jscheen jscheen   4096 Oct 19 22:00 inputs/
drwxrwxr-x  4 jscheen jscheen   4096 Nov 30 15:25 lomap/
-rw-rw-r--  1 jscheen jscheen   8710 Dec  3 09:22 pretraining_history.csv
-rw-rw-r--  1 jscheen jscheen  20900 Dec  3 09:22 pretraining_history_plot.png
-rw-rw-r--  1 jscheen jscheen  16858 Oct 27 09:40 pretraining_stdout.out
drwxr-xr-x  2 jscheen jscheen   4096 Dec  3 10:30 trained_model_weights/
-rw-rw-r--  1 jscheen jscheen  11507 Dec  3 10:03 training_history_finetuned_0.csv
-rw-rw-r--  1 jscheen jscheen  12343 Dec  3 10:08 training_history_finetuned_1.csv
-rw-rw-r--  1 jscheen jscheen  19198 Dec  3 10:14 training_history_finetuned_2.csv
-rw-rw-r--  1 jscheen jscheen  22038 Dec  3 10:21 training_history_finetuned_3.csv
-rw-rw-r--  1 jscheen jscheen  14980 Dec  3 10:30 training_history_finetuned_4.csv
-rw-rw-r--  1 jscheen jscheen  46001 Dec  3 10:03 training_history_plot_finetuned_0.png
-rw-rw-r--  1 jscheen jscheen  52085 Dec  3 10:08 training_history_plot_finetuned_1.png
-rw-rw-r--  1 jscheen jscheen  56560 Dec  3 10:14 training_history_plot_finetuned_2.png
-rw-rw-r--  1 jscheen jscheen  46833 Dec  3 10:21 training_history_plot_finetuned_3.png
-rw-rw-r--  1 jscheen jscheen  47806 Dec  3 10:30 training_history_plot_finetuned_4.png
-rw-rw-r--  1 jscheen jscheen  58665 Dec  3 10:00 training_history_plot_transfer_0.png
-rw-rw-r--  1 jscheen jscheen  56843 Dec  3 10:05 training_history_plot_transfer_1.png
-rw-rw-r--  1 jscheen jscheen  43829 Dec  3 10:10 training_history_plot_transfer_2.png
-rw-rw-r--  1 jscheen jscheen  52865 Dec  3 10:16 training_history_plot_transfer_3.png
-rw-rw-r--  1 jscheen jscheen  55415 Dec  3 10:26 training_history_plot_transfer_4.png
-rw-rw-r--  1 jscheen jscheen  28951 Dec  3 10:00 training_history_transfer_0.csv
-rw-rw-r--  1 jscheen jscheen  13251 Dec  3 10:05 training_history_transfer_1.csv
-rw-rw-r--  1 jscheen jscheen  12238 Dec  3 10:10 training_history_transfer_2.csv
-rw-rw-r--  1 jscheen jscheen  11001 Dec  3 10:16 training_history_transfer_3.csv
-rw-rw-r--  1 jscheen jscheen  31336 Dec  3 10:26 training_history_transfer_4.csv
-rw-rw-r--  1 jscheen jscheen 498080 Oct 27 17:08 transferlearning_stdout.out
-rw-rw-r--  1 jscheen jscheen 170191 Dec  2 23:15 twin_model.png
-rw-rw-r--  1 jscheen jscheen     72 Nov 30 09:37 walltime_ml_pred_per_tgt.csv
(data_driven_fep_rel) jscheen@yoko:process$ cat transferlearning_stdout.out 
Writing FEP-Space results..
Found 2286 SMILES references; unable to find 17.
Written file: process/fepspace_smiles_per_sem.csv
Retrieving FEP atom-mappings..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 0

Generating graphs from SMILES..

Setting up training set.
Size: 2057

Setting up validation set.
Size: 229

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing (MessagePassing (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding (PartitionPad (None, None, 64)     0           message_passing[0][0]            
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing[1][0]            
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking (Masking)               (None, None, 64)     0           partition_padding[0][0]          
                                                                 partition_padding[1][0]          
__________________________________________________________________________________________________
transformer_encoder (Transforme (None, None, 64)     199040      masking[0][0]                    
                                                                 masking[1][0]                    
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 64)           0           transformer_encoder[0][0]        
                                                                 transformer_encoder[1][0]        
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 512)          33280       global_average_pooling1d[0][0]   
                                                                 global_average_pooling1d[1][0]   
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 10)           110         dense_4[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 450)          230850      dense_2[0][0]                    
                                                                 dense_2[1][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 5)            55          dense_5[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 905)          0           dense_3[0][0]                    
                                                                 dense_3[1][0]                    
                                                                 dense_6[0][0]                    
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 700)          634200      concatenate[0][0]                
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 560)          392560      dense_7[0][0]                    
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 373)          209253      dense_11[0][0]                   
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 187)          69938       dense_12[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1)            188         dense_13[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
41/41 - 6s - loss: 0.2980 - mae: 0.6096 - val_loss: 0.1341 - val_mae: 0.4434
Epoch 2/5000
41/41 - 1s - loss: 0.1681 - mae: 0.4121 - val_loss: 0.1212 - val_mae: 0.4015
Epoch 3/5000
41/41 - 1s - loss: 0.1661 - mae: 0.4075 - val_loss: 0.1295 - val_mae: 0.4308
Epoch 4/5000
41/41 - 1s - loss: 0.1660 - mae: 0.4069 - val_loss: 0.1276 - val_mae: 0.4247
Epoch 5/5000
41/41 - 1s - loss: 0.1655 - mae: 0.4059 - val_loss: 0.1284 - val_mae: 0.4302
Epoch 6/5000
41/41 - 1s - loss: 0.1642 - mae: 0.4031 - val_loss: 0.1267 - val_mae: 0.4219
Epoch 7/5000
41/41 - 1s - loss: 0.1637 - mae: 0.4022 - val_loss: 0.1278 - val_mae: 0.4306
Epoch 8/5000
41/41 - 1s - loss: 0.1633 - mae: 0.4012 - val_loss: 0.1238 - val_mae: 0.4175
Epoch 9/5000
41/41 - 1s - loss: 0.1617 - mae: 0.3979 - val_loss: 0.1180 - val_mae: 0.3940
Epoch 10/5000
41/41 - 1s - loss: 0.1606 - mae: 0.3973 - val_loss: 0.1150 - val_mae: 0.3849
Epoch 11/5000
41/41 - 1s - loss: 0.1590 - mae: 0.3921 - val_loss: 0.1241 - val_mae: 0.4205
Epoch 12/5000
41/41 - 1s - loss: 0.1592 - mae: 0.3929 - val_loss: 0.1221 - val_mae: 0.4162
Epoch 13/5000
41/41 - 1s - loss: 0.1571 - mae: 0.3890 - val_loss: 0.1119 - val_mae: 0.3730
Epoch 14/5000
41/41 - 1s - loss: 0.1546 - mae: 0.3836 - val_loss: 0.1097 - val_mae: 0.3581
Epoch 15/5000
41/41 - 1s - loss: 0.1567 - mae: 0.3840 - val_loss: 0.1074 - val_mae: 0.3458
Epoch 16/5000
41/41 - 1s - loss: 0.1538 - mae: 0.3799 - val_loss: 0.1056 - val_mae: 0.3262
Epoch 17/5000
41/41 - 1s - loss: 0.1535 - mae: 0.3773 - val_loss: 0.1056 - val_mae: 0.3474
Epoch 18/5000
41/41 - 1s - loss: 0.1531 - mae: 0.3762 - val_loss: 0.1036 - val_mae: 0.3325
Epoch 19/5000
41/41 - 1s - loss: 0.1523 - mae: 0.3747 - val_loss: 0.1043 - val_mae: 0.3466
Epoch 20/5000
41/41 - 1s - loss: 0.1516 - mae: 0.3725 - val_loss: 0.1056 - val_mae: 0.3577
Epoch 21/5000
41/41 - 1s - loss: 0.1508 - mae: 0.3715 - val_loss: 0.1022 - val_mae: 0.3388
Epoch 22/5000
41/41 - 1s - loss: 0.1505 - mae: 0.3700 - val_loss: 0.1031 - val_mae: 0.3484
Epoch 23/5000
41/41 - 1s - loss: 0.1503 - mae: 0.3733 - val_loss: 0.1031 - val_mae: 0.3067
Epoch 24/5000
41/41 - 1s - loss: 0.1489 - mae: 0.3670 - val_loss: 0.0982 - val_mae: 0.3230
Epoch 25/5000
41/41 - 1s - loss: 0.1479 - mae: 0.3645 - val_loss: 0.0993 - val_mae: 0.3105
Epoch 26/5000
41/41 - 1s - loss: 0.1481 - mae: 0.3648 - val_loss: 0.1009 - val_mae: 0.3460
Epoch 27/5000
41/41 - 1s - loss: 0.1465 - mae: 0.3629 - val_loss: 0.0990 - val_mae: 0.3368
Epoch 28/5000
41/41 - 1s - loss: 0.1457 - mae: 0.3586 - val_loss: 0.0951 - val_mae: 0.3105
Epoch 29/5000
41/41 - 1s - loss: 0.1449 - mae: 0.3570 - val_loss: 0.0980 - val_mae: 0.3020
Epoch 30/5000
41/41 - 1s - loss: 0.1466 - mae: 0.3623 - val_loss: 0.0968 - val_mae: 0.2933
Epoch 31/5000
41/41 - 1s - loss: 0.1473 - mae: 0.3611 - val_loss: 0.1076 - val_mae: 0.3716
Epoch 32/5000
41/41 - 1s - loss: 0.1472 - mae: 0.3647 - val_loss: 0.0987 - val_mae: 0.2956
Epoch 33/5000
41/41 - 1s - loss: 0.1449 - mae: 0.3575 - val_loss: 0.0943 - val_mae: 0.3086
Epoch 34/5000
41/41 - 1s - loss: 0.1455 - mae: 0.3583 - val_loss: 0.1171 - val_mae: 0.4131
Epoch 35/5000
41/41 - 1s - loss: 0.1459 - mae: 0.3618 - val_loss: 0.0943 - val_mae: 0.3028
Epoch 36/5000
41/41 - 1s - loss: 0.1438 - mae: 0.3541 - val_loss: 0.1016 - val_mae: 0.3579
Epoch 37/5000
41/41 - 1s - loss: 0.1451 - mae: 0.3576 - val_loss: 0.1006 - val_mae: 0.3517
Epoch 38/5000
41/41 - 1s - loss: 0.1415 - mae: 0.3501 - val_loss: 0.0946 - val_mae: 0.3214
Epoch 39/5000
41/41 - 1s - loss: 0.1396 - mae: 0.3441 - val_loss: 0.0940 - val_mae: 0.2934
Epoch 40/5000
41/41 - 1s - loss: 0.1432 - mae: 0.3522 - val_loss: 0.0977 - val_mae: 0.3419
Epoch 41/5000
41/41 - 1s - loss: 0.1430 - mae: 0.3499 - val_loss: 0.1040 - val_mae: 0.3689
Epoch 42/5000
41/41 - 1s - loss: 0.1429 - mae: 0.3523 - val_loss: 0.0929 - val_mae: 0.3033
Epoch 43/5000
41/41 - 1s - loss: 0.1401 - mae: 0.3450 - val_loss: 0.0911 - val_mae: 0.2916
Epoch 44/5000
41/41 - 1s - loss: 0.1381 - mae: 0.3399 - val_loss: 0.0915 - val_mae: 0.3002
Epoch 45/5000
41/41 - 1s - loss: 0.1430 - mae: 0.3493 - val_loss: 0.1163 - val_mae: 0.4122
Epoch 46/5000
41/41 - 1s - loss: 0.1379 - mae: 0.3414 - val_loss: 0.0898 - val_mae: 0.2844
Epoch 47/5000
41/41 - 1s - loss: 0.1416 - mae: 0.3469 - val_loss: 0.0908 - val_mae: 0.2980
Epoch 48/5000
41/41 - 1s - loss: 0.1406 - mae: 0.3430 - val_loss: 0.1212 - val_mae: 0.4251
Epoch 49/5000
41/41 - 1s - loss: 0.1432 - mae: 0.3524 - val_loss: 0.1188 - val_mae: 0.4136
Epoch 50/5000
41/41 - 1s - loss: 0.1421 - mae: 0.3504 - val_loss: 0.1038 - val_mae: 0.3674
Epoch 51/5000
41/41 - 1s - loss: 0.1395 - mae: 0.3437 - val_loss: 0.0971 - val_mae: 0.3425
Epoch 52/5000
41/41 - 1s - loss: 0.1358 - mae: 0.3354 - val_loss: 0.0937 - val_mae: 0.3238
Epoch 53/5000
41/41 - 1s - loss: 0.1376 - mae: 0.3351 - val_loss: 0.1196 - val_mae: 0.4181
Epoch 54/5000
41/41 - 1s - loss: 0.1413 - mae: 0.3477 - val_loss: 0.1141 - val_mae: 0.4005
Epoch 55/5000
41/41 - 1s - loss: 0.1378 - mae: 0.3418 - val_loss: 0.0913 - val_mae: 0.3102
Epoch 56/5000
41/41 - 1s - loss: 0.1376 - mae: 0.3350 - val_loss: 0.1231 - val_mae: 0.4292
Epoch 57/5000
41/41 - 1s - loss: 0.1422 - mae: 0.3506 - val_loss: 0.1073 - val_mae: 0.3771
Epoch 58/5000
41/41 - 1s - loss: 0.1394 - mae: 0.3422 - val_loss: 0.1193 - val_mae: 0.4095
Epoch 59/5000
41/41 - 1s - loss: 0.1394 - mae: 0.3422 - val_loss: 0.1305 - val_mae: 0.4378
Epoch 60/5000
41/41 - 1s - loss: 0.1403 - mae: 0.3462 - val_loss: 0.0993 - val_mae: 0.3393
Epoch 61/5000
41/41 - 1s - loss: 0.1337 - mae: 0.3303 - val_loss: 0.0895 - val_mae: 0.2925
Epoch 62/5000
41/41 - 1s - loss: 0.1338 - mae: 0.3279 - val_loss: 0.0953 - val_mae: 0.3310
Epoch 63/5000
41/41 - 1s - loss: 0.1343 - mae: 0.3300 - val_loss: 0.0990 - val_mae: 0.3444
Epoch 64/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3294 - val_loss: 0.1206 - val_mae: 0.4203
Epoch 65/5000
41/41 - 1s - loss: 0.1355 - mae: 0.3349 - val_loss: 0.0912 - val_mae: 0.3031
Epoch 66/5000
41/41 - 1s - loss: 0.1332 - mae: 0.3282 - val_loss: 0.0908 - val_mae: 0.3050
Epoch 67/5000
41/41 - 1s - loss: 0.1357 - mae: 0.3302 - val_loss: 0.1272 - val_mae: 0.4326
Epoch 68/5000
41/41 - 1s - loss: 0.1394 - mae: 0.3436 - val_loss: 0.1306 - val_mae: 0.4426
Epoch 69/5000
41/41 - 1s - loss: 0.1409 - mae: 0.3458 - val_loss: 0.1223 - val_mae: 0.4146
Epoch 70/5000
41/41 - 1s - loss: 0.1378 - mae: 0.3392 - val_loss: 0.1190 - val_mae: 0.4115
Epoch 71/5000
41/41 - 1s - loss: 0.1371 - mae: 0.3375 - val_loss: 0.1288 - val_mae: 0.4318
Epoch 72/5000
41/41 - 1s - loss: 0.1377 - mae: 0.3383 - val_loss: 0.1196 - val_mae: 0.4068
Epoch 73/5000
41/41 - 1s - loss: 0.1370 - mae: 0.3366 - val_loss: 0.1206 - val_mae: 0.4076
Epoch 74/5000
41/41 - 1s - loss: 0.1339 - mae: 0.3303 - val_loss: 0.0978 - val_mae: 0.3406
Epoch 75/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3270 - val_loss: 0.1005 - val_mae: 0.3380
Epoch 76/5000
41/41 - 1s - loss: 0.1322 - mae: 0.3256 - val_loss: 0.0964 - val_mae: 0.3322
Epoch 77/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3271 - val_loss: 0.1025 - val_mae: 0.3459
Epoch 78/5000
41/41 - 1s - loss: 0.1324 - mae: 0.3269 - val_loss: 0.0925 - val_mae: 0.3070
Epoch 79/5000
41/41 - 1s - loss: 0.1331 - mae: 0.3248 - val_loss: 0.1277 - val_mae: 0.4282
Epoch 80/5000
41/41 - 1s - loss: 0.1355 - mae: 0.3359 - val_loss: 0.0954 - val_mae: 0.3343
Epoch 81/5000
41/41 - 1s - loss: 0.1330 - mae: 0.3264 - val_loss: 0.1287 - val_mae: 0.4239
Epoch 82/5000
41/41 - 1s - loss: 0.1370 - mae: 0.3365 - val_loss: 0.1226 - val_mae: 0.4171
Epoch 83/5000
41/41 - 1s - loss: 0.1364 - mae: 0.3358 - val_loss: 0.1335 - val_mae: 0.4412
Epoch 84/5000
41/41 - 1s - loss: 0.1374 - mae: 0.3394 - val_loss: 0.1290 - val_mae: 0.4317
Epoch 85/5000
41/41 - 1s - loss: 0.1369 - mae: 0.3357 - val_loss: 0.1219 - val_mae: 0.4097
Epoch 86/5000
41/41 - 1s - loss: 0.1340 - mae: 0.3292 - val_loss: 0.1223 - val_mae: 0.4107
Epoch 87/5000
41/41 - 1s - loss: 0.1331 - mae: 0.3275 - val_loss: 0.1155 - val_mae: 0.3930
Epoch 88/5000
41/41 - 1s - loss: 0.1325 - mae: 0.3253 - val_loss: 0.1362 - val_mae: 0.4423
Epoch 89/5000
41/41 - 1s - loss: 0.1376 - mae: 0.3362 - val_loss: 0.1176 - val_mae: 0.4065
Epoch 90/5000
41/41 - 1s - loss: 0.1394 - mae: 0.3454 - val_loss: 0.1080 - val_mae: 0.3775
Epoch 91/5000
41/41 - 1s - loss: 0.1319 - mae: 0.3266 - val_loss: 0.1138 - val_mae: 0.3894
Epoch 92/5000
41/41 - 1s - loss: 0.1320 - mae: 0.3250 - val_loss: 0.1219 - val_mae: 0.4070
Epoch 93/5000
41/41 - 1s - loss: 0.1331 - mae: 0.3265 - val_loss: 0.1306 - val_mae: 0.4277
Epoch 94/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3304 - val_loss: 0.1203 - val_mae: 0.4065
Epoch 95/5000
41/41 - 1s - loss: 0.1354 - mae: 0.3303 - val_loss: 0.1165 - val_mae: 0.3971
Epoch 96/5000
41/41 - 1s - loss: 0.1355 - mae: 0.3322 - val_loss: 0.1150 - val_mae: 0.3905
Epoch 97/5000
41/41 - 1s - loss: 0.1341 - mae: 0.3283 - val_loss: 0.1239 - val_mae: 0.4123
Epoch 98/5000
41/41 - 1s - loss: 0.1343 - mae: 0.3282 - val_loss: 0.1208 - val_mae: 0.4037
Epoch 99/5000
41/41 - 1s - loss: 0.1349 - mae: 0.3315 - val_loss: 0.1089 - val_mae: 0.3710
Epoch 100/5000
41/41 - 1s - loss: 0.1325 - mae: 0.3249 - val_loss: 0.1305 - val_mae: 0.4245
Epoch 101/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3318 - val_loss: 0.1084 - val_mae: 0.3731
Epoch 102/5000
41/41 - 1s - loss: 0.1332 - mae: 0.3262 - val_loss: 0.1193 - val_mae: 0.4033
Epoch 103/5000
41/41 - 1s - loss: 0.1320 - mae: 0.3240 - val_loss: 0.1205 - val_mae: 0.4067
Epoch 104/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3326 - val_loss: 0.1216 - val_mae: 0.4116
Epoch 105/5000
41/41 - 1s - loss: 0.1360 - mae: 0.3350 - val_loss: 0.1114 - val_mae: 0.3908
Epoch 106/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3364 - val_loss: 0.0900 - val_mae: 0.2991
Epoch 107/5000
41/41 - 1s - loss: 0.1315 - mae: 0.3242 - val_loss: 0.1008 - val_mae: 0.3460
Epoch 108/5000
41/41 - 1s - loss: 0.1292 - mae: 0.3195 - val_loss: 0.1077 - val_mae: 0.3594
Epoch 109/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3198 - val_loss: 0.1274 - val_mae: 0.4190
Epoch 110/5000
41/41 - 1s - loss: 0.1319 - mae: 0.3247 - val_loss: 0.1328 - val_mae: 0.4264
Epoch 111/5000
41/41 - 1s - loss: 0.1353 - mae: 0.3318 - val_loss: 0.1283 - val_mae: 0.4253
Epoch 112/5000
41/41 - 1s - loss: 0.1363 - mae: 0.3394 - val_loss: 0.1114 - val_mae: 0.3697
Epoch 113/5000
41/41 - 1s - loss: 0.1302 - mae: 0.3208 - val_loss: 0.1201 - val_mae: 0.3992
Epoch 114/5000
41/41 - 1s - loss: 0.1326 - mae: 0.3261 - val_loss: 0.1299 - val_mae: 0.4206
Epoch 115/5000
41/41 - 1s - loss: 0.1336 - mae: 0.3272 - val_loss: 0.1298 - val_mae: 0.4231
Epoch 116/5000
41/41 - 1s - loss: 0.1351 - mae: 0.3356 - val_loss: 0.1058 - val_mae: 0.3556
Epoch 117/5000
41/41 - 1s - loss: 0.1291 - mae: 0.3187 - val_loss: 0.1281 - val_mae: 0.4143
Epoch 118/5000
41/41 - 1s - loss: 0.1316 - mae: 0.3221 - val_loss: 0.1349 - val_mae: 0.4354
Epoch 119/5000
41/41 - 1s - loss: 0.1385 - mae: 0.3422 - val_loss: 0.1193 - val_mae: 0.4023
Epoch 120/5000
41/41 - 1s - loss: 0.1326 - mae: 0.3294 - val_loss: 0.1178 - val_mae: 0.3914
Epoch 121/5000
41/41 - 1s - loss: 0.1319 - mae: 0.3228 - val_loss: 0.1279 - val_mae: 0.4174
Epoch 122/5000
41/41 - 1s - loss: 0.1342 - mae: 0.3348 - val_loss: 0.1178 - val_mae: 0.3826
Epoch 123/5000
41/41 - 1s - loss: 0.1320 - mae: 0.3244 - val_loss: 0.1272 - val_mae: 0.4133
Epoch 124/5000
41/41 - 1s - loss: 0.1338 - mae: 0.3323 - val_loss: 0.1137 - val_mae: 0.3810
Epoch 125/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3255 - val_loss: 0.1014 - val_mae: 0.3446
Epoch 126/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3204 - val_loss: 0.1163 - val_mae: 0.3885
Epoch 127/5000
41/41 - 1s - loss: 0.1314 - mae: 0.3223 - val_loss: 0.1092 - val_mae: 0.3718
Epoch 128/5000
41/41 - 1s - loss: 0.1330 - mae: 0.3303 - val_loss: 0.1166 - val_mae: 0.3875
Epoch 129/5000
41/41 - 1s - loss: 0.1324 - mae: 0.3256 - val_loss: 0.1168 - val_mae: 0.3961
Epoch 130/5000
41/41 - 1s - loss: 0.1321 - mae: 0.3272 - val_loss: 0.1207 - val_mae: 0.3887
Epoch 131/5000
41/41 - 1s - loss: 0.1314 - mae: 0.3230 - val_loss: 0.1174 - val_mae: 0.3917
Epoch 132/5000
41/41 - 1s - loss: 0.1305 - mae: 0.3216 - val_loss: 0.1145 - val_mae: 0.3718
Epoch 133/5000
41/41 - 1s - loss: 0.1299 - mae: 0.3197 - val_loss: 0.1127 - val_mae: 0.3732
Epoch 134/5000
41/41 - 1s - loss: 0.1315 - mae: 0.3259 - val_loss: 0.1020 - val_mae: 0.3359
Epoch 135/5000
41/41 - 1s - loss: 0.1286 - mae: 0.3153 - val_loss: 0.1144 - val_mae: 0.3826
Epoch 136/5000
41/41 - 1s - loss: 0.1305 - mae: 0.3227 - val_loss: 0.1087 - val_mae: 0.3624
Epoch 137/5000
41/41 - 1s - loss: 0.1286 - mae: 0.3150 - val_loss: 0.1140 - val_mae: 0.3767
Epoch 138/5000
41/41 - 1s - loss: 0.1294 - mae: 0.3184 - val_loss: 0.1137 - val_mae: 0.3778
Epoch 139/5000
41/41 - 1s - loss: 0.1310 - mae: 0.3231 - val_loss: 0.1154 - val_mae: 0.3754
Epoch 140/5000
41/41 - 1s - loss: 0.1291 - mae: 0.3192 - val_loss: 0.1132 - val_mae: 0.3685
Epoch 141/5000
41/41 - 1s - loss: 0.1280 - mae: 0.3142 - val_loss: 0.1227 - val_mae: 0.4001
Epoch 142/5000
41/41 - 1s - loss: 0.1306 - mae: 0.3248 - val_loss: 0.1144 - val_mae: 0.3666
Epoch 143/5000
41/41 - 1s - loss: 0.1274 - mae: 0.3147 - val_loss: 0.1199 - val_mae: 0.3849
Epoch 144/5000
41/41 - 1s - loss: 0.1294 - mae: 0.3181 - val_loss: 0.1153 - val_mae: 0.3793
Epoch 145/5000
41/41 - 1s - loss: 0.1283 - mae: 0.3157 - val_loss: 0.1101 - val_mae: 0.3596
Epoch 146/5000
41/41 - 1s - loss: 0.1291 - mae: 0.3167 - val_loss: 0.1019 - val_mae: 0.3348
Epoch 147/5000
41/41 - 1s - loss: 0.1273 - mae: 0.3121 - val_loss: 0.1055 - val_mae: 0.3432
Restoring model weights from the end of the best epoch.
Epoch 00147: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_0..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing (MessagePassing (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding (PartitionPad (None, None, 64)     0           message_passing[0][0]            
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing[1][0]            
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking (Masking)               (None, None, 64)     0           partition_padding[0][0]          
                                                                 partition_padding[1][0]          
__________________________________________________________________________________________________
transformer_encoder (Transforme (None, None, 64)     199040      masking[0][0]                    
                                                                 masking[1][0]                    
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 64)           0           transformer_encoder[0][0]        
                                                                 transformer_encoder[1][0]        
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 512)          33280       global_average_pooling1d[0][0]   
                                                                 global_average_pooling1d[1][0]   
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 10)           110         dense_4[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 450)          230850      dense_2[0][0]                    
                                                                 dense_2[1][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 5)            55          dense_5[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 905)          0           dense_3[0][0]                    
                                                                 dense_3[1][0]                    
                                                                 dense_6[0][0]                    
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 700)          634200      concatenate[0][0]                
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 560)          392560      dense_7[0][0]                    
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 373)          209253      dense_11[0][0]                   
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 187)          69938       dense_12[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1)            188         dense_13[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
41/41 - 6s - loss: 0.1399 - mae: 0.3425 - val_loss: 0.0895 - val_mae: 0.3078
Epoch 2/5000
41/41 - 1s - loss: 0.1272 - mae: 0.3143 - val_loss: 0.0858 - val_mae: 0.3056
Epoch 3/5000
41/41 - 1s - loss: 0.1227 - mae: 0.3031 - val_loss: 0.0896 - val_mae: 0.3180
Epoch 4/5000
41/41 - 1s - loss: 0.1197 - mae: 0.2962 - val_loss: 0.0896 - val_mae: 0.3164
Epoch 5/5000
41/41 - 1s - loss: 0.1166 - mae: 0.2892 - val_loss: 0.0898 - val_mae: 0.3185
Epoch 6/5000
41/41 - 1s - loss: 0.1140 - mae: 0.2839 - val_loss: 0.0886 - val_mae: 0.3129
Epoch 7/5000
41/41 - 1s - loss: 0.1122 - mae: 0.2794 - val_loss: 0.0889 - val_mae: 0.3117
Epoch 8/5000
41/41 - 1s - loss: 0.1107 - mae: 0.2757 - val_loss: 0.0907 - val_mae: 0.3187
Epoch 9/5000
41/41 - 1s - loss: 0.1107 - mae: 0.2769 - val_loss: 0.0913 - val_mae: 0.3219
Epoch 10/5000
41/41 - 1s - loss: 0.1127 - mae: 0.2802 - val_loss: 0.1151 - val_mae: 0.3797
Epoch 11/5000
41/41 - 1s - loss: 0.1146 - mae: 0.2880 - val_loss: 0.0786 - val_mae: 0.2726
Epoch 12/5000
41/41 - 1s - loss: 0.1070 - mae: 0.2694 - val_loss: 0.0800 - val_mae: 0.2853
Epoch 13/5000
41/41 - 1s - loss: 0.1053 - mae: 0.2655 - val_loss: 0.0840 - val_mae: 0.2971
Epoch 14/5000
41/41 - 1s - loss: 0.1034 - mae: 0.2609 - val_loss: 0.0802 - val_mae: 0.2882
Epoch 15/5000
41/41 - 1s - loss: 0.1015 - mae: 0.2572 - val_loss: 0.0831 - val_mae: 0.2936
Epoch 16/5000
41/41 - 1s - loss: 0.0994 - mae: 0.2523 - val_loss: 0.0867 - val_mae: 0.3062
Epoch 17/5000
41/41 - 1s - loss: 0.0980 - mae: 0.2492 - val_loss: 0.0846 - val_mae: 0.2976
Epoch 18/5000
41/41 - 1s - loss: 0.0967 - mae: 0.2468 - val_loss: 0.0876 - val_mae: 0.3020
Epoch 19/5000
41/41 - 1s - loss: 0.0955 - mae: 0.2442 - val_loss: 0.0888 - val_mae: 0.2947
Epoch 20/5000
41/41 - 1s - loss: 0.0944 - mae: 0.2425 - val_loss: 0.0978 - val_mae: 0.3157
Epoch 21/5000
41/41 - 1s - loss: 0.0922 - mae: 0.2378 - val_loss: 0.1011 - val_mae: 0.3209
Epoch 22/5000
41/41 - 1s - loss: 0.0924 - mae: 0.2385 - val_loss: 0.1064 - val_mae: 0.3356
Epoch 23/5000
41/41 - 1s - loss: 0.0919 - mae: 0.2384 - val_loss: 0.1235 - val_mae: 0.3747
Epoch 24/5000
41/41 - 1s - loss: 0.0925 - mae: 0.2401 - val_loss: 0.1189 - val_mae: 0.3650
Epoch 25/5000
41/41 - 1s - loss: 0.1002 - mae: 0.2572 - val_loss: 0.0815 - val_mae: 0.2599
Epoch 26/5000
41/41 - 1s - loss: 0.1000 - mae: 0.2623 - val_loss: 0.0793 - val_mae: 0.2652
Epoch 27/5000
41/41 - 1s - loss: 0.0919 - mae: 0.2397 - val_loss: 0.0784 - val_mae: 0.2530
Epoch 28/5000
41/41 - 1s - loss: 0.0893 - mae: 0.2331 - val_loss: 0.0805 - val_mae: 0.2579
Epoch 29/5000
41/41 - 1s - loss: 0.0863 - mae: 0.2262 - val_loss: 0.0795 - val_mae: 0.2582
Epoch 30/5000
41/41 - 1s - loss: 0.0844 - mae: 0.2220 - val_loss: 0.0793 - val_mae: 0.2612
Epoch 31/5000
41/41 - 1s - loss: 0.0830 - mae: 0.2186 - val_loss: 0.0782 - val_mae: 0.2557
Epoch 32/5000
41/41 - 1s - loss: 0.0821 - mae: 0.2171 - val_loss: 0.0749 - val_mae: 0.2451
Epoch 33/5000
41/41 - 1s - loss: 0.0810 - mae: 0.2167 - val_loss: 0.0745 - val_mae: 0.2409
Epoch 34/5000
41/41 - 1s - loss: 0.0796 - mae: 0.2136 - val_loss: 0.0757 - val_mae: 0.2405
Epoch 35/5000
41/41 - 1s - loss: 0.0790 - mae: 0.2130 - val_loss: 0.0772 - val_mae: 0.2425
Epoch 36/5000
41/41 - 1s - loss: 0.0778 - mae: 0.2113 - val_loss: 0.0765 - val_mae: 0.2483
Epoch 37/5000
41/41 - 1s - loss: 0.0778 - mae: 0.2120 - val_loss: 0.0754 - val_mae: 0.2526
Epoch 38/5000
41/41 - 1s - loss: 0.0790 - mae: 0.2171 - val_loss: 0.0718 - val_mae: 0.2268
Epoch 39/5000
41/41 - 1s - loss: 0.0869 - mae: 0.2365 - val_loss: 0.0824 - val_mae: 0.2399
Epoch 40/5000
41/41 - 1s - loss: 0.0996 - mae: 0.2680 - val_loss: 0.0806 - val_mae: 0.2418
Epoch 41/5000
41/41 - 1s - loss: 0.0989 - mae: 0.2614 - val_loss: 0.0970 - val_mae: 0.3143
Epoch 42/5000
41/41 - 1s - loss: 0.0828 - mae: 0.2296 - val_loss: 0.0791 - val_mae: 0.2498
Epoch 43/5000
41/41 - 1s - loss: 0.0844 - mae: 0.2299 - val_loss: 0.0833 - val_mae: 0.2591
Epoch 44/5000
41/41 - 1s - loss: 0.0866 - mae: 0.2351 - val_loss: 0.0993 - val_mae: 0.3027
Epoch 45/5000
41/41 - 1s - loss: 0.0802 - mae: 0.2230 - val_loss: 0.1114 - val_mae: 0.3387
Epoch 46/5000
41/41 - 1s - loss: 0.0747 - mae: 0.2116 - val_loss: 0.1009 - val_mae: 0.3091
Epoch 47/5000
41/41 - 1s - loss: 0.0722 - mae: 0.2040 - val_loss: 0.0969 - val_mae: 0.3011
Epoch 48/5000
41/41 - 1s - loss: 0.0707 - mae: 0.1991 - val_loss: 0.0924 - val_mae: 0.2907
Epoch 49/5000
41/41 - 1s - loss: 0.0697 - mae: 0.1993 - val_loss: 0.1071 - val_mae: 0.3216
Epoch 50/5000
41/41 - 1s - loss: 0.0711 - mae: 0.2036 - val_loss: 0.1286 - val_mae: 0.3671
Epoch 51/5000
41/41 - 1s - loss: 0.0739 - mae: 0.2129 - val_loss: 0.1233 - val_mae: 0.3730
Epoch 52/5000
41/41 - 1s - loss: 0.0748 - mae: 0.2184 - val_loss: 0.1446 - val_mae: 0.4049
Epoch 53/5000
41/41 - 1s - loss: 0.0763 - mae: 0.2179 - val_loss: 0.1108 - val_mae: 0.3567
Epoch 54/5000
41/41 - 1s - loss: 0.0785 - mae: 0.2238 - val_loss: 0.0949 - val_mae: 0.3127
Epoch 55/5000
41/41 - 1s - loss: 0.0773 - mae: 0.2234 - val_loss: 0.0935 - val_mae: 0.2837
Epoch 56/5000
41/41 - 1s - loss: 0.0775 - mae: 0.2241 - val_loss: 0.0939 - val_mae: 0.2860
Epoch 57/5000
41/41 - 1s - loss: 0.0748 - mae: 0.2200 - val_loss: 0.1138 - val_mae: 0.3221
Epoch 58/5000
41/41 - 1s - loss: 0.0745 - mae: 0.2217 - val_loss: 0.0912 - val_mae: 0.2802
Epoch 59/5000
41/41 - 1s - loss: 0.0753 - mae: 0.2257 - val_loss: 0.0912 - val_mae: 0.2592
Epoch 60/5000
41/41 - 1s - loss: 0.0759 - mae: 0.2227 - val_loss: 0.1006 - val_mae: 0.2804
Epoch 61/5000
41/41 - 1s - loss: 0.0760 - mae: 0.2227 - val_loss: 0.0831 - val_mae: 0.2554
Epoch 62/5000
41/41 - 1s - loss: 0.0811 - mae: 0.2369 - val_loss: 0.0906 - val_mae: 0.2586
Epoch 63/5000
41/41 - 1s - loss: 0.0884 - mae: 0.2504 - val_loss: 0.0919 - val_mae: 0.2537
Epoch 64/5000
41/41 - 1s - loss: 0.0829 - mae: 0.2374 - val_loss: 0.0906 - val_mae: 0.2534
Epoch 65/5000
41/41 - 1s - loss: 0.0795 - mae: 0.2294 - val_loss: 0.0838 - val_mae: 0.2442
Epoch 66/5000
41/41 - 1s - loss: 0.0816 - mae: 0.2294 - val_loss: 0.0841 - val_mae: 0.2471
Epoch 67/5000
41/41 - 1s - loss: 0.0745 - mae: 0.2156 - val_loss: 0.0894 - val_mae: 0.2518
Epoch 68/5000
41/41 - 1s - loss: 0.0743 - mae: 0.2155 - val_loss: 0.0874 - val_mae: 0.2500
Epoch 69/5000
41/41 - 1s - loss: 0.0666 - mae: 0.1989 - val_loss: 0.0806 - val_mae: 0.2339
Epoch 70/5000
41/41 - 1s - loss: 0.0695 - mae: 0.2044 - val_loss: 0.0823 - val_mae: 0.2369
Epoch 71/5000
41/41 - 1s - loss: 0.0627 - mae: 0.1889 - val_loss: 0.0818 - val_mae: 0.2337
Epoch 72/5000
41/41 - 1s - loss: 0.0590 - mae: 0.1797 - val_loss: 0.0819 - val_mae: 0.2331
Epoch 73/5000
41/41 - 1s - loss: 0.0555 - mae: 0.1698 - val_loss: 0.0821 - val_mae: 0.2333
Epoch 74/5000
41/41 - 1s - loss: 0.0554 - mae: 0.1691 - val_loss: 0.0800 - val_mae: 0.2292
Epoch 75/5000
41/41 - 1s - loss: 0.0548 - mae: 0.1685 - val_loss: 0.0777 - val_mae: 0.2292
Epoch 76/5000
41/41 - 1s - loss: 0.0557 - mae: 0.1719 - val_loss: 0.0807 - val_mae: 0.2360
Epoch 77/5000
41/41 - 1s - loss: 0.0551 - mae: 0.1721 - val_loss: 0.0815 - val_mae: 0.2386
Epoch 78/5000
41/41 - 1s - loss: 0.0582 - mae: 0.1831 - val_loss: 0.0864 - val_mae: 0.2407
Epoch 79/5000
41/41 - 1s - loss: 0.0586 - mae: 0.1813 - val_loss: 0.0898 - val_mae: 0.2491
Epoch 80/5000
41/41 - 1s - loss: 0.0594 - mae: 0.1839 - val_loss: 0.0838 - val_mae: 0.2418
Epoch 81/5000
41/41 - 1s - loss: 0.0567 - mae: 0.1776 - val_loss: 0.0824 - val_mae: 0.2354
Epoch 82/5000
41/41 - 1s - loss: 0.0560 - mae: 0.1775 - val_loss: 0.0915 - val_mae: 0.2503
Epoch 83/5000
41/41 - 1s - loss: 0.0548 - mae: 0.1748 - val_loss: 0.0807 - val_mae: 0.2418
Epoch 84/5000
41/41 - 1s - loss: 0.0544 - mae: 0.1742 - val_loss: 0.0841 - val_mae: 0.2376
Epoch 85/5000
41/41 - 1s - loss: 0.0556 - mae: 0.1756 - val_loss: 0.0908 - val_mae: 0.2523
Epoch 86/5000
41/41 - 1s - loss: 0.0571 - mae: 0.1790 - val_loss: 0.0915 - val_mae: 0.2623
Epoch 87/5000
41/41 - 1s - loss: 0.0564 - mae: 0.1777 - val_loss: 0.0848 - val_mae: 0.2439
Epoch 88/5000
41/41 - 1s - loss: 0.0554 - mae: 0.1755 - val_loss: 0.0870 - val_mae: 0.2482
Epoch 89/5000
41/41 - 1s - loss: 0.0558 - mae: 0.1759 - val_loss: 0.0872 - val_mae: 0.2535
Epoch 90/5000
41/41 - 1s - loss: 0.0510 - mae: 0.1655 - val_loss: 0.0784 - val_mae: 0.2365
Epoch 91/5000
41/41 - 1s - loss: 0.0555 - mae: 0.1793 - val_loss: 0.0829 - val_mae: 0.2394
Epoch 92/5000
41/41 - 1s - loss: 0.0534 - mae: 0.1734 - val_loss: 0.0901 - val_mae: 0.2573
Epoch 93/5000
41/41 - 1s - loss: 0.0511 - mae: 0.1696 - val_loss: 0.0829 - val_mae: 0.2422
Epoch 94/5000
41/41 - 1s - loss: 0.0553 - mae: 0.1772 - val_loss: 0.0941 - val_mae: 0.2576
Epoch 95/5000
41/41 - 1s - loss: 0.0578 - mae: 0.1823 - val_loss: 0.0919 - val_mae: 0.2639
Epoch 96/5000
41/41 - 1s - loss: 0.0572 - mae: 0.1837 - val_loss: 0.0876 - val_mae: 0.2502
Epoch 97/5000
41/41 - 1s - loss: 0.0633 - mae: 0.1955 - val_loss: 0.0885 - val_mae: 0.2552
Epoch 98/5000
41/41 - 1s - loss: 0.0556 - mae: 0.1800 - val_loss: 0.0830 - val_mae: 0.2432
Epoch 99/5000
41/41 - 1s - loss: 0.0586 - mae: 0.1866 - val_loss: 0.0815 - val_mae: 0.2447
Epoch 100/5000
41/41 - 1s - loss: 0.0579 - mae: 0.1864 - val_loss: 0.0808 - val_mae: 0.2442
Epoch 101/5000
41/41 - 1s - loss: 0.0544 - mae: 0.1814 - val_loss: 0.0825 - val_mae: 0.2436
Epoch 102/5000
41/41 - 1s - loss: 0.0489 - mae: 0.1650 - val_loss: 0.0781 - val_mae: 0.2382
Epoch 103/5000
41/41 - 1s - loss: 0.0471 - mae: 0.1621 - val_loss: 0.0782 - val_mae: 0.2347
Epoch 104/5000
41/41 - 1s - loss: 0.0458 - mae: 0.1566 - val_loss: 0.0793 - val_mae: 0.2374
Epoch 105/5000
41/41 - 1s - loss: 0.0443 - mae: 0.1544 - val_loss: 0.0810 - val_mae: 0.2389
Epoch 106/5000
41/41 - 1s - loss: 0.0434 - mae: 0.1510 - val_loss: 0.0917 - val_mae: 0.2586
Epoch 107/5000
41/41 - 1s - loss: 0.0451 - mae: 0.1553 - val_loss: 0.0850 - val_mae: 0.2471
Epoch 108/5000
41/41 - 1s - loss: 0.0408 - mae: 0.1495 - val_loss: 0.0843 - val_mae: 0.2402
Epoch 109/5000
41/41 - 1s - loss: 0.0396 - mae: 0.1423 - val_loss: 0.0873 - val_mae: 0.2484
Epoch 110/5000
41/41 - 1s - loss: 0.0416 - mae: 0.1491 - val_loss: 0.0782 - val_mae: 0.2308
Epoch 111/5000
41/41 - 1s - loss: 0.0392 - mae: 0.1411 - val_loss: 0.0953 - val_mae: 0.2656
Epoch 112/5000
41/41 - 1s - loss: 0.0422 - mae: 0.1512 - val_loss: 0.0902 - val_mae: 0.2542
Epoch 113/5000
41/41 - 1s - loss: 0.0379 - mae: 0.1408 - val_loss: 0.0949 - val_mae: 0.2704
Epoch 114/5000
41/41 - 1s - loss: 0.0448 - mae: 0.1603 - val_loss: 0.0814 - val_mae: 0.2436
Epoch 115/5000
41/41 - 1s - loss: 0.0432 - mae: 0.1548 - val_loss: 0.0920 - val_mae: 0.2664
Epoch 116/5000
41/41 - 1s - loss: 0.0391 - mae: 0.1424 - val_loss: 0.0848 - val_mae: 0.2483
Epoch 117/5000
41/41 - 1s - loss: 0.0355 - mae: 0.1323 - val_loss: 0.0942 - val_mae: 0.2651
Epoch 118/5000
41/41 - 1s - loss: 0.0353 - mae: 0.1316 - val_loss: 0.0893 - val_mae: 0.2537
Epoch 119/5000
41/41 - 1s - loss: 0.0365 - mae: 0.1417 - val_loss: 0.0921 - val_mae: 0.2718
Epoch 120/5000
41/41 - 1s - loss: 0.0373 - mae: 0.1411 - val_loss: 0.0945 - val_mae: 0.2655
Epoch 121/5000
41/41 - 1s - loss: 0.0396 - mae: 0.1458 - val_loss: 0.0863 - val_mae: 0.2450
Epoch 122/5000
41/41 - 1s - loss: 0.0384 - mae: 0.1479 - val_loss: 0.0786 - val_mae: 0.2400
Epoch 123/5000
41/41 - 1s - loss: 0.0407 - mae: 0.1525 - val_loss: 0.0870 - val_mae: 0.2686
Epoch 124/5000
41/41 - 1s - loss: 0.0422 - mae: 0.1559 - val_loss: 0.0828 - val_mae: 0.2470
Epoch 125/5000
41/41 - 1s - loss: 0.0373 - mae: 0.1408 - val_loss: 0.0839 - val_mae: 0.2503
Epoch 126/5000
41/41 - 1s - loss: 0.0347 - mae: 0.1378 - val_loss: 0.0834 - val_mae: 0.2445
Epoch 127/5000
41/41 - 1s - loss: 0.0330 - mae: 0.1361 - val_loss: 0.0744 - val_mae: 0.2300
Epoch 128/5000
41/41 - 1s - loss: 0.0333 - mae: 0.1347 - val_loss: 0.0882 - val_mae: 0.2568
Epoch 129/5000
41/41 - 1s - loss: 0.0317 - mae: 0.1314 - val_loss: 0.0821 - val_mae: 0.2365
Epoch 130/5000
41/41 - 1s - loss: 0.0331 - mae: 0.1320 - val_loss: 0.0805 - val_mae: 0.2368
Epoch 131/5000
41/41 - 1s - loss: 0.0342 - mae: 0.1389 - val_loss: 0.0787 - val_mae: 0.2394
Epoch 132/5000
41/41 - 1s - loss: 0.0319 - mae: 0.1346 - val_loss: 0.0804 - val_mae: 0.2373
Epoch 133/5000
41/41 - 1s - loss: 0.0336 - mae: 0.1406 - val_loss: 0.0707 - val_mae: 0.2243
Epoch 134/5000
41/41 - 1s - loss: 0.0310 - mae: 0.1317 - val_loss: 0.0839 - val_mae: 0.2469
Epoch 135/5000
41/41 - 1s - loss: 0.0298 - mae: 0.1291 - val_loss: 0.0708 - val_mae: 0.2187
Epoch 136/5000
41/41 - 1s - loss: 0.0308 - mae: 0.1350 - val_loss: 0.0783 - val_mae: 0.2366
Epoch 137/5000
41/41 - 1s - loss: 0.0336 - mae: 0.1420 - val_loss: 0.0730 - val_mae: 0.2288
Epoch 138/5000
41/41 - 1s - loss: 0.0331 - mae: 0.1377 - val_loss: 0.0949 - val_mae: 0.2772
Epoch 139/5000
41/41 - 1s - loss: 0.0418 - mae: 0.1577 - val_loss: 0.0732 - val_mae: 0.2281
Epoch 140/5000
41/41 - 1s - loss: 0.0349 - mae: 0.1428 - val_loss: 0.0772 - val_mae: 0.2285
Epoch 141/5000
41/41 - 1s - loss: 0.0346 - mae: 0.1403 - val_loss: 0.0847 - val_mae: 0.2425
Epoch 142/5000
41/41 - 1s - loss: 0.0318 - mae: 0.1382 - val_loss: 0.0808 - val_mae: 0.2455
Epoch 143/5000
41/41 - 1s - loss: 0.0335 - mae: 0.1391 - val_loss: 0.0924 - val_mae: 0.2651
Epoch 144/5000
41/41 - 1s - loss: 0.0309 - mae: 0.1369 - val_loss: 0.0967 - val_mae: 0.2669
Epoch 145/5000
41/41 - 1s - loss: 0.0383 - mae: 0.1560 - val_loss: 0.0896 - val_mae: 0.2608
Epoch 146/5000
41/41 - 1s - loss: 0.0363 - mae: 0.1499 - val_loss: 0.1012 - val_mae: 0.2834
Epoch 147/5000
41/41 - 1s - loss: 0.0392 - mae: 0.1544 - val_loss: 0.1023 - val_mae: 0.2958
Epoch 148/5000
41/41 - 1s - loss: 0.0372 - mae: 0.1487 - val_loss: 0.1312 - val_mae: 0.3383
Epoch 149/5000
41/41 - 1s - loss: 0.0369 - mae: 0.1513 - val_loss: 0.1195 - val_mae: 0.3238
Epoch 150/5000
41/41 - 1s - loss: 0.0381 - mae: 0.1495 - val_loss: 0.0998 - val_mae: 0.2991
Epoch 151/5000
41/41 - 1s - loss: 0.0503 - mae: 0.1769 - val_loss: 0.0926 - val_mae: 0.2895
Epoch 152/5000
41/41 - 1s - loss: 0.0512 - mae: 0.1828 - val_loss: 0.0681 - val_mae: 0.2238
Epoch 153/5000
41/41 - 1s - loss: 0.0439 - mae: 0.1681 - val_loss: 0.0849 - val_mae: 0.2487
Epoch 154/5000
41/41 - 1s - loss: 0.0308 - mae: 0.1322 - val_loss: 0.0865 - val_mae: 0.2471
Epoch 155/5000
41/41 - 1s - loss: 0.0284 - mae: 0.1232 - val_loss: 0.0857 - val_mae: 0.2423
Epoch 156/5000
41/41 - 1s - loss: 0.0273 - mae: 0.1198 - val_loss: 0.0792 - val_mae: 0.2334
Epoch 157/5000
41/41 - 1s - loss: 0.0248 - mae: 0.1158 - val_loss: 0.0856 - val_mae: 0.2463
Epoch 158/5000
41/41 - 1s - loss: 0.0234 - mae: 0.1115 - val_loss: 0.0859 - val_mae: 0.2527
Epoch 159/5000
41/41 - 1s - loss: 0.0219 - mae: 0.1024 - val_loss: 0.0900 - val_mae: 0.2570
Epoch 160/5000
41/41 - 1s - loss: 0.0217 - mae: 0.1069 - val_loss: 0.0872 - val_mae: 0.2576
Epoch 161/5000
41/41 - 1s - loss: 0.0254 - mae: 0.1169 - val_loss: 0.0790 - val_mae: 0.2396
Epoch 162/5000
41/41 - 1s - loss: 0.0219 - mae: 0.1100 - val_loss: 0.0890 - val_mae: 0.2652
Epoch 163/5000
41/41 - 1s - loss: 0.0246 - mae: 0.1178 - val_loss: 0.0816 - val_mae: 0.2390
Epoch 164/5000
41/41 - 1s - loss: 0.0261 - mae: 0.1203 - val_loss: 0.0822 - val_mae: 0.2427
Epoch 165/5000
41/41 - 1s - loss: 0.0215 - mae: 0.1105 - val_loss: 0.0909 - val_mae: 0.2593
Epoch 166/5000
41/41 - 1s - loss: 0.0255 - mae: 0.1165 - val_loss: 0.0819 - val_mae: 0.2367
Epoch 167/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1158 - val_loss: 0.0735 - val_mae: 0.2268
Epoch 168/5000
41/41 - 1s - loss: 0.0280 - mae: 0.1237 - val_loss: 0.0840 - val_mae: 0.2436
Epoch 169/5000
41/41 - 1s - loss: 0.0246 - mae: 0.1208 - val_loss: 0.0831 - val_mae: 0.2407
Epoch 170/5000
41/41 - 1s - loss: 0.0231 - mae: 0.1131 - val_loss: 0.0776 - val_mae: 0.2254
Epoch 171/5000
41/41 - 1s - loss: 0.0224 - mae: 0.1098 - val_loss: 0.0728 - val_mae: 0.2230
Epoch 172/5000
41/41 - 1s - loss: 0.0235 - mae: 0.1151 - val_loss: 0.0779 - val_mae: 0.2313
Epoch 173/5000
41/41 - 1s - loss: 0.0188 - mae: 0.1025 - val_loss: 0.0772 - val_mae: 0.2340
Epoch 174/5000
41/41 - 1s - loss: 0.0196 - mae: 0.1055 - val_loss: 0.0784 - val_mae: 0.2320
Epoch 175/5000
41/41 - 1s - loss: 0.0208 - mae: 0.1092 - val_loss: 0.0968 - val_mae: 0.2777
Epoch 176/5000
41/41 - 1s - loss: 0.0239 - mae: 0.1185 - val_loss: 0.0760 - val_mae: 0.2283
Epoch 177/5000
41/41 - 1s - loss: 0.0228 - mae: 0.1107 - val_loss: 0.1016 - val_mae: 0.2802
Epoch 178/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1171 - val_loss: 0.0770 - val_mae: 0.2342
Epoch 179/5000
41/41 - 1s - loss: 0.0195 - mae: 0.1020 - val_loss: 0.0936 - val_mae: 0.2635
Epoch 180/5000
41/41 - 1s - loss: 0.0187 - mae: 0.1009 - val_loss: 0.0848 - val_mae: 0.2469
Epoch 181/5000
41/41 - 1s - loss: 0.0179 - mae: 0.0980 - val_loss: 0.0841 - val_mae: 0.2468
Epoch 182/5000
41/41 - 1s - loss: 0.0193 - mae: 0.1018 - val_loss: 0.0868 - val_mae: 0.2592
Epoch 183/5000
41/41 - 1s - loss: 0.0189 - mae: 0.1021 - val_loss: 0.0850 - val_mae: 0.2477
Epoch 184/5000
41/41 - 1s - loss: 0.0195 - mae: 0.1023 - val_loss: 0.0827 - val_mae: 0.2563
Epoch 185/5000
41/41 - 1s - loss: 0.0183 - mae: 0.0989 - val_loss: 0.0861 - val_mae: 0.2431
Epoch 186/5000
41/41 - 1s - loss: 0.0159 - mae: 0.0965 - val_loss: 0.0807 - val_mae: 0.2377
Epoch 187/5000
41/41 - 1s - loss: 0.0211 - mae: 0.1074 - val_loss: 0.0758 - val_mae: 0.2263
Epoch 188/5000
41/41 - 1s - loss: 0.0178 - mae: 0.0989 - val_loss: 0.0777 - val_mae: 0.2334
Epoch 189/5000
41/41 - 1s - loss: 0.0169 - mae: 0.0922 - val_loss: 0.0823 - val_mae: 0.2315
Epoch 190/5000
41/41 - 1s - loss: 0.0159 - mae: 0.0931 - val_loss: 0.0792 - val_mae: 0.2355
Epoch 191/5000
41/41 - 1s - loss: 0.0155 - mae: 0.0889 - val_loss: 0.0801 - val_mae: 0.2299
Epoch 192/5000
41/41 - 1s - loss: 0.0138 - mae: 0.0871 - val_loss: 0.0814 - val_mae: 0.2390
Epoch 193/5000
41/41 - 1s - loss: 0.0155 - mae: 0.0909 - val_loss: 0.0745 - val_mae: 0.2206
Epoch 194/5000
41/41 - 1s - loss: 0.0154 - mae: 0.0928 - val_loss: 0.0756 - val_mae: 0.2293
Epoch 195/5000
41/41 - 1s - loss: 0.0162 - mae: 0.0951 - val_loss: 0.0840 - val_mae: 0.2454
Epoch 196/5000
41/41 - 1s - loss: 0.0160 - mae: 0.0973 - val_loss: 0.0746 - val_mae: 0.2273
Epoch 197/5000
41/41 - 1s - loss: 0.0202 - mae: 0.0998 - val_loss: 0.0942 - val_mae: 0.2622
Epoch 198/5000
41/41 - 1s - loss: 0.0180 - mae: 0.0984 - val_loss: 0.0833 - val_mae: 0.2426
Epoch 199/5000
41/41 - 1s - loss: 0.0216 - mae: 0.1091 - val_loss: 0.0730 - val_mae: 0.2228
Epoch 200/5000
41/41 - 1s - loss: 0.0209 - mae: 0.1064 - val_loss: 0.1031 - val_mae: 0.2879
Epoch 201/5000
41/41 - 1s - loss: 0.0184 - mae: 0.1072 - val_loss: 0.0969 - val_mae: 0.2688
Epoch 202/5000
41/41 - 1s - loss: 0.0170 - mae: 0.1027 - val_loss: 0.0773 - val_mae: 0.2326
Epoch 203/5000
41/41 - 1s - loss: 0.0236 - mae: 0.1091 - val_loss: 0.0948 - val_mae: 0.2733
Epoch 204/5000
41/41 - 1s - loss: 0.0224 - mae: 0.1141 - val_loss: 0.0884 - val_mae: 0.2527
Epoch 205/5000
41/41 - 1s - loss: 0.0191 - mae: 0.1033 - val_loss: 0.0895 - val_mae: 0.2529
Epoch 206/5000
41/41 - 1s - loss: 0.0181 - mae: 0.0990 - val_loss: 0.0855 - val_mae: 0.2623
Epoch 207/5000
41/41 - 1s - loss: 0.0174 - mae: 0.0978 - val_loss: 0.0761 - val_mae: 0.2302
Epoch 208/5000
41/41 - 1s - loss: 0.0231 - mae: 0.1139 - val_loss: 0.0803 - val_mae: 0.2469
Epoch 209/5000
41/41 - 1s - loss: 0.0200 - mae: 0.1115 - val_loss: 0.0806 - val_mae: 0.2455
Epoch 210/5000
41/41 - 1s - loss: 0.0223 - mae: 0.1099 - val_loss: 0.0902 - val_mae: 0.2494
Epoch 211/5000
41/41 - 1s - loss: 0.0165 - mae: 0.1012 - val_loss: 0.0801 - val_mae: 0.2322
Epoch 212/5000
41/41 - 1s - loss: 0.0186 - mae: 0.1068 - val_loss: 0.0833 - val_mae: 0.2298
Epoch 213/5000
41/41 - 1s - loss: 0.0159 - mae: 0.1004 - val_loss: 0.0748 - val_mae: 0.2263
Epoch 214/5000
41/41 - 1s - loss: 0.0141 - mae: 0.0913 - val_loss: 0.0819 - val_mae: 0.2324
Epoch 215/5000
41/41 - 1s - loss: 0.0190 - mae: 0.1137 - val_loss: 0.0808 - val_mae: 0.2432
Epoch 216/5000
41/41 - 1s - loss: 0.0177 - mae: 0.1058 - val_loss: 0.1028 - val_mae: 0.2798
Epoch 217/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1190 - val_loss: 0.0985 - val_mae: 0.2979
Epoch 218/5000
41/41 - 1s - loss: 0.0215 - mae: 0.1164 - val_loss: 0.0805 - val_mae: 0.2544
Epoch 219/5000
41/41 - 1s - loss: 0.0222 - mae: 0.1183 - val_loss: 0.0796 - val_mae: 0.2339
Epoch 220/5000
41/41 - 1s - loss: 0.0210 - mae: 0.1087 - val_loss: 0.0750 - val_mae: 0.2272
Epoch 221/5000
41/41 - 1s - loss: 0.0200 - mae: 0.1116 - val_loss: 0.0784 - val_mae: 0.2242
Epoch 222/5000
41/41 - 1s - loss: 0.0140 - mae: 0.1000 - val_loss: 0.0749 - val_mae: 0.2299
Epoch 223/5000
41/41 - 1s - loss: 0.0176 - mae: 0.1015 - val_loss: 0.0797 - val_mae: 0.2364
Epoch 224/5000
41/41 - 1s - loss: 0.0183 - mae: 0.1026 - val_loss: 0.0948 - val_mae: 0.2757
Epoch 225/5000
41/41 - 1s - loss: 0.0174 - mae: 0.0945 - val_loss: 0.0863 - val_mae: 0.2566
Epoch 226/5000
41/41 - 1s - loss: 0.0158 - mae: 0.0913 - val_loss: 0.0804 - val_mae: 0.2534
Epoch 227/5000
41/41 - 1s - loss: 0.0183 - mae: 0.1031 - val_loss: 0.0762 - val_mae: 0.2229
Epoch 228/5000
41/41 - 1s - loss: 0.0132 - mae: 0.0899 - val_loss: 0.0742 - val_mae: 0.2311
Epoch 229/5000
41/41 - 1s - loss: 0.0125 - mae: 0.0881 - val_loss: 0.0751 - val_mae: 0.2239
Epoch 230/5000
41/41 - 1s - loss: 0.0133 - mae: 0.0891 - val_loss: 0.0818 - val_mae: 0.2342
Epoch 231/5000
41/41 - 1s - loss: 0.0167 - mae: 0.1028 - val_loss: 0.0782 - val_mae: 0.2463
Epoch 232/5000
41/41 - 1s - loss: 0.0111 - mae: 0.0859 - val_loss: 0.0929 - val_mae: 0.2650
Epoch 233/5000
41/41 - 1s - loss: 0.0148 - mae: 0.0928 - val_loss: 0.0897 - val_mae: 0.2705
Epoch 234/5000
41/41 - 1s - loss: 0.0152 - mae: 0.0909 - val_loss: 0.0811 - val_mae: 0.2416
Epoch 235/5000
41/41 - 1s - loss: 0.0133 - mae: 0.0900 - val_loss: 0.0781 - val_mae: 0.2394
Epoch 236/5000
41/41 - 1s - loss: 0.0114 - mae: 0.0826 - val_loss: 0.0812 - val_mae: 0.2393
Restoring model weights from the end of the best epoch.
Epoch 00236: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_0..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 1

Generating graphs from SMILES..

Setting up training set.
Size: 2057

Setting up validation set.
Size: 229

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_9"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_1 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_1 (PartitionP (None, None, 64)     0           message_passing_1[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_1[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_1 (Masking)             (None, None, 64)     0           partition_padding_1[0][0]        
                                                                 partition_padding_1[1][0]        
__________________________________________________________________________________________________
transformer_encoder_1 (Transfor (None, None, 64)     199040      masking_1[0][0]                  
                                                                 masking_1[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_1 (Glo (None, 64)           0           transformer_encoder_1[0][0]      
                                                                 transformer_encoder_1[1][0]      
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 512)          33280       global_average_pooling1d_1[0][0] 
                                                                 global_average_pooling1d_1[1][0] 
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 10)           110         dense_21[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 450)          230850      dense_19[0][0]                   
                                                                 dense_19[1][0]                   
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 5)            55          dense_22[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 905)          0           dense_20[0][0]                   
                                                                 dense_20[1][0]                   
                                                                 dense_23[0][0]                   
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 700)          634200      concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 560)          392560      dense_24[0][0]                   
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 373)          209253      dense_28[0][0]                   
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 187)          69938       dense_29[0][0]                   
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 1)            188         dense_30[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
41/41 - 5s - loss: 0.2886 - mae: 0.5926 - val_loss: 0.0978 - val_mae: 0.3063
Epoch 2/5000
41/41 - 1s - loss: 0.1699 - mae: 0.4155 - val_loss: 0.0953 - val_mae: 0.2951
Epoch 3/5000
41/41 - 1s - loss: 0.1695 - mae: 0.4139 - val_loss: 0.0943 - val_mae: 0.2999
Epoch 4/5000
41/41 - 1s - loss: 0.1685 - mae: 0.4128 - val_loss: 0.0936 - val_mae: 0.3297
Epoch 5/5000
41/41 - 1s - loss: 0.1667 - mae: 0.4087 - val_loss: 0.0985 - val_mae: 0.3612
Epoch 6/5000
41/41 - 1s - loss: 0.1650 - mae: 0.4069 - val_loss: 0.0915 - val_mae: 0.3150
Epoch 7/5000
41/41 - 1s - loss: 0.1651 - mae: 0.4057 - val_loss: 0.0971 - val_mae: 0.3560
Epoch 8/5000
41/41 - 1s - loss: 0.1629 - mae: 0.4019 - val_loss: 0.0929 - val_mae: 0.3377
Epoch 9/5000
41/41 - 1s - loss: 0.1626 - mae: 0.4005 - val_loss: 0.0922 - val_mae: 0.3312
Epoch 10/5000
41/41 - 1s - loss: 0.1615 - mae: 0.3984 - val_loss: 0.0908 - val_mae: 0.2859
Epoch 11/5000
41/41 - 1s - loss: 0.1599 - mae: 0.3935 - val_loss: 0.0896 - val_mae: 0.2895
Epoch 12/5000
41/41 - 1s - loss: 0.1584 - mae: 0.3896 - val_loss: 0.0891 - val_mae: 0.2871
Epoch 13/5000
41/41 - 1s - loss: 0.1568 - mae: 0.3856 - val_loss: 0.0855 - val_mae: 0.2846
Epoch 14/5000
41/41 - 1s - loss: 0.1552 - mae: 0.3830 - val_loss: 0.0880 - val_mae: 0.2773
Epoch 15/5000
41/41 - 1s - loss: 0.1537 - mae: 0.3798 - val_loss: 0.0874 - val_mae: 0.2804
Epoch 16/5000
41/41 - 1s - loss: 0.1541 - mae: 0.3808 - val_loss: 0.0853 - val_mae: 0.2706
Epoch 17/5000
41/41 - 1s - loss: 0.1514 - mae: 0.3755 - val_loss: 0.0862 - val_mae: 0.2763
Epoch 18/5000
41/41 - 1s - loss: 0.1527 - mae: 0.3772 - val_loss: 0.0833 - val_mae: 0.2728
Epoch 19/5000
41/41 - 1s - loss: 0.1500 - mae: 0.3721 - val_loss: 0.0829 - val_mae: 0.2752
Epoch 20/5000
41/41 - 1s - loss: 0.1512 - mae: 0.3757 - val_loss: 0.0878 - val_mae: 0.2640
Epoch 21/5000
41/41 - 1s - loss: 0.1491 - mae: 0.3668 - val_loss: 0.0808 - val_mae: 0.2797
Epoch 22/5000
41/41 - 1s - loss: 0.1459 - mae: 0.3631 - val_loss: 0.0879 - val_mae: 0.3401
Epoch 23/5000
41/41 - 1s - loss: 0.1507 - mae: 0.3720 - val_loss: 0.0826 - val_mae: 0.2620
Epoch 24/5000
41/41 - 1s - loss: 0.1487 - mae: 0.3704 - val_loss: 0.0857 - val_mae: 0.2629
Epoch 25/5000
41/41 - 1s - loss: 0.1471 - mae: 0.3613 - val_loss: 0.0836 - val_mae: 0.3173
Epoch 26/5000
41/41 - 1s - loss: 0.1469 - mae: 0.3633 - val_loss: 0.0794 - val_mae: 0.2679
Epoch 27/5000
41/41 - 1s - loss: 0.1443 - mae: 0.3582 - val_loss: 0.0848 - val_mae: 0.2593
Epoch 28/5000
41/41 - 1s - loss: 0.1488 - mae: 0.3694 - val_loss: 0.0819 - val_mae: 0.2980
Epoch 29/5000
41/41 - 1s - loss: 0.1470 - mae: 0.3609 - val_loss: 0.0801 - val_mae: 0.2765
Epoch 30/5000
41/41 - 1s - loss: 0.1447 - mae: 0.3593 - val_loss: 0.0823 - val_mae: 0.2649
Epoch 31/5000
41/41 - 1s - loss: 0.1449 - mae: 0.3571 - val_loss: 0.0835 - val_mae: 0.2688
Epoch 32/5000
41/41 - 1s - loss: 0.1453 - mae: 0.3611 - val_loss: 0.0886 - val_mae: 0.3369
Epoch 33/5000
41/41 - 1s - loss: 0.1467 - mae: 0.3612 - val_loss: 0.0828 - val_mae: 0.2695
Epoch 34/5000
41/41 - 1s - loss: 0.1437 - mae: 0.3534 - val_loss: 0.0844 - val_mae: 0.2659
Epoch 35/5000
41/41 - 1s - loss: 0.1412 - mae: 0.3476 - val_loss: 0.0806 - val_mae: 0.2660
Epoch 36/5000
41/41 - 1s - loss: 0.1430 - mae: 0.3537 - val_loss: 0.0801 - val_mae: 0.2670
Epoch 37/5000
41/41 - 1s - loss: 0.1446 - mae: 0.3546 - val_loss: 0.0786 - val_mae: 0.2568
Epoch 38/5000
41/41 - 1s - loss: 0.1411 - mae: 0.3473 - val_loss: 0.0825 - val_mae: 0.2555
Epoch 39/5000
41/41 - 1s - loss: 0.1419 - mae: 0.3497 - val_loss: 0.0811 - val_mae: 0.2549
Epoch 40/5000
41/41 - 1s - loss: 0.1432 - mae: 0.3522 - val_loss: 0.0815 - val_mae: 0.2609
Epoch 41/5000
41/41 - 1s - loss: 0.1409 - mae: 0.3474 - val_loss: 0.0795 - val_mae: 0.2587
Epoch 42/5000
41/41 - 1s - loss: 0.1434 - mae: 0.3527 - val_loss: 0.0826 - val_mae: 0.2630
Epoch 43/5000
41/41 - 1s - loss: 0.1437 - mae: 0.3535 - val_loss: 0.0921 - val_mae: 0.3544
Epoch 44/5000
41/41 - 1s - loss: 0.1460 - mae: 0.3601 - val_loss: 0.1105 - val_mae: 0.4146
Epoch 45/5000
41/41 - 1s - loss: 0.1404 - mae: 0.3468 - val_loss: 0.0809 - val_mae: 0.2649
Epoch 46/5000
41/41 - 1s - loss: 0.1425 - mae: 0.3484 - val_loss: 0.0857 - val_mae: 0.3202
Epoch 47/5000
41/41 - 1s - loss: 0.1411 - mae: 0.3464 - val_loss: 0.0796 - val_mae: 0.2777
Epoch 48/5000
41/41 - 1s - loss: 0.1389 - mae: 0.3392 - val_loss: 0.0820 - val_mae: 0.2712
Epoch 49/5000
41/41 - 1s - loss: 0.1378 - mae: 0.3374 - val_loss: 0.0797 - val_mae: 0.2658
Epoch 50/5000
41/41 - 1s - loss: 0.1383 - mae: 0.3367 - val_loss: 0.0824 - val_mae: 0.2630
Epoch 51/5000
41/41 - 1s - loss: 0.1396 - mae: 0.3424 - val_loss: 0.0915 - val_mae: 0.3448
Epoch 52/5000
41/41 - 1s - loss: 0.1397 - mae: 0.3435 - val_loss: 0.0844 - val_mae: 0.2951
Epoch 53/5000
41/41 - 1s - loss: 0.1383 - mae: 0.3393 - val_loss: 0.0797 - val_mae: 0.2677
Epoch 54/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3318 - val_loss: 0.0802 - val_mae: 0.2696
Epoch 55/5000
41/41 - 1s - loss: 0.1361 - mae: 0.3334 - val_loss: 0.0815 - val_mae: 0.2700
Epoch 56/5000
41/41 - 1s - loss: 0.1354 - mae: 0.3318 - val_loss: 0.0823 - val_mae: 0.2694
Epoch 57/5000
41/41 - 1s - loss: 0.1386 - mae: 0.3400 - val_loss: 0.0902 - val_mae: 0.3358
Epoch 58/5000
41/41 - 1s - loss: 0.1388 - mae: 0.3413 - val_loss: 0.0793 - val_mae: 0.2645
Epoch 59/5000
41/41 - 1s - loss: 0.1384 - mae: 0.3384 - val_loss: 0.0944 - val_mae: 0.3435
Epoch 60/5000
41/41 - 1s - loss: 0.1378 - mae: 0.3379 - val_loss: 0.0834 - val_mae: 0.2764
Epoch 61/5000
41/41 - 1s - loss: 0.1382 - mae: 0.3391 - val_loss: 0.0828 - val_mae: 0.2917
Epoch 62/5000
41/41 - 1s - loss: 0.1379 - mae: 0.3391 - val_loss: 0.0882 - val_mae: 0.3061
Epoch 63/5000
41/41 - 1s - loss: 0.1370 - mae: 0.3360 - val_loss: 0.0823 - val_mae: 0.2762
Epoch 64/5000
41/41 - 1s - loss: 0.1362 - mae: 0.3350 - val_loss: 0.0849 - val_mae: 0.2771
Epoch 65/5000
41/41 - 1s - loss: 0.1337 - mae: 0.3262 - val_loss: 0.0813 - val_mae: 0.2691
Epoch 66/5000
41/41 - 1s - loss: 0.1321 - mae: 0.3241 - val_loss: 0.0804 - val_mae: 0.2721
Epoch 67/5000
41/41 - 1s - loss: 0.1336 - mae: 0.3267 - val_loss: 0.0818 - val_mae: 0.2755
Epoch 68/5000
41/41 - 1s - loss: 0.1335 - mae: 0.3265 - val_loss: 0.0853 - val_mae: 0.2795
Epoch 69/5000
41/41 - 1s - loss: 0.1328 - mae: 0.3246 - val_loss: 0.0848 - val_mae: 0.2780
Epoch 70/5000
41/41 - 1s - loss: 0.1354 - mae: 0.3318 - val_loss: 0.1023 - val_mae: 0.3640
Epoch 71/5000
41/41 - 1s - loss: 0.1355 - mae: 0.3340 - val_loss: 0.0912 - val_mae: 0.2908
Epoch 72/5000
41/41 - 1s - loss: 0.1334 - mae: 0.3268 - val_loss: 0.0893 - val_mae: 0.2816
Epoch 73/5000
41/41 - 1s - loss: 0.1340 - mae: 0.3294 - val_loss: 0.0911 - val_mae: 0.2984
Epoch 74/5000
41/41 - 1s - loss: 0.1435 - mae: 0.3501 - val_loss: 0.1385 - val_mae: 0.4642
Epoch 75/5000
41/41 - 1s - loss: 0.1427 - mae: 0.3526 - val_loss: 0.1044 - val_mae: 0.3704
Epoch 76/5000
41/41 - 1s - loss: 0.1403 - mae: 0.3471 - val_loss: 0.1001 - val_mae: 0.3563
Epoch 77/5000
41/41 - 1s - loss: 0.1395 - mae: 0.3417 - val_loss: 0.1259 - val_mae: 0.4295
Epoch 78/5000
41/41 - 1s - loss: 0.1374 - mae: 0.3389 - val_loss: 0.1024 - val_mae: 0.3704
Epoch 79/5000
41/41 - 1s - loss: 0.1363 - mae: 0.3357 - val_loss: 0.1002 - val_mae: 0.3685
Epoch 80/5000
41/41 - 1s - loss: 0.1360 - mae: 0.3346 - val_loss: 0.0964 - val_mae: 0.3494
Epoch 81/5000
41/41 - 1s - loss: 0.1371 - mae: 0.3373 - val_loss: 0.1134 - val_mae: 0.4027
Epoch 82/5000
41/41 - 1s - loss: 0.1370 - mae: 0.3372 - val_loss: 0.1096 - val_mae: 0.3926
Epoch 83/5000
41/41 - 1s - loss: 0.1369 - mae: 0.3374 - val_loss: 0.1171 - val_mae: 0.4039
Epoch 84/5000
41/41 - 1s - loss: 0.1359 - mae: 0.3347 - val_loss: 0.1188 - val_mae: 0.4107
Epoch 85/5000
41/41 - 1s - loss: 0.1364 - mae: 0.3348 - val_loss: 0.1168 - val_mae: 0.4068
Epoch 86/5000
41/41 - 1s - loss: 0.1354 - mae: 0.3333 - val_loss: 0.1235 - val_mae: 0.4271
Epoch 87/5000
41/41 - 1s - loss: 0.1363 - mae: 0.3357 - val_loss: 0.1225 - val_mae: 0.4239
Epoch 88/5000
41/41 - 1s - loss: 0.1368 - mae: 0.3347 - val_loss: 0.1304 - val_mae: 0.4467
Epoch 89/5000
41/41 - 1s - loss: 0.1392 - mae: 0.3455 - val_loss: 0.1354 - val_mae: 0.4542
Epoch 90/5000
41/41 - 1s - loss: 0.1368 - mae: 0.3389 - val_loss: 0.1140 - val_mae: 0.4049
Epoch 91/5000
41/41 - 1s - loss: 0.1336 - mae: 0.3296 - val_loss: 0.1055 - val_mae: 0.3862
Epoch 92/5000
41/41 - 1s - loss: 0.1322 - mae: 0.3252 - val_loss: 0.0931 - val_mae: 0.3264
Epoch 93/5000
41/41 - 1s - loss: 0.1335 - mae: 0.3273 - val_loss: 0.1112 - val_mae: 0.3844
Epoch 94/5000
41/41 - 1s - loss: 0.1365 - mae: 0.3348 - val_loss: 0.1276 - val_mae: 0.4381
Epoch 95/5000
41/41 - 1s - loss: 0.1369 - mae: 0.3378 - val_loss: 0.1194 - val_mae: 0.4184
Epoch 96/5000
41/41 - 1s - loss: 0.1355 - mae: 0.3322 - val_loss: 0.1181 - val_mae: 0.4178
Epoch 97/5000
41/41 - 1s - loss: 0.1378 - mae: 0.3382 - val_loss: 0.1254 - val_mae: 0.4345
Epoch 98/5000
41/41 - 1s - loss: 0.1358 - mae: 0.3354 - val_loss: 0.0939 - val_mae: 0.3397
Epoch 99/5000
41/41 - 1s - loss: 0.1319 - mae: 0.3239 - val_loss: 0.0949 - val_mae: 0.3444
Epoch 100/5000
41/41 - 1s - loss: 0.1318 - mae: 0.3235 - val_loss: 0.1080 - val_mae: 0.3829
Epoch 101/5000
41/41 - 1s - loss: 0.1307 - mae: 0.3214 - val_loss: 0.1004 - val_mae: 0.3629
Epoch 102/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3197 - val_loss: 0.0948 - val_mae: 0.3321
Epoch 103/5000
41/41 - 1s - loss: 0.1320 - mae: 0.3243 - val_loss: 0.1080 - val_mae: 0.3690
Epoch 104/5000
41/41 - 1s - loss: 0.1377 - mae: 0.3351 - val_loss: 0.1260 - val_mae: 0.4199
Epoch 105/5000
41/41 - 1s - loss: 0.1367 - mae: 0.3403 - val_loss: 0.1154 - val_mae: 0.4146
Epoch 106/5000
41/41 - 1s - loss: 0.1360 - mae: 0.3344 - val_loss: 0.1243 - val_mae: 0.4247
Epoch 107/5000
41/41 - 1s - loss: 0.1366 - mae: 0.3368 - val_loss: 0.1233 - val_mae: 0.4264
Epoch 108/5000
41/41 - 1s - loss: 0.1342 - mae: 0.3327 - val_loss: 0.1125 - val_mae: 0.3922
Epoch 109/5000
41/41 - 1s - loss: 0.1326 - mae: 0.3274 - val_loss: 0.1104 - val_mae: 0.3920
Epoch 110/5000
41/41 - 1s - loss: 0.1308 - mae: 0.3223 - val_loss: 0.1133 - val_mae: 0.3942
Epoch 111/5000
41/41 - 1s - loss: 0.1302 - mae: 0.3208 - val_loss: 0.1113 - val_mae: 0.3909
Epoch 112/5000
41/41 - 1s - loss: 0.1299 - mae: 0.3193 - val_loss: 0.1190 - val_mae: 0.4076
Epoch 113/5000
41/41 - 1s - loss: 0.1320 - mae: 0.3255 - val_loss: 0.1204 - val_mae: 0.4080
Epoch 114/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3217 - val_loss: 0.1165 - val_mae: 0.3904
Epoch 115/5000
41/41 - 1s - loss: 0.1325 - mae: 0.3268 - val_loss: 0.1344 - val_mae: 0.4440
Epoch 116/5000
41/41 - 1s - loss: 0.1345 - mae: 0.3322 - val_loss: 0.1362 - val_mae: 0.4455
Epoch 117/5000
41/41 - 1s - loss: 0.1346 - mae: 0.3338 - val_loss: 0.1265 - val_mae: 0.4130
Epoch 118/5000
41/41 - 1s - loss: 0.1355 - mae: 0.3309 - val_loss: 0.1246 - val_mae: 0.4066
Epoch 119/5000
41/41 - 1s - loss: 0.1353 - mae: 0.3379 - val_loss: 0.0874 - val_mae: 0.3122
Epoch 120/5000
41/41 - 1s - loss: 0.1278 - mae: 0.3137 - val_loss: 0.1030 - val_mae: 0.3645
Epoch 121/5000
41/41 - 1s - loss: 0.1292 - mae: 0.3181 - val_loss: 0.1107 - val_mae: 0.3864
Epoch 122/5000
41/41 - 1s - loss: 0.1288 - mae: 0.3167 - val_loss: 0.1152 - val_mae: 0.3971
Epoch 123/5000
41/41 - 1s - loss: 0.1298 - mae: 0.3192 - val_loss: 0.1287 - val_mae: 0.4188
Epoch 124/5000
41/41 - 1s - loss: 0.1308 - mae: 0.3219 - val_loss: 0.1389 - val_mae: 0.4430
Epoch 125/5000
41/41 - 1s - loss: 0.1344 - mae: 0.3304 - val_loss: 0.1326 - val_mae: 0.4274
Epoch 126/5000
41/41 - 1s - loss: 0.1333 - mae: 0.3357 - val_loss: 0.1074 - val_mae: 0.3641
Epoch 127/5000
41/41 - 1s - loss: 0.1293 - mae: 0.3173 - val_loss: 0.1300 - val_mae: 0.4200
Epoch 128/5000
41/41 - 1s - loss: 0.1300 - mae: 0.3207 - val_loss: 0.1224 - val_mae: 0.4095
Epoch 129/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3246 - val_loss: 0.1191 - val_mae: 0.4043
Epoch 130/5000
41/41 - 1s - loss: 0.1335 - mae: 0.3344 - val_loss: 0.1206 - val_mae: 0.4060
Epoch 131/5000
41/41 - 1s - loss: 0.1295 - mae: 0.3196 - val_loss: 0.1189 - val_mae: 0.4021
Epoch 132/5000
41/41 - 1s - loss: 0.1311 - mae: 0.3240 - val_loss: 0.1311 - val_mae: 0.4306
Epoch 133/5000
41/41 - 1s - loss: 0.1328 - mae: 0.3275 - val_loss: 0.1219 - val_mae: 0.4041
Epoch 134/5000
41/41 - 1s - loss: 0.1319 - mae: 0.3298 - val_loss: 0.1318 - val_mae: 0.4118
Epoch 135/5000
41/41 - 1s - loss: 0.1290 - mae: 0.3180 - val_loss: 0.1259 - val_mae: 0.4087
Epoch 136/5000
41/41 - 1s - loss: 0.1318 - mae: 0.3237 - val_loss: 0.1433 - val_mae: 0.4469
Epoch 137/5000
41/41 - 1s - loss: 0.1314 - mae: 0.3284 - val_loss: 0.1158 - val_mae: 0.3939
Epoch 138/5000
41/41 - 1s - loss: 0.1307 - mae: 0.3201 - val_loss: 0.1251 - val_mae: 0.4139
Epoch 139/5000
41/41 - 1s - loss: 0.1336 - mae: 0.3306 - val_loss: 0.1101 - val_mae: 0.3756
Epoch 140/5000
41/41 - 1s - loss: 0.1323 - mae: 0.3267 - val_loss: 0.0796 - val_mae: 0.2773
Restoring model weights from the end of the best epoch.
Epoch 00140: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_1..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_9"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_1 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_1 (PartitionP (None, None, 64)     0           message_passing_1[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_1[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_1 (Masking)             (None, None, 64)     0           partition_padding_1[0][0]        
                                                                 partition_padding_1[1][0]        
__________________________________________________________________________________________________
transformer_encoder_1 (Transfor (None, None, 64)     199040      masking_1[0][0]                  
                                                                 masking_1[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_1 (Glo (None, 64)           0           transformer_encoder_1[0][0]      
                                                                 transformer_encoder_1[1][0]      
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 512)          33280       global_average_pooling1d_1[0][0] 
                                                                 global_average_pooling1d_1[1][0] 
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 10)           110         dense_21[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 450)          230850      dense_19[0][0]                   
                                                                 dense_19[1][0]                   
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 5)            55          dense_22[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 905)          0           dense_20[0][0]                   
                                                                 dense_20[1][0]                   
                                                                 dense_23[0][0]                   
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 700)          634200      concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 560)          392560      dense_24[0][0]                   
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 373)          209253      dense_28[0][0]                   
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 187)          69938       dense_29[0][0]                   
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 1)            188         dense_30[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
41/41 - 6s - loss: 0.1392 - mae: 0.3431 - val_loss: 0.0810 - val_mae: 0.2978
Epoch 2/5000
41/41 - 1s - loss: 0.1281 - mae: 0.3144 - val_loss: 0.0827 - val_mae: 0.3107
Epoch 3/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3060 - val_loss: 0.0778 - val_mae: 0.2910
Epoch 4/5000
41/41 - 1s - loss: 0.1215 - mae: 0.2990 - val_loss: 0.0796 - val_mae: 0.3005
Epoch 5/5000
41/41 - 1s - loss: 0.1204 - mae: 0.2958 - val_loss: 0.0884 - val_mae: 0.3317
Epoch 6/5000
41/41 - 1s - loss: 0.1191 - mae: 0.2938 - val_loss: 0.0807 - val_mae: 0.3050
Epoch 7/5000
41/41 - 1s - loss: 0.1167 - mae: 0.2900 - val_loss: 0.0725 - val_mae: 0.2756
Epoch 8/5000
41/41 - 1s - loss: 0.1136 - mae: 0.2835 - val_loss: 0.0813 - val_mae: 0.3078
Epoch 9/5000
41/41 - 1s - loss: 0.1119 - mae: 0.2794 - val_loss: 0.0827 - val_mae: 0.3120
Epoch 10/5000
41/41 - 1s - loss: 0.1109 - mae: 0.2765 - val_loss: 0.0837 - val_mae: 0.3140
Epoch 11/5000
41/41 - 1s - loss: 0.1109 - mae: 0.2771 - val_loss: 0.0726 - val_mae: 0.2793
Epoch 12/5000
41/41 - 1s - loss: 0.1090 - mae: 0.2736 - val_loss: 0.0635 - val_mae: 0.2448
Epoch 13/5000
41/41 - 1s - loss: 0.1052 - mae: 0.2644 - val_loss: 0.0662 - val_mae: 0.2529
Epoch 14/5000
41/41 - 1s - loss: 0.1034 - mae: 0.2603 - val_loss: 0.0688 - val_mae: 0.2654
Epoch 15/5000
41/41 - 1s - loss: 0.1022 - mae: 0.2584 - val_loss: 0.0672 - val_mae: 0.2609
Epoch 16/5000
41/41 - 1s - loss: 0.1012 - mae: 0.2562 - val_loss: 0.0697 - val_mae: 0.2701
Epoch 17/5000
41/41 - 1s - loss: 0.1015 - mae: 0.2577 - val_loss: 0.0795 - val_mae: 0.2972
Epoch 18/5000
41/41 - 1s - loss: 0.1025 - mae: 0.2587 - val_loss: 0.0809 - val_mae: 0.2938
Epoch 19/5000
41/41 - 1s - loss: 0.1057 - mae: 0.2658 - val_loss: 0.0583 - val_mae: 0.2127
Epoch 20/5000
41/41 - 1s - loss: 0.1014 - mae: 0.2560 - val_loss: 0.0588 - val_mae: 0.2128
Epoch 21/5000
41/41 - 1s - loss: 0.0963 - mae: 0.2436 - val_loss: 0.0662 - val_mae: 0.2396
Epoch 22/5000
41/41 - 1s - loss: 0.0946 - mae: 0.2403 - val_loss: 0.0688 - val_mae: 0.2478
Epoch 23/5000
41/41 - 1s - loss: 0.0933 - mae: 0.2374 - val_loss: 0.0698 - val_mae: 0.2517
Epoch 24/5000
41/41 - 1s - loss: 0.0924 - mae: 0.2357 - val_loss: 0.0716 - val_mae: 0.2545
Epoch 25/5000
41/41 - 1s - loss: 0.0917 - mae: 0.2344 - val_loss: 0.0745 - val_mae: 0.2614
Epoch 26/5000
41/41 - 1s - loss: 0.0918 - mae: 0.2354 - val_loss: 0.0774 - val_mae: 0.2712
Epoch 27/5000
41/41 - 1s - loss: 0.0930 - mae: 0.2383 - val_loss: 0.0700 - val_mae: 0.2510
Epoch 28/5000
41/41 - 1s - loss: 0.0921 - mae: 0.2365 - val_loss: 0.0699 - val_mae: 0.2454
Epoch 29/5000
41/41 - 1s - loss: 0.0893 - mae: 0.2310 - val_loss: 0.0735 - val_mae: 0.2538
Epoch 30/5000
41/41 - 1s - loss: 0.0880 - mae: 0.2282 - val_loss: 0.0758 - val_mae: 0.2628
Epoch 31/5000
41/41 - 1s - loss: 0.0863 - mae: 0.2250 - val_loss: 0.0672 - val_mae: 0.2425
Epoch 32/5000
41/41 - 1s - loss: 0.0837 - mae: 0.2174 - val_loss: 0.0705 - val_mae: 0.2550
Epoch 33/5000
41/41 - 1s - loss: 0.0825 - mae: 0.2148 - val_loss: 0.0720 - val_mae: 0.2606
Epoch 34/5000
41/41 - 1s - loss: 0.0813 - mae: 0.2121 - val_loss: 0.0723 - val_mae: 0.2630
Epoch 35/5000
41/41 - 1s - loss: 0.0802 - mae: 0.2103 - val_loss: 0.0727 - val_mae: 0.2637
Epoch 36/5000
41/41 - 1s - loss: 0.0794 - mae: 0.2081 - val_loss: 0.0699 - val_mae: 0.2598
Epoch 37/5000
41/41 - 1s - loss: 0.0788 - mae: 0.2064 - val_loss: 0.0679 - val_mae: 0.2513
Epoch 38/5000
41/41 - 1s - loss: 0.0795 - mae: 0.2094 - val_loss: 0.0741 - val_mae: 0.2693
Epoch 39/5000
41/41 - 1s - loss: 0.0799 - mae: 0.2111 - val_loss: 0.0717 - val_mae: 0.2600
Epoch 40/5000
41/41 - 1s - loss: 0.0807 - mae: 0.2153 - val_loss: 0.0733 - val_mae: 0.2618
Epoch 41/5000
41/41 - 1s - loss: 0.0818 - mae: 0.2186 - val_loss: 0.0713 - val_mae: 0.2502
Epoch 42/5000
41/41 - 1s - loss: 0.0854 - mae: 0.2283 - val_loss: 0.1123 - val_mae: 0.3498
Epoch 43/5000
41/41 - 1s - loss: 0.0856 - mae: 0.2251 - val_loss: 0.0928 - val_mae: 0.3112
Epoch 44/5000
41/41 - 1s - loss: 0.0907 - mae: 0.2397 - val_loss: 0.0596 - val_mae: 0.2087
Epoch 45/5000
41/41 - 1s - loss: 0.0810 - mae: 0.2171 - val_loss: 0.0627 - val_mae: 0.2144
Epoch 46/5000
41/41 - 1s - loss: 0.0773 - mae: 0.2095 - val_loss: 0.0611 - val_mae: 0.2180
Epoch 47/5000
41/41 - 1s - loss: 0.0745 - mae: 0.2023 - val_loss: 0.0615 - val_mae: 0.2198
Epoch 48/5000
41/41 - 1s - loss: 0.0724 - mae: 0.1977 - val_loss: 0.0660 - val_mae: 0.2270
Epoch 49/5000
41/41 - 1s - loss: 0.0701 - mae: 0.1933 - val_loss: 0.0701 - val_mae: 0.2386
Epoch 50/5000
41/41 - 1s - loss: 0.0688 - mae: 0.1910 - val_loss: 0.0773 - val_mae: 0.2522
Epoch 51/5000
41/41 - 1s - loss: 0.0677 - mae: 0.1900 - val_loss: 0.0787 - val_mae: 0.2544
Epoch 52/5000
41/41 - 1s - loss: 0.0681 - mae: 0.1913 - val_loss: 0.0818 - val_mae: 0.2603
Epoch 53/5000
41/41 - 1s - loss: 0.0678 - mae: 0.1916 - val_loss: 0.0761 - val_mae: 0.2438
Epoch 54/5000
41/41 - 1s - loss: 0.0679 - mae: 0.1948 - val_loss: 0.0681 - val_mae: 0.2187
Epoch 55/5000
41/41 - 1s - loss: 0.0711 - mae: 0.2057 - val_loss: 0.0781 - val_mae: 0.2485
Epoch 56/5000
41/41 - 1s - loss: 0.0713 - mae: 0.2059 - val_loss: 0.1067 - val_mae: 0.3204
Epoch 57/5000
41/41 - 1s - loss: 0.0765 - mae: 0.2160 - val_loss: 0.0884 - val_mae: 0.2797
Epoch 58/5000
41/41 - 1s - loss: 0.0804 - mae: 0.2218 - val_loss: 0.0615 - val_mae: 0.2068
Epoch 59/5000
41/41 - 1s - loss: 0.0718 - mae: 0.2062 - val_loss: 0.0592 - val_mae: 0.2044
Epoch 60/5000
41/41 - 1s - loss: 0.0677 - mae: 0.1958 - val_loss: 0.0599 - val_mae: 0.2125
Epoch 61/5000
41/41 - 1s - loss: 0.0651 - mae: 0.1910 - val_loss: 0.0605 - val_mae: 0.2141
Epoch 62/5000
41/41 - 1s - loss: 0.0687 - mae: 0.2008 - val_loss: 0.0637 - val_mae: 0.2092
Epoch 63/5000
41/41 - 1s - loss: 0.0739 - mae: 0.2142 - val_loss: 0.0630 - val_mae: 0.2143
Epoch 64/5000
41/41 - 1s - loss: 0.0768 - mae: 0.2244 - val_loss: 0.0766 - val_mae: 0.2434
Epoch 65/5000
41/41 - 1s - loss: 0.0785 - mae: 0.2273 - val_loss: 0.1072 - val_mae: 0.3169
Epoch 66/5000
41/41 - 1s - loss: 0.0767 - mae: 0.2222 - val_loss: 0.1140 - val_mae: 0.3347
Epoch 67/5000
41/41 - 1s - loss: 0.0670 - mae: 0.2035 - val_loss: 0.0916 - val_mae: 0.2678
Epoch 68/5000
41/41 - 1s - loss: 0.0617 - mae: 0.1906 - val_loss: 0.0957 - val_mae: 0.2686
Epoch 69/5000
41/41 - 1s - loss: 0.0606 - mae: 0.1894 - val_loss: 0.1177 - val_mae: 0.3174
Epoch 70/5000
41/41 - 1s - loss: 0.0610 - mae: 0.1894 - val_loss: 0.1305 - val_mae: 0.3451
Epoch 71/5000
41/41 - 1s - loss: 0.0650 - mae: 0.2008 - val_loss: 0.1316 - val_mae: 0.3491
Epoch 72/5000
41/41 - 1s - loss: 0.0620 - mae: 0.1976 - val_loss: 0.1079 - val_mae: 0.2902
Epoch 73/5000
41/41 - 1s - loss: 0.0625 - mae: 0.1963 - val_loss: 0.0703 - val_mae: 0.2202
Epoch 74/5000
41/41 - 1s - loss: 0.0613 - mae: 0.1936 - val_loss: 0.0719 - val_mae: 0.2222
Epoch 75/5000
41/41 - 1s - loss: 0.0638 - mae: 0.1992 - val_loss: 0.0591 - val_mae: 0.2015
Epoch 76/5000
41/41 - 1s - loss: 0.0668 - mae: 0.2093 - val_loss: 0.1035 - val_mae: 0.2776
Epoch 77/5000
41/41 - 1s - loss: 0.0615 - mae: 0.1954 - val_loss: 0.0986 - val_mae: 0.2643
Epoch 78/5000
41/41 - 1s - loss: 0.0579 - mae: 0.1905 - val_loss: 0.0838 - val_mae: 0.2312
Epoch 79/5000
41/41 - 1s - loss: 0.0581 - mae: 0.1912 - val_loss: 0.0763 - val_mae: 0.2266
Epoch 80/5000
41/41 - 1s - loss: 0.0684 - mae: 0.2137 - val_loss: 0.0898 - val_mae: 0.2359
Epoch 81/5000
41/41 - 1s - loss: 0.0599 - mae: 0.1914 - val_loss: 0.0868 - val_mae: 0.2436
Epoch 82/5000
41/41 - 1s - loss: 0.0582 - mae: 0.1918 - val_loss: 0.0800 - val_mae: 0.2235
Epoch 83/5000
41/41 - 1s - loss: 0.0552 - mae: 0.1885 - val_loss: 0.0733 - val_mae: 0.2177
Epoch 84/5000
41/41 - 1s - loss: 0.0747 - mae: 0.2283 - val_loss: 0.0802 - val_mae: 0.2278
Epoch 85/5000
41/41 - 1s - loss: 0.0712 - mae: 0.2195 - val_loss: 0.0722 - val_mae: 0.2192
Epoch 86/5000
41/41 - 1s - loss: 0.0766 - mae: 0.2314 - val_loss: 0.0780 - val_mae: 0.2309
Epoch 87/5000
41/41 - 1s - loss: 0.0751 - mae: 0.2266 - val_loss: 0.0689 - val_mae: 0.2199
Epoch 88/5000
41/41 - 1s - loss: 0.0815 - mae: 0.2408 - val_loss: 0.0769 - val_mae: 0.2492
Epoch 89/5000
41/41 - 1s - loss: 0.0793 - mae: 0.2322 - val_loss: 0.0653 - val_mae: 0.2211
Epoch 90/5000
41/41 - 1s - loss: 0.0650 - mae: 0.2031 - val_loss: 0.0673 - val_mae: 0.2184
Epoch 91/5000
41/41 - 1s - loss: 0.0546 - mae: 0.1792 - val_loss: 0.0691 - val_mae: 0.2144
Epoch 92/5000
41/41 - 1s - loss: 0.0503 - mae: 0.1675 - val_loss: 0.0637 - val_mae: 0.2068
Epoch 93/5000
41/41 - 1s - loss: 0.0485 - mae: 0.1637 - val_loss: 0.0646 - val_mae: 0.2123
Epoch 94/5000
41/41 - 1s - loss: 0.0495 - mae: 0.1678 - val_loss: 0.0695 - val_mae: 0.2144
Epoch 95/5000
41/41 - 1s - loss: 0.0490 - mae: 0.1648 - val_loss: 0.0605 - val_mae: 0.2019
Epoch 96/5000
41/41 - 1s - loss: 0.0492 - mae: 0.1634 - val_loss: 0.0576 - val_mae: 0.1969
Epoch 97/5000
41/41 - 1s - loss: 0.0591 - mae: 0.1892 - val_loss: 0.0623 - val_mae: 0.2027
Epoch 98/5000
41/41 - 1s - loss: 0.0502 - mae: 0.1697 - val_loss: 0.0595 - val_mae: 0.1959
Epoch 99/5000
41/41 - 1s - loss: 0.0554 - mae: 0.1809 - val_loss: 0.0643 - val_mae: 0.2036
Epoch 100/5000
41/41 - 1s - loss: 0.0547 - mae: 0.1807 - val_loss: 0.0703 - val_mae: 0.2173
Epoch 101/5000
41/41 - 1s - loss: 0.0625 - mae: 0.1970 - val_loss: 0.0712 - val_mae: 0.2211
Epoch 102/5000
41/41 - 1s - loss: 0.0654 - mae: 0.2076 - val_loss: 0.0681 - val_mae: 0.2241
Epoch 103/5000
41/41 - 1s - loss: 0.0571 - mae: 0.1895 - val_loss: 0.0698 - val_mae: 0.2324
Epoch 104/5000
41/41 - 1s - loss: 0.0477 - mae: 0.1662 - val_loss: 0.0737 - val_mae: 0.2273
Epoch 105/5000
41/41 - 1s - loss: 0.0473 - mae: 0.1648 - val_loss: 0.0830 - val_mae: 0.2397
Epoch 106/5000
41/41 - 1s - loss: 0.0455 - mae: 0.1614 - val_loss: 0.0845 - val_mae: 0.2482
Epoch 107/5000
41/41 - 1s - loss: 0.0430 - mae: 0.1545 - val_loss: 0.0891 - val_mae: 0.2510
Epoch 108/5000
41/41 - 1s - loss: 0.0443 - mae: 0.1562 - val_loss: 0.0751 - val_mae: 0.2283
Epoch 109/5000
41/41 - 1s - loss: 0.0433 - mae: 0.1526 - val_loss: 0.0799 - val_mae: 0.2344
Epoch 110/5000
41/41 - 1s - loss: 0.0405 - mae: 0.1451 - val_loss: 0.0808 - val_mae: 0.2307
Epoch 111/5000
41/41 - 1s - loss: 0.0430 - mae: 0.1517 - val_loss: 0.0753 - val_mae: 0.2284
Epoch 112/5000
41/41 - 1s - loss: 0.0423 - mae: 0.1492 - val_loss: 0.0783 - val_mae: 0.2237
Epoch 113/5000
41/41 - 1s - loss: 0.0426 - mae: 0.1495 - val_loss: 0.0835 - val_mae: 0.2264
Epoch 114/5000
41/41 - 1s - loss: 0.0426 - mae: 0.1479 - val_loss: 0.0751 - val_mae: 0.2183
Epoch 115/5000
41/41 - 1s - loss: 0.0467 - mae: 0.1607 - val_loss: 0.0771 - val_mae: 0.2225
Epoch 116/5000
41/41 - 1s - loss: 0.0485 - mae: 0.1683 - val_loss: 0.0785 - val_mae: 0.2258
Epoch 117/5000
41/41 - 1s - loss: 0.0536 - mae: 0.1807 - val_loss: 0.0723 - val_mae: 0.2270
Epoch 118/5000
41/41 - 1s - loss: 0.0554 - mae: 0.1874 - val_loss: 0.0698 - val_mae: 0.2236
Epoch 119/5000
41/41 - 1s - loss: 0.0565 - mae: 0.1864 - val_loss: 0.0671 - val_mae: 0.2208
Epoch 120/5000
41/41 - 1s - loss: 0.0479 - mae: 0.1661 - val_loss: 0.0729 - val_mae: 0.2261
Epoch 121/5000
41/41 - 1s - loss: 0.0425 - mae: 0.1530 - val_loss: 0.0698 - val_mae: 0.2244
Epoch 122/5000
41/41 - 1s - loss: 0.0384 - mae: 0.1409 - val_loss: 0.0649 - val_mae: 0.2111
Epoch 123/5000
41/41 - 1s - loss: 0.0388 - mae: 0.1393 - val_loss: 0.0643 - val_mae: 0.2155
Epoch 124/5000
41/41 - 1s - loss: 0.0357 - mae: 0.1327 - val_loss: 0.0713 - val_mae: 0.2250
Epoch 125/5000
41/41 - 1s - loss: 0.0356 - mae: 0.1320 - val_loss: 0.0722 - val_mae: 0.2211
Epoch 126/5000
41/41 - 1s - loss: 0.0368 - mae: 0.1334 - val_loss: 0.0659 - val_mae: 0.2135
Epoch 127/5000
41/41 - 1s - loss: 0.0378 - mae: 0.1340 - val_loss: 0.0697 - val_mae: 0.2180
Epoch 128/5000
41/41 - 1s - loss: 0.0350 - mae: 0.1317 - val_loss: 0.0853 - val_mae: 0.2376
Epoch 129/5000
41/41 - 1s - loss: 0.0396 - mae: 0.1440 - val_loss: 0.0702 - val_mae: 0.2155
Epoch 130/5000
41/41 - 1s - loss: 0.0345 - mae: 0.1310 - val_loss: 0.0688 - val_mae: 0.2153
Epoch 131/5000
41/41 - 1s - loss: 0.0335 - mae: 0.1301 - val_loss: 0.0825 - val_mae: 0.2283
Epoch 132/5000
41/41 - 1s - loss: 0.0383 - mae: 0.1428 - val_loss: 0.0639 - val_mae: 0.2090
Epoch 133/5000
41/41 - 1s - loss: 0.0339 - mae: 0.1298 - val_loss: 0.0724 - val_mae: 0.2202
Epoch 134/5000
41/41 - 1s - loss: 0.0316 - mae: 0.1248 - val_loss: 0.0856 - val_mae: 0.2321
Epoch 135/5000
41/41 - 1s - loss: 0.0391 - mae: 0.1456 - val_loss: 0.0642 - val_mae: 0.2102
Epoch 136/5000
41/41 - 1s - loss: 0.0343 - mae: 0.1319 - val_loss: 0.0800 - val_mae: 0.2288
Epoch 137/5000
41/41 - 1s - loss: 0.0322 - mae: 0.1281 - val_loss: 0.0850 - val_mae: 0.2314
Epoch 138/5000
41/41 - 1s - loss: 0.0305 - mae: 0.1224 - val_loss: 0.0805 - val_mae: 0.2262
Epoch 139/5000
41/41 - 1s - loss: 0.0300 - mae: 0.1194 - val_loss: 0.0761 - val_mae: 0.2221
Epoch 140/5000
41/41 - 1s - loss: 0.0306 - mae: 0.1218 - val_loss: 0.0839 - val_mae: 0.2317
Epoch 141/5000
41/41 - 1s - loss: 0.0311 - mae: 0.1251 - val_loss: 0.0830 - val_mae: 0.2340
Epoch 142/5000
41/41 - 1s - loss: 0.0316 - mae: 0.1247 - val_loss: 0.0753 - val_mae: 0.2265
Epoch 143/5000
41/41 - 1s - loss: 0.0309 - mae: 0.1238 - val_loss: 0.0736 - val_mae: 0.2273
Epoch 144/5000
41/41 - 1s - loss: 0.0316 - mae: 0.1272 - val_loss: 0.0847 - val_mae: 0.2375
Epoch 145/5000
41/41 - 1s - loss: 0.0293 - mae: 0.1198 - val_loss: 0.0724 - val_mae: 0.2197
Epoch 146/5000
41/41 - 1s - loss: 0.0256 - mae: 0.1123 - val_loss: 0.0893 - val_mae: 0.2474
Epoch 147/5000
41/41 - 1s - loss: 0.0262 - mae: 0.1127 - val_loss: 0.0838 - val_mae: 0.2507
Epoch 148/5000
41/41 - 1s - loss: 0.0264 - mae: 0.1125 - val_loss: 0.0843 - val_mae: 0.2420
Epoch 149/5000
41/41 - 1s - loss: 0.0276 - mae: 0.1167 - val_loss: 0.0817 - val_mae: 0.2348
Epoch 150/5000
41/41 - 1s - loss: 0.0280 - mae: 0.1178 - val_loss: 0.0810 - val_mae: 0.2429
Epoch 151/5000
41/41 - 1s - loss: 0.0326 - mae: 0.1285 - val_loss: 0.1044 - val_mae: 0.3006
Epoch 152/5000
41/41 - 1s - loss: 0.0348 - mae: 0.1366 - val_loss: 0.0914 - val_mae: 0.2586
Epoch 153/5000
41/41 - 1s - loss: 0.0305 - mae: 0.1260 - val_loss: 0.0978 - val_mae: 0.2739
Epoch 154/5000
41/41 - 1s - loss: 0.0300 - mae: 0.1234 - val_loss: 0.0916 - val_mae: 0.2591
Epoch 155/5000
41/41 - 1s - loss: 0.0303 - mae: 0.1268 - val_loss: 0.0988 - val_mae: 0.2785
Epoch 156/5000
41/41 - 1s - loss: 0.0300 - mae: 0.1279 - val_loss: 0.1000 - val_mae: 0.2746
Epoch 157/5000
41/41 - 1s - loss: 0.0328 - mae: 0.1335 - val_loss: 0.0807 - val_mae: 0.2269
Epoch 158/5000
41/41 - 1s - loss: 0.0338 - mae: 0.1368 - val_loss: 0.0769 - val_mae: 0.2367
Epoch 159/5000
41/41 - 1s - loss: 0.0327 - mae: 0.1341 - val_loss: 0.0898 - val_mae: 0.2443
Epoch 160/5000
41/41 - 1s - loss: 0.0339 - mae: 0.1380 - val_loss: 0.0757 - val_mae: 0.2183
Epoch 161/5000
41/41 - 1s - loss: 0.0386 - mae: 0.1507 - val_loss: 0.0663 - val_mae: 0.2097
Epoch 162/5000
41/41 - 1s - loss: 0.0498 - mae: 0.1782 - val_loss: 0.0697 - val_mae: 0.2167
Epoch 163/5000
41/41 - 1s - loss: 0.0486 - mae: 0.1766 - val_loss: 0.0712 - val_mae: 0.2282
Epoch 164/5000
41/41 - 1s - loss: 0.0521 - mae: 0.1861 - val_loss: 0.0631 - val_mae: 0.2040
Epoch 165/5000
41/41 - 1s - loss: 0.0383 - mae: 0.1469 - val_loss: 0.0983 - val_mae: 0.2607
Epoch 166/5000
41/41 - 1s - loss: 0.0333 - mae: 0.1334 - val_loss: 0.0731 - val_mae: 0.2315
Epoch 167/5000
41/41 - 1s - loss: 0.0293 - mae: 0.1231 - val_loss: 0.0880 - val_mae: 0.2445
Epoch 168/5000
41/41 - 1s - loss: 0.0278 - mae: 0.1204 - val_loss: 0.0814 - val_mae: 0.2395
Epoch 169/5000
41/41 - 1s - loss: 0.0273 - mae: 0.1184 - val_loss: 0.0730 - val_mae: 0.2211
Epoch 170/5000
41/41 - 1s - loss: 0.0243 - mae: 0.1092 - val_loss: 0.0813 - val_mae: 0.2287
Epoch 171/5000
41/41 - 1s - loss: 0.0219 - mae: 0.0989 - val_loss: 0.0846 - val_mae: 0.2337
Epoch 172/5000
41/41 - 1s - loss: 0.0238 - mae: 0.1036 - val_loss: 0.0727 - val_mae: 0.2165
Epoch 173/5000
41/41 - 1s - loss: 0.0234 - mae: 0.1065 - val_loss: 0.0867 - val_mae: 0.2376
Epoch 174/5000
41/41 - 1s - loss: 0.0246 - mae: 0.1099 - val_loss: 0.0949 - val_mae: 0.2578
Epoch 175/5000
41/41 - 1s - loss: 0.0267 - mae: 0.1187 - val_loss: 0.0803 - val_mae: 0.2357
Epoch 176/5000
41/41 - 1s - loss: 0.0261 - mae: 0.1164 - val_loss: 0.0718 - val_mae: 0.2144
Epoch 177/5000
41/41 - 1s - loss: 0.0244 - mae: 0.1116 - val_loss: 0.0832 - val_mae: 0.2278
Epoch 178/5000
41/41 - 1s - loss: 0.0241 - mae: 0.1035 - val_loss: 0.0762 - val_mae: 0.2181
Epoch 179/5000
41/41 - 1s - loss: 0.0226 - mae: 0.1030 - val_loss: 0.0704 - val_mae: 0.2087
Epoch 180/5000
41/41 - 1s - loss: 0.0241 - mae: 0.1077 - val_loss: 0.0810 - val_mae: 0.2263
Epoch 181/5000
41/41 - 1s - loss: 0.0218 - mae: 0.1016 - val_loss: 0.0873 - val_mae: 0.2331
Epoch 182/5000
41/41 - 1s - loss: 0.0241 - mae: 0.1128 - val_loss: 0.0679 - val_mae: 0.2076
Epoch 183/5000
41/41 - 1s - loss: 0.0237 - mae: 0.1099 - val_loss: 0.0715 - val_mae: 0.2148
Epoch 184/5000
41/41 - 1s - loss: 0.0209 - mae: 0.1032 - val_loss: 0.0784 - val_mae: 0.2170
Epoch 185/5000
41/41 - 1s - loss: 0.0225 - mae: 0.1093 - val_loss: 0.0679 - val_mae: 0.2092
Epoch 186/5000
41/41 - 1s - loss: 0.0249 - mae: 0.1121 - val_loss: 0.0646 - val_mae: 0.2053
Epoch 187/5000
41/41 - 1s - loss: 0.0206 - mae: 0.1006 - val_loss: 0.0853 - val_mae: 0.2366
Epoch 188/5000
41/41 - 1s - loss: 0.0239 - mae: 0.1148 - val_loss: 0.0661 - val_mae: 0.2094
Epoch 189/5000
41/41 - 1s - loss: 0.0208 - mae: 0.1050 - val_loss: 0.0694 - val_mae: 0.2128
Epoch 190/5000
41/41 - 1s - loss: 0.0218 - mae: 0.1070 - val_loss: 0.0899 - val_mae: 0.2438
Epoch 191/5000
41/41 - 1s - loss: 0.0190 - mae: 0.1027 - val_loss: 0.0752 - val_mae: 0.2271
Epoch 192/5000
41/41 - 1s - loss: 0.0232 - mae: 0.1142 - val_loss: 0.0917 - val_mae: 0.2577
Epoch 193/5000
41/41 - 1s - loss: 0.0222 - mae: 0.1099 - val_loss: 0.0835 - val_mae: 0.2480
Epoch 194/5000
41/41 - 1s - loss: 0.0240 - mae: 0.1192 - val_loss: 0.0887 - val_mae: 0.2587
Epoch 195/5000
41/41 - 1s - loss: 0.0207 - mae: 0.1108 - val_loss: 0.0882 - val_mae: 0.2662
Epoch 196/5000
41/41 - 1s - loss: 0.0227 - mae: 0.1130 - val_loss: 0.0981 - val_mae: 0.2802
Epoch 197/5000
41/41 - 1s - loss: 0.0243 - mae: 0.1232 - val_loss: 0.0854 - val_mae: 0.2470
Epoch 198/5000
41/41 - 1s - loss: 0.0267 - mae: 0.1226 - val_loss: 0.0893 - val_mae: 0.2509
Epoch 199/5000
41/41 - 1s - loss: 0.0214 - mae: 0.1174 - val_loss: 0.0781 - val_mae: 0.2309
Restoring model weights from the end of the best epoch.
Epoch 00199: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_1..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 2

Generating graphs from SMILES..

Setting up training set.
Size: 2057

Setting up validation set.
Size: 229

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_14"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_2 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_2 (PartitionP (None, None, 64)     0           message_passing_2[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_2[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_2 (Masking)             (None, None, 64)     0           partition_padding_2[0][0]        
                                                                 partition_padding_2[1][0]        
__________________________________________________________________________________________________
transformer_encoder_2 (Transfor (None, None, 64)     199040      masking_2[0][0]                  
                                                                 masking_2[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_2 (Glo (None, 64)           0           transformer_encoder_2[0][0]      
                                                                 transformer_encoder_2[1][0]      
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 512)          33280       global_average_pooling1d_2[0][0] 
                                                                 global_average_pooling1d_2[1][0] 
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 10)           110         dense_38[0][0]                   
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 450)          230850      dense_36[0][0]                   
                                                                 dense_36[1][0]                   
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 5)            55          dense_39[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 905)          0           dense_37[0][0]                   
                                                                 dense_37[1][0]                   
                                                                 dense_40[0][0]                   
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 700)          634200      concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 560)          392560      dense_41[0][0]                   
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 373)          209253      dense_45[0][0]                   
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 187)          69938       dense_46[0][0]                   
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 1)            188         dense_47[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
41/41 - 5s - loss: 0.3703 - mae: 0.7012 - val_loss: 0.1298 - val_mae: 0.3786
Epoch 2/5000
41/41 - 1s - loss: 0.1647 - mae: 0.4083 - val_loss: 0.1283 - val_mae: 0.3623
Epoch 3/5000
41/41 - 1s - loss: 0.1639 - mae: 0.4069 - val_loss: 0.1273 - val_mae: 0.3523
Epoch 4/5000
41/41 - 1s - loss: 0.1621 - mae: 0.4024 - val_loss: 0.1261 - val_mae: 0.3501
Epoch 5/5000
41/41 - 1s - loss: 0.1596 - mae: 0.3973 - val_loss: 0.1259 - val_mae: 0.3519
Epoch 6/5000
41/41 - 1s - loss: 0.1578 - mae: 0.3935 - val_loss: 0.1246 - val_mae: 0.3638
Epoch 7/5000
41/41 - 1s - loss: 0.1576 - mae: 0.3927 - val_loss: 0.1235 - val_mae: 0.3527
Epoch 8/5000
41/41 - 1s - loss: 0.1581 - mae: 0.3931 - val_loss: 0.1233 - val_mae: 0.3423
Epoch 9/5000
41/41 - 1s - loss: 0.1563 - mae: 0.3895 - val_loss: 0.1213 - val_mae: 0.3451
Epoch 10/5000
41/41 - 1s - loss: 0.1564 - mae: 0.3907 - val_loss: 0.1220 - val_mae: 0.3376
Epoch 11/5000
41/41 - 1s - loss: 0.1536 - mae: 0.3837 - val_loss: 0.1202 - val_mae: 0.3404
Epoch 12/5000
41/41 - 1s - loss: 0.1551 - mae: 0.3877 - val_loss: 0.1219 - val_mae: 0.3317
Epoch 13/5000
41/41 - 1s - loss: 0.1540 - mae: 0.3852 - val_loss: 0.1220 - val_mae: 0.3238
Epoch 14/5000
41/41 - 1s - loss: 0.1497 - mae: 0.3744 - val_loss: 0.1191 - val_mae: 0.3356
Epoch 15/5000
41/41 - 1s - loss: 0.1528 - mae: 0.3829 - val_loss: 0.1200 - val_mae: 0.3250
Epoch 16/5000
41/41 - 1s - loss: 0.1489 - mae: 0.3733 - val_loss: 0.1169 - val_mae: 0.3400
Epoch 17/5000
41/41 - 1s - loss: 0.1505 - mae: 0.3786 - val_loss: 0.1188 - val_mae: 0.3250
Epoch 18/5000
41/41 - 1s - loss: 0.1492 - mae: 0.3757 - val_loss: 0.1177 - val_mae: 0.3214
Epoch 19/5000
41/41 - 1s - loss: 0.1462 - mae: 0.3676 - val_loss: 0.1156 - val_mae: 0.3291
Epoch 20/5000
41/41 - 1s - loss: 0.1498 - mae: 0.3776 - val_loss: 0.1181 - val_mae: 0.3271
Epoch 21/5000
41/41 - 1s - loss: 0.1450 - mae: 0.3619 - val_loss: 0.1164 - val_mae: 0.3329
Epoch 22/5000
41/41 - 1s - loss: 0.1496 - mae: 0.3770 - val_loss: 0.1178 - val_mae: 0.3323
Epoch 23/5000
41/41 - 1s - loss: 0.1439 - mae: 0.3582 - val_loss: 0.1152 - val_mae: 0.3372
Epoch 24/5000
41/41 - 1s - loss: 0.1465 - mae: 0.3682 - val_loss: 0.1165 - val_mae: 0.3335
Epoch 25/5000
41/41 - 1s - loss: 0.1428 - mae: 0.3561 - val_loss: 0.1162 - val_mae: 0.3262
Epoch 26/5000
41/41 - 1s - loss: 0.1447 - mae: 0.3641 - val_loss: 0.1160 - val_mae: 0.3258
Epoch 27/5000
41/41 - 1s - loss: 0.1415 - mae: 0.3537 - val_loss: 0.1146 - val_mae: 0.3304
Epoch 28/5000
41/41 - 1s - loss: 0.1435 - mae: 0.3617 - val_loss: 0.1160 - val_mae: 0.3339
Epoch 29/5000
41/41 - 1s - loss: 0.1417 - mae: 0.3546 - val_loss: 0.1159 - val_mae: 0.3183
Epoch 30/5000
41/41 - 1s - loss: 0.1435 - mae: 0.3607 - val_loss: 0.1206 - val_mae: 0.3637
Epoch 31/5000
41/41 - 1s - loss: 0.1410 - mae: 0.3511 - val_loss: 0.1158 - val_mae: 0.3448
Epoch 32/5000
41/41 - 1s - loss: 0.1403 - mae: 0.3508 - val_loss: 0.1144 - val_mae: 0.3316
Epoch 33/5000
41/41 - 1s - loss: 0.1396 - mae: 0.3509 - val_loss: 0.1134 - val_mae: 0.3272
Epoch 34/5000
41/41 - 1s - loss: 0.1400 - mae: 0.3522 - val_loss: 0.1173 - val_mae: 0.3385
Epoch 35/5000
41/41 - 1s - loss: 0.1394 - mae: 0.3471 - val_loss: 0.1146 - val_mae: 0.3315
Epoch 36/5000
41/41 - 1s - loss: 0.1366 - mae: 0.3413 - val_loss: 0.1132 - val_mae: 0.3079
Epoch 37/5000
41/41 - 1s - loss: 0.1372 - mae: 0.3432 - val_loss: 0.1130 - val_mae: 0.3206
Epoch 38/5000
41/41 - 1s - loss: 0.1374 - mae: 0.3447 - val_loss: 0.1152 - val_mae: 0.3112
Epoch 39/5000
41/41 - 1s - loss: 0.1369 - mae: 0.3403 - val_loss: 0.1174 - val_mae: 0.3071
Epoch 40/5000
41/41 - 1s - loss: 0.1390 - mae: 0.3458 - val_loss: 0.1131 - val_mae: 0.3039
Epoch 41/5000
41/41 - 1s - loss: 0.1357 - mae: 0.3378 - val_loss: 0.1150 - val_mae: 0.3069
Epoch 42/5000
41/41 - 1s - loss: 0.1373 - mae: 0.3417 - val_loss: 0.1107 - val_mae: 0.3139
Epoch 43/5000
41/41 - 1s - loss: 0.1354 - mae: 0.3385 - val_loss: 0.1113 - val_mae: 0.3090
Epoch 44/5000
41/41 - 1s - loss: 0.1347 - mae: 0.3370 - val_loss: 0.1133 - val_mae: 0.3072
Epoch 45/5000
41/41 - 1s - loss: 0.1364 - mae: 0.3392 - val_loss: 0.1107 - val_mae: 0.3117
Epoch 46/5000
41/41 - 1s - loss: 0.1357 - mae: 0.3380 - val_loss: 0.1151 - val_mae: 0.3055
Epoch 47/5000
41/41 - 1s - loss: 0.1368 - mae: 0.3398 - val_loss: 0.1108 - val_mae: 0.3094
Epoch 48/5000
41/41 - 1s - loss: 0.1345 - mae: 0.3350 - val_loss: 0.1133 - val_mae: 0.3131
Epoch 49/5000
41/41 - 1s - loss: 0.1362 - mae: 0.3360 - val_loss: 0.1153 - val_mae: 0.3319
Epoch 50/5000
41/41 - 1s - loss: 0.1346 - mae: 0.3350 - val_loss: 0.1156 - val_mae: 0.3099
Epoch 51/5000
41/41 - 1s - loss: 0.1365 - mae: 0.3384 - val_loss: 0.1158 - val_mae: 0.3285
Epoch 52/5000
41/41 - 1s - loss: 0.1390 - mae: 0.3465 - val_loss: 0.1267 - val_mae: 0.3937
Epoch 53/5000
41/41 - 1s - loss: 0.1403 - mae: 0.3493 - val_loss: 0.1109 - val_mae: 0.3143
Epoch 54/5000
41/41 - 1s - loss: 0.1333 - mae: 0.3336 - val_loss: 0.1108 - val_mae: 0.3080
Epoch 55/5000
41/41 - 1s - loss: 0.1358 - mae: 0.3379 - val_loss: 0.1110 - val_mae: 0.3092
Epoch 56/5000
41/41 - 1s - loss: 0.1392 - mae: 0.3437 - val_loss: 0.1154 - val_mae: 0.3355
Epoch 57/5000
41/41 - 1s - loss: 0.1370 - mae: 0.3431 - val_loss: 0.1122 - val_mae: 0.3145
Epoch 58/5000
41/41 - 1s - loss: 0.1323 - mae: 0.3298 - val_loss: 0.1128 - val_mae: 0.3109
Epoch 59/5000
41/41 - 1s - loss: 0.1343 - mae: 0.3325 - val_loss: 0.1145 - val_mae: 0.3189
Epoch 60/5000
41/41 - 1s - loss: 0.1315 - mae: 0.3271 - val_loss: 0.1103 - val_mae: 0.3125
Epoch 61/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3356 - val_loss: 0.1116 - val_mae: 0.3113
Epoch 62/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3381 - val_loss: 0.1140 - val_mae: 0.3120
Epoch 63/5000
41/41 - 1s - loss: 0.1319 - mae: 0.3283 - val_loss: 0.1143 - val_mae: 0.3130
Epoch 64/5000
41/41 - 1s - loss: 0.1332 - mae: 0.3327 - val_loss: 0.1100 - val_mae: 0.3052
Epoch 65/5000
41/41 - 1s - loss: 0.1364 - mae: 0.3398 - val_loss: 0.1137 - val_mae: 0.3323
Epoch 66/5000
41/41 - 1s - loss: 0.1321 - mae: 0.3305 - val_loss: 0.1109 - val_mae: 0.3142
Epoch 67/5000
41/41 - 1s - loss: 0.1338 - mae: 0.3326 - val_loss: 0.1133 - val_mae: 0.3226
Epoch 68/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3311 - val_loss: 0.1121 - val_mae: 0.3167
Epoch 69/5000
41/41 - 1s - loss: 0.1345 - mae: 0.3350 - val_loss: 0.1110 - val_mae: 0.3097
Epoch 70/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3370 - val_loss: 0.1112 - val_mae: 0.3231
Epoch 71/5000
41/41 - 1s - loss: 0.1355 - mae: 0.3372 - val_loss: 0.1148 - val_mae: 0.3356
Epoch 72/5000
41/41 - 1s - loss: 0.1414 - mae: 0.3492 - val_loss: 0.1159 - val_mae: 0.3484
Epoch 73/5000
41/41 - 1s - loss: 0.1339 - mae: 0.3359 - val_loss: 0.1117 - val_mae: 0.3186
Epoch 74/5000
41/41 - 1s - loss: 0.1309 - mae: 0.3261 - val_loss: 0.1123 - val_mae: 0.3204
Epoch 75/5000
41/41 - 1s - loss: 0.1326 - mae: 0.3300 - val_loss: 0.1091 - val_mae: 0.3202
Epoch 76/5000
41/41 - 1s - loss: 0.1345 - mae: 0.3351 - val_loss: 0.1087 - val_mae: 0.3155
Epoch 77/5000
41/41 - 1s - loss: 0.1335 - mae: 0.3323 - val_loss: 0.1121 - val_mae: 0.3133
Epoch 78/5000
41/41 - 1s - loss: 0.1311 - mae: 0.3259 - val_loss: 0.1142 - val_mae: 0.3191
Epoch 79/5000
41/41 - 1s - loss: 0.1311 - mae: 0.3271 - val_loss: 0.1116 - val_mae: 0.3045
Epoch 80/5000
41/41 - 1s - loss: 0.1324 - mae: 0.3267 - val_loss: 0.1131 - val_mae: 0.3143
Epoch 81/5000
41/41 - 1s - loss: 0.1321 - mae: 0.3281 - val_loss: 0.1158 - val_mae: 0.3219
Epoch 82/5000
41/41 - 1s - loss: 0.1309 - mae: 0.3256 - val_loss: 0.1121 - val_mae: 0.3126
Epoch 83/5000
41/41 - 1s - loss: 0.1332 - mae: 0.3293 - val_loss: 0.1112 - val_mae: 0.3200
Epoch 84/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3382 - val_loss: 0.1096 - val_mae: 0.3218
Epoch 85/5000
41/41 - 1s - loss: 0.1293 - mae: 0.3206 - val_loss: 0.1145 - val_mae: 0.3193
Epoch 86/5000
41/41 - 1s - loss: 0.1378 - mae: 0.3436 - val_loss: 0.1122 - val_mae: 0.3202
Epoch 87/5000
41/41 - 1s - loss: 0.1374 - mae: 0.3434 - val_loss: 0.1178 - val_mae: 0.3591
Epoch 88/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3387 - val_loss: 0.1143 - val_mae: 0.3526
Epoch 89/5000
41/41 - 1s - loss: 0.1360 - mae: 0.3374 - val_loss: 0.1255 - val_mae: 0.3729
Epoch 90/5000
41/41 - 1s - loss: 0.1323 - mae: 0.3286 - val_loss: 0.1277 - val_mae: 0.3827
Epoch 91/5000
41/41 - 1s - loss: 0.1302 - mae: 0.3249 - val_loss: 0.1132 - val_mae: 0.3466
Epoch 92/5000
41/41 - 1s - loss: 0.1332 - mae: 0.3319 - val_loss: 0.1179 - val_mae: 0.3633
Epoch 93/5000
41/41 - 1s - loss: 0.1346 - mae: 0.3351 - val_loss: 0.1277 - val_mae: 0.3944
Epoch 94/5000
41/41 - 1s - loss: 0.1354 - mae: 0.3369 - val_loss: 0.1363 - val_mae: 0.4072
Epoch 95/5000
41/41 - 1s - loss: 0.1370 - mae: 0.3419 - val_loss: 0.1261 - val_mae: 0.3904
Epoch 96/5000
41/41 - 1s - loss: 0.1352 - mae: 0.3350 - val_loss: 0.1305 - val_mae: 0.4005
Epoch 97/5000
41/41 - 1s - loss: 0.1301 - mae: 0.3227 - val_loss: 0.1226 - val_mae: 0.3750
Epoch 98/5000
41/41 - 1s - loss: 0.1326 - mae: 0.3295 - val_loss: 0.1303 - val_mae: 0.3978
Epoch 99/5000
41/41 - 1s - loss: 0.1333 - mae: 0.3323 - val_loss: 0.1325 - val_mae: 0.3912
Epoch 100/5000
41/41 - 1s - loss: 0.1322 - mae: 0.3294 - val_loss: 0.1352 - val_mae: 0.4059
Epoch 101/5000
41/41 - 1s - loss: 0.1321 - mae: 0.3283 - val_loss: 0.1224 - val_mae: 0.3690
Epoch 102/5000
41/41 - 1s - loss: 0.1289 - mae: 0.3193 - val_loss: 0.1316 - val_mae: 0.3994
Epoch 103/5000
41/41 - 1s - loss: 0.1313 - mae: 0.3269 - val_loss: 0.1270 - val_mae: 0.3812
Epoch 104/5000
41/41 - 1s - loss: 0.1323 - mae: 0.3289 - val_loss: 0.1333 - val_mae: 0.4012
Epoch 105/5000
41/41 - 1s - loss: 0.1316 - mae: 0.3270 - val_loss: 0.1379 - val_mae: 0.4115
Epoch 106/5000
41/41 - 1s - loss: 0.1322 - mae: 0.3280 - val_loss: 0.1420 - val_mae: 0.4278
Epoch 107/5000
41/41 - 1s - loss: 0.1298 - mae: 0.3225 - val_loss: 0.1324 - val_mae: 0.4019
Epoch 108/5000
41/41 - 1s - loss: 0.1277 - mae: 0.3167 - val_loss: 0.1363 - val_mae: 0.4062
Epoch 109/5000
41/41 - 1s - loss: 0.1295 - mae: 0.3214 - val_loss: 0.1440 - val_mae: 0.4219
Epoch 110/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3257 - val_loss: 0.1523 - val_mae: 0.4481
Epoch 111/5000
41/41 - 1s - loss: 0.1318 - mae: 0.3274 - val_loss: 0.1356 - val_mae: 0.4087
Epoch 112/5000
41/41 - 1s - loss: 0.1271 - mae: 0.3160 - val_loss: 0.1345 - val_mae: 0.4032
Epoch 113/5000
41/41 - 1s - loss: 0.1279 - mae: 0.3172 - val_loss: 0.1441 - val_mae: 0.4211
Epoch 114/5000
41/41 - 1s - loss: 0.1298 - mae: 0.3231 - val_loss: 0.1522 - val_mae: 0.4419
Epoch 115/5000
41/41 - 1s - loss: 0.1297 - mae: 0.3227 - val_loss: 0.1461 - val_mae: 0.4304
Epoch 116/5000
41/41 - 1s - loss: 0.1287 - mae: 0.3199 - val_loss: 0.1482 - val_mae: 0.4383
Epoch 117/5000
41/41 - 1s - loss: 0.1263 - mae: 0.3140 - val_loss: 0.1360 - val_mae: 0.4069
Epoch 118/5000
41/41 - 1s - loss: 0.1258 - mae: 0.3113 - val_loss: 0.1334 - val_mae: 0.3959
Epoch 119/5000
41/41 - 1s - loss: 0.1251 - mae: 0.3097 - val_loss: 0.1356 - val_mae: 0.4004
Epoch 120/5000
41/41 - 1s - loss: 0.1251 - mae: 0.3091 - val_loss: 0.1316 - val_mae: 0.3893
Epoch 121/5000
41/41 - 1s - loss: 0.1260 - mae: 0.3142 - val_loss: 0.1311 - val_mae: 0.3921
Epoch 122/5000
41/41 - 1s - loss: 0.1273 - mae: 0.3163 - val_loss: 0.1342 - val_mae: 0.3981
Epoch 123/5000
41/41 - 1s - loss: 0.1273 - mae: 0.3173 - val_loss: 0.1440 - val_mae: 0.4289
Epoch 124/5000
41/41 - 1s - loss: 0.1290 - mae: 0.3209 - val_loss: 0.1592 - val_mae: 0.4647
Epoch 125/5000
41/41 - 1s - loss: 0.1309 - mae: 0.3257 - val_loss: 0.1425 - val_mae: 0.4290
Epoch 126/5000
41/41 - 1s - loss: 0.1255 - mae: 0.3135 - val_loss: 0.1350 - val_mae: 0.4023
Epoch 127/5000
41/41 - 1s - loss: 0.1252 - mae: 0.3109 - val_loss: 0.1231 - val_mae: 0.3613
Epoch 128/5000
41/41 - 1s - loss: 0.1233 - mae: 0.3052 - val_loss: 0.1522 - val_mae: 0.4390
Epoch 129/5000
41/41 - 1s - loss: 0.1250 - mae: 0.3118 - val_loss: 0.1313 - val_mae: 0.3899
Epoch 130/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3074 - val_loss: 0.1402 - val_mae: 0.4145
Epoch 131/5000
41/41 - 1s - loss: 0.1264 - mae: 0.3160 - val_loss: 0.1329 - val_mae: 0.3882
Epoch 132/5000
41/41 - 1s - loss: 0.1259 - mae: 0.3130 - val_loss: 0.1290 - val_mae: 0.3847
Epoch 133/5000
41/41 - 1s - loss: 0.1223 - mae: 0.3035 - val_loss: 0.1365 - val_mae: 0.4109
Epoch 134/5000
41/41 - 1s - loss: 0.1253 - mae: 0.3120 - val_loss: 0.1308 - val_mae: 0.3771
Epoch 135/5000
41/41 - 1s - loss: 0.1241 - mae: 0.3084 - val_loss: 0.1364 - val_mae: 0.3996
Epoch 136/5000
41/41 - 1s - loss: 0.1236 - mae: 0.3068 - val_loss: 0.1392 - val_mae: 0.4085
Epoch 137/5000
41/41 - 1s - loss: 0.1273 - mae: 0.3182 - val_loss: 0.1292 - val_mae: 0.3818
Epoch 138/5000
41/41 - 1s - loss: 0.1251 - mae: 0.3104 - val_loss: 0.1529 - val_mae: 0.4425
Epoch 139/5000
41/41 - 1s - loss: 0.1308 - mae: 0.3262 - val_loss: 0.1637 - val_mae: 0.4664
Epoch 140/5000
41/41 - 1s - loss: 0.1302 - mae: 0.3249 - val_loss: 0.1500 - val_mae: 0.4442
Epoch 141/5000
41/41 - 1s - loss: 0.1295 - mae: 0.3210 - val_loss: 0.1166 - val_mae: 0.3437
Restoring model weights from the end of the best epoch.
Epoch 00141: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_2..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_14"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_2 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_2 (PartitionP (None, None, 64)     0           message_passing_2[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_2[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_2 (Masking)             (None, None, 64)     0           partition_padding_2[0][0]        
                                                                 partition_padding_2[1][0]        
__________________________________________________________________________________________________
transformer_encoder_2 (Transfor (None, None, 64)     199040      masking_2[0][0]                  
                                                                 masking_2[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_2 (Glo (None, 64)           0           transformer_encoder_2[0][0]      
                                                                 transformer_encoder_2[1][0]      
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 512)          33280       global_average_pooling1d_2[0][0] 
                                                                 global_average_pooling1d_2[1][0] 
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 10)           110         dense_38[0][0]                   
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 450)          230850      dense_36[0][0]                   
                                                                 dense_36[1][0]                   
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 5)            55          dense_39[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 905)          0           dense_37[0][0]                   
                                                                 dense_37[1][0]                   
                                                                 dense_40[0][0]                   
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 700)          634200      concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 560)          392560      dense_41[0][0]                   
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 373)          209253      dense_45[0][0]                   
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 187)          69938       dense_46[0][0]                   
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 1)            188         dense_47[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
41/41 - 6s - loss: 0.1395 - mae: 0.3454 - val_loss: 0.1228 - val_mae: 0.3728
Epoch 2/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3161 - val_loss: 0.1146 - val_mae: 0.3532
Epoch 3/5000
41/41 - 1s - loss: 0.1217 - mae: 0.3027 - val_loss: 0.1112 - val_mae: 0.3438
Epoch 4/5000
41/41 - 1s - loss: 0.1182 - mae: 0.2944 - val_loss: 0.1081 - val_mae: 0.3332
Epoch 5/5000
41/41 - 1s - loss: 0.1151 - mae: 0.2878 - val_loss: 0.1029 - val_mae: 0.3136
Epoch 6/5000
41/41 - 1s - loss: 0.1125 - mae: 0.2812 - val_loss: 0.0997 - val_mae: 0.3039
Epoch 7/5000
41/41 - 1s - loss: 0.1102 - mae: 0.2759 - val_loss: 0.1000 - val_mae: 0.3055
Epoch 8/5000
41/41 - 1s - loss: 0.1091 - mae: 0.2738 - val_loss: 0.0978 - val_mae: 0.3073
Epoch 9/5000
41/41 - 1s - loss: 0.1082 - mae: 0.2721 - val_loss: 0.0955 - val_mae: 0.3016
Epoch 10/5000
41/41 - 1s - loss: 0.1062 - mae: 0.2678 - val_loss: 0.0888 - val_mae: 0.2774
Epoch 11/5000
41/41 - 1s - loss: 0.1044 - mae: 0.2640 - val_loss: 0.0875 - val_mae: 0.2741
Epoch 12/5000
41/41 - 1s - loss: 0.1026 - mae: 0.2598 - val_loss: 0.0936 - val_mae: 0.3024
Epoch 13/5000
41/41 - 1s - loss: 0.1030 - mae: 0.2614 - val_loss: 0.1089 - val_mae: 0.3461
Epoch 14/5000
41/41 - 1s - loss: 0.1049 - mae: 0.2669 - val_loss: 0.1164 - val_mae: 0.3602
Epoch 15/5000
41/41 - 1s - loss: 0.1071 - mae: 0.2683 - val_loss: 0.1405 - val_mae: 0.4135
Epoch 16/5000
41/41 - 1s - loss: 0.1124 - mae: 0.2872 - val_loss: 0.1059 - val_mae: 0.3323
Epoch 17/5000
41/41 - 1s - loss: 0.1016 - mae: 0.2606 - val_loss: 0.1082 - val_mae: 0.3349
Epoch 18/5000
41/41 - 1s - loss: 0.1009 - mae: 0.2590 - val_loss: 0.1062 - val_mae: 0.3278
Epoch 19/5000
41/41 - 1s - loss: 0.0972 - mae: 0.2503 - val_loss: 0.1067 - val_mae: 0.3315
Epoch 20/5000
41/41 - 1s - loss: 0.0961 - mae: 0.2482 - val_loss: 0.1048 - val_mae: 0.3253
Epoch 21/5000
41/41 - 1s - loss: 0.0939 - mae: 0.2426 - val_loss: 0.1040 - val_mae: 0.3247
Epoch 22/5000
41/41 - 1s - loss: 0.0921 - mae: 0.2387 - val_loss: 0.1060 - val_mae: 0.3295
Epoch 23/5000
41/41 - 1s - loss: 0.0908 - mae: 0.2353 - val_loss: 0.1072 - val_mae: 0.3282
Epoch 24/5000
41/41 - 1s - loss: 0.0896 - mae: 0.2328 - val_loss: 0.1089 - val_mae: 0.3284
Epoch 25/5000
41/41 - 1s - loss: 0.0900 - mae: 0.2341 - val_loss: 0.1100 - val_mae: 0.3333
Epoch 26/5000
41/41 - 1s - loss: 0.0911 - mae: 0.2364 - val_loss: 0.1169 - val_mae: 0.3469
Epoch 27/5000
41/41 - 1s - loss: 0.0909 - mae: 0.2343 - val_loss: 0.1189 - val_mae: 0.3518
Epoch 28/5000
41/41 - 1s - loss: 0.0940 - mae: 0.2427 - val_loss: 0.1008 - val_mae: 0.3027
Epoch 29/5000
41/41 - 1s - loss: 0.0921 - mae: 0.2405 - val_loss: 0.0969 - val_mae: 0.2973
Epoch 30/5000
41/41 - 1s - loss: 0.0870 - mae: 0.2257 - val_loss: 0.1009 - val_mae: 0.3084
Epoch 31/5000
41/41 - 1s - loss: 0.0847 - mae: 0.2202 - val_loss: 0.1033 - val_mae: 0.3168
Epoch 32/5000
41/41 - 1s - loss: 0.0832 - mae: 0.2169 - val_loss: 0.1141 - val_mae: 0.3415
Epoch 33/5000
41/41 - 1s - loss: 0.0831 - mae: 0.2169 - val_loss: 0.1319 - val_mae: 0.3773
Epoch 34/5000
41/41 - 1s - loss: 0.0843 - mae: 0.2211 - val_loss: 0.1486 - val_mae: 0.4148
Epoch 35/5000
41/41 - 1s - loss: 0.0849 - mae: 0.2230 - val_loss: 0.1698 - val_mae: 0.4450
Epoch 36/5000
41/41 - 1s - loss: 0.0876 - mae: 0.2297 - val_loss: 0.1438 - val_mae: 0.3870
Epoch 37/5000
41/41 - 1s - loss: 0.0949 - mae: 0.2515 - val_loss: 0.1301 - val_mae: 0.3864
Epoch 38/5000
41/41 - 1s - loss: 0.0852 - mae: 0.2266 - val_loss: 0.1567 - val_mae: 0.4360
Epoch 39/5000
41/41 - 1s - loss: 0.0851 - mae: 0.2289 - val_loss: 0.1412 - val_mae: 0.4040
Epoch 40/5000
41/41 - 1s - loss: 0.0845 - mae: 0.2249 - val_loss: 0.1596 - val_mae: 0.4405
Epoch 41/5000
41/41 - 1s - loss: 0.0849 - mae: 0.2279 - val_loss: 0.1522 - val_mae: 0.4252
Epoch 42/5000
41/41 - 1s - loss: 0.0873 - mae: 0.2341 - val_loss: 0.1565 - val_mae: 0.4406
Epoch 43/5000
41/41 - 1s - loss: 0.0926 - mae: 0.2480 - val_loss: 0.1041 - val_mae: 0.3320
Epoch 44/5000
41/41 - 1s - loss: 0.0979 - mae: 0.2592 - val_loss: 0.0932 - val_mae: 0.2687
Epoch 45/5000
41/41 - 1s - loss: 0.0881 - mae: 0.2381 - val_loss: 0.0884 - val_mae: 0.2582
Epoch 46/5000
41/41 - 1s - loss: 0.0787 - mae: 0.2149 - val_loss: 0.0955 - val_mae: 0.2879
Epoch 47/5000
41/41 - 1s - loss: 0.0760 - mae: 0.2069 - val_loss: 0.0974 - val_mae: 0.2975
Epoch 48/5000
41/41 - 1s - loss: 0.0751 - mae: 0.2044 - val_loss: 0.0933 - val_mae: 0.2873
Epoch 49/5000
41/41 - 1s - loss: 0.0738 - mae: 0.2018 - val_loss: 0.0919 - val_mae: 0.2853
Epoch 50/5000
41/41 - 1s - loss: 0.0724 - mae: 0.1985 - val_loss: 0.0909 - val_mae: 0.2856
Epoch 51/5000
41/41 - 1s - loss: 0.0712 - mae: 0.1965 - val_loss: 0.0894 - val_mae: 0.2839
Epoch 52/5000
41/41 - 1s - loss: 0.0703 - mae: 0.1951 - val_loss: 0.0877 - val_mae: 0.2733
Epoch 53/5000
41/41 - 1s - loss: 0.0690 - mae: 0.1920 - val_loss: 0.0853 - val_mae: 0.2639
Epoch 54/5000
41/41 - 1s - loss: 0.0669 - mae: 0.1893 - val_loss: 0.0923 - val_mae: 0.2810
Epoch 55/5000
41/41 - 1s - loss: 0.0652 - mae: 0.1869 - val_loss: 0.1025 - val_mae: 0.3023
Epoch 56/5000
41/41 - 1s - loss: 0.0649 - mae: 0.1860 - val_loss: 0.1053 - val_mae: 0.3135
Epoch 57/5000
41/41 - 1s - loss: 0.0649 - mae: 0.1866 - val_loss: 0.0973 - val_mae: 0.2975
Epoch 58/5000
41/41 - 1s - loss: 0.0639 - mae: 0.1850 - val_loss: 0.0912 - val_mae: 0.2734
Epoch 59/5000
41/41 - 1s - loss: 0.0639 - mae: 0.1877 - val_loss: 0.0880 - val_mae: 0.2512
Epoch 60/5000
41/41 - 1s - loss: 0.0653 - mae: 0.1950 - val_loss: 0.0928 - val_mae: 0.2670
Epoch 61/5000
41/41 - 1s - loss: 0.0663 - mae: 0.1985 - val_loss: 0.1038 - val_mae: 0.3118
Epoch 62/5000
41/41 - 1s - loss: 0.0717 - mae: 0.2104 - val_loss: 0.1123 - val_mae: 0.3312
Epoch 63/5000
41/41 - 1s - loss: 0.0727 - mae: 0.2186 - val_loss: 0.1364 - val_mae: 0.3756
Epoch 64/5000
41/41 - 1s - loss: 0.0722 - mae: 0.2132 - val_loss: 0.1177 - val_mae: 0.3590
Epoch 65/5000
41/41 - 1s - loss: 0.0703 - mae: 0.2096 - val_loss: 0.0973 - val_mae: 0.2886
Epoch 66/5000
41/41 - 1s - loss: 0.0624 - mae: 0.1923 - val_loss: 0.1078 - val_mae: 0.3122
Epoch 67/5000
41/41 - 1s - loss: 0.0602 - mae: 0.1867 - val_loss: 0.0960 - val_mae: 0.2811
Epoch 68/5000
41/41 - 1s - loss: 0.0590 - mae: 0.1841 - val_loss: 0.1070 - val_mae: 0.3061
Epoch 69/5000
41/41 - 1s - loss: 0.0595 - mae: 0.1855 - val_loss: 0.0978 - val_mae: 0.2804
Epoch 70/5000
41/41 - 1s - loss: 0.0583 - mae: 0.1832 - val_loss: 0.1111 - val_mae: 0.3095
Epoch 71/5000
41/41 - 1s - loss: 0.0583 - mae: 0.1842 - val_loss: 0.1102 - val_mae: 0.3155
Epoch 72/5000
41/41 - 1s - loss: 0.0593 - mae: 0.1877 - val_loss: 0.0995 - val_mae: 0.3056
Epoch 73/5000
41/41 - 1s - loss: 0.0611 - mae: 0.1935 - val_loss: 0.0996 - val_mae: 0.3068
Epoch 74/5000
41/41 - 1s - loss: 0.0649 - mae: 0.2057 - val_loss: 0.1071 - val_mae: 0.3119
Epoch 75/5000
41/41 - 1s - loss: 0.0638 - mae: 0.2046 - val_loss: 0.0962 - val_mae: 0.2895
Epoch 76/5000
41/41 - 1s - loss: 0.0730 - mae: 0.2195 - val_loss: 0.1047 - val_mae: 0.3171
Epoch 77/5000
41/41 - 1s - loss: 0.0666 - mae: 0.2072 - val_loss: 0.0995 - val_mae: 0.2964
Epoch 78/5000
41/41 - 1s - loss: 0.0630 - mae: 0.2020 - val_loss: 0.0880 - val_mae: 0.2554
Epoch 79/5000
41/41 - 1s - loss: 0.0668 - mae: 0.2094 - val_loss: 0.0892 - val_mae: 0.2522
Epoch 80/5000
41/41 - 1s - loss: 0.0711 - mae: 0.2190 - val_loss: 0.1001 - val_mae: 0.2542
Epoch 81/5000
41/41 - 1s - loss: 0.0887 - mae: 0.2565 - val_loss: 0.1139 - val_mae: 0.2676
Epoch 82/5000
41/41 - 1s - loss: 0.0901 - mae: 0.2560 - val_loss: 0.1043 - val_mae: 0.2543
Epoch 83/5000
41/41 - 1s - loss: 0.0848 - mae: 0.2448 - val_loss: 0.1069 - val_mae: 0.2576
Epoch 84/5000
41/41 - 1s - loss: 0.0786 - mae: 0.2322 - val_loss: 0.1035 - val_mae: 0.2554
Epoch 85/5000
41/41 - 1s - loss: 0.0696 - mae: 0.2122 - val_loss: 0.0986 - val_mae: 0.2457
Epoch 86/5000
41/41 - 1s - loss: 0.0625 - mae: 0.1970 - val_loss: 0.0957 - val_mae: 0.2428
Epoch 87/5000
41/41 - 1s - loss: 0.0581 - mae: 0.1853 - val_loss: 0.0957 - val_mae: 0.2408
Epoch 88/5000
41/41 - 1s - loss: 0.0593 - mae: 0.1877 - val_loss: 0.1006 - val_mae: 0.2471
Epoch 89/5000
41/41 - 1s - loss: 0.0624 - mae: 0.1946 - val_loss: 0.1019 - val_mae: 0.2543
Epoch 90/5000
41/41 - 1s - loss: 0.0669 - mae: 0.2079 - val_loss: 0.0979 - val_mae: 0.2460
Epoch 91/5000
41/41 - 1s - loss: 0.0619 - mae: 0.1938 - val_loss: 0.0931 - val_mae: 0.2374
Epoch 92/5000
41/41 - 1s - loss: 0.0587 - mae: 0.1907 - val_loss: 0.0886 - val_mae: 0.2412
Epoch 93/5000
41/41 - 1s - loss: 0.0493 - mae: 0.1635 - val_loss: 0.0897 - val_mae: 0.2474
Epoch 94/5000
41/41 - 1s - loss: 0.0471 - mae: 0.1561 - val_loss: 0.0927 - val_mae: 0.2398
Epoch 95/5000
41/41 - 1s - loss: 0.0478 - mae: 0.1647 - val_loss: 0.0894 - val_mae: 0.2392
Epoch 96/5000
41/41 - 1s - loss: 0.0480 - mae: 0.1624 - val_loss: 0.0951 - val_mae: 0.2456
Epoch 97/5000
41/41 - 1s - loss: 0.0485 - mae: 0.1672 - val_loss: 0.0903 - val_mae: 0.2354
Epoch 98/5000
41/41 - 1s - loss: 0.0472 - mae: 0.1621 - val_loss: 0.0929 - val_mae: 0.2378
Epoch 99/5000
41/41 - 1s - loss: 0.0466 - mae: 0.1608 - val_loss: 0.0962 - val_mae: 0.2463
Epoch 100/5000
41/41 - 1s - loss: 0.0455 - mae: 0.1597 - val_loss: 0.0940 - val_mae: 0.2410
Epoch 101/5000
41/41 - 1s - loss: 0.0472 - mae: 0.1632 - val_loss: 0.0935 - val_mae: 0.2440
Epoch 102/5000
41/41 - 1s - loss: 0.0450 - mae: 0.1576 - val_loss: 0.0997 - val_mae: 0.2554
Epoch 103/5000
41/41 - 1s - loss: 0.0459 - mae: 0.1603 - val_loss: 0.0931 - val_mae: 0.2394
Epoch 104/5000
41/41 - 1s - loss: 0.0472 - mae: 0.1616 - val_loss: 0.0965 - val_mae: 0.2474
Epoch 105/5000
41/41 - 1s - loss: 0.0484 - mae: 0.1666 - val_loss: 0.0984 - val_mae: 0.2526
Epoch 106/5000
41/41 - 1s - loss: 0.0480 - mae: 0.1657 - val_loss: 0.0956 - val_mae: 0.2450
Epoch 107/5000
41/41 - 1s - loss: 0.0491 - mae: 0.1685 - val_loss: 0.0926 - val_mae: 0.2395
Epoch 108/5000
41/41 - 1s - loss: 0.0523 - mae: 0.1765 - val_loss: 0.0934 - val_mae: 0.2423
Epoch 109/5000
41/41 - 1s - loss: 0.0536 - mae: 0.1811 - val_loss: 0.0868 - val_mae: 0.2469
Epoch 110/5000
41/41 - 1s - loss: 0.0529 - mae: 0.1783 - val_loss: 0.0963 - val_mae: 0.2675
Epoch 111/5000
41/41 - 1s - loss: 0.0487 - mae: 0.1677 - val_loss: 0.0990 - val_mae: 0.2825
Epoch 112/5000
41/41 - 1s - loss: 0.0435 - mae: 0.1546 - val_loss: 0.0967 - val_mae: 0.2663
Epoch 113/5000
41/41 - 1s - loss: 0.0396 - mae: 0.1441 - val_loss: 0.0961 - val_mae: 0.2653
Epoch 114/5000
41/41 - 1s - loss: 0.0374 - mae: 0.1353 - val_loss: 0.0942 - val_mae: 0.2577
Epoch 115/5000
41/41 - 1s - loss: 0.0381 - mae: 0.1350 - val_loss: 0.0937 - val_mae: 0.2530
Epoch 116/5000
41/41 - 1s - loss: 0.0372 - mae: 0.1382 - val_loss: 0.0933 - val_mae: 0.2574
Epoch 117/5000
41/41 - 1s - loss: 0.0368 - mae: 0.1344 - val_loss: 0.0942 - val_mae: 0.2568
Epoch 118/5000
41/41 - 1s - loss: 0.0354 - mae: 0.1320 - val_loss: 0.0927 - val_mae: 0.2484
Epoch 119/5000
41/41 - 1s - loss: 0.0357 - mae: 0.1347 - val_loss: 0.0964 - val_mae: 0.2619
Epoch 120/5000
41/41 - 1s - loss: 0.0364 - mae: 0.1331 - val_loss: 0.0965 - val_mae: 0.2535
Epoch 121/5000
41/41 - 1s - loss: 0.0375 - mae: 0.1404 - val_loss: 0.0941 - val_mae: 0.2535
Epoch 122/5000
41/41 - 1s - loss: 0.0358 - mae: 0.1315 - val_loss: 0.0977 - val_mae: 0.2528
Epoch 123/5000
41/41 - 1s - loss: 0.0379 - mae: 0.1411 - val_loss: 0.0914 - val_mae: 0.2454
Epoch 124/5000
41/41 - 1s - loss: 0.0332 - mae: 0.1275 - val_loss: 0.0936 - val_mae: 0.2532
Epoch 125/5000
41/41 - 1s - loss: 0.0339 - mae: 0.1312 - val_loss: 0.0914 - val_mae: 0.2438
Epoch 126/5000
41/41 - 1s - loss: 0.0341 - mae: 0.1288 - val_loss: 0.0966 - val_mae: 0.2517
Epoch 127/5000
41/41 - 1s - loss: 0.0359 - mae: 0.1340 - val_loss: 0.0956 - val_mae: 0.2482
Epoch 128/5000
41/41 - 1s - loss: 0.0372 - mae: 0.1343 - val_loss: 0.0937 - val_mae: 0.2406
Epoch 129/5000
41/41 - 1s - loss: 0.0372 - mae: 0.1424 - val_loss: 0.0981 - val_mae: 0.2609
Epoch 130/5000
41/41 - 1s - loss: 0.0342 - mae: 0.1324 - val_loss: 0.0981 - val_mae: 0.2549
Epoch 131/5000
41/41 - 1s - loss: 0.0352 - mae: 0.1340 - val_loss: 0.0983 - val_mae: 0.2494
Epoch 132/5000
41/41 - 1s - loss: 0.0307 - mae: 0.1235 - val_loss: 0.0975 - val_mae: 0.2561
Epoch 133/5000
41/41 - 1s - loss: 0.0299 - mae: 0.1204 - val_loss: 0.1013 - val_mae: 0.2637
Epoch 134/5000
41/41 - 1s - loss: 0.0302 - mae: 0.1241 - val_loss: 0.0983 - val_mae: 0.2569
Epoch 135/5000
41/41 - 1s - loss: 0.0274 - mae: 0.1144 - val_loss: 0.0970 - val_mae: 0.2564
Epoch 136/5000
41/41 - 1s - loss: 0.0306 - mae: 0.1233 - val_loss: 0.0971 - val_mae: 0.2538
Epoch 137/5000
41/41 - 1s - loss: 0.0318 - mae: 0.1274 - val_loss: 0.0934 - val_mae: 0.2485
Epoch 138/5000
41/41 - 1s - loss: 0.0301 - mae: 0.1223 - val_loss: 0.1036 - val_mae: 0.2792
Epoch 139/5000
41/41 - 1s - loss: 0.0313 - mae: 0.1283 - val_loss: 0.0966 - val_mae: 0.2549
Epoch 140/5000
41/41 - 1s - loss: 0.0294 - mae: 0.1192 - val_loss: 0.0932 - val_mae: 0.2487
Epoch 141/5000
41/41 - 1s - loss: 0.0295 - mae: 0.1182 - val_loss: 0.1086 - val_mae: 0.2829
Epoch 142/5000
41/41 - 1s - loss: 0.0312 - mae: 0.1257 - val_loss: 0.0929 - val_mae: 0.2512
Epoch 143/5000
41/41 - 1s - loss: 0.0292 - mae: 0.1177 - val_loss: 0.1049 - val_mae: 0.2783
Epoch 144/5000
41/41 - 1s - loss: 0.0269 - mae: 0.1127 - val_loss: 0.1123 - val_mae: 0.2944
Epoch 145/5000
41/41 - 1s - loss: 0.0330 - mae: 0.1346 - val_loss: 0.1013 - val_mae: 0.2697
Epoch 146/5000
41/41 - 1s - loss: 0.0295 - mae: 0.1235 - val_loss: 0.1142 - val_mae: 0.3036
Epoch 147/5000
41/41 - 1s - loss: 0.0311 - mae: 0.1304 - val_loss: 0.1175 - val_mae: 0.3006
Epoch 148/5000
41/41 - 1s - loss: 0.0265 - mae: 0.1159 - val_loss: 0.1103 - val_mae: 0.2928
Epoch 149/5000
41/41 - 1s - loss: 0.0320 - mae: 0.1307 - val_loss: 0.1088 - val_mae: 0.2859
Epoch 150/5000
41/41 - 1s - loss: 0.0294 - mae: 0.1274 - val_loss: 0.1123 - val_mae: 0.3020
Epoch 151/5000
41/41 - 1s - loss: 0.0314 - mae: 0.1329 - val_loss: 0.1065 - val_mae: 0.2854
Epoch 152/5000
41/41 - 1s - loss: 0.0275 - mae: 0.1217 - val_loss: 0.1067 - val_mae: 0.2827
Epoch 153/5000
41/41 - 1s - loss: 0.0307 - mae: 0.1287 - val_loss: 0.1026 - val_mae: 0.2824
Epoch 154/5000
41/41 - 1s - loss: 0.0293 - mae: 0.1251 - val_loss: 0.0981 - val_mae: 0.2628
Epoch 155/5000
41/41 - 1s - loss: 0.0317 - mae: 0.1322 - val_loss: 0.0987 - val_mae: 0.2711
Epoch 156/5000
41/41 - 1s - loss: 0.0292 - mae: 0.1290 - val_loss: 0.0984 - val_mae: 0.2557
Epoch 157/5000
41/41 - 1s - loss: 0.0305 - mae: 0.1292 - val_loss: 0.0937 - val_mae: 0.2431
Epoch 158/5000
41/41 - 1s - loss: 0.0298 - mae: 0.1327 - val_loss: 0.0967 - val_mae: 0.2451
Epoch 159/5000
41/41 - 1s - loss: 0.0415 - mae: 0.1550 - val_loss: 0.0966 - val_mae: 0.2530
Epoch 160/5000
41/41 - 1s - loss: 0.0392 - mae: 0.1590 - val_loss: 0.1016 - val_mae: 0.2675
Epoch 161/5000
41/41 - 1s - loss: 0.0453 - mae: 0.1750 - val_loss: 0.0910 - val_mae: 0.2433
Epoch 162/5000
41/41 - 1s - loss: 0.0376 - mae: 0.1511 - val_loss: 0.0917 - val_mae: 0.2436
Epoch 163/5000
41/41 - 1s - loss: 0.0351 - mae: 0.1474 - val_loss: 0.0944 - val_mae: 0.2510
Epoch 164/5000
41/41 - 1s - loss: 0.0371 - mae: 0.1513 - val_loss: 0.0895 - val_mae: 0.2423
Epoch 165/5000
41/41 - 1s - loss: 0.0304 - mae: 0.1280 - val_loss: 0.0988 - val_mae: 0.2674
Epoch 166/5000
41/41 - 1s - loss: 0.0331 - mae: 0.1360 - val_loss: 0.1006 - val_mae: 0.2837
Epoch 167/5000
41/41 - 1s - loss: 0.0288 - mae: 0.1236 - val_loss: 0.1038 - val_mae: 0.2926
Epoch 168/5000
41/41 - 1s - loss: 0.0284 - mae: 0.1221 - val_loss: 0.1132 - val_mae: 0.3017
Epoch 169/5000
41/41 - 1s - loss: 0.0270 - mae: 0.1143 - val_loss: 0.1040 - val_mae: 0.2820
Epoch 170/5000
41/41 - 1s - loss: 0.0255 - mae: 0.1139 - val_loss: 0.1043 - val_mae: 0.2747
Epoch 171/5000
41/41 - 1s - loss: 0.0247 - mae: 0.1125 - val_loss: 0.1061 - val_mae: 0.2715
Epoch 172/5000
41/41 - 1s - loss: 0.0209 - mae: 0.1019 - val_loss: 0.0994 - val_mae: 0.2587
Epoch 173/5000
41/41 - 1s - loss: 0.0212 - mae: 0.1008 - val_loss: 0.0977 - val_mae: 0.2538
Epoch 174/5000
41/41 - 1s - loss: 0.0205 - mae: 0.1018 - val_loss: 0.0960 - val_mae: 0.2538
Epoch 175/5000
41/41 - 1s - loss: 0.0200 - mae: 0.1036 - val_loss: 0.0934 - val_mae: 0.2497
Epoch 176/5000
41/41 - 1s - loss: 0.0226 - mae: 0.1036 - val_loss: 0.0985 - val_mae: 0.2626
Epoch 177/5000
41/41 - 1s - loss: 0.0217 - mae: 0.1087 - val_loss: 0.0964 - val_mae: 0.2572
Epoch 178/5000
41/41 - 1s - loss: 0.0214 - mae: 0.1063 - val_loss: 0.1025 - val_mae: 0.2743
Epoch 179/5000
41/41 - 1s - loss: 0.0189 - mae: 0.1024 - val_loss: 0.1030 - val_mae: 0.2799
Epoch 180/5000
41/41 - 1s - loss: 0.0237 - mae: 0.1136 - val_loss: 0.1083 - val_mae: 0.2885
Epoch 181/5000
41/41 - 1s - loss: 0.0211 - mae: 0.1047 - val_loss: 0.1093 - val_mae: 0.3032
Epoch 182/5000
41/41 - 1s - loss: 0.0223 - mae: 0.1109 - val_loss: 0.1134 - val_mae: 0.2998
Epoch 183/5000
41/41 - 1s - loss: 0.0224 - mae: 0.1097 - val_loss: 0.1093 - val_mae: 0.2917
Epoch 184/5000
41/41 - 1s - loss: 0.0195 - mae: 0.1058 - val_loss: 0.0988 - val_mae: 0.2748
Epoch 185/5000
41/41 - 1s - loss: 0.0251 - mae: 0.1217 - val_loss: 0.1058 - val_mae: 0.2812
Epoch 186/5000
41/41 - 1s - loss: 0.0226 - mae: 0.1154 - val_loss: 0.0946 - val_mae: 0.2587
Epoch 187/5000
41/41 - 1s - loss: 0.0235 - mae: 0.1214 - val_loss: 0.0959 - val_mae: 0.2492
Epoch 188/5000
41/41 - 1s - loss: 0.0220 - mae: 0.1171 - val_loss: 0.0945 - val_mae: 0.2400
Epoch 189/5000
41/41 - 1s - loss: 0.0269 - mae: 0.1386 - val_loss: 0.0959 - val_mae: 0.2507
Epoch 190/5000
41/41 - 1s - loss: 0.0310 - mae: 0.1455 - val_loss: 0.0930 - val_mae: 0.2548
Epoch 191/5000
41/41 - 1s - loss: 0.0294 - mae: 0.1348 - val_loss: 0.1018 - val_mae: 0.2866
Epoch 192/5000
41/41 - 1s - loss: 0.0226 - mae: 0.1109 - val_loss: 0.0994 - val_mae: 0.2754
Epoch 193/5000
41/41 - 1s - loss: 0.0193 - mae: 0.1005 - val_loss: 0.1025 - val_mae: 0.2776
Epoch 194/5000
41/41 - 1s - loss: 0.0194 - mae: 0.0969 - val_loss: 0.1000 - val_mae: 0.2702
Epoch 195/5000
41/41 - 1s - loss: 0.0187 - mae: 0.0952 - val_loss: 0.1032 - val_mae: 0.2715
Epoch 196/5000
41/41 - 1s - loss: 0.0171 - mae: 0.0940 - val_loss: 0.0984 - val_mae: 0.2601
Epoch 197/5000
41/41 - 1s - loss: 0.0203 - mae: 0.0999 - val_loss: 0.0981 - val_mae: 0.2671
Epoch 198/5000
41/41 - 1s - loss: 0.0146 - mae: 0.0892 - val_loss: 0.0973 - val_mae: 0.2565
Restoring model weights from the end of the best epoch.
Epoch 00198: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_2..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 3

Generating graphs from SMILES..

Setting up training set.
Size: 2057

Setting up validation set.
Size: 229

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_19"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_3 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_3 (PartitionP (None, None, 64)     0           message_passing_3[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_3[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_3 (Masking)             (None, None, 64)     0           partition_padding_3[0][0]        
                                                                 partition_padding_3[1][0]        
__________________________________________________________________________________________________
transformer_encoder_3 (Transfor (None, None, 64)     199040      masking_3[0][0]                  
                                                                 masking_3[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_3 (Glo (None, 64)           0           transformer_encoder_3[0][0]      
                                                                 transformer_encoder_3[1][0]      
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 512)          33280       global_average_pooling1d_3[0][0] 
                                                                 global_average_pooling1d_3[1][0] 
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 10)           110         dense_55[0][0]                   
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 450)          230850      dense_53[0][0]                   
                                                                 dense_53[1][0]                   
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 5)            55          dense_56[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 905)          0           dense_54[0][0]                   
                                                                 dense_54[1][0]                   
                                                                 dense_57[0][0]                   
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 700)          634200      concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 560)          392560      dense_58[0][0]                   
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 373)          209253      dense_62[0][0]                   
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 187)          69938       dense_63[0][0]                   
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 1)            188         dense_64[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
41/41 - 5s - loss: 0.3153 - mae: 0.6337 - val_loss: 0.1718 - val_mae: 0.4180
Epoch 2/5000
41/41 - 1s - loss: 0.1602 - mae: 0.4017 - val_loss: 0.1714 - val_mae: 0.4269
Epoch 3/5000
41/41 - 1s - loss: 0.1590 - mae: 0.4001 - val_loss: 0.1688 - val_mae: 0.4027
Epoch 4/5000
41/41 - 1s - loss: 0.1581 - mae: 0.3968 - val_loss: 0.1681 - val_mae: 0.3964
Epoch 5/5000
41/41 - 1s - loss: 0.1563 - mae: 0.3930 - val_loss: 0.1668 - val_mae: 0.3920
Epoch 6/5000
41/41 - 1s - loss: 0.1553 - mae: 0.3907 - val_loss: 0.1653 - val_mae: 0.3930
Epoch 7/5000
41/41 - 1s - loss: 0.1543 - mae: 0.3880 - val_loss: 0.1644 - val_mae: 0.3851
Epoch 8/5000
41/41 - 1s - loss: 0.1568 - mae: 0.3939 - val_loss: 0.1636 - val_mae: 0.3840
Epoch 9/5000
41/41 - 1s - loss: 0.1529 - mae: 0.3834 - val_loss: 0.1634 - val_mae: 0.3834
Epoch 10/5000
41/41 - 1s - loss: 0.1528 - mae: 0.3845 - val_loss: 0.1629 - val_mae: 0.3728
Epoch 11/5000
41/41 - 1s - loss: 0.1507 - mae: 0.3802 - val_loss: 0.1622 - val_mae: 0.3712
Epoch 12/5000
41/41 - 1s - loss: 0.1502 - mae: 0.3789 - val_loss: 0.1619 - val_mae: 0.3668
Epoch 13/5000
41/41 - 1s - loss: 0.1495 - mae: 0.3774 - val_loss: 0.1621 - val_mae: 0.3650
Epoch 14/5000
41/41 - 1s - loss: 0.1493 - mae: 0.3766 - val_loss: 0.1622 - val_mae: 0.3623
Epoch 15/5000
41/41 - 1s - loss: 0.1474 - mae: 0.3721 - val_loss: 0.1605 - val_mae: 0.3673
Epoch 16/5000
41/41 - 1s - loss: 0.1477 - mae: 0.3730 - val_loss: 0.1625 - val_mae: 0.3720
Epoch 17/5000
41/41 - 1s - loss: 0.1490 - mae: 0.3778 - val_loss: 0.1613 - val_mae: 0.3601
Epoch 18/5000
41/41 - 1s - loss: 0.1452 - mae: 0.3663 - val_loss: 0.1592 - val_mae: 0.3685
Epoch 19/5000
41/41 - 1s - loss: 0.1438 - mae: 0.3640 - val_loss: 0.1580 - val_mae: 0.3660
Epoch 20/5000
41/41 - 1s - loss: 0.1467 - mae: 0.3732 - val_loss: 0.1619 - val_mae: 0.3574
Epoch 21/5000
41/41 - 1s - loss: 0.1444 - mae: 0.3634 - val_loss: 0.1590 - val_mae: 0.3680
Epoch 22/5000
41/41 - 1s - loss: 0.1440 - mae: 0.3661 - val_loss: 0.1607 - val_mae: 0.3565
Epoch 23/5000
41/41 - 1s - loss: 0.1408 - mae: 0.3550 - val_loss: 0.1573 - val_mae: 0.3885
Epoch 24/5000
41/41 - 1s - loss: 0.1428 - mae: 0.3631 - val_loss: 0.1549 - val_mae: 0.3658
Epoch 25/5000
41/41 - 1s - loss: 0.1396 - mae: 0.3524 - val_loss: 0.1543 - val_mae: 0.3671
Epoch 26/5000
41/41 - 1s - loss: 0.1426 - mae: 0.3626 - val_loss: 0.1561 - val_mae: 0.3730
Epoch 27/5000
41/41 - 1s - loss: 0.1407 - mae: 0.3543 - val_loss: 0.1568 - val_mae: 0.3669
Epoch 28/5000
41/41 - 1s - loss: 0.1425 - mae: 0.3626 - val_loss: 0.1552 - val_mae: 0.3764
Epoch 29/5000
41/41 - 1s - loss: 0.1401 - mae: 0.3542 - val_loss: 0.1641 - val_mae: 0.4250
Epoch 30/5000
41/41 - 1s - loss: 0.1385 - mae: 0.3506 - val_loss: 0.1554 - val_mae: 0.3862
Epoch 31/5000
41/41 - 1s - loss: 0.1381 - mae: 0.3509 - val_loss: 0.1544 - val_mae: 0.3931
Epoch 32/5000
41/41 - 1s - loss: 0.1372 - mae: 0.3486 - val_loss: 0.1524 - val_mae: 0.3611
Epoch 33/5000
41/41 - 1s - loss: 0.1399 - mae: 0.3538 - val_loss: 0.1685 - val_mae: 0.4538
Epoch 34/5000
41/41 - 1s - loss: 0.1425 - mae: 0.3612 - val_loss: 0.1737 - val_mae: 0.4605
Epoch 35/5000
41/41 - 1s - loss: 0.1391 - mae: 0.3526 - val_loss: 0.1552 - val_mae: 0.3884
Epoch 36/5000
41/41 - 1s - loss: 0.1381 - mae: 0.3476 - val_loss: 0.1546 - val_mae: 0.3805
Epoch 37/5000
41/41 - 1s - loss: 0.1380 - mae: 0.3471 - val_loss: 0.1537 - val_mae: 0.3791
Epoch 38/5000
41/41 - 1s - loss: 0.1362 - mae: 0.3432 - val_loss: 0.1535 - val_mae: 0.3524
Epoch 39/5000
41/41 - 1s - loss: 0.1350 - mae: 0.3409 - val_loss: 0.1545 - val_mae: 0.3580
Epoch 40/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3413 - val_loss: 0.1528 - val_mae: 0.3472
Epoch 41/5000
41/41 - 1s - loss: 0.1355 - mae: 0.3429 - val_loss: 0.1543 - val_mae: 0.3694
Epoch 42/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3412 - val_loss: 0.1568 - val_mae: 0.3558
Epoch 43/5000
41/41 - 1s - loss: 0.1369 - mae: 0.3440 - val_loss: 0.1587 - val_mae: 0.3514
Epoch 44/5000
41/41 - 1s - loss: 0.1402 - mae: 0.3522 - val_loss: 0.1683 - val_mae: 0.4587
Epoch 45/5000
41/41 - 1s - loss: 0.1345 - mae: 0.3396 - val_loss: 0.1530 - val_mae: 0.3460
Epoch 46/5000
41/41 - 1s - loss: 0.1324 - mae: 0.3349 - val_loss: 0.1539 - val_mae: 0.3425
Epoch 47/5000
41/41 - 1s - loss: 0.1339 - mae: 0.3365 - val_loss: 0.1568 - val_mae: 0.3390
Epoch 48/5000
41/41 - 1s - loss: 0.1344 - mae: 0.3404 - val_loss: 0.1522 - val_mae: 0.3382
Epoch 49/5000
41/41 - 1s - loss: 0.1344 - mae: 0.3385 - val_loss: 0.1532 - val_mae: 0.3426
Epoch 50/5000
41/41 - 1s - loss: 0.1361 - mae: 0.3443 - val_loss: 0.1506 - val_mae: 0.3411
Epoch 51/5000
41/41 - 1s - loss: 0.1329 - mae: 0.3347 - val_loss: 0.1535 - val_mae: 0.3471
Epoch 52/5000
41/41 - 1s - loss: 0.1342 - mae: 0.3368 - val_loss: 0.1625 - val_mae: 0.3400
Epoch 53/5000
41/41 - 1s - loss: 0.1400 - mae: 0.3542 - val_loss: 0.1530 - val_mae: 0.3402
Epoch 54/5000
41/41 - 1s - loss: 0.1310 - mae: 0.3315 - val_loss: 0.1527 - val_mae: 0.3381
Epoch 55/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3370 - val_loss: 0.1481 - val_mae: 0.3486
Epoch 56/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3324 - val_loss: 0.1494 - val_mae: 0.3391
Epoch 57/5000
41/41 - 1s - loss: 0.1308 - mae: 0.3306 - val_loss: 0.1572 - val_mae: 0.3339
Epoch 58/5000
41/41 - 1s - loss: 0.1370 - mae: 0.3453 - val_loss: 0.1555 - val_mae: 0.3398
Epoch 59/5000
41/41 - 1s - loss: 0.1385 - mae: 0.3490 - val_loss: 0.1505 - val_mae: 0.3511
Epoch 60/5000
41/41 - 1s - loss: 0.1382 - mae: 0.3469 - val_loss: 0.1806 - val_mae: 0.4795
Epoch 61/5000
41/41 - 1s - loss: 0.1381 - mae: 0.3476 - val_loss: 0.2011 - val_mae: 0.5226
Epoch 62/5000
41/41 - 1s - loss: 0.1380 - mae: 0.3510 - val_loss: 0.1588 - val_mae: 0.4057
Epoch 63/5000
41/41 - 1s - loss: 0.1357 - mae: 0.3387 - val_loss: 0.1757 - val_mae: 0.4726
Epoch 64/5000
41/41 - 1s - loss: 0.1351 - mae: 0.3417 - val_loss: 0.1818 - val_mae: 0.4791
Epoch 65/5000
41/41 - 1s - loss: 0.1343 - mae: 0.3391 - val_loss: 0.1885 - val_mae: 0.4987
Epoch 66/5000
41/41 - 1s - loss: 0.1332 - mae: 0.3351 - val_loss: 0.1765 - val_mae: 0.4683
Epoch 67/5000
41/41 - 1s - loss: 0.1310 - mae: 0.3313 - val_loss: 0.1511 - val_mae: 0.3913
Epoch 68/5000
41/41 - 1s - loss: 0.1352 - mae: 0.3360 - val_loss: 0.1895 - val_mae: 0.5001
Epoch 69/5000
41/41 - 1s - loss: 0.1336 - mae: 0.3405 - val_loss: 0.1770 - val_mae: 0.4635
Epoch 70/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3301 - val_loss: 0.1715 - val_mae: 0.4540
Epoch 71/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3299 - val_loss: 0.1644 - val_mae: 0.4367
Epoch 72/5000
41/41 - 1s - loss: 0.1332 - mae: 0.3343 - val_loss: 0.1868 - val_mae: 0.4866
Epoch 73/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3337 - val_loss: 0.1844 - val_mae: 0.4890
Epoch 74/5000
41/41 - 1s - loss: 0.1324 - mae: 0.3341 - val_loss: 0.1923 - val_mae: 0.5042
Epoch 75/5000
41/41 - 1s - loss: 0.1328 - mae: 0.3336 - val_loss: 0.1809 - val_mae: 0.4793
Epoch 76/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3302 - val_loss: 0.1815 - val_mae: 0.4799
Epoch 77/5000
41/41 - 1s - loss: 0.1310 - mae: 0.3287 - val_loss: 0.1915 - val_mae: 0.5029
Epoch 78/5000
41/41 - 1s - loss: 0.1321 - mae: 0.3340 - val_loss: 0.1803 - val_mae: 0.4776
Epoch 79/5000
41/41 - 1s - loss: 0.1298 - mae: 0.3263 - val_loss: 0.1780 - val_mae: 0.4710
Epoch 80/5000
41/41 - 1s - loss: 0.1302 - mae: 0.3275 - val_loss: 0.1753 - val_mae: 0.4632
Epoch 81/5000
41/41 - 1s - loss: 0.1294 - mae: 0.3243 - val_loss: 0.1810 - val_mae: 0.4809
Epoch 82/5000
41/41 - 1s - loss: 0.1296 - mae: 0.3267 - val_loss: 0.1863 - val_mae: 0.4898
Epoch 83/5000
41/41 - 1s - loss: 0.1309 - mae: 0.3289 - val_loss: 0.1855 - val_mae: 0.4871
Epoch 84/5000
41/41 - 1s - loss: 0.1307 - mae: 0.3280 - val_loss: 0.1836 - val_mae: 0.4830
Epoch 85/5000
41/41 - 1s - loss: 0.1309 - mae: 0.3288 - val_loss: 0.1810 - val_mae: 0.4801
Epoch 86/5000
41/41 - 1s - loss: 0.1297 - mae: 0.3263 - val_loss: 0.1845 - val_mae: 0.4848
Epoch 87/5000
41/41 - 1s - loss: 0.1289 - mae: 0.3248 - val_loss: 0.1720 - val_mae: 0.4519
Epoch 88/5000
41/41 - 1s - loss: 0.1278 - mae: 0.3202 - val_loss: 0.1749 - val_mae: 0.4618
Epoch 89/5000
41/41 - 1s - loss: 0.1279 - mae: 0.3212 - val_loss: 0.1741 - val_mae: 0.4578
Epoch 90/5000
41/41 - 1s - loss: 0.1273 - mae: 0.3200 - val_loss: 0.1592 - val_mae: 0.4241
Epoch 91/5000
41/41 - 1s - loss: 0.1289 - mae: 0.3235 - val_loss: 0.1991 - val_mae: 0.5197
Epoch 92/5000
41/41 - 1s - loss: 0.1328 - mae: 0.3341 - val_loss: 0.1926 - val_mae: 0.5115
Epoch 93/5000
41/41 - 1s - loss: 0.1307 - mae: 0.3313 - val_loss: 0.1674 - val_mae: 0.4323
Epoch 94/5000
41/41 - 1s - loss: 0.1274 - mae: 0.3208 - val_loss: 0.1581 - val_mae: 0.4171
Epoch 95/5000
41/41 - 1s - loss: 0.1278 - mae: 0.3202 - val_loss: 0.1863 - val_mae: 0.4853
Epoch 96/5000
41/41 - 1s - loss: 0.1288 - mae: 0.3256 - val_loss: 0.1903 - val_mae: 0.4947
Epoch 97/5000
41/41 - 1s - loss: 0.1292 - mae: 0.3268 - val_loss: 0.1887 - val_mae: 0.4908
Epoch 98/5000
41/41 - 1s - loss: 0.1281 - mae: 0.3222 - val_loss: 0.1872 - val_mae: 0.4913
Epoch 99/5000
41/41 - 1s - loss: 0.1289 - mae: 0.3234 - val_loss: 0.1908 - val_mae: 0.4992
Epoch 100/5000
41/41 - 1s - loss: 0.1293 - mae: 0.3246 - val_loss: 0.1800 - val_mae: 0.4769
Epoch 101/5000
41/41 - 1s - loss: 0.1293 - mae: 0.3265 - val_loss: 0.1653 - val_mae: 0.4234
Epoch 102/5000
41/41 - 1s - loss: 0.1254 - mae: 0.3141 - val_loss: 0.1716 - val_mae: 0.4513
Epoch 103/5000
41/41 - 1s - loss: 0.1257 - mae: 0.3154 - val_loss: 0.1798 - val_mae: 0.4662
Epoch 104/5000
41/41 - 1s - loss: 0.1280 - mae: 0.3198 - val_loss: 0.1964 - val_mae: 0.5129
Epoch 105/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3330 - val_loss: 0.1823 - val_mae: 0.4763
Epoch 106/5000
41/41 - 1s - loss: 0.1276 - mae: 0.3232 - val_loss: 0.1736 - val_mae: 0.4527
Epoch 107/5000
41/41 - 1s - loss: 0.1259 - mae: 0.3154 - val_loss: 0.1795 - val_mae: 0.4679
Epoch 108/5000
41/41 - 1s - loss: 0.1250 - mae: 0.3124 - val_loss: 0.1796 - val_mae: 0.4672
Epoch 109/5000
41/41 - 1s - loss: 0.1250 - mae: 0.3129 - val_loss: 0.1900 - val_mae: 0.4957
Epoch 110/5000
41/41 - 1s - loss: 0.1285 - mae: 0.3231 - val_loss: 0.1820 - val_mae: 0.4753
Epoch 111/5000
41/41 - 1s - loss: 0.1254 - mae: 0.3151 - val_loss: 0.1765 - val_mae: 0.4575
Epoch 112/5000
41/41 - 1s - loss: 0.1251 - mae: 0.3137 - val_loss: 0.1912 - val_mae: 0.4966
Epoch 113/5000
41/41 - 1s - loss: 0.1263 - mae: 0.3187 - val_loss: 0.1796 - val_mae: 0.4631
Epoch 114/5000
41/41 - 1s - loss: 0.1239 - mae: 0.3107 - val_loss: 0.1733 - val_mae: 0.4588
Epoch 115/5000
41/41 - 1s - loss: 0.1235 - mae: 0.3099 - val_loss: 0.1826 - val_mae: 0.4748
Epoch 116/5000
41/41 - 1s - loss: 0.1247 - mae: 0.3128 - val_loss: 0.1827 - val_mae: 0.4807
Epoch 117/5000
41/41 - 1s - loss: 0.1263 - mae: 0.3180 - val_loss: 0.1731 - val_mae: 0.4433
Epoch 118/5000
41/41 - 1s - loss: 0.1256 - mae: 0.3162 - val_loss: 0.1828 - val_mae: 0.4786
Epoch 119/5000
41/41 - 1s - loss: 0.1275 - mae: 0.3233 - val_loss: 0.1621 - val_mae: 0.4106
Epoch 120/5000
41/41 - 1s - loss: 0.1234 - mae: 0.3107 - val_loss: 0.1752 - val_mae: 0.4541
Epoch 121/5000
41/41 - 1s - loss: 0.1225 - mae: 0.3088 - val_loss: 0.1634 - val_mae: 0.4232
Epoch 122/5000
41/41 - 1s - loss: 0.1222 - mae: 0.3075 - val_loss: 0.1834 - val_mae: 0.4753
Epoch 123/5000
41/41 - 1s - loss: 0.1244 - mae: 0.3152 - val_loss: 0.1835 - val_mae: 0.4675
Epoch 124/5000
41/41 - 1s - loss: 0.1244 - mae: 0.3136 - val_loss: 0.1864 - val_mae: 0.4740
Epoch 125/5000
41/41 - 1s - loss: 0.1252 - mae: 0.3157 - val_loss: 0.1972 - val_mae: 0.5061
Epoch 126/5000
41/41 - 1s - loss: 0.1290 - mae: 0.3269 - val_loss: 0.1752 - val_mae: 0.4488
Epoch 127/5000
41/41 - 1s - loss: 0.1261 - mae: 0.3197 - val_loss: 0.1795 - val_mae: 0.4606
Epoch 128/5000
41/41 - 1s - loss: 0.1222 - mae: 0.3065 - val_loss: 0.1748 - val_mae: 0.4441
Epoch 129/5000
41/41 - 1s - loss: 0.1231 - mae: 0.3099 - val_loss: 0.1897 - val_mae: 0.4915
Epoch 130/5000
41/41 - 1s - loss: 0.1263 - mae: 0.3179 - val_loss: 0.1883 - val_mae: 0.4843
Epoch 131/5000
41/41 - 1s - loss: 0.1255 - mae: 0.3155 - val_loss: 0.1764 - val_mae: 0.4550
Epoch 132/5000
41/41 - 1s - loss: 0.1220 - mae: 0.3076 - val_loss: 0.1676 - val_mae: 0.4369
Epoch 133/5000
41/41 - 1s - loss: 0.1207 - mae: 0.3036 - val_loss: 0.1884 - val_mae: 0.4791
Epoch 134/5000
41/41 - 1s - loss: 0.1232 - mae: 0.3099 - val_loss: 0.1884 - val_mae: 0.4855
Epoch 135/5000
41/41 - 1s - loss: 0.1228 - mae: 0.3105 - val_loss: 0.1921 - val_mae: 0.4969
Epoch 136/5000
41/41 - 1s - loss: 0.1267 - mae: 0.3198 - val_loss: 0.1896 - val_mae: 0.4883
Epoch 137/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3249 - val_loss: 0.1777 - val_mae: 0.4528
Epoch 138/5000
41/41 - 1s - loss: 0.1204 - mae: 0.3035 - val_loss: 0.1815 - val_mae: 0.4661
Epoch 139/5000
41/41 - 1s - loss: 0.1221 - mae: 0.3088 - val_loss: 0.1980 - val_mae: 0.5065
Epoch 140/5000
41/41 - 1s - loss: 0.1244 - mae: 0.3152 - val_loss: 0.1736 - val_mae: 0.4454
Epoch 141/5000
41/41 - 1s - loss: 0.1236 - mae: 0.3096 - val_loss: 0.1878 - val_mae: 0.4852
Epoch 142/5000
41/41 - 1s - loss: 0.1264 - mae: 0.3220 - val_loss: 0.1635 - val_mae: 0.4170
Epoch 143/5000
41/41 - 1s - loss: 0.1181 - mae: 0.2998 - val_loss: 0.1717 - val_mae: 0.4424
Epoch 144/5000
41/41 - 1s - loss: 0.1184 - mae: 0.2978 - val_loss: 0.1742 - val_mae: 0.4473
Epoch 145/5000
41/41 - 1s - loss: 0.1221 - mae: 0.3080 - val_loss: 0.1885 - val_mae: 0.4866
Epoch 146/5000
41/41 - 1s - loss: 0.1226 - mae: 0.3098 - val_loss: 0.1843 - val_mae: 0.4789
Epoch 147/5000
41/41 - 1s - loss: 0.1258 - mae: 0.3216 - val_loss: 0.1767 - val_mae: 0.4524
Epoch 148/5000
41/41 - 1s - loss: 0.1241 - mae: 0.3118 - val_loss: 0.1841 - val_mae: 0.4752
Epoch 149/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3141 - val_loss: 0.1696 - val_mae: 0.4261
Epoch 150/5000
41/41 - 1s - loss: 0.1200 - mae: 0.3012 - val_loss: 0.1772 - val_mae: 0.4638
Epoch 151/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3104 - val_loss: 0.1748 - val_mae: 0.4434
Epoch 152/5000
41/41 - 1s - loss: 0.1217 - mae: 0.3080 - val_loss: 0.1716 - val_mae: 0.4306
Epoch 153/5000
41/41 - 1s - loss: 0.1187 - mae: 0.2993 - val_loss: 0.1770 - val_mae: 0.4491
Epoch 154/5000
41/41 - 1s - loss: 0.1213 - mae: 0.3041 - val_loss: 0.1751 - val_mae: 0.4557
Epoch 155/5000
41/41 - 1s - loss: 0.1233 - mae: 0.3149 - val_loss: 0.1561 - val_mae: 0.3903
Epoch 156/5000
41/41 - 1s - loss: 0.1196 - mae: 0.3000 - val_loss: 0.1731 - val_mae: 0.4492
Epoch 157/5000
41/41 - 1s - loss: 0.1223 - mae: 0.3076 - val_loss: 0.1615 - val_mae: 0.4136
Epoch 158/5000
41/41 - 1s - loss: 0.1289 - mae: 0.3271 - val_loss: 0.1658 - val_mae: 0.4303
Restoring model weights from the end of the best epoch.
Epoch 00158: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_3..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_19"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_3 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_3 (PartitionP (None, None, 64)     0           message_passing_3[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_3[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_3 (Masking)             (None, None, 64)     0           partition_padding_3[0][0]        
                                                                 partition_padding_3[1][0]        
__________________________________________________________________________________________________
transformer_encoder_3 (Transfor (None, None, 64)     199040      masking_3[0][0]                  
                                                                 masking_3[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_3 (Glo (None, 64)           0           transformer_encoder_3[0][0]      
                                                                 transformer_encoder_3[1][0]      
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 512)          33280       global_average_pooling1d_3[0][0] 
                                                                 global_average_pooling1d_3[1][0] 
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 10)           110         dense_55[0][0]                   
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 450)          230850      dense_53[0][0]                   
                                                                 dense_53[1][0]                   
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 5)            55          dense_56[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 905)          0           dense_54[0][0]                   
                                                                 dense_54[1][0]                   
                                                                 dense_57[0][0]                   
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 700)          634200      concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 560)          392560      dense_58[0][0]                   
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 373)          209253      dense_62[0][0]                   
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 187)          69938       dense_63[0][0]                   
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 1)            188         dense_64[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
41/41 - 7s - loss: 0.1337 - mae: 0.3348 - val_loss: 0.1490 - val_mae: 0.3713
Epoch 2/5000
41/41 - 1s - loss: 0.1249 - mae: 0.3154 - val_loss: 0.1395 - val_mae: 0.3529
Epoch 3/5000
41/41 - 1s - loss: 0.1201 - mae: 0.3068 - val_loss: 0.1394 - val_mae: 0.3521
Epoch 4/5000
41/41 - 1s - loss: 0.1163 - mae: 0.2963 - val_loss: 0.1432 - val_mae: 0.3700
Epoch 5/5000
41/41 - 1s - loss: 0.1132 - mae: 0.2890 - val_loss: 0.1443 - val_mae: 0.3734
Epoch 6/5000
41/41 - 1s - loss: 0.1101 - mae: 0.2817 - val_loss: 0.1489 - val_mae: 0.3900
Epoch 7/5000
41/41 - 1s - loss: 0.1087 - mae: 0.2788 - val_loss: 0.1586 - val_mae: 0.4097
Epoch 8/5000
41/41 - 1s - loss: 0.1072 - mae: 0.2746 - val_loss: 0.1608 - val_mae: 0.4186
Epoch 9/5000
41/41 - 1s - loss: 0.1070 - mae: 0.2750 - val_loss: 0.1484 - val_mae: 0.3765
Epoch 10/5000
41/41 - 1s - loss: 0.1055 - mae: 0.2727 - val_loss: 0.1356 - val_mae: 0.3386
Epoch 11/5000
41/41 - 1s - loss: 0.1010 - mae: 0.2618 - val_loss: 0.1425 - val_mae: 0.3697
Epoch 12/5000
41/41 - 1s - loss: 0.0985 - mae: 0.2560 - val_loss: 0.1455 - val_mae: 0.3772
Epoch 13/5000
41/41 - 1s - loss: 0.0969 - mae: 0.2532 - val_loss: 0.1524 - val_mae: 0.3954
Epoch 14/5000
41/41 - 1s - loss: 0.0960 - mae: 0.2522 - val_loss: 0.1472 - val_mae: 0.3765
Epoch 15/5000
41/41 - 1s - loss: 0.0954 - mae: 0.2498 - val_loss: 0.1557 - val_mae: 0.3930
Epoch 16/5000
41/41 - 1s - loss: 0.0956 - mae: 0.2505 - val_loss: 0.1694 - val_mae: 0.4278
Epoch 17/5000
41/41 - 1s - loss: 0.1000 - mae: 0.2587 - val_loss: 0.1473 - val_mae: 0.3747
Epoch 18/5000
41/41 - 1s - loss: 0.0990 - mae: 0.2607 - val_loss: 0.1308 - val_mae: 0.3123
Epoch 19/5000
41/41 - 1s - loss: 0.0935 - mae: 0.2486 - val_loss: 0.1395 - val_mae: 0.3456
Epoch 20/5000
41/41 - 1s - loss: 0.0902 - mae: 0.2391 - val_loss: 0.1529 - val_mae: 0.3834
Epoch 21/5000
41/41 - 1s - loss: 0.0905 - mae: 0.2396 - val_loss: 0.1588 - val_mae: 0.3968
Epoch 22/5000
41/41 - 1s - loss: 0.0895 - mae: 0.2373 - val_loss: 0.1428 - val_mae: 0.3435
Epoch 23/5000
41/41 - 1s - loss: 0.0896 - mae: 0.2386 - val_loss: 0.1431 - val_mae: 0.3489
Epoch 24/5000
41/41 - 1s - loss: 0.0879 - mae: 0.2344 - val_loss: 0.1498 - val_mae: 0.3681
Epoch 25/5000
41/41 - 1s - loss: 0.0874 - mae: 0.2352 - val_loss: 0.1594 - val_mae: 0.3919
Epoch 26/5000
41/41 - 1s - loss: 0.0879 - mae: 0.2358 - val_loss: 0.1736 - val_mae: 0.4294
Epoch 27/5000
41/41 - 1s - loss: 0.0937 - mae: 0.2455 - val_loss: 0.1306 - val_mae: 0.3104
Epoch 28/5000
41/41 - 1s - loss: 0.0935 - mae: 0.2543 - val_loss: 0.1332 - val_mae: 0.3191
Epoch 29/5000
41/41 - 1s - loss: 0.0890 - mae: 0.2414 - val_loss: 0.1341 - val_mae: 0.3081
Epoch 30/5000
41/41 - 1s - loss: 0.0870 - mae: 0.2363 - val_loss: 0.1347 - val_mae: 0.3072
Epoch 31/5000
41/41 - 1s - loss: 0.0873 - mae: 0.2359 - val_loss: 0.1390 - val_mae: 0.3068
Epoch 32/5000
41/41 - 1s - loss: 0.0878 - mae: 0.2377 - val_loss: 0.1441 - val_mae: 0.3122
Epoch 33/5000
41/41 - 1s - loss: 0.0963 - mae: 0.2556 - val_loss: 0.1419 - val_mae: 0.3155
Epoch 34/5000
41/41 - 1s - loss: 0.0937 - mae: 0.2477 - val_loss: 0.1438 - val_mae: 0.3613
Epoch 35/5000
41/41 - 1s - loss: 0.0828 - mae: 0.2243 - val_loss: 0.1371 - val_mae: 0.3346
Epoch 36/5000
41/41 - 1s - loss: 0.0807 - mae: 0.2187 - val_loss: 0.1368 - val_mae: 0.3348
Epoch 37/5000
41/41 - 1s - loss: 0.0798 - mae: 0.2155 - val_loss: 0.1393 - val_mae: 0.3445
Epoch 38/5000
41/41 - 1s - loss: 0.0789 - mae: 0.2130 - val_loss: 0.1421 - val_mae: 0.3522
Epoch 39/5000
41/41 - 1s - loss: 0.0776 - mae: 0.2117 - val_loss: 0.1452 - val_mae: 0.3617
Epoch 40/5000
41/41 - 1s - loss: 0.0747 - mae: 0.2059 - val_loss: 0.1462 - val_mae: 0.3580
Epoch 41/5000
41/41 - 1s - loss: 0.0731 - mae: 0.2029 - val_loss: 0.1440 - val_mae: 0.3478
Epoch 42/5000
41/41 - 1s - loss: 0.0721 - mae: 0.2008 - val_loss: 0.1465 - val_mae: 0.3486
Epoch 43/5000
41/41 - 1s - loss: 0.0710 - mae: 0.1987 - val_loss: 0.1461 - val_mae: 0.3440
Epoch 44/5000
41/41 - 1s - loss: 0.0698 - mae: 0.1962 - val_loss: 0.1549 - val_mae: 0.3615
Epoch 45/5000
41/41 - 1s - loss: 0.0712 - mae: 0.1992 - val_loss: 0.1542 - val_mae: 0.3650
Epoch 46/5000
41/41 - 1s - loss: 0.0720 - mae: 0.2027 - val_loss: 0.1357 - val_mae: 0.3160
Epoch 47/5000
41/41 - 1s - loss: 0.0729 - mae: 0.2060 - val_loss: 0.1435 - val_mae: 0.3222
Epoch 48/5000
41/41 - 1s - loss: 0.0701 - mae: 0.1991 - val_loss: 0.1475 - val_mae: 0.3396
Epoch 49/5000
41/41 - 1s - loss: 0.0696 - mae: 0.2016 - val_loss: 0.1307 - val_mae: 0.3188
Epoch 50/5000
41/41 - 1s - loss: 0.0712 - mae: 0.2057 - val_loss: 0.1408 - val_mae: 0.3460
Epoch 51/5000
41/41 - 1s - loss: 0.0694 - mae: 0.1992 - val_loss: 0.1350 - val_mae: 0.3301
Epoch 52/5000
41/41 - 1s - loss: 0.0746 - mae: 0.2121 - val_loss: 0.1276 - val_mae: 0.2961
Epoch 53/5000
41/41 - 1s - loss: 0.0716 - mae: 0.2078 - val_loss: 0.1414 - val_mae: 0.3576
Epoch 54/5000
41/41 - 1s - loss: 0.0708 - mae: 0.2073 - val_loss: 0.1486 - val_mae: 0.3752
Epoch 55/5000
41/41 - 1s - loss: 0.0750 - mae: 0.2134 - val_loss: 0.1753 - val_mae: 0.4503
Epoch 56/5000
41/41 - 1s - loss: 0.0817 - mae: 0.2316 - val_loss: 0.1348 - val_mae: 0.3554
Epoch 57/5000
41/41 - 1s - loss: 0.0764 - mae: 0.2268 - val_loss: 0.1331 - val_mae: 0.3401
Epoch 58/5000
41/41 - 1s - loss: 0.0699 - mae: 0.2060 - val_loss: 0.1484 - val_mae: 0.3759
Epoch 59/5000
41/41 - 1s - loss: 0.0711 - mae: 0.2097 - val_loss: 0.1360 - val_mae: 0.3581
Epoch 60/5000
41/41 - 1s - loss: 0.0685 - mae: 0.2077 - val_loss: 0.1404 - val_mae: 0.3389
Epoch 61/5000
41/41 - 1s - loss: 0.0640 - mae: 0.1938 - val_loss: 0.1396 - val_mae: 0.3440
Epoch 62/5000
41/41 - 1s - loss: 0.0656 - mae: 0.1936 - val_loss: 0.1415 - val_mae: 0.3724
Epoch 63/5000
41/41 - 1s - loss: 0.0692 - mae: 0.2065 - val_loss: 0.1185 - val_mae: 0.3333
Epoch 64/5000
41/41 - 1s - loss: 0.0683 - mae: 0.2098 - val_loss: 0.1248 - val_mae: 0.3229
Epoch 65/5000
41/41 - 1s - loss: 0.0680 - mae: 0.2054 - val_loss: 0.1344 - val_mae: 0.3648
Epoch 66/5000
41/41 - 1s - loss: 0.0678 - mae: 0.2073 - val_loss: 0.1248 - val_mae: 0.3145
Epoch 67/5000
41/41 - 1s - loss: 0.0714 - mae: 0.2168 - val_loss: 0.1251 - val_mae: 0.3173
Epoch 68/5000
41/41 - 1s - loss: 0.0726 - mae: 0.2203 - val_loss: 0.1314 - val_mae: 0.3040
Epoch 69/5000
41/41 - 1s - loss: 0.0826 - mae: 0.2379 - val_loss: 0.1375 - val_mae: 0.3103
Epoch 70/5000
41/41 - 1s - loss: 0.0952 - mae: 0.2666 - val_loss: 0.1591 - val_mae: 0.3335
Epoch 71/5000
41/41 - 1s - loss: 0.0916 - mae: 0.2597 - val_loss: 0.1369 - val_mae: 0.3039
Epoch 72/5000
41/41 - 1s - loss: 0.0800 - mae: 0.2361 - val_loss: 0.1407 - val_mae: 0.3038
Epoch 73/5000
41/41 - 1s - loss: 0.0833 - mae: 0.2397 - val_loss: 0.1474 - val_mae: 0.3110
Epoch 74/5000
41/41 - 1s - loss: 0.0751 - mae: 0.2214 - val_loss: 0.1423 - val_mae: 0.3054
Epoch 75/5000
41/41 - 1s - loss: 0.0684 - mae: 0.2082 - val_loss: 0.1342 - val_mae: 0.2958
Epoch 76/5000
41/41 - 1s - loss: 0.0620 - mae: 0.1923 - val_loss: 0.1260 - val_mae: 0.2893
Epoch 77/5000
41/41 - 1s - loss: 0.0587 - mae: 0.1839 - val_loss: 0.1254 - val_mae: 0.2865
Epoch 78/5000
41/41 - 1s - loss: 0.0565 - mae: 0.1794 - val_loss: 0.1324 - val_mae: 0.2911
Epoch 79/5000
41/41 - 1s - loss: 0.0576 - mae: 0.1827 - val_loss: 0.1296 - val_mae: 0.2922
Epoch 80/5000
41/41 - 1s - loss: 0.0639 - mae: 0.1962 - val_loss: 0.1350 - val_mae: 0.2948
Epoch 81/5000
41/41 - 1s - loss: 0.0639 - mae: 0.1988 - val_loss: 0.1422 - val_mae: 0.3032
Epoch 82/5000
41/41 - 1s - loss: 0.0729 - mae: 0.2190 - val_loss: 0.1455 - val_mae: 0.3086
Epoch 83/5000
41/41 - 1s - loss: 0.0742 - mae: 0.2225 - val_loss: 0.1379 - val_mae: 0.2972
Epoch 84/5000
41/41 - 1s - loss: 0.0741 - mae: 0.2237 - val_loss: 0.1265 - val_mae: 0.2951
Epoch 85/5000
41/41 - 1s - loss: 0.0622 - mae: 0.1968 - val_loss: 0.1200 - val_mae: 0.2872
Epoch 86/5000
41/41 - 1s - loss: 0.0542 - mae: 0.1749 - val_loss: 0.1294 - val_mae: 0.2870
Epoch 87/5000
41/41 - 1s - loss: 0.0516 - mae: 0.1691 - val_loss: 0.1210 - val_mae: 0.2807
Epoch 88/5000
41/41 - 1s - loss: 0.0531 - mae: 0.1737 - val_loss: 0.1181 - val_mae: 0.2784
Epoch 89/5000
41/41 - 1s - loss: 0.0520 - mae: 0.1715 - val_loss: 0.1105 - val_mae: 0.2708
Epoch 90/5000
41/41 - 1s - loss: 0.0500 - mae: 0.1654 - val_loss: 0.1089 - val_mae: 0.2686
Epoch 91/5000
41/41 - 1s - loss: 0.0488 - mae: 0.1638 - val_loss: 0.1116 - val_mae: 0.2790
Epoch 92/5000
41/41 - 1s - loss: 0.0529 - mae: 0.1745 - val_loss: 0.1076 - val_mae: 0.2659
Epoch 93/5000
41/41 - 1s - loss: 0.0500 - mae: 0.1648 - val_loss: 0.1106 - val_mae: 0.2665
Epoch 94/5000
41/41 - 1s - loss: 0.0481 - mae: 0.1606 - val_loss: 0.1110 - val_mae: 0.2681
Epoch 95/5000
41/41 - 1s - loss: 0.0475 - mae: 0.1586 - val_loss: 0.1109 - val_mae: 0.2760
Epoch 96/5000
41/41 - 1s - loss: 0.0481 - mae: 0.1610 - val_loss: 0.1117 - val_mae: 0.2738
Epoch 97/5000
41/41 - 1s - loss: 0.0450 - mae: 0.1520 - val_loss: 0.1150 - val_mae: 0.2709
Epoch 98/5000
41/41 - 1s - loss: 0.0483 - mae: 0.1634 - val_loss: 0.1069 - val_mae: 0.2689
Epoch 99/5000
41/41 - 1s - loss: 0.0437 - mae: 0.1482 - val_loss: 0.1086 - val_mae: 0.2651
Epoch 100/5000
41/41 - 1s - loss: 0.0448 - mae: 0.1536 - val_loss: 0.1113 - val_mae: 0.2726
Epoch 101/5000
41/41 - 1s - loss: 0.0450 - mae: 0.1515 - val_loss: 0.1094 - val_mae: 0.2671
Epoch 102/5000
41/41 - 1s - loss: 0.0441 - mae: 0.1500 - val_loss: 0.1097 - val_mae: 0.2648
Epoch 103/5000
41/41 - 1s - loss: 0.0449 - mae: 0.1504 - val_loss: 0.1106 - val_mae: 0.2702
Epoch 104/5000
41/41 - 1s - loss: 0.0425 - mae: 0.1488 - val_loss: 0.1061 - val_mae: 0.2654
Epoch 105/5000
41/41 - 1s - loss: 0.0421 - mae: 0.1458 - val_loss: 0.1173 - val_mae: 0.2866
Epoch 106/5000
41/41 - 1s - loss: 0.0442 - mae: 0.1559 - val_loss: 0.1089 - val_mae: 0.2665
Epoch 107/5000
41/41 - 1s - loss: 0.0462 - mae: 0.1594 - val_loss: 0.1047 - val_mae: 0.2547
Epoch 108/5000
41/41 - 1s - loss: 0.0446 - mae: 0.1547 - val_loss: 0.1018 - val_mae: 0.2542
Epoch 109/5000
41/41 - 1s - loss: 0.0435 - mae: 0.1562 - val_loss: 0.1048 - val_mae: 0.2590
Epoch 110/5000
41/41 - 1s - loss: 0.0411 - mae: 0.1456 - val_loss: 0.1047 - val_mae: 0.2610
Epoch 111/5000
41/41 - 1s - loss: 0.0409 - mae: 0.1482 - val_loss: 0.1055 - val_mae: 0.2568
Epoch 112/5000
41/41 - 1s - loss: 0.0470 - mae: 0.1582 - val_loss: 0.1065 - val_mae: 0.2603
Epoch 113/5000
41/41 - 1s - loss: 0.0443 - mae: 0.1582 - val_loss: 0.1063 - val_mae: 0.2553
Epoch 114/5000
41/41 - 1s - loss: 0.0427 - mae: 0.1555 - val_loss: 0.1138 - val_mae: 0.2666
Epoch 115/5000
41/41 - 1s - loss: 0.0423 - mae: 0.1535 - val_loss: 0.1136 - val_mae: 0.2779
Epoch 116/5000
41/41 - 1s - loss: 0.0376 - mae: 0.1406 - val_loss: 0.1072 - val_mae: 0.2678
Epoch 117/5000
41/41 - 1s - loss: 0.0380 - mae: 0.1428 - val_loss: 0.1179 - val_mae: 0.2764
Epoch 118/5000
41/41 - 1s - loss: 0.0380 - mae: 0.1429 - val_loss: 0.1132 - val_mae: 0.2683
Epoch 119/5000
41/41 - 1s - loss: 0.0437 - mae: 0.1600 - val_loss: 0.1367 - val_mae: 0.3011
Epoch 120/5000
41/41 - 1s - loss: 0.0431 - mae: 0.1590 - val_loss: 0.1316 - val_mae: 0.3180
Epoch 121/5000
41/41 - 1s - loss: 0.0455 - mae: 0.1661 - val_loss: 0.1338 - val_mae: 0.2942
Epoch 122/5000
41/41 - 1s - loss: 0.0400 - mae: 0.1503 - val_loss: 0.1199 - val_mae: 0.2809
Epoch 123/5000
41/41 - 1s - loss: 0.0344 - mae: 0.1326 - val_loss: 0.1406 - val_mae: 0.3212
Epoch 124/5000
41/41 - 1s - loss: 0.0379 - mae: 0.1441 - val_loss: 0.1292 - val_mae: 0.2859
Epoch 125/5000
41/41 - 1s - loss: 0.0327 - mae: 0.1306 - val_loss: 0.1270 - val_mae: 0.2823
Epoch 126/5000
41/41 - 1s - loss: 0.0358 - mae: 0.1382 - val_loss: 0.1331 - val_mae: 0.2938
Epoch 127/5000
41/41 - 1s - loss: 0.0331 - mae: 0.1310 - val_loss: 0.1383 - val_mae: 0.3198
Epoch 128/5000
41/41 - 1s - loss: 0.0386 - mae: 0.1443 - val_loss: 0.1393 - val_mae: 0.3044
Epoch 129/5000
41/41 - 1s - loss: 0.0379 - mae: 0.1455 - val_loss: 0.1251 - val_mae: 0.2825
Epoch 130/5000
41/41 - 1s - loss: 0.0340 - mae: 0.1309 - val_loss: 0.1312 - val_mae: 0.2988
Epoch 131/5000
41/41 - 1s - loss: 0.0340 - mae: 0.1313 - val_loss: 0.1268 - val_mae: 0.2878
Epoch 132/5000
41/41 - 1s - loss: 0.0299 - mae: 0.1208 - val_loss: 0.1363 - val_mae: 0.3083
Epoch 133/5000
41/41 - 1s - loss: 0.0297 - mae: 0.1188 - val_loss: 0.1291 - val_mae: 0.2935
Epoch 134/5000
41/41 - 1s - loss: 0.0287 - mae: 0.1176 - val_loss: 0.1255 - val_mae: 0.2865
Epoch 135/5000
41/41 - 1s - loss: 0.0293 - mae: 0.1190 - val_loss: 0.1294 - val_mae: 0.2928
Epoch 136/5000
41/41 - 1s - loss: 0.0289 - mae: 0.1186 - val_loss: 0.1453 - val_mae: 0.3395
Epoch 137/5000
41/41 - 1s - loss: 0.0302 - mae: 0.1211 - val_loss: 0.1339 - val_mae: 0.3040
Epoch 138/5000
41/41 - 1s - loss: 0.0313 - mae: 0.1289 - val_loss: 0.1335 - val_mae: 0.3024
Epoch 139/5000
41/41 - 1s - loss: 0.0286 - mae: 0.1178 - val_loss: 0.1259 - val_mae: 0.2806
Epoch 140/5000
41/41 - 1s - loss: 0.0382 - mae: 0.1450 - val_loss: 0.1261 - val_mae: 0.2895
Epoch 141/5000
41/41 - 1s - loss: 0.0323 - mae: 0.1307 - val_loss: 0.1349 - val_mae: 0.3272
Epoch 142/5000
41/41 - 1s - loss: 0.0333 - mae: 0.1279 - val_loss: 0.1448 - val_mae: 0.3475
Epoch 143/5000
41/41 - 1s - loss: 0.0436 - mae: 0.1626 - val_loss: 0.1377 - val_mae: 0.3052
Epoch 144/5000
41/41 - 1s - loss: 0.0301 - mae: 0.1222 - val_loss: 0.1384 - val_mae: 0.3355
Epoch 145/5000
41/41 - 1s - loss: 0.0348 - mae: 0.1375 - val_loss: 0.1298 - val_mae: 0.2868
Epoch 146/5000
41/41 - 1s - loss: 0.0270 - mae: 0.1129 - val_loss: 0.1378 - val_mae: 0.3175
Epoch 147/5000
41/41 - 1s - loss: 0.0293 - mae: 0.1204 - val_loss: 0.1414 - val_mae: 0.3352
Epoch 148/5000
41/41 - 1s - loss: 0.0319 - mae: 0.1305 - val_loss: 0.1388 - val_mae: 0.3050
Epoch 149/5000
41/41 - 1s - loss: 0.0301 - mae: 0.1226 - val_loss: 0.1219 - val_mae: 0.2848
Epoch 150/5000
41/41 - 1s - loss: 0.0310 - mae: 0.1277 - val_loss: 0.1311 - val_mae: 0.3065
Epoch 151/5000
41/41 - 1s - loss: 0.0325 - mae: 0.1272 - val_loss: 0.1315 - val_mae: 0.3239
Epoch 152/5000
41/41 - 1s - loss: 0.0375 - mae: 0.1513 - val_loss: 0.1325 - val_mae: 0.2946
Epoch 153/5000
41/41 - 1s - loss: 0.0323 - mae: 0.1307 - val_loss: 0.1397 - val_mae: 0.3055
Epoch 154/5000
41/41 - 1s - loss: 0.0325 - mae: 0.1300 - val_loss: 0.1401 - val_mae: 0.3044
Epoch 155/5000
41/41 - 1s - loss: 0.0279 - mae: 0.1175 - val_loss: 0.1376 - val_mae: 0.3008
Epoch 156/5000
41/41 - 1s - loss: 0.0299 - mae: 0.1188 - val_loss: 0.1325 - val_mae: 0.2929
Epoch 157/5000
41/41 - 1s - loss: 0.0296 - mae: 0.1223 - val_loss: 0.1430 - val_mae: 0.3048
Epoch 158/5000
41/41 - 1s - loss: 0.0267 - mae: 0.1116 - val_loss: 0.1307 - val_mae: 0.2977
Epoch 159/5000
41/41 - 1s - loss: 0.0286 - mae: 0.1197 - val_loss: 0.1284 - val_mae: 0.2885
Epoch 160/5000
41/41 - 1s - loss: 0.0293 - mae: 0.1212 - val_loss: 0.1356 - val_mae: 0.3002
Epoch 161/5000
41/41 - 1s - loss: 0.0297 - mae: 0.1215 - val_loss: 0.1388 - val_mae: 0.3011
Epoch 162/5000
41/41 - 1s - loss: 0.0283 - mae: 0.1196 - val_loss: 0.1301 - val_mae: 0.2960
Epoch 163/5000
41/41 - 1s - loss: 0.0335 - mae: 0.1382 - val_loss: 0.1228 - val_mae: 0.2833
Epoch 164/5000
41/41 - 1s - loss: 0.0329 - mae: 0.1342 - val_loss: 0.1485 - val_mae: 0.3243
Epoch 165/5000
41/41 - 1s - loss: 0.0350 - mae: 0.1384 - val_loss: 0.1261 - val_mae: 0.2928
Epoch 166/5000
41/41 - 1s - loss: 0.0359 - mae: 0.1409 - val_loss: 0.1289 - val_mae: 0.2979
Epoch 167/5000
41/41 - 1s - loss: 0.0350 - mae: 0.1437 - val_loss: 0.1294 - val_mae: 0.2994
Epoch 168/5000
41/41 - 1s - loss: 0.0337 - mae: 0.1377 - val_loss: 0.1267 - val_mae: 0.2942
Epoch 169/5000
41/41 - 1s - loss: 0.0369 - mae: 0.1466 - val_loss: 0.1353 - val_mae: 0.2953
Epoch 170/5000
41/41 - 1s - loss: 0.0328 - mae: 0.1396 - val_loss: 0.1505 - val_mae: 0.3222
Epoch 171/5000
41/41 - 1s - loss: 0.0311 - mae: 0.1315 - val_loss: 0.1555 - val_mae: 0.3406
Epoch 172/5000
41/41 - 1s - loss: 0.0354 - mae: 0.1392 - val_loss: 0.1510 - val_mae: 0.3242
Epoch 173/5000
41/41 - 1s - loss: 0.0289 - mae: 0.1194 - val_loss: 0.1503 - val_mae: 0.3286
Epoch 174/5000
41/41 - 1s - loss: 0.0297 - mae: 0.1239 - val_loss: 0.1491 - val_mae: 0.3148
Epoch 175/5000
41/41 - 1s - loss: 0.0275 - mae: 0.1125 - val_loss: 0.1362 - val_mae: 0.3022
Epoch 176/5000
41/41 - 1s - loss: 0.0249 - mae: 0.1049 - val_loss: 0.1360 - val_mae: 0.3016
Epoch 177/5000
41/41 - 1s - loss: 0.0255 - mae: 0.1086 - val_loss: 0.1395 - val_mae: 0.3039
Epoch 178/5000
41/41 - 1s - loss: 0.0243 - mae: 0.1063 - val_loss: 0.1412 - val_mae: 0.3139
Epoch 179/5000
41/41 - 1s - loss: 0.0259 - mae: 0.1128 - val_loss: 0.1323 - val_mae: 0.3025
Epoch 180/5000
41/41 - 1s - loss: 0.0248 - mae: 0.1087 - val_loss: 0.1351 - val_mae: 0.3017
Epoch 181/5000
41/41 - 1s - loss: 0.0268 - mae: 0.1191 - val_loss: 0.1431 - val_mae: 0.3112
Epoch 182/5000
41/41 - 1s - loss: 0.0255 - mae: 0.1131 - val_loss: 0.1511 - val_mae: 0.3331
Epoch 183/5000
41/41 - 1s - loss: 0.0277 - mae: 0.1174 - val_loss: 0.1476 - val_mae: 0.3167
Epoch 184/5000
41/41 - 1s - loss: 0.0241 - mae: 0.1059 - val_loss: 0.1544 - val_mae: 0.3361
Epoch 185/5000
41/41 - 1s - loss: 0.0266 - mae: 0.1127 - val_loss: 0.1586 - val_mae: 0.3402
Epoch 186/5000
41/41 - 1s - loss: 0.0239 - mae: 0.1053 - val_loss: 0.1542 - val_mae: 0.3362
Epoch 187/5000
41/41 - 1s - loss: 0.0271 - mae: 0.1140 - val_loss: 0.1621 - val_mae: 0.3502
Epoch 188/5000
41/41 - 1s - loss: 0.0231 - mae: 0.1028 - val_loss: 0.1633 - val_mae: 0.3551
Epoch 189/5000
41/41 - 1s - loss: 0.0255 - mae: 0.1076 - val_loss: 0.1611 - val_mae: 0.3437
Epoch 190/5000
41/41 - 1s - loss: 0.0224 - mae: 0.0990 - val_loss: 0.1589 - val_mae: 0.3448
Epoch 191/5000
41/41 - 1s - loss: 0.0228 - mae: 0.0980 - val_loss: 0.1515 - val_mae: 0.3388
Epoch 192/5000
41/41 - 1s - loss: 0.0238 - mae: 0.1044 - val_loss: 0.1445 - val_mae: 0.3170
Epoch 193/5000
41/41 - 1s - loss: 0.0238 - mae: 0.1024 - val_loss: 0.1398 - val_mae: 0.3146
Epoch 194/5000
41/41 - 1s - loss: 0.0237 - mae: 0.1024 - val_loss: 0.1458 - val_mae: 0.3180
Epoch 195/5000
41/41 - 1s - loss: 0.0240 - mae: 0.1043 - val_loss: 0.1430 - val_mae: 0.3128
Epoch 196/5000
41/41 - 1s - loss: 0.0247 - mae: 0.1063 - val_loss: 0.1279 - val_mae: 0.2972
Epoch 197/5000
41/41 - 1s - loss: 0.0264 - mae: 0.1161 - val_loss: 0.1398 - val_mae: 0.3090
Epoch 198/5000
41/41 - 1s - loss: 0.0245 - mae: 0.1076 - val_loss: 0.1454 - val_mae: 0.3238
Epoch 199/5000
41/41 - 1s - loss: 0.0278 - mae: 0.1183 - val_loss: 0.1282 - val_mae: 0.2986
Epoch 200/5000
41/41 - 1s - loss: 0.0305 - mae: 0.1259 - val_loss: 0.1287 - val_mae: 0.2942
Epoch 201/5000
41/41 - 1s - loss: 0.0307 - mae: 0.1289 - val_loss: 0.1239 - val_mae: 0.2917
Epoch 202/5000
41/41 - 1s - loss: 0.0258 - mae: 0.1140 - val_loss: 0.1404 - val_mae: 0.3132
Epoch 203/5000
41/41 - 1s - loss: 0.0269 - mae: 0.1192 - val_loss: 0.1544 - val_mae: 0.3215
Epoch 204/5000
41/41 - 1s - loss: 0.0246 - mae: 0.1147 - val_loss: 0.1652 - val_mae: 0.3406
Epoch 205/5000
41/41 - 1s - loss: 0.0248 - mae: 0.1130 - val_loss: 0.1441 - val_mae: 0.3169
Epoch 206/5000
41/41 - 1s - loss: 0.0248 - mae: 0.1093 - val_loss: 0.1692 - val_mae: 0.3505
Epoch 207/5000
41/41 - 1s - loss: 0.0235 - mae: 0.1082 - val_loss: 0.1829 - val_mae: 0.3667
Epoch 208/5000
41/41 - 1s - loss: 0.0277 - mae: 0.1178 - val_loss: 0.1570 - val_mae: 0.3269
Epoch 209/5000
41/41 - 1s - loss: 0.0225 - mae: 0.0995 - val_loss: 0.1524 - val_mae: 0.3405
Restoring model weights from the end of the best epoch.
Epoch 00209: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_3..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 4

Generating graphs from SMILES..

Setting up training set.
Size: 2057

Setting up validation set.
Size: 229

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_24"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_4 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_4 (PartitionP (None, None, 64)     0           message_passing_4[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_4[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_4 (Masking)             (None, None, 64)     0           partition_padding_4[0][0]        
                                                                 partition_padding_4[1][0]        
__________________________________________________________________________________________________
transformer_encoder_4 (Transfor (None, None, 64)     199040      masking_4[0][0]                  
                                                                 masking_4[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_4 (Glo (None, 64)           0           transformer_encoder_4[0][0]      
                                                                 transformer_encoder_4[1][0]      
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 512)          33280       global_average_pooling1d_4[0][0] 
                                                                 global_average_pooling1d_4[1][0] 
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 10)           110         dense_72[0][0]                   
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 450)          230850      dense_70[0][0]                   
                                                                 dense_70[1][0]                   
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 5)            55          dense_73[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 905)          0           dense_71[0][0]                   
                                                                 dense_71[1][0]                   
                                                                 dense_74[0][0]                   
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 700)          634200      concatenate_4[0][0]              
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 560)          392560      dense_75[0][0]                   
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 373)          209253      dense_79[0][0]                   
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 187)          69938       dense_80[0][0]                   
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 1)            188         dense_81[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
41/41 - 5s - loss: 0.3179 - mae: 0.6293 - val_loss: 0.1413 - val_mae: 0.3914
Epoch 2/5000
41/41 - 1s - loss: 0.1585 - mae: 0.4037 - val_loss: 0.1374 - val_mae: 0.3585
Epoch 3/5000
41/41 - 1s - loss: 0.1586 - mae: 0.4018 - val_loss: 0.1387 - val_mae: 0.3396
Epoch 4/5000
41/41 - 1s - loss: 0.1561 - mae: 0.3964 - val_loss: 0.1382 - val_mae: 0.3377
Epoch 5/5000
41/41 - 1s - loss: 0.1558 - mae: 0.3965 - val_loss: 0.1357 - val_mae: 0.3423
Epoch 6/5000
41/41 - 1s - loss: 0.1559 - mae: 0.3970 - val_loss: 0.1333 - val_mae: 0.3483
Epoch 7/5000
41/41 - 1s - loss: 0.1547 - mae: 0.3944 - val_loss: 0.1354 - val_mae: 0.3740
Epoch 8/5000
41/41 - 1s - loss: 0.1533 - mae: 0.3921 - val_loss: 0.1323 - val_mae: 0.3491
Epoch 9/5000
41/41 - 1s - loss: 0.1527 - mae: 0.3900 - val_loss: 0.1319 - val_mae: 0.3427
Epoch 10/5000
41/41 - 1s - loss: 0.1518 - mae: 0.3884 - val_loss: 0.1311 - val_mae: 0.3437
Epoch 11/5000
41/41 - 1s - loss: 0.1505 - mae: 0.3858 - val_loss: 0.1306 - val_mae: 0.3302
Epoch 12/5000
41/41 - 1s - loss: 0.1490 - mae: 0.3794 - val_loss: 0.1275 - val_mae: 0.3264
Epoch 13/5000
41/41 - 1s - loss: 0.1452 - mae: 0.3730 - val_loss: 0.1245 - val_mae: 0.3325
Epoch 14/5000
41/41 - 1s - loss: 0.1454 - mae: 0.3728 - val_loss: 0.1259 - val_mae: 0.3545
Epoch 15/5000
41/41 - 1s - loss: 0.1442 - mae: 0.3696 - val_loss: 0.1241 - val_mae: 0.3456
Epoch 16/5000
41/41 - 1s - loss: 0.1437 - mae: 0.3679 - val_loss: 0.1200 - val_mae: 0.3273
Epoch 17/5000
41/41 - 1s - loss: 0.1431 - mae: 0.3680 - val_loss: 0.1210 - val_mae: 0.3018
Epoch 18/5000
41/41 - 1s - loss: 0.1410 - mae: 0.3639 - val_loss: 0.1189 - val_mae: 0.3342
Epoch 19/5000
41/41 - 1s - loss: 0.1408 - mae: 0.3618 - val_loss: 0.1184 - val_mae: 0.3358
Epoch 20/5000
41/41 - 1s - loss: 0.1388 - mae: 0.3565 - val_loss: 0.1161 - val_mae: 0.3232
Epoch 21/5000
41/41 - 1s - loss: 0.1375 - mae: 0.3523 - val_loss: 0.1162 - val_mae: 0.3251
Epoch 22/5000
41/41 - 1s - loss: 0.1368 - mae: 0.3522 - val_loss: 0.1139 - val_mae: 0.3155
Epoch 23/5000
41/41 - 1s - loss: 0.1370 - mae: 0.3514 - val_loss: 0.1154 - val_mae: 0.3266
Epoch 24/5000
41/41 - 1s - loss: 0.1355 - mae: 0.3486 - val_loss: 0.1125 - val_mae: 0.3130
Epoch 25/5000
41/41 - 1s - loss: 0.1346 - mae: 0.3464 - val_loss: 0.1118 - val_mae: 0.3086
Epoch 26/5000
41/41 - 1s - loss: 0.1350 - mae: 0.3488 - val_loss: 0.1126 - val_mae: 0.3147
Epoch 27/5000
41/41 - 1s - loss: 0.1334 - mae: 0.3432 - val_loss: 0.1117 - val_mae: 0.3168
Epoch 28/5000
41/41 - 1s - loss: 0.1334 - mae: 0.3425 - val_loss: 0.1120 - val_mae: 0.3281
Epoch 29/5000
41/41 - 1s - loss: 0.1381 - mae: 0.3560 - val_loss: 0.1167 - val_mae: 0.2912
Epoch 30/5000
41/41 - 1s - loss: 0.1383 - mae: 0.3564 - val_loss: 0.1208 - val_mae: 0.2872
Epoch 31/5000
41/41 - 1s - loss: 0.1349 - mae: 0.3463 - val_loss: 0.1106 - val_mae: 0.2978
Epoch 32/5000
41/41 - 1s - loss: 0.1334 - mae: 0.3460 - val_loss: 0.1190 - val_mae: 0.2815
Epoch 33/5000
41/41 - 1s - loss: 0.1323 - mae: 0.3388 - val_loss: 0.1123 - val_mae: 0.2771
Epoch 34/5000
41/41 - 1s - loss: 0.1301 - mae: 0.3356 - val_loss: 0.1080 - val_mae: 0.2965
Epoch 35/5000
41/41 - 1s - loss: 0.1360 - mae: 0.3504 - val_loss: 0.1228 - val_mae: 0.3719
Epoch 36/5000
41/41 - 1s - loss: 0.1368 - mae: 0.3499 - val_loss: 0.1081 - val_mae: 0.3053
Epoch 37/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3482 - val_loss: 0.1320 - val_mae: 0.4025
Epoch 38/5000
41/41 - 1s - loss: 0.1361 - mae: 0.3483 - val_loss: 0.1099 - val_mae: 0.2819
Epoch 39/5000
41/41 - 1s - loss: 0.1360 - mae: 0.3474 - val_loss: 0.1256 - val_mae: 0.3805
Epoch 40/5000
41/41 - 1s - loss: 0.1341 - mae: 0.3438 - val_loss: 0.1080 - val_mae: 0.2695
Epoch 41/5000
41/41 - 1s - loss: 0.1308 - mae: 0.3349 - val_loss: 0.1121 - val_mae: 0.2867
Epoch 42/5000
41/41 - 1s - loss: 0.1366 - mae: 0.3477 - val_loss: 0.1119 - val_mae: 0.3161
Epoch 43/5000
41/41 - 1s - loss: 0.1340 - mae: 0.3426 - val_loss: 0.1080 - val_mae: 0.3010
Epoch 44/5000
41/41 - 1s - loss: 0.1317 - mae: 0.3382 - val_loss: 0.1083 - val_mae: 0.2871
Epoch 45/5000
41/41 - 1s - loss: 0.1321 - mae: 0.3372 - val_loss: 0.1091 - val_mae: 0.2712
Epoch 46/5000
41/41 - 1s - loss: 0.1307 - mae: 0.3325 - val_loss: 0.1112 - val_mae: 0.3220
Epoch 47/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3332 - val_loss: 0.1066 - val_mae: 0.2664
Epoch 48/5000
41/41 - 1s - loss: 0.1294 - mae: 0.3295 - val_loss: 0.1089 - val_mae: 0.3066
Epoch 49/5000
41/41 - 1s - loss: 0.1302 - mae: 0.3320 - val_loss: 0.1079 - val_mae: 0.2758
Epoch 50/5000
41/41 - 1s - loss: 0.1310 - mae: 0.3330 - val_loss: 0.1325 - val_mae: 0.3973
Epoch 51/5000
41/41 - 1s - loss: 0.1308 - mae: 0.3354 - val_loss: 0.1064 - val_mae: 0.2749
Epoch 52/5000
41/41 - 1s - loss: 0.1289 - mae: 0.3288 - val_loss: 0.1084 - val_mae: 0.2902
Epoch 53/5000
41/41 - 1s - loss: 0.1328 - mae: 0.3386 - val_loss: 0.1066 - val_mae: 0.2742
Epoch 54/5000
41/41 - 1s - loss: 0.1280 - mae: 0.3246 - val_loss: 0.1105 - val_mae: 0.2829
Epoch 55/5000
41/41 - 1s - loss: 0.1322 - mae: 0.3377 - val_loss: 0.1072 - val_mae: 0.2693
Epoch 56/5000
41/41 - 1s - loss: 0.1276 - mae: 0.3244 - val_loss: 0.1058 - val_mae: 0.2655
Epoch 57/5000
41/41 - 1s - loss: 0.1274 - mae: 0.3237 - val_loss: 0.1056 - val_mae: 0.2786
Epoch 58/5000
41/41 - 1s - loss: 0.1284 - mae: 0.3268 - val_loss: 0.1064 - val_mae: 0.2871
Epoch 59/5000
41/41 - 1s - loss: 0.1259 - mae: 0.3223 - val_loss: 0.1067 - val_mae: 0.2691
Epoch 60/5000
41/41 - 1s - loss: 0.1268 - mae: 0.3230 - val_loss: 0.1057 - val_mae: 0.2779
Epoch 61/5000
41/41 - 1s - loss: 0.1275 - mae: 0.3251 - val_loss: 0.1063 - val_mae: 0.2739
Epoch 62/5000
41/41 - 1s - loss: 0.1240 - mae: 0.3159 - val_loss: 0.1056 - val_mae: 0.2705
Epoch 63/5000
41/41 - 1s - loss: 0.1260 - mae: 0.3195 - val_loss: 0.1094 - val_mae: 0.2893
Epoch 64/5000
41/41 - 1s - loss: 0.1319 - mae: 0.3373 - val_loss: 0.1063 - val_mae: 0.2825
Epoch 65/5000
41/41 - 1s - loss: 0.1289 - mae: 0.3284 - val_loss: 0.1050 - val_mae: 0.2850
Epoch 66/5000
41/41 - 1s - loss: 0.1239 - mae: 0.3168 - val_loss: 0.1047 - val_mae: 0.2670
Epoch 67/5000
41/41 - 1s - loss: 0.1254 - mae: 0.3187 - val_loss: 0.1077 - val_mae: 0.2866
Epoch 68/5000
41/41 - 1s - loss: 0.1298 - mae: 0.3327 - val_loss: 0.1060 - val_mae: 0.2736
Epoch 69/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3148 - val_loss: 0.1050 - val_mae: 0.2689
Epoch 70/5000
41/41 - 1s - loss: 0.1246 - mae: 0.3158 - val_loss: 0.1086 - val_mae: 0.2810
Epoch 71/5000
41/41 - 1s - loss: 0.1316 - mae: 0.3367 - val_loss: 0.1079 - val_mae: 0.2968
Epoch 72/5000
41/41 - 1s - loss: 0.1261 - mae: 0.3231 - val_loss: 0.1055 - val_mae: 0.2788
Epoch 73/5000
41/41 - 1s - loss: 0.1265 - mae: 0.3225 - val_loss: 0.1063 - val_mae: 0.2823
Epoch 74/5000
41/41 - 1s - loss: 0.1225 - mae: 0.3122 - val_loss: 0.1064 - val_mae: 0.2950
Epoch 75/5000
41/41 - 1s - loss: 0.1214 - mae: 0.3101 - val_loss: 0.1058 - val_mae: 0.2797
Epoch 76/5000
41/41 - 1s - loss: 0.1214 - mae: 0.3093 - val_loss: 0.1066 - val_mae: 0.2834
Epoch 77/5000
41/41 - 1s - loss: 0.1224 - mae: 0.3124 - val_loss: 0.1053 - val_mae: 0.2715
Epoch 78/5000
41/41 - 1s - loss: 0.1219 - mae: 0.3114 - val_loss: 0.1040 - val_mae: 0.2645
Epoch 79/5000
41/41 - 1s - loss: 0.1218 - mae: 0.3102 - val_loss: 0.1075 - val_mae: 0.2804
Epoch 80/5000
41/41 - 1s - loss: 0.1229 - mae: 0.3135 - val_loss: 0.1075 - val_mae: 0.2664
Epoch 81/5000
41/41 - 1s - loss: 0.1240 - mae: 0.3167 - val_loss: 0.1092 - val_mae: 0.2846
Epoch 82/5000
41/41 - 1s - loss: 0.1257 - mae: 0.3232 - val_loss: 0.1076 - val_mae: 0.2822
Epoch 83/5000
41/41 - 1s - loss: 0.1212 - mae: 0.3093 - val_loss: 0.1057 - val_mae: 0.2787
Epoch 84/5000
41/41 - 1s - loss: 0.1217 - mae: 0.3109 - val_loss: 0.1039 - val_mae: 0.2683
Epoch 85/5000
41/41 - 1s - loss: 0.1205 - mae: 0.3053 - val_loss: 0.1040 - val_mae: 0.2611
Epoch 86/5000
41/41 - 1s - loss: 0.1218 - mae: 0.3104 - val_loss: 0.1069 - val_mae: 0.2651
Epoch 87/5000
41/41 - 1s - loss: 0.1219 - mae: 0.3115 - val_loss: 0.1079 - val_mae: 0.2817
Epoch 88/5000
41/41 - 1s - loss: 0.1199 - mae: 0.3061 - val_loss: 0.1061 - val_mae: 0.2739
Epoch 89/5000
41/41 - 1s - loss: 0.1205 - mae: 0.3069 - val_loss: 0.1060 - val_mae: 0.2644
Epoch 90/5000
41/41 - 1s - loss: 0.1219 - mae: 0.3116 - val_loss: 0.1086 - val_mae: 0.2806
Epoch 91/5000
41/41 - 1s - loss: 0.1290 - mae: 0.3302 - val_loss: 0.1073 - val_mae: 0.2820
Epoch 92/5000
41/41 - 1s - loss: 0.1232 - mae: 0.3167 - val_loss: 0.1065 - val_mae: 0.2894
Epoch 93/5000
41/41 - 1s - loss: 0.1248 - mae: 0.3199 - val_loss: 0.1068 - val_mae: 0.2855
Epoch 94/5000
41/41 - 1s - loss: 0.1206 - mae: 0.3083 - val_loss: 0.1041 - val_mae: 0.2649
Epoch 95/5000
41/41 - 1s - loss: 0.1213 - mae: 0.3105 - val_loss: 0.1059 - val_mae: 0.2728
Epoch 96/5000
41/41 - 1s - loss: 0.1195 - mae: 0.3040 - val_loss: 0.1053 - val_mae: 0.2659
Epoch 97/5000
41/41 - 1s - loss: 0.1183 - mae: 0.3013 - val_loss: 0.1045 - val_mae: 0.2680
Epoch 98/5000
41/41 - 1s - loss: 0.1181 - mae: 0.3005 - val_loss: 0.1056 - val_mae: 0.2624
Epoch 99/5000
41/41 - 1s - loss: 0.1196 - mae: 0.3044 - val_loss: 0.1063 - val_mae: 0.2690
Epoch 100/5000
41/41 - 1s - loss: 0.1197 - mae: 0.3057 - val_loss: 0.1069 - val_mae: 0.2690
Epoch 101/5000
41/41 - 1s - loss: 0.1189 - mae: 0.3046 - val_loss: 0.1062 - val_mae: 0.2685
Epoch 102/5000
41/41 - 1s - loss: 0.1196 - mae: 0.3032 - val_loss: 0.1066 - val_mae: 0.2725
Epoch 103/5000
41/41 - 1s - loss: 0.1183 - mae: 0.3013 - val_loss: 0.1058 - val_mae: 0.2737
Epoch 104/5000
41/41 - 1s - loss: 0.1189 - mae: 0.3037 - val_loss: 0.1058 - val_mae: 0.2888
Epoch 105/5000
41/41 - 1s - loss: 0.1203 - mae: 0.3075 - val_loss: 0.1073 - val_mae: 0.2896
Epoch 106/5000
41/41 - 1s - loss: 0.1185 - mae: 0.3043 - val_loss: 0.1059 - val_mae: 0.2816
Epoch 107/5000
41/41 - 1s - loss: 0.1199 - mae: 0.3073 - val_loss: 0.1078 - val_mae: 0.2897
Epoch 108/5000
41/41 - 1s - loss: 0.1186 - mae: 0.3042 - val_loss: 0.1076 - val_mae: 0.2804
Epoch 109/5000
41/41 - 1s - loss: 0.1193 - mae: 0.3055 - val_loss: 0.1106 - val_mae: 0.2858
Epoch 110/5000
41/41 - 1s - loss: 0.1209 - mae: 0.3091 - val_loss: 0.1067 - val_mae: 0.2809
Epoch 111/5000
41/41 - 1s - loss: 0.1198 - mae: 0.3073 - val_loss: 0.1074 - val_mae: 0.2860
Epoch 112/5000
41/41 - 1s - loss: 0.1183 - mae: 0.3040 - val_loss: 0.1080 - val_mae: 0.2663
Epoch 113/5000
41/41 - 1s - loss: 0.1208 - mae: 0.3110 - val_loss: 0.1072 - val_mae: 0.2904
Epoch 114/5000
41/41 - 1s - loss: 0.1321 - mae: 0.3332 - val_loss: 0.1399 - val_mae: 0.4225
Epoch 115/5000
41/41 - 1s - loss: 0.1335 - mae: 0.3431 - val_loss: 0.1101 - val_mae: 0.2976
Epoch 116/5000
41/41 - 1s - loss: 0.1357 - mae: 0.3447 - val_loss: 0.1284 - val_mae: 0.3734
Epoch 117/5000
41/41 - 1s - loss: 0.1256 - mae: 0.3212 - val_loss: 0.1067 - val_mae: 0.2967
Epoch 118/5000
41/41 - 1s - loss: 0.1226 - mae: 0.3139 - val_loss: 0.1055 - val_mae: 0.2780
Epoch 119/5000
41/41 - 1s - loss: 0.1188 - mae: 0.3038 - val_loss: 0.1053 - val_mae: 0.2695
Epoch 120/5000
41/41 - 1s - loss: 0.1189 - mae: 0.3045 - val_loss: 0.1052 - val_mae: 0.2643
Epoch 121/5000
41/41 - 1s - loss: 0.1273 - mae: 0.3239 - val_loss: 0.1134 - val_mae: 0.3247
Epoch 122/5000
41/41 - 1s - loss: 0.1311 - mae: 0.3361 - val_loss: 0.1140 - val_mae: 0.3184
Epoch 123/5000
41/41 - 1s - loss: 0.1291 - mae: 0.3323 - val_loss: 0.1190 - val_mae: 0.3402
Epoch 124/5000
41/41 - 1s - loss: 0.1293 - mae: 0.3271 - val_loss: 0.1297 - val_mae: 0.3890
Epoch 125/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3238 - val_loss: 0.1187 - val_mae: 0.3425
Epoch 126/5000
41/41 - 1s - loss: 0.1272 - mae: 0.3253 - val_loss: 0.1192 - val_mae: 0.3401
Epoch 127/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3221 - val_loss: 0.1338 - val_mae: 0.3884
Epoch 128/5000
41/41 - 1s - loss: 0.1259 - mae: 0.3215 - val_loss: 0.1385 - val_mae: 0.4014
Epoch 129/5000
41/41 - 1s - loss: 0.1263 - mae: 0.3239 - val_loss: 0.1265 - val_mae: 0.3601
Epoch 130/5000
41/41 - 1s - loss: 0.1251 - mae: 0.3197 - val_loss: 0.1283 - val_mae: 0.3810
Epoch 131/5000
41/41 - 1s - loss: 0.1258 - mae: 0.3216 - val_loss: 0.1308 - val_mae: 0.3762
Epoch 132/5000
41/41 - 1s - loss: 0.1255 - mae: 0.3195 - val_loss: 0.1405 - val_mae: 0.4102
Epoch 133/5000
41/41 - 1s - loss: 0.1253 - mae: 0.3206 - val_loss: 0.1265 - val_mae: 0.3565
Epoch 134/5000
41/41 - 1s - loss: 0.1235 - mae: 0.3139 - val_loss: 0.1329 - val_mae: 0.3745
Epoch 135/5000
41/41 - 1s - loss: 0.1240 - mae: 0.3162 - val_loss: 0.1323 - val_mae: 0.3802
Epoch 136/5000
41/41 - 1s - loss: 0.1244 - mae: 0.3166 - val_loss: 0.1401 - val_mae: 0.4031
Epoch 137/5000
41/41 - 1s - loss: 0.1241 - mae: 0.3161 - val_loss: 0.1379 - val_mae: 0.3977
Epoch 138/5000
41/41 - 1s - loss: 0.1238 - mae: 0.3161 - val_loss: 0.1417 - val_mae: 0.4047
Epoch 139/5000
41/41 - 1s - loss: 0.1239 - mae: 0.3197 - val_loss: 0.1263 - val_mae: 0.3560
Epoch 140/5000
41/41 - 1s - loss: 0.1206 - mae: 0.3080 - val_loss: 0.1222 - val_mae: 0.3564
Epoch 141/5000
41/41 - 1s - loss: 0.1233 - mae: 0.3136 - val_loss: 0.1399 - val_mae: 0.4047
Epoch 142/5000
41/41 - 1s - loss: 0.1231 - mae: 0.3163 - val_loss: 0.1322 - val_mae: 0.3899
Epoch 143/5000
41/41 - 1s - loss: 0.1224 - mae: 0.3114 - val_loss: 0.1326 - val_mae: 0.3846
Epoch 144/5000
41/41 - 1s - loss: 0.1211 - mae: 0.3098 - val_loss: 0.1340 - val_mae: 0.3849
Epoch 145/5000
41/41 - 1s - loss: 0.1214 - mae: 0.3092 - val_loss: 0.1314 - val_mae: 0.3817
Epoch 146/5000
41/41 - 1s - loss: 0.1205 - mae: 0.3089 - val_loss: 0.1289 - val_mae: 0.3652
Epoch 147/5000
41/41 - 1s - loss: 0.1199 - mae: 0.3062 - val_loss: 0.1277 - val_mae: 0.3634
Epoch 148/5000
41/41 - 1s - loss: 0.1199 - mae: 0.3059 - val_loss: 0.1315 - val_mae: 0.3736
Epoch 149/5000
41/41 - 1s - loss: 0.1203 - mae: 0.3086 - val_loss: 0.1379 - val_mae: 0.4025
Epoch 150/5000
41/41 - 1s - loss: 0.1209 - mae: 0.3115 - val_loss: 0.1262 - val_mae: 0.3521
Epoch 151/5000
41/41 - 1s - loss: 0.1208 - mae: 0.3081 - val_loss: 0.1228 - val_mae: 0.3547
Epoch 152/5000
41/41 - 1s - loss: 0.1187 - mae: 0.3031 - val_loss: 0.1109 - val_mae: 0.3071
Epoch 153/5000
41/41 - 1s - loss: 0.1167 - mae: 0.2979 - val_loss: 0.1116 - val_mae: 0.2992
Epoch 154/5000
41/41 - 1s - loss: 0.1158 - mae: 0.2962 - val_loss: 0.1097 - val_mae: 0.2951
Epoch 155/5000
41/41 - 1s - loss: 0.1166 - mae: 0.2966 - val_loss: 0.1124 - val_mae: 0.3145
Epoch 156/5000
41/41 - 1s - loss: 0.1159 - mae: 0.2952 - val_loss: 0.1059 - val_mae: 0.2862
Epoch 157/5000
41/41 - 1s - loss: 0.1164 - mae: 0.2972 - val_loss: 0.1126 - val_mae: 0.3099
Epoch 158/5000
41/41 - 1s - loss: 0.1185 - mae: 0.3037 - val_loss: 0.1138 - val_mae: 0.3193
Epoch 159/5000
41/41 - 1s - loss: 0.1216 - mae: 0.3106 - val_loss: 0.1331 - val_mae: 0.3883
Epoch 160/5000
41/41 - 1s - loss: 0.1249 - mae: 0.3202 - val_loss: 0.1260 - val_mae: 0.3632
Epoch 161/5000
41/41 - 1s - loss: 0.1188 - mae: 0.3046 - val_loss: 0.1214 - val_mae: 0.3513
Epoch 162/5000
41/41 - 1s - loss: 0.1193 - mae: 0.3058 - val_loss: 0.1305 - val_mae: 0.3706
Epoch 163/5000
41/41 - 1s - loss: 0.1209 - mae: 0.3094 - val_loss: 0.1444 - val_mae: 0.4210
Epoch 164/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3222 - val_loss: 0.1300 - val_mae: 0.3634
Epoch 165/5000
41/41 - 1s - loss: 0.1217 - mae: 0.3104 - val_loss: 0.1410 - val_mae: 0.4024
Epoch 166/5000
41/41 - 1s - loss: 0.1236 - mae: 0.3206 - val_loss: 0.1201 - val_mae: 0.3355
Epoch 167/5000
41/41 - 1s - loss: 0.1169 - mae: 0.3000 - val_loss: 0.1178 - val_mae: 0.3273
Epoch 168/5000
41/41 - 1s - loss: 0.1174 - mae: 0.3013 - val_loss: 0.1197 - val_mae: 0.3330
Epoch 169/5000
41/41 - 1s - loss: 0.1178 - mae: 0.3016 - val_loss: 0.1243 - val_mae: 0.3468
Epoch 170/5000
41/41 - 1s - loss: 0.1178 - mae: 0.3018 - val_loss: 0.1240 - val_mae: 0.3420
Epoch 171/5000
41/41 - 1s - loss: 0.1187 - mae: 0.3042 - val_loss: 0.1361 - val_mae: 0.3813
Epoch 172/5000
41/41 - 1s - loss: 0.1209 - mae: 0.3088 - val_loss: 0.1483 - val_mae: 0.4206
Epoch 173/5000
41/41 - 1s - loss: 0.1208 - mae: 0.3095 - val_loss: 0.1277 - val_mae: 0.3562
Epoch 174/5000
41/41 - 1s - loss: 0.1176 - mae: 0.3014 - val_loss: 0.1296 - val_mae: 0.3664
Epoch 175/5000
41/41 - 1s - loss: 0.1174 - mae: 0.3019 - val_loss: 0.1383 - val_mae: 0.3871
Epoch 176/5000
41/41 - 1s - loss: 0.1203 - mae: 0.3085 - val_loss: 0.1438 - val_mae: 0.4143
Epoch 177/5000
41/41 - 1s - loss: 0.1216 - mae: 0.3148 - val_loss: 0.1286 - val_mae: 0.3555
Epoch 178/5000
41/41 - 1s - loss: 0.1180 - mae: 0.3024 - val_loss: 0.1511 - val_mae: 0.4263
Epoch 179/5000
41/41 - 1s - loss: 0.1212 - mae: 0.3145 - val_loss: 0.1231 - val_mae: 0.3368
Epoch 180/5000
41/41 - 1s - loss: 0.1156 - mae: 0.2953 - val_loss: 0.1322 - val_mae: 0.3722
Epoch 181/5000
41/41 - 1s - loss: 0.1171 - mae: 0.2984 - val_loss: 0.1407 - val_mae: 0.3918
Epoch 182/5000
41/41 - 1s - loss: 0.1169 - mae: 0.2993 - val_loss: 0.1234 - val_mae: 0.3380
Epoch 183/5000
41/41 - 1s - loss: 0.1158 - mae: 0.2957 - val_loss: 0.1302 - val_mae: 0.3591
Epoch 184/5000
41/41 - 1s - loss: 0.1152 - mae: 0.2958 - val_loss: 0.1323 - val_mae: 0.3766
Epoch 185/5000
41/41 - 1s - loss: 0.1165 - mae: 0.2979 - val_loss: 0.1462 - val_mae: 0.4004
Epoch 186/5000
41/41 - 1s - loss: 0.1197 - mae: 0.3071 - val_loss: 0.1254 - val_mae: 0.3597
Restoring model weights from the end of the best epoch.
Epoch 00186: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_4..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_24"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_4 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_4 (PartitionP (None, None, 64)     0           message_passing_4[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_4[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_4 (Masking)             (None, None, 64)     0           partition_padding_4[0][0]        
                                                                 partition_padding_4[1][0]        
__________________________________________________________________________________________________
transformer_encoder_4 (Transfor (None, None, 64)     199040      masking_4[0][0]                  
                                                                 masking_4[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_4 (Glo (None, 64)           0           transformer_encoder_4[0][0]      
                                                                 transformer_encoder_4[1][0]      
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 512)          33280       global_average_pooling1d_4[0][0] 
                                                                 global_average_pooling1d_4[1][0] 
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 10)           110         dense_72[0][0]                   
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 450)          230850      dense_70[0][0]                   
                                                                 dense_70[1][0]                   
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 5)            55          dense_73[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 905)          0           dense_71[0][0]                   
                                                                 dense_71[1][0]                   
                                                                 dense_74[0][0]                   
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 700)          634200      concatenate_4[0][0]              
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 560)          392560      dense_75[0][0]                   
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 373)          209253      dense_79[0][0]                   
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 187)          69938       dense_80[0][0]                   
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 1)            188         dense_81[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
41/41 - 6s - loss: 0.1388 - mae: 0.3508 - val_loss: 0.1055 - val_mae: 0.2815
Epoch 2/5000
41/41 - 1s - loss: 0.1169 - mae: 0.3048 - val_loss: 0.1198 - val_mae: 0.3280
Epoch 3/5000
41/41 - 1s - loss: 0.1129 - mae: 0.2896 - val_loss: 0.1179 - val_mae: 0.3073
Epoch 4/5000
41/41 - 1s - loss: 0.1092 - mae: 0.2807 - val_loss: 0.1186 - val_mae: 0.3056
Epoch 5/5000
41/41 - 1s - loss: 0.1061 - mae: 0.2743 - val_loss: 0.1254 - val_mae: 0.3264
Epoch 6/5000
41/41 - 1s - loss: 0.1048 - mae: 0.2714 - val_loss: 0.1308 - val_mae: 0.3429
Epoch 7/5000
41/41 - 1s - loss: 0.1037 - mae: 0.2688 - val_loss: 0.1389 - val_mae: 0.3624
Epoch 8/5000
41/41 - 1s - loss: 0.1034 - mae: 0.2688 - val_loss: 0.1457 - val_mae: 0.3778
Epoch 9/5000
41/41 - 1s - loss: 0.1060 - mae: 0.2756 - val_loss: 0.1199 - val_mae: 0.2994
Epoch 10/5000
41/41 - 1s - loss: 0.0992 - mae: 0.2621 - val_loss: 0.1236 - val_mae: 0.3190
Epoch 11/5000
41/41 - 1s - loss: 0.0945 - mae: 0.2497 - val_loss: 0.1306 - val_mae: 0.3430
Epoch 12/5000
41/41 - 1s - loss: 0.0917 - mae: 0.2441 - val_loss: 0.1329 - val_mae: 0.3480
Epoch 13/5000
41/41 - 1s - loss: 0.0896 - mae: 0.2390 - val_loss: 0.1351 - val_mae: 0.3577
Epoch 14/5000
41/41 - 1s - loss: 0.0883 - mae: 0.2364 - val_loss: 0.1403 - val_mae: 0.3730
Epoch 15/5000
41/41 - 1s - loss: 0.0872 - mae: 0.2328 - val_loss: 0.1505 - val_mae: 0.3933
Epoch 16/5000
41/41 - 1s - loss: 0.0871 - mae: 0.2331 - val_loss: 0.1409 - val_mae: 0.3693
Epoch 17/5000
41/41 - 1s - loss: 0.0861 - mae: 0.2309 - val_loss: 0.1353 - val_mae: 0.3537
Epoch 18/5000
41/41 - 1s - loss: 0.0850 - mae: 0.2288 - val_loss: 0.1334 - val_mae: 0.3520
Epoch 19/5000
41/41 - 1s - loss: 0.0862 - mae: 0.2328 - val_loss: 0.1254 - val_mae: 0.3211
Epoch 20/5000
41/41 - 1s - loss: 0.0905 - mae: 0.2432 - val_loss: 0.1612 - val_mae: 0.4157
Epoch 21/5000
41/41 - 1s - loss: 0.0943 - mae: 0.2528 - val_loss: 0.1333 - val_mae: 0.3431
Epoch 22/5000
41/41 - 1s - loss: 0.0927 - mae: 0.2554 - val_loss: 0.1328 - val_mae: 0.3449
Epoch 23/5000
41/41 - 1s - loss: 0.0855 - mae: 0.2338 - val_loss: 0.1313 - val_mae: 0.3399
Epoch 24/5000
41/41 - 1s - loss: 0.0862 - mae: 0.2391 - val_loss: 0.1360 - val_mae: 0.3490
Epoch 25/5000
41/41 - 1s - loss: 0.0809 - mae: 0.2242 - val_loss: 0.1377 - val_mae: 0.3565
Epoch 26/5000
41/41 - 1s - loss: 0.0800 - mae: 0.2224 - val_loss: 0.1356 - val_mae: 0.3503
Epoch 27/5000
41/41 - 1s - loss: 0.0801 - mae: 0.2240 - val_loss: 0.1331 - val_mae: 0.3465
Epoch 28/5000
41/41 - 1s - loss: 0.0789 - mae: 0.2229 - val_loss: 0.1360 - val_mae: 0.3534
Epoch 29/5000
41/41 - 1s - loss: 0.0788 - mae: 0.2233 - val_loss: 0.1376 - val_mae: 0.3636
Epoch 30/5000
41/41 - 1s - loss: 0.0775 - mae: 0.2203 - val_loss: 0.1326 - val_mae: 0.3588
Epoch 31/5000
41/41 - 1s - loss: 0.0769 - mae: 0.2198 - val_loss: 0.1225 - val_mae: 0.3304
Epoch 32/5000
41/41 - 1s - loss: 0.0791 - mae: 0.2263 - val_loss: 0.1298 - val_mae: 0.3457
Epoch 33/5000
41/41 - 1s - loss: 0.0837 - mae: 0.2393 - val_loss: 0.1188 - val_mae: 0.2872
Epoch 34/5000
41/41 - 1s - loss: 0.0908 - mae: 0.2580 - val_loss: 0.1186 - val_mae: 0.2825
Epoch 35/5000
41/41 - 1s - loss: 0.0919 - mae: 0.2553 - val_loss: 0.1096 - val_mae: 0.2612
Epoch 36/5000
41/41 - 1s - loss: 0.0912 - mae: 0.2491 - val_loss: 0.1094 - val_mae: 0.2692
Epoch 37/5000
41/41 - 1s - loss: 0.0804 - mae: 0.2257 - val_loss: 0.1068 - val_mae: 0.2640
Epoch 38/5000
41/41 - 1s - loss: 0.0715 - mae: 0.2078 - val_loss: 0.1076 - val_mae: 0.2633
Epoch 39/5000
41/41 - 1s - loss: 0.0686 - mae: 0.2026 - val_loss: 0.1110 - val_mae: 0.2715
Epoch 40/5000
41/41 - 1s - loss: 0.0654 - mae: 0.1963 - val_loss: 0.1098 - val_mae: 0.2615
Epoch 41/5000
41/41 - 1s - loss: 0.0634 - mae: 0.1924 - val_loss: 0.1110 - val_mae: 0.2673
Epoch 42/5000
41/41 - 1s - loss: 0.0624 - mae: 0.1924 - val_loss: 0.1108 - val_mae: 0.2642
Epoch 43/5000
41/41 - 1s - loss: 0.0601 - mae: 0.1871 - val_loss: 0.1153 - val_mae: 0.2774
Epoch 44/5000
41/41 - 1s - loss: 0.0614 - mae: 0.1929 - val_loss: 0.1187 - val_mae: 0.2847
Epoch 45/5000
41/41 - 1s - loss: 0.0636 - mae: 0.1989 - val_loss: 0.1178 - val_mae: 0.2859
Epoch 46/5000
41/41 - 1s - loss: 0.0689 - mae: 0.2076 - val_loss: 0.1357 - val_mae: 0.3415
Epoch 47/5000
41/41 - 1s - loss: 0.0711 - mae: 0.2134 - val_loss: 0.1101 - val_mae: 0.2613
Epoch 48/5000
41/41 - 1s - loss: 0.0703 - mae: 0.2123 - val_loss: 0.1121 - val_mae: 0.2735
Epoch 49/5000
41/41 - 1s - loss: 0.0712 - mae: 0.2152 - val_loss: 0.1151 - val_mae: 0.2700
Epoch 50/5000
41/41 - 1s - loss: 0.0761 - mae: 0.2246 - val_loss: 0.1405 - val_mae: 0.3541
Epoch 51/5000
41/41 - 1s - loss: 0.0879 - mae: 0.2482 - val_loss: 0.1052 - val_mae: 0.2623
Epoch 52/5000
41/41 - 1s - loss: 0.0700 - mae: 0.2135 - val_loss: 0.1139 - val_mae: 0.2924
Epoch 53/5000
41/41 - 1s - loss: 0.0603 - mae: 0.1917 - val_loss: 0.1308 - val_mae: 0.3268
Epoch 54/5000
41/41 - 1s - loss: 0.0562 - mae: 0.1840 - val_loss: 0.1298 - val_mae: 0.3215
Epoch 55/5000
41/41 - 1s - loss: 0.0535 - mae: 0.1784 - val_loss: 0.1211 - val_mae: 0.3109
Epoch 56/5000
41/41 - 1s - loss: 0.0512 - mae: 0.1743 - val_loss: 0.1167 - val_mae: 0.2843
Epoch 57/5000
41/41 - 1s - loss: 0.0550 - mae: 0.1834 - val_loss: 0.1108 - val_mae: 0.2726
Epoch 58/5000
41/41 - 1s - loss: 0.0556 - mae: 0.1874 - val_loss: 0.1146 - val_mae: 0.2748
Epoch 59/5000
41/41 - 1s - loss: 0.0544 - mae: 0.1820 - val_loss: 0.1182 - val_mae: 0.2878
Epoch 60/5000
41/41 - 1s - loss: 0.0565 - mae: 0.1847 - val_loss: 0.1244 - val_mae: 0.3035
Epoch 61/5000
41/41 - 1s - loss: 0.0624 - mae: 0.1963 - val_loss: 0.1083 - val_mae: 0.2680
Epoch 62/5000
41/41 - 1s - loss: 0.0539 - mae: 0.1813 - val_loss: 0.1154 - val_mae: 0.2899
Epoch 63/5000
41/41 - 1s - loss: 0.0505 - mae: 0.1743 - val_loss: 0.1186 - val_mae: 0.3008
Epoch 64/5000
41/41 - 1s - loss: 0.0633 - mae: 0.2030 - val_loss: 0.1132 - val_mae: 0.2821
Epoch 65/5000
41/41 - 1s - loss: 0.0582 - mae: 0.1936 - val_loss: 0.1091 - val_mae: 0.2701
Epoch 66/5000
41/41 - 1s - loss: 0.0507 - mae: 0.1769 - val_loss: 0.1117 - val_mae: 0.2646
Epoch 67/5000
41/41 - 1s - loss: 0.0528 - mae: 0.1814 - val_loss: 0.1149 - val_mae: 0.2840
Epoch 68/5000
41/41 - 1s - loss: 0.0486 - mae: 0.1743 - val_loss: 0.1120 - val_mae: 0.2826
Epoch 69/5000
41/41 - 1s - loss: 0.0549 - mae: 0.1872 - val_loss: 0.1232 - val_mae: 0.2987
Epoch 70/5000
41/41 - 1s - loss: 0.0547 - mae: 0.1886 - val_loss: 0.1069 - val_mae: 0.2550
Epoch 71/5000
41/41 - 1s - loss: 0.0536 - mae: 0.1892 - val_loss: 0.1123 - val_mae: 0.2588
Epoch 72/5000
41/41 - 1s - loss: 0.0566 - mae: 0.1932 - val_loss: 0.1066 - val_mae: 0.2605
Epoch 73/5000
41/41 - 1s - loss: 0.0593 - mae: 0.1997 - val_loss: 0.1068 - val_mae: 0.2529
Epoch 74/5000
41/41 - 1s - loss: 0.0563 - mae: 0.1942 - val_loss: 0.1086 - val_mae: 0.2503
Epoch 75/5000
41/41 - 1s - loss: 0.0520 - mae: 0.1879 - val_loss: 0.1133 - val_mae: 0.2568
Epoch 76/5000
41/41 - 1s - loss: 0.0566 - mae: 0.1959 - val_loss: 0.1131 - val_mae: 0.2555
Epoch 77/5000
41/41 - 1s - loss: 0.0618 - mae: 0.2101 - val_loss: 0.1191 - val_mae: 0.2665
Epoch 78/5000
41/41 - 1s - loss: 0.0669 - mae: 0.2201 - val_loss: 0.1229 - val_mae: 0.2777
Epoch 79/5000
41/41 - 1s - loss: 0.0752 - mae: 0.2357 - val_loss: 0.1146 - val_mae: 0.2703
Epoch 80/5000
41/41 - 1s - loss: 0.0734 - mae: 0.2322 - val_loss: 0.1067 - val_mae: 0.2574
Epoch 81/5000
41/41 - 1s - loss: 0.0590 - mae: 0.1983 - val_loss: 0.1059 - val_mae: 0.2529
Epoch 82/5000
41/41 - 1s - loss: 0.0591 - mae: 0.2000 - val_loss: 0.1064 - val_mae: 0.2527
Epoch 83/5000
41/41 - 1s - loss: 0.0587 - mae: 0.2010 - val_loss: 0.1085 - val_mae: 0.2588
Epoch 84/5000
41/41 - 1s - loss: 0.0582 - mae: 0.1979 - val_loss: 0.1095 - val_mae: 0.2648
Epoch 85/5000
41/41 - 1s - loss: 0.0538 - mae: 0.1879 - val_loss: 0.1107 - val_mae: 0.2671
Epoch 86/5000
41/41 - 1s - loss: 0.0559 - mae: 0.1945 - val_loss: 0.1079 - val_mae: 0.2627
Epoch 87/5000
41/41 - 1s - loss: 0.0544 - mae: 0.1934 - val_loss: 0.1095 - val_mae: 0.2650
Epoch 88/5000
41/41 - 1s - loss: 0.0505 - mae: 0.1806 - val_loss: 0.1074 - val_mae: 0.2645
Epoch 89/5000
41/41 - 1s - loss: 0.0458 - mae: 0.1735 - val_loss: 0.1115 - val_mae: 0.2690
Epoch 90/5000
41/41 - 1s - loss: 0.0429 - mae: 0.1636 - val_loss: 0.1141 - val_mae: 0.2779
Epoch 91/5000
41/41 - 1s - loss: 0.0392 - mae: 0.1564 - val_loss: 0.1125 - val_mae: 0.2666
Epoch 92/5000
41/41 - 1s - loss: 0.0363 - mae: 0.1462 - val_loss: 0.1135 - val_mae: 0.2753
Epoch 93/5000
41/41 - 1s - loss: 0.0341 - mae: 0.1398 - val_loss: 0.1144 - val_mae: 0.2762
Epoch 94/5000
41/41 - 1s - loss: 0.0337 - mae: 0.1386 - val_loss: 0.1090 - val_mae: 0.2650
Epoch 95/5000
41/41 - 1s - loss: 0.0353 - mae: 0.1428 - val_loss: 0.1110 - val_mae: 0.2611
Epoch 96/5000
41/41 - 1s - loss: 0.0376 - mae: 0.1486 - val_loss: 0.1089 - val_mae: 0.2678
Epoch 97/5000
41/41 - 1s - loss: 0.0392 - mae: 0.1550 - val_loss: 0.1086 - val_mae: 0.2622
Epoch 98/5000
41/41 - 1s - loss: 0.0323 - mae: 0.1349 - val_loss: 0.1111 - val_mae: 0.2644
Epoch 99/5000
41/41 - 1s - loss: 0.0325 - mae: 0.1350 - val_loss: 0.1090 - val_mae: 0.2632
Epoch 100/5000
41/41 - 1s - loss: 0.0347 - mae: 0.1429 - val_loss: 0.1108 - val_mae: 0.2654
Epoch 101/5000
41/41 - 1s - loss: 0.0310 - mae: 0.1286 - val_loss: 0.1120 - val_mae: 0.2649
Epoch 102/5000
41/41 - 1s - loss: 0.0303 - mae: 0.1313 - val_loss: 0.1121 - val_mae: 0.2755
Epoch 103/5000
41/41 - 1s - loss: 0.0352 - mae: 0.1450 - val_loss: 0.1139 - val_mae: 0.2708
Epoch 104/5000
41/41 - 1s - loss: 0.0316 - mae: 0.1346 - val_loss: 0.1125 - val_mae: 0.2678
Epoch 105/5000
41/41 - 1s - loss: 0.0390 - mae: 0.1508 - val_loss: 0.1107 - val_mae: 0.2733
Epoch 106/5000
41/41 - 1s - loss: 0.0347 - mae: 0.1433 - val_loss: 0.1100 - val_mae: 0.2617
Epoch 107/5000
41/41 - 1s - loss: 0.0307 - mae: 0.1304 - val_loss: 0.1146 - val_mae: 0.2739
Epoch 108/5000
41/41 - 1s - loss: 0.0300 - mae: 0.1304 - val_loss: 0.1126 - val_mae: 0.2717
Epoch 109/5000
41/41 - 1s - loss: 0.0291 - mae: 0.1272 - val_loss: 0.1123 - val_mae: 0.2682
Epoch 110/5000
41/41 - 1s - loss: 0.0269 - mae: 0.1216 - val_loss: 0.1113 - val_mae: 0.2674
Epoch 111/5000
41/41 - 1s - loss: 0.0269 - mae: 0.1211 - val_loss: 0.1120 - val_mae: 0.2673
Epoch 112/5000
41/41 - 1s - loss: 0.0328 - mae: 0.1379 - val_loss: 0.1129 - val_mae: 0.2715
Epoch 113/5000
41/41 - 1s - loss: 0.0308 - mae: 0.1332 - val_loss: 0.1130 - val_mae: 0.2656
Epoch 114/5000
41/41 - 1s - loss: 0.0344 - mae: 0.1420 - val_loss: 0.1090 - val_mae: 0.2673
Epoch 115/5000
41/41 - 1s - loss: 0.0281 - mae: 0.1271 - val_loss: 0.1114 - val_mae: 0.2683
Epoch 116/5000
41/41 - 1s - loss: 0.0284 - mae: 0.1256 - val_loss: 0.1110 - val_mae: 0.2654
Epoch 117/5000
41/41 - 1s - loss: 0.0276 - mae: 0.1237 - val_loss: 0.1138 - val_mae: 0.2683
Epoch 118/5000
41/41 - 1s - loss: 0.0278 - mae: 0.1213 - val_loss: 0.1096 - val_mae: 0.2632
Epoch 119/5000
41/41 - 1s - loss: 0.0302 - mae: 0.1323 - val_loss: 0.1157 - val_mae: 0.2730
Epoch 120/5000
41/41 - 1s - loss: 0.0267 - mae: 0.1192 - val_loss: 0.1113 - val_mae: 0.2640
Epoch 121/5000
41/41 - 1s - loss: 0.0279 - mae: 0.1234 - val_loss: 0.1116 - val_mae: 0.2712
Epoch 122/5000
41/41 - 1s - loss: 0.0341 - mae: 0.1440 - val_loss: 0.1129 - val_mae: 0.2725
Epoch 123/5000
41/41 - 1s - loss: 0.0287 - mae: 0.1269 - val_loss: 0.1130 - val_mae: 0.2642
Epoch 124/5000
41/41 - 1s - loss: 0.0333 - mae: 0.1392 - val_loss: 0.1148 - val_mae: 0.2851
Epoch 125/5000
41/41 - 1s - loss: 0.0375 - mae: 0.1500 - val_loss: 0.1157 - val_mae: 0.2745
Epoch 126/5000
41/41 - 1s - loss: 0.0273 - mae: 0.1237 - val_loss: 0.1135 - val_mae: 0.2754
Epoch 127/5000
41/41 - 1s - loss: 0.0327 - mae: 0.1373 - val_loss: 0.1161 - val_mae: 0.2731
Epoch 128/5000
41/41 - 1s - loss: 0.0269 - mae: 0.1199 - val_loss: 0.1176 - val_mae: 0.2878
Epoch 129/5000
41/41 - 1s - loss: 0.0311 - mae: 0.1356 - val_loss: 0.1185 - val_mae: 0.2789
Epoch 130/5000
41/41 - 1s - loss: 0.0274 - mae: 0.1243 - val_loss: 0.1165 - val_mae: 0.2766
Epoch 131/5000
41/41 - 1s - loss: 0.0276 - mae: 0.1211 - val_loss: 0.1255 - val_mae: 0.3000
Epoch 132/5000
41/41 - 1s - loss: 0.0345 - mae: 0.1490 - val_loss: 0.1197 - val_mae: 0.2809
Epoch 133/5000
41/41 - 1s - loss: 0.0284 - mae: 0.1221 - val_loss: 0.1238 - val_mae: 0.2938
Epoch 134/5000
41/41 - 1s - loss: 0.0299 - mae: 0.1340 - val_loss: 0.1207 - val_mae: 0.2809
Epoch 135/5000
41/41 - 1s - loss: 0.0286 - mae: 0.1258 - val_loss: 0.1228 - val_mae: 0.3016
Epoch 136/5000
41/41 - 1s - loss: 0.0266 - mae: 0.1225 - val_loss: 0.1299 - val_mae: 0.3057
Epoch 137/5000
41/41 - 1s - loss: 0.0298 - mae: 0.1356 - val_loss: 0.1212 - val_mae: 0.2875
Epoch 138/5000
41/41 - 1s - loss: 0.0254 - mae: 0.1166 - val_loss: 0.1353 - val_mae: 0.3193
Epoch 139/5000
41/41 - 1s - loss: 0.0321 - mae: 0.1405 - val_loss: 0.1246 - val_mae: 0.2915
Epoch 140/5000
41/41 - 1s - loss: 0.0325 - mae: 0.1352 - val_loss: 0.1426 - val_mae: 0.3437
Epoch 141/5000
41/41 - 1s - loss: 0.0389 - mae: 0.1558 - val_loss: 0.1201 - val_mae: 0.2857
Epoch 142/5000
41/41 - 1s - loss: 0.0305 - mae: 0.1312 - val_loss: 0.1303 - val_mae: 0.3206
Epoch 143/5000
41/41 - 1s - loss: 0.0310 - mae: 0.1351 - val_loss: 0.1186 - val_mae: 0.2817
Epoch 144/5000
41/41 - 1s - loss: 0.0314 - mae: 0.1329 - val_loss: 0.1241 - val_mae: 0.3015
Epoch 145/5000
41/41 - 1s - loss: 0.0267 - mae: 0.1220 - val_loss: 0.1126 - val_mae: 0.2710
Epoch 146/5000
41/41 - 1s - loss: 0.0272 - mae: 0.1250 - val_loss: 0.1162 - val_mae: 0.2821
Epoch 147/5000
41/41 - 1s - loss: 0.0252 - mae: 0.1151 - val_loss: 0.1119 - val_mae: 0.2665
Epoch 148/5000
41/41 - 1s - loss: 0.0295 - mae: 0.1340 - val_loss: 0.1136 - val_mae: 0.2772
Epoch 149/5000
41/41 - 1s - loss: 0.0245 - mae: 0.1171 - val_loss: 0.1094 - val_mae: 0.2603
Epoch 150/5000
41/41 - 1s - loss: 0.0296 - mae: 0.1365 - val_loss: 0.1101 - val_mae: 0.2701
Epoch 151/5000
41/41 - 1s - loss: 0.0248 - mae: 0.1196 - val_loss: 0.1053 - val_mae: 0.2554
Epoch 152/5000
41/41 - 1s - loss: 0.0280 - mae: 0.1304 - val_loss: 0.1069 - val_mae: 0.2596
Epoch 153/5000
41/41 - 1s - loss: 0.0326 - mae: 0.1327 - val_loss: 0.1061 - val_mae: 0.2568
Epoch 154/5000
41/41 - 1s - loss: 0.0308 - mae: 0.1343 - val_loss: 0.1090 - val_mae: 0.2588
Epoch 155/5000
41/41 - 1s - loss: 0.0317 - mae: 0.1379 - val_loss: 0.1099 - val_mae: 0.2623
Epoch 156/5000
41/41 - 1s - loss: 0.0327 - mae: 0.1391 - val_loss: 0.1099 - val_mae: 0.2593
Epoch 157/5000
41/41 - 1s - loss: 0.0363 - mae: 0.1531 - val_loss: 0.1058 - val_mae: 0.2598
Epoch 158/5000
41/41 - 1s - loss: 0.0316 - mae: 0.1364 - val_loss: 0.1113 - val_mae: 0.2624
Epoch 159/5000
41/41 - 1s - loss: 0.0364 - mae: 0.1497 - val_loss: 0.1119 - val_mae: 0.2688
Epoch 160/5000
41/41 - 1s - loss: 0.0320 - mae: 0.1418 - val_loss: 0.1189 - val_mae: 0.2880
Epoch 161/5000
41/41 - 1s - loss: 0.0273 - mae: 0.1269 - val_loss: 0.1233 - val_mae: 0.2973
Epoch 162/5000
41/41 - 1s - loss: 0.0242 - mae: 0.1167 - val_loss: 0.1207 - val_mae: 0.2939
Epoch 163/5000
41/41 - 1s - loss: 0.0238 - mae: 0.1170 - val_loss: 0.1204 - val_mae: 0.2884
Epoch 164/5000
41/41 - 1s - loss: 0.0218 - mae: 0.1039 - val_loss: 0.1199 - val_mae: 0.2913
Epoch 165/5000
41/41 - 1s - loss: 0.0217 - mae: 0.1100 - val_loss: 0.1205 - val_mae: 0.2870
Epoch 166/5000
41/41 - 1s - loss: 0.0225 - mae: 0.1104 - val_loss: 0.1162 - val_mae: 0.2859
Epoch 167/5000
41/41 - 1s - loss: 0.0216 - mae: 0.1081 - val_loss: 0.1193 - val_mae: 0.2851
Epoch 168/5000
41/41 - 1s - loss: 0.0224 - mae: 0.1096 - val_loss: 0.1148 - val_mae: 0.2820
Epoch 169/5000
41/41 - 1s - loss: 0.0193 - mae: 0.1020 - val_loss: 0.1168 - val_mae: 0.2807
Epoch 170/5000
41/41 - 1s - loss: 0.0190 - mae: 0.1007 - val_loss: 0.1148 - val_mae: 0.2809
Epoch 171/5000
41/41 - 1s - loss: 0.0180 - mae: 0.0982 - val_loss: 0.1139 - val_mae: 0.2770
Epoch 172/5000
41/41 - 1s - loss: 0.0181 - mae: 0.0986 - val_loss: 0.1137 - val_mae: 0.2769
Epoch 173/5000
41/41 - 1s - loss: 0.0178 - mae: 0.0964 - val_loss: 0.1159 - val_mae: 0.2799
Epoch 174/5000
41/41 - 1s - loss: 0.0160 - mae: 0.0911 - val_loss: 0.1137 - val_mae: 0.2794
Epoch 175/5000
41/41 - 1s - loss: 0.0185 - mae: 0.0995 - val_loss: 0.1155 - val_mae: 0.2795
Restoring model weights from the end of the best epoch.
Epoch 00175: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_4..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 5

Generating graphs from SMILES..

Setting up training set.
Size: 2057

Setting up validation set.
Size: 229

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_29"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_5 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_5 (PartitionP (None, None, 64)     0           message_passing_5[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_5[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_5 (Masking)             (None, None, 64)     0           partition_padding_5[0][0]        
                                                                 partition_padding_5[1][0]        
__________________________________________________________________________________________________
transformer_encoder_5 (Transfor (None, None, 64)     199040      masking_5[0][0]                  
                                                                 masking_5[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_5 (Glo (None, 64)           0           transformer_encoder_5[0][0]      
                                                                 transformer_encoder_5[1][0]      
__________________________________________________________________________________________________
dense_89 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_87 (Dense)                (None, 512)          33280       global_average_pooling1d_5[0][0] 
                                                                 global_average_pooling1d_5[1][0] 
__________________________________________________________________________________________________
dense_90 (Dense)                (None, 10)           110         dense_89[0][0]                   
__________________________________________________________________________________________________
dense_88 (Dense)                (None, 450)          230850      dense_87[0][0]                   
                                                                 dense_87[1][0]                   
__________________________________________________________________________________________________
dense_91 (Dense)                (None, 5)            55          dense_90[0][0]                   
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 905)          0           dense_88[0][0]                   
                                                                 dense_88[1][0]                   
                                                                 dense_91[0][0]                   
__________________________________________________________________________________________________
dense_92 (Dense)                (None, 700)          634200      concatenate_5[0][0]              
__________________________________________________________________________________________________
dense_96 (Dense)                (None, 560)          392560      dense_92[0][0]                   
__________________________________________________________________________________________________
dense_97 (Dense)                (None, 373)          209253      dense_96[0][0]                   
__________________________________________________________________________________________________
dense_98 (Dense)                (None, 187)          69938       dense_97[0][0]                   
__________________________________________________________________________________________________
dense_99 (Dense)                (None, 1)            188         dense_98[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
41/41 - 6s - loss: 0.2954 - mae: 0.5997 - val_loss: 0.1572 - val_mae: 0.3869
Epoch 2/5000
41/41 - 1s - loss: 0.1652 - mae: 0.4079 - val_loss: 0.1604 - val_mae: 0.3842
Epoch 3/5000
41/41 - 1s - loss: 0.1633 - mae: 0.4041 - val_loss: 0.1593 - val_mae: 0.3863
Epoch 4/5000
41/41 - 1s - loss: 0.1633 - mae: 0.4049 - val_loss: 0.1566 - val_mae: 0.3910
Epoch 5/5000
41/41 - 1s - loss: 0.1626 - mae: 0.4026 - val_loss: 0.1617 - val_mae: 0.4318
Epoch 6/5000
41/41 - 1s - loss: 0.1599 - mae: 0.3997 - val_loss: 0.1551 - val_mae: 0.3972
Epoch 7/5000
41/41 - 1s - loss: 0.1589 - mae: 0.3962 - val_loss: 0.1587 - val_mae: 0.4210
Epoch 8/5000
41/41 - 1s - loss: 0.1576 - mae: 0.3948 - val_loss: 0.1548 - val_mae: 0.4042
Epoch 9/5000
41/41 - 1s - loss: 0.1577 - mae: 0.3943 - val_loss: 0.1518 - val_mae: 0.3877
Epoch 10/5000
41/41 - 1s - loss: 0.1568 - mae: 0.3907 - val_loss: 0.1552 - val_mae: 0.4113
Epoch 11/5000
41/41 - 1s - loss: 0.1553 - mae: 0.3887 - val_loss: 0.1514 - val_mae: 0.3744
Epoch 12/5000
41/41 - 1s - loss: 0.1545 - mae: 0.3857 - val_loss: 0.1512 - val_mae: 0.3761
Epoch 13/5000
41/41 - 1s - loss: 0.1544 - mae: 0.3851 - val_loss: 0.1499 - val_mae: 0.3852
Epoch 14/5000
41/41 - 1s - loss: 0.1539 - mae: 0.3851 - val_loss: 0.1502 - val_mae: 0.3862
Epoch 15/5000
41/41 - 1s - loss: 0.1536 - mae: 0.3833 - val_loss: 0.1489 - val_mae: 0.3838
Epoch 16/5000
41/41 - 1s - loss: 0.1530 - mae: 0.3827 - val_loss: 0.1491 - val_mae: 0.3710
Epoch 17/5000
41/41 - 1s - loss: 0.1520 - mae: 0.3800 - val_loss: 0.1485 - val_mae: 0.3662
Epoch 18/5000
41/41 - 1s - loss: 0.1516 - mae: 0.3795 - val_loss: 0.1470 - val_mae: 0.3679
Epoch 19/5000
41/41 - 1s - loss: 0.1514 - mae: 0.3784 - val_loss: 0.1460 - val_mae: 0.3765
Epoch 20/5000
41/41 - 1s - loss: 0.1511 - mae: 0.3783 - val_loss: 0.1438 - val_mae: 0.3641
Epoch 21/5000
41/41 - 1s - loss: 0.1504 - mae: 0.3756 - val_loss: 0.1436 - val_mae: 0.3689
Epoch 22/5000
41/41 - 1s - loss: 0.1488 - mae: 0.3726 - val_loss: 0.1438 - val_mae: 0.3599
Epoch 23/5000
41/41 - 1s - loss: 0.1484 - mae: 0.3718 - val_loss: 0.1426 - val_mae: 0.3551
Epoch 24/5000
41/41 - 1s - loss: 0.1469 - mae: 0.3675 - val_loss: 0.1443 - val_mae: 0.3475
Epoch 25/5000
41/41 - 1s - loss: 0.1455 - mae: 0.3646 - val_loss: 0.1426 - val_mae: 0.3491
Epoch 26/5000
41/41 - 1s - loss: 0.1440 - mae: 0.3599 - val_loss: 0.1438 - val_mae: 0.3548
Epoch 27/5000
41/41 - 1s - loss: 0.1427 - mae: 0.3584 - val_loss: 0.1398 - val_mae: 0.3430
Epoch 28/5000
41/41 - 1s - loss: 0.1419 - mae: 0.3568 - val_loss: 0.1391 - val_mae: 0.3445
Epoch 29/5000
41/41 - 1s - loss: 0.1427 - mae: 0.3583 - val_loss: 0.1444 - val_mae: 0.3469
Epoch 30/5000
41/41 - 1s - loss: 0.1445 - mae: 0.3616 - val_loss: 0.1364 - val_mae: 0.3532
Epoch 31/5000
41/41 - 1s - loss: 0.1459 - mae: 0.3651 - val_loss: 0.1434 - val_mae: 0.3444
Epoch 32/5000
41/41 - 1s - loss: 0.1433 - mae: 0.3584 - val_loss: 0.1400 - val_mae: 0.3724
Epoch 33/5000
41/41 - 1s - loss: 0.1447 - mae: 0.3632 - val_loss: 0.1432 - val_mae: 0.3344
Epoch 34/5000
41/41 - 1s - loss: 0.1421 - mae: 0.3548 - val_loss: 0.1375 - val_mae: 0.3426
Epoch 35/5000
41/41 - 1s - loss: 0.1386 - mae: 0.3491 - val_loss: 0.1413 - val_mae: 0.3368
Epoch 36/5000
41/41 - 1s - loss: 0.1404 - mae: 0.3509 - val_loss: 0.1456 - val_mae: 0.3475
Epoch 37/5000
41/41 - 1s - loss: 0.1430 - mae: 0.3604 - val_loss: 0.1381 - val_mae: 0.3290
Epoch 38/5000
41/41 - 1s - loss: 0.1431 - mae: 0.3573 - val_loss: 0.1362 - val_mae: 0.3475
Epoch 39/5000
41/41 - 1s - loss: 0.1406 - mae: 0.3515 - val_loss: 0.1404 - val_mae: 0.3412
Epoch 40/5000
41/41 - 1s - loss: 0.1413 - mae: 0.3559 - val_loss: 0.1437 - val_mae: 0.3404
Epoch 41/5000
41/41 - 1s - loss: 0.1427 - mae: 0.3560 - val_loss: 0.1407 - val_mae: 0.3311
Epoch 42/5000
41/41 - 1s - loss: 0.1432 - mae: 0.3573 - val_loss: 0.1380 - val_mae: 0.3332
Epoch 43/5000
41/41 - 1s - loss: 0.1421 - mae: 0.3539 - val_loss: 0.1388 - val_mae: 0.3330
Epoch 44/5000
41/41 - 1s - loss: 0.1430 - mae: 0.3577 - val_loss: 0.1343 - val_mae: 0.3281
Epoch 45/5000
41/41 - 1s - loss: 0.1424 - mae: 0.3547 - val_loss: 0.1331 - val_mae: 0.3424
Epoch 46/5000
41/41 - 1s - loss: 0.1415 - mae: 0.3545 - val_loss: 0.1325 - val_mae: 0.3353
Epoch 47/5000
41/41 - 1s - loss: 0.1428 - mae: 0.3559 - val_loss: 0.1339 - val_mae: 0.3511
Epoch 48/5000
41/41 - 1s - loss: 0.1404 - mae: 0.3521 - val_loss: 0.1320 - val_mae: 0.3351
Epoch 49/5000
41/41 - 1s - loss: 0.1375 - mae: 0.3441 - val_loss: 0.1319 - val_mae: 0.3365
Epoch 50/5000
41/41 - 1s - loss: 0.1383 - mae: 0.3453 - val_loss: 0.1334 - val_mae: 0.3248
Epoch 51/5000
41/41 - 1s - loss: 0.1414 - mae: 0.3523 - val_loss: 0.1424 - val_mae: 0.3879
Epoch 52/5000
41/41 - 1s - loss: 0.1374 - mae: 0.3441 - val_loss: 0.1335 - val_mae: 0.3247
Epoch 53/5000
41/41 - 1s - loss: 0.1380 - mae: 0.3463 - val_loss: 0.1326 - val_mae: 0.3440
Epoch 54/5000
41/41 - 1s - loss: 0.1379 - mae: 0.3440 - val_loss: 0.1391 - val_mae: 0.3732
Epoch 55/5000
41/41 - 1s - loss: 0.1399 - mae: 0.3496 - val_loss: 0.1486 - val_mae: 0.4026
Epoch 56/5000
41/41 - 1s - loss: 0.1383 - mae: 0.3450 - val_loss: 0.1567 - val_mae: 0.4261
Epoch 57/5000
41/41 - 1s - loss: 0.1372 - mae: 0.3439 - val_loss: 0.1405 - val_mae: 0.3692
Epoch 58/5000
41/41 - 1s - loss: 0.1326 - mae: 0.3315 - val_loss: 0.1313 - val_mae: 0.3197
Epoch 59/5000
41/41 - 1s - loss: 0.1350 - mae: 0.3363 - val_loss: 0.1328 - val_mae: 0.3448
Epoch 60/5000
41/41 - 1s - loss: 0.1354 - mae: 0.3384 - val_loss: 0.1313 - val_mae: 0.3316
Epoch 61/5000
41/41 - 1s - loss: 0.1364 - mae: 0.3400 - val_loss: 0.1448 - val_mae: 0.3892
Epoch 62/5000
41/41 - 1s - loss: 0.1369 - mae: 0.3431 - val_loss: 0.1409 - val_mae: 0.3743
Epoch 63/5000
41/41 - 1s - loss: 0.1340 - mae: 0.3333 - val_loss: 0.1449 - val_mae: 0.3885
Epoch 64/5000
41/41 - 1s - loss: 0.1376 - mae: 0.3419 - val_loss: 0.1395 - val_mae: 0.3747
Epoch 65/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3387 - val_loss: 0.1366 - val_mae: 0.3527
Epoch 66/5000
41/41 - 1s - loss: 0.1317 - mae: 0.3299 - val_loss: 0.1307 - val_mae: 0.3357
Epoch 67/5000
41/41 - 1s - loss: 0.1334 - mae: 0.3325 - val_loss: 0.1303 - val_mae: 0.3356
Epoch 68/5000
41/41 - 1s - loss: 0.1320 - mae: 0.3304 - val_loss: 0.1320 - val_mae: 0.3383
Epoch 69/5000
41/41 - 1s - loss: 0.1345 - mae: 0.3360 - val_loss: 0.1368 - val_mae: 0.3640
Epoch 70/5000
41/41 - 1s - loss: 0.1376 - mae: 0.3437 - val_loss: 0.1380 - val_mae: 0.3659
Epoch 71/5000
41/41 - 1s - loss: 0.1341 - mae: 0.3331 - val_loss: 0.1486 - val_mae: 0.4035
Epoch 72/5000
41/41 - 1s - loss: 0.1358 - mae: 0.3388 - val_loss: 0.1385 - val_mae: 0.3671
Epoch 73/5000
41/41 - 1s - loss: 0.1344 - mae: 0.3361 - val_loss: 0.1332 - val_mae: 0.3418
Epoch 74/5000
41/41 - 1s - loss: 0.1330 - mae: 0.3309 - val_loss: 0.1398 - val_mae: 0.3740
Epoch 75/5000
41/41 - 1s - loss: 0.1353 - mae: 0.3373 - val_loss: 0.1375 - val_mae: 0.3528
Epoch 76/5000
41/41 - 1s - loss: 0.1334 - mae: 0.3316 - val_loss: 0.1556 - val_mae: 0.4260
Epoch 77/5000
41/41 - 1s - loss: 0.1374 - mae: 0.3464 - val_loss: 0.1366 - val_mae: 0.3465
Epoch 78/5000
41/41 - 1s - loss: 0.1342 - mae: 0.3353 - val_loss: 0.1620 - val_mae: 0.4380
Epoch 79/5000
41/41 - 1s - loss: 0.1350 - mae: 0.3400 - val_loss: 0.1385 - val_mae: 0.3491
Epoch 80/5000
41/41 - 1s - loss: 0.1335 - mae: 0.3309 - val_loss: 0.1707 - val_mae: 0.4577
Epoch 81/5000
41/41 - 1s - loss: 0.1353 - mae: 0.3395 - val_loss: 0.1464 - val_mae: 0.3800
Epoch 82/5000
41/41 - 1s - loss: 0.1329 - mae: 0.3291 - val_loss: 0.1660 - val_mae: 0.4452
Epoch 83/5000
41/41 - 1s - loss: 0.1331 - mae: 0.3345 - val_loss: 0.1520 - val_mae: 0.4004
Epoch 84/5000
41/41 - 1s - loss: 0.1320 - mae: 0.3272 - val_loss: 0.1639 - val_mae: 0.4419
Epoch 85/5000
41/41 - 1s - loss: 0.1344 - mae: 0.3371 - val_loss: 0.1384 - val_mae: 0.3565
Epoch 86/5000
41/41 - 1s - loss: 0.1341 - mae: 0.3324 - val_loss: 0.1675 - val_mae: 0.4431
Epoch 87/5000
41/41 - 1s - loss: 0.1332 - mae: 0.3330 - val_loss: 0.1490 - val_mae: 0.3991
Epoch 88/5000
41/41 - 1s - loss: 0.1296 - mae: 0.3235 - val_loss: 0.1478 - val_mae: 0.3933
Epoch 89/5000
41/41 - 1s - loss: 0.1313 - mae: 0.3249 - val_loss: 0.1648 - val_mae: 0.4449
Epoch 90/5000
41/41 - 1s - loss: 0.1341 - mae: 0.3382 - val_loss: 0.1432 - val_mae: 0.3653
Epoch 91/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3244 - val_loss: 0.1714 - val_mae: 0.4618
Epoch 92/5000
41/41 - 1s - loss: 0.1344 - mae: 0.3385 - val_loss: 0.1376 - val_mae: 0.3518
Epoch 93/5000
41/41 - 1s - loss: 0.1305 - mae: 0.3239 - val_loss: 0.1681 - val_mae: 0.4460
Epoch 94/5000
41/41 - 1s - loss: 0.1326 - mae: 0.3328 - val_loss: 0.1486 - val_mae: 0.3892
Epoch 95/5000
41/41 - 1s - loss: 0.1307 - mae: 0.3231 - val_loss: 0.1702 - val_mae: 0.4551
Epoch 96/5000
41/41 - 1s - loss: 0.1322 - mae: 0.3326 - val_loss: 0.1457 - val_mae: 0.3715
Epoch 97/5000
41/41 - 1s - loss: 0.1292 - mae: 0.3206 - val_loss: 0.1577 - val_mae: 0.4173
Epoch 98/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3264 - val_loss: 0.1443 - val_mae: 0.3745
Epoch 99/5000
41/41 - 1s - loss: 0.1295 - mae: 0.3205 - val_loss: 0.1769 - val_mae: 0.4657
Epoch 100/5000
41/41 - 1s - loss: 0.1319 - mae: 0.3312 - val_loss: 0.1467 - val_mae: 0.3790
Epoch 101/5000
41/41 - 1s - loss: 0.1292 - mae: 0.3199 - val_loss: 0.1830 - val_mae: 0.4767
Epoch 102/5000
41/41 - 1s - loss: 0.1323 - mae: 0.3341 - val_loss: 0.1424 - val_mae: 0.3687
Epoch 103/5000
41/41 - 1s - loss: 0.1280 - mae: 0.3176 - val_loss: 0.1706 - val_mae: 0.4489
Epoch 104/5000
41/41 - 1s - loss: 0.1300 - mae: 0.3244 - val_loss: 0.1586 - val_mae: 0.4215
Epoch 105/5000
41/41 - 1s - loss: 0.1296 - mae: 0.3225 - val_loss: 0.1699 - val_mae: 0.4416
Epoch 106/5000
41/41 - 1s - loss: 0.1300 - mae: 0.3265 - val_loss: 0.1514 - val_mae: 0.3887
Epoch 107/5000
41/41 - 1s - loss: 0.1275 - mae: 0.3174 - val_loss: 0.1754 - val_mae: 0.4570
Epoch 108/5000
41/41 - 1s - loss: 0.1301 - mae: 0.3273 - val_loss: 0.1456 - val_mae: 0.3723
Epoch 109/5000
41/41 - 1s - loss: 0.1278 - mae: 0.3186 - val_loss: 0.1602 - val_mae: 0.4261
Epoch 110/5000
41/41 - 1s - loss: 0.1282 - mae: 0.3197 - val_loss: 0.1475 - val_mae: 0.3861
Epoch 111/5000
41/41 - 1s - loss: 0.1277 - mae: 0.3175 - val_loss: 0.1649 - val_mae: 0.4371
Epoch 112/5000
41/41 - 1s - loss: 0.1288 - mae: 0.3240 - val_loss: 0.1517 - val_mae: 0.3868
Epoch 113/5000
41/41 - 1s - loss: 0.1267 - mae: 0.3157 - val_loss: 0.1699 - val_mae: 0.4450
Epoch 114/5000
41/41 - 1s - loss: 0.1277 - mae: 0.3206 - val_loss: 0.1595 - val_mae: 0.4170
Epoch 115/5000
41/41 - 1s - loss: 0.1269 - mae: 0.3179 - val_loss: 0.1509 - val_mae: 0.3926
Epoch 116/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3172 - val_loss: 0.1540 - val_mae: 0.3912
Epoch 117/5000
41/41 - 1s - loss: 0.1271 - mae: 0.3184 - val_loss: 0.1735 - val_mae: 0.4456
Epoch 118/5000
41/41 - 1s - loss: 0.1295 - mae: 0.3258 - val_loss: 0.1389 - val_mae: 0.3609
Epoch 119/5000
41/41 - 1s - loss: 0.1247 - mae: 0.3116 - val_loss: 0.1447 - val_mae: 0.3703
Epoch 120/5000
41/41 - 1s - loss: 0.1259 - mae: 0.3147 - val_loss: 0.1977 - val_mae: 0.4951
Epoch 121/5000
41/41 - 1s - loss: 0.1298 - mae: 0.3273 - val_loss: 0.1774 - val_mae: 0.4490
Epoch 122/5000
41/41 - 1s - loss: 0.1299 - mae: 0.3267 - val_loss: 0.1513 - val_mae: 0.3690
Epoch 123/5000
41/41 - 1s - loss: 0.1252 - mae: 0.3141 - val_loss: 0.1472 - val_mae: 0.3766
Epoch 124/5000
41/41 - 1s - loss: 0.1251 - mae: 0.3124 - val_loss: 0.1657 - val_mae: 0.4226
Epoch 125/5000
41/41 - 1s - loss: 0.1275 - mae: 0.3196 - val_loss: 0.1871 - val_mae: 0.4779
Epoch 126/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3309 - val_loss: 0.1446 - val_mae: 0.3521
Epoch 127/5000
41/41 - 1s - loss: 0.1273 - mae: 0.3166 - val_loss: 0.1818 - val_mae: 0.4666
Epoch 128/5000
41/41 - 1s - loss: 0.1286 - mae: 0.3278 - val_loss: 0.1375 - val_mae: 0.3413
Epoch 129/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3251 - val_loss: 0.1862 - val_mae: 0.4840
Epoch 130/5000
41/41 - 1s - loss: 0.1337 - mae: 0.3395 - val_loss: 0.1449 - val_mae: 0.3774
Epoch 131/5000
41/41 - 1s - loss: 0.1265 - mae: 0.3156 - val_loss: 0.2143 - val_mae: 0.5280
Epoch 132/5000
41/41 - 1s - loss: 0.1316 - mae: 0.3352 - val_loss: 0.1627 - val_mae: 0.4012
Epoch 133/5000
41/41 - 1s - loss: 0.1260 - mae: 0.3126 - val_loss: 0.2014 - val_mae: 0.5009
Epoch 134/5000
41/41 - 1s - loss: 0.1311 - mae: 0.3313 - val_loss: 0.1418 - val_mae: 0.3574
Epoch 135/5000
41/41 - 1s - loss: 0.1267 - mae: 0.3155 - val_loss: 0.1718 - val_mae: 0.4490
Epoch 136/5000
41/41 - 1s - loss: 0.1279 - mae: 0.3260 - val_loss: 0.1563 - val_mae: 0.3860
Epoch 137/5000
41/41 - 1s - loss: 0.1271 - mae: 0.3153 - val_loss: 0.1940 - val_mae: 0.4895
Epoch 138/5000
41/41 - 1s - loss: 0.1325 - mae: 0.3353 - val_loss: 0.1929 - val_mae: 0.4761
Epoch 139/5000
41/41 - 1s - loss: 0.1280 - mae: 0.3242 - val_loss: 0.1528 - val_mae: 0.3860
Epoch 140/5000
41/41 - 1s - loss: 0.1274 - mae: 0.3140 - val_loss: 0.1838 - val_mae: 0.4742
Epoch 141/5000
41/41 - 1s - loss: 0.1296 - mae: 0.3292 - val_loss: 0.1629 - val_mae: 0.4114
Epoch 142/5000
41/41 - 1s - loss: 0.1256 - mae: 0.3123 - val_loss: 0.1898 - val_mae: 0.4762
Epoch 143/5000
41/41 - 1s - loss: 0.1310 - mae: 0.3305 - val_loss: 0.1723 - val_mae: 0.4410
Epoch 144/5000
41/41 - 1s - loss: 0.1249 - mae: 0.3111 - val_loss: 0.2082 - val_mae: 0.5063
Epoch 145/5000
41/41 - 1s - loss: 0.1301 - mae: 0.3272 - val_loss: 0.1458 - val_mae: 0.3724
Epoch 146/5000
41/41 - 1s - loss: 0.1256 - mae: 0.3129 - val_loss: 0.2215 - val_mae: 0.5352
Epoch 147/5000
41/41 - 1s - loss: 0.1320 - mae: 0.3352 - val_loss: 0.1835 - val_mae: 0.4631
Epoch 148/5000
41/41 - 1s - loss: 0.1272 - mae: 0.3194 - val_loss: 0.1952 - val_mae: 0.4651
Epoch 149/5000
41/41 - 1s - loss: 0.1287 - mae: 0.3243 - val_loss: 0.1600 - val_mae: 0.4025
Epoch 150/5000
41/41 - 1s - loss: 0.1249 - mae: 0.3103 - val_loss: 0.2020 - val_mae: 0.5011
Epoch 151/5000
41/41 - 1s - loss: 0.1341 - mae: 0.3362 - val_loss: 0.1664 - val_mae: 0.4265
Epoch 152/5000
41/41 - 1s - loss: 0.1306 - mae: 0.3303 - val_loss: 0.1506 - val_mae: 0.3999
Epoch 153/5000
41/41 - 1s - loss: 0.1269 - mae: 0.3164 - val_loss: 0.1803 - val_mae: 0.4664
Epoch 154/5000
41/41 - 1s - loss: 0.1341 - mae: 0.3321 - val_loss: 0.1341 - val_mae: 0.3419
Epoch 155/5000
41/41 - 1s - loss: 0.1361 - mae: 0.3454 - val_loss: 0.1374 - val_mae: 0.3582
Epoch 156/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3278 - val_loss: 0.1535 - val_mae: 0.4016
Epoch 157/5000
41/41 - 1s - loss: 0.1274 - mae: 0.3213 - val_loss: 0.1904 - val_mae: 0.4731
Epoch 158/5000
41/41 - 1s - loss: 0.1289 - mae: 0.3255 - val_loss: 0.1884 - val_mae: 0.4691
Epoch 159/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3124 - val_loss: 0.1910 - val_mae: 0.4575
Restoring model weights from the end of the best epoch.
Epoch 00159: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_5..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_29"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_5 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_5 (PartitionP (None, None, 64)     0           message_passing_5[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_5[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_5 (Masking)             (None, None, 64)     0           partition_padding_5[0][0]        
                                                                 partition_padding_5[1][0]        
__________________________________________________________________________________________________
transformer_encoder_5 (Transfor (None, None, 64)     199040      masking_5[0][0]                  
                                                                 masking_5[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_5 (Glo (None, 64)           0           transformer_encoder_5[0][0]      
                                                                 transformer_encoder_5[1][0]      
__________________________________________________________________________________________________
dense_89 (Dense)                (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_87 (Dense)                (None, 512)          33280       global_average_pooling1d_5[0][0] 
                                                                 global_average_pooling1d_5[1][0] 
__________________________________________________________________________________________________
dense_90 (Dense)                (None, 10)           110         dense_89[0][0]                   
__________________________________________________________________________________________________
dense_88 (Dense)                (None, 450)          230850      dense_87[0][0]                   
                                                                 dense_87[1][0]                   
__________________________________________________________________________________________________
dense_91 (Dense)                (None, 5)            55          dense_90[0][0]                   
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 905)          0           dense_88[0][0]                   
                                                                 dense_88[1][0]                   
                                                                 dense_91[0][0]                   
__________________________________________________________________________________________________
dense_92 (Dense)                (None, 700)          634200      concatenate_5[0][0]              
__________________________________________________________________________________________________
dense_96 (Dense)                (None, 560)          392560      dense_92[0][0]                   
__________________________________________________________________________________________________
dense_97 (Dense)                (None, 373)          209253      dense_96[0][0]                   
__________________________________________________________________________________________________
dense_98 (Dense)                (None, 187)          69938       dense_97[0][0]                   
__________________________________________________________________________________________________
dense_99 (Dense)                (None, 1)            188         dense_98[0][0]                   
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
41/41 - 6s - loss: 0.1332 - mae: 0.3307 - val_loss: 0.1473 - val_mae: 0.3994
Epoch 2/5000
41/41 - 1s - loss: 0.1239 - mae: 0.3108 - val_loss: 0.1329 - val_mae: 0.3507
Epoch 3/5000
41/41 - 1s - loss: 0.1175 - mae: 0.2964 - val_loss: 0.1377 - val_mae: 0.3684
Epoch 4/5000
41/41 - 1s - loss: 0.1159 - mae: 0.2918 - val_loss: 0.1432 - val_mae: 0.3807
Epoch 5/5000
41/41 - 1s - loss: 0.1132 - mae: 0.2862 - val_loss: 0.1396 - val_mae: 0.3671
Epoch 6/5000
41/41 - 1s - loss: 0.1099 - mae: 0.2792 - val_loss: 0.1352 - val_mae: 0.3533
Epoch 7/5000
41/41 - 1s - loss: 0.1076 - mae: 0.2751 - val_loss: 0.1397 - val_mae: 0.3620
Epoch 8/5000
41/41 - 1s - loss: 0.1053 - mae: 0.2709 - val_loss: 0.1442 - val_mae: 0.3711
Epoch 9/5000
41/41 - 1s - loss: 0.1038 - mae: 0.2675 - val_loss: 0.1530 - val_mae: 0.3924
Epoch 10/5000
41/41 - 1s - loss: 0.1035 - mae: 0.2672 - val_loss: 0.1575 - val_mae: 0.4010
Epoch 11/5000
41/41 - 1s - loss: 0.1060 - mae: 0.2724 - val_loss: 0.1338 - val_mae: 0.3401
Epoch 12/5000
41/41 - 1s - loss: 0.1021 - mae: 0.2659 - val_loss: 0.1322 - val_mae: 0.3374
Epoch 13/5000
41/41 - 1s - loss: 0.0980 - mae: 0.2555 - val_loss: 0.1361 - val_mae: 0.3460
Epoch 14/5000
41/41 - 1s - loss: 0.0951 - mae: 0.2486 - val_loss: 0.1392 - val_mae: 0.3548
Epoch 15/5000
41/41 - 1s - loss: 0.0934 - mae: 0.2447 - val_loss: 0.1442 - val_mae: 0.3663
Epoch 16/5000
41/41 - 1s - loss: 0.0931 - mae: 0.2439 - val_loss: 0.1531 - val_mae: 0.3897
Epoch 17/5000
41/41 - 1s - loss: 0.0949 - mae: 0.2478 - val_loss: 0.1611 - val_mae: 0.4037
Epoch 18/5000
41/41 - 1s - loss: 0.0973 - mae: 0.2538 - val_loss: 0.1462 - val_mae: 0.3613
Epoch 19/5000
41/41 - 1s - loss: 0.0951 - mae: 0.2508 - val_loss: 0.1404 - val_mae: 0.3487
Epoch 20/5000
41/41 - 1s - loss: 0.0934 - mae: 0.2466 - val_loss: 0.1341 - val_mae: 0.3396
Epoch 21/5000
41/41 - 1s - loss: 0.0891 - mae: 0.2361 - val_loss: 0.1346 - val_mae: 0.3419
Epoch 22/5000
41/41 - 1s - loss: 0.0863 - mae: 0.2292 - val_loss: 0.1386 - val_mae: 0.3530
Epoch 23/5000
41/41 - 1s - loss: 0.0849 - mae: 0.2263 - val_loss: 0.1466 - val_mae: 0.3714
Epoch 24/5000
41/41 - 1s - loss: 0.0839 - mae: 0.2241 - val_loss: 0.1496 - val_mae: 0.3776
Epoch 25/5000
41/41 - 1s - loss: 0.0834 - mae: 0.2229 - val_loss: 0.1466 - val_mae: 0.3691
Epoch 26/5000
41/41 - 1s - loss: 0.0839 - mae: 0.2256 - val_loss: 0.1578 - val_mae: 0.3865
Epoch 27/5000
41/41 - 1s - loss: 0.0838 - mae: 0.2265 - val_loss: 0.1576 - val_mae: 0.3793
Epoch 28/5000
41/41 - 1s - loss: 0.0859 - mae: 0.2313 - val_loss: 0.1586 - val_mae: 0.4000
Epoch 29/5000
41/41 - 1s - loss: 0.0847 - mae: 0.2272 - val_loss: 0.1417 - val_mae: 0.3511
Epoch 30/5000
41/41 - 1s - loss: 0.0879 - mae: 0.2352 - val_loss: 0.1390 - val_mae: 0.3387
Epoch 31/5000
41/41 - 1s - loss: 0.0883 - mae: 0.2383 - val_loss: 0.1279 - val_mae: 0.3123
Epoch 32/5000
41/41 - 1s - loss: 0.0884 - mae: 0.2394 - val_loss: 0.1239 - val_mae: 0.3122
Epoch 33/5000
41/41 - 1s - loss: 0.0847 - mae: 0.2314 - val_loss: 0.1270 - val_mae: 0.3219
Epoch 34/5000
41/41 - 1s - loss: 0.0832 - mae: 0.2274 - val_loss: 0.1261 - val_mae: 0.3171
Epoch 35/5000
41/41 - 1s - loss: 0.0841 - mae: 0.2294 - val_loss: 0.1194 - val_mae: 0.2994
Epoch 36/5000
41/41 - 1s - loss: 0.0854 - mae: 0.2327 - val_loss: 0.1270 - val_mae: 0.3115
Epoch 37/5000
41/41 - 1s - loss: 0.0877 - mae: 0.2382 - val_loss: 0.1345 - val_mae: 0.3225
Epoch 38/5000
41/41 - 1s - loss: 0.0894 - mae: 0.2414 - val_loss: 0.1337 - val_mae: 0.3056
Epoch 39/5000
41/41 - 1s - loss: 0.0932 - mae: 0.2514 - val_loss: 0.1299 - val_mae: 0.3015
Epoch 40/5000
41/41 - 1s - loss: 0.0907 - mae: 0.2451 - val_loss: 0.1337 - val_mae: 0.3237
Epoch 41/5000
41/41 - 1s - loss: 0.0762 - mae: 0.2101 - val_loss: 0.1251 - val_mae: 0.2930
Epoch 42/5000
41/41 - 1s - loss: 0.0766 - mae: 0.2117 - val_loss: 0.1261 - val_mae: 0.2960
Epoch 43/5000
41/41 - 1s - loss: 0.0753 - mae: 0.2086 - val_loss: 0.1230 - val_mae: 0.2947
Epoch 44/5000
41/41 - 1s - loss: 0.0744 - mae: 0.2051 - val_loss: 0.1220 - val_mae: 0.2950
Epoch 45/5000
41/41 - 1s - loss: 0.0727 - mae: 0.2013 - val_loss: 0.1246 - val_mae: 0.3105
Epoch 46/5000
41/41 - 1s - loss: 0.0716 - mae: 0.1992 - val_loss: 0.1238 - val_mae: 0.3093
Epoch 47/5000
41/41 - 1s - loss: 0.0692 - mae: 0.1951 - val_loss: 0.1172 - val_mae: 0.2952
Epoch 48/5000
41/41 - 1s - loss: 0.0678 - mae: 0.1930 - val_loss: 0.1134 - val_mae: 0.2867
Epoch 49/5000
41/41 - 1s - loss: 0.0670 - mae: 0.1921 - val_loss: 0.1156 - val_mae: 0.2921
Epoch 50/5000
41/41 - 1s - loss: 0.0681 - mae: 0.1959 - val_loss: 0.1189 - val_mae: 0.3002
Epoch 51/5000
41/41 - 1s - loss: 0.0705 - mae: 0.2011 - val_loss: 0.1205 - val_mae: 0.3074
Epoch 52/5000
41/41 - 1s - loss: 0.0706 - mae: 0.2024 - val_loss: 0.1141 - val_mae: 0.2918
Epoch 53/5000
41/41 - 1s - loss: 0.0714 - mae: 0.2070 - val_loss: 0.1133 - val_mae: 0.2927
Epoch 54/5000
41/41 - 1s - loss: 0.0769 - mae: 0.2180 - val_loss: 0.1092 - val_mae: 0.2968
Epoch 55/5000
41/41 - 1s - loss: 0.0770 - mae: 0.2184 - val_loss: 0.1348 - val_mae: 0.3621
Epoch 56/5000
41/41 - 1s - loss: 0.0798 - mae: 0.2217 - val_loss: 0.1375 - val_mae: 0.3577
Epoch 57/5000
41/41 - 1s - loss: 0.0763 - mae: 0.2208 - val_loss: 0.1280 - val_mae: 0.3217
Epoch 58/5000
41/41 - 1s - loss: 0.0657 - mae: 0.1953 - val_loss: 0.1157 - val_mae: 0.3110
Epoch 59/5000
41/41 - 1s - loss: 0.0639 - mae: 0.1908 - val_loss: 0.1136 - val_mae: 0.3157
Epoch 60/5000
41/41 - 1s - loss: 0.0621 - mae: 0.1864 - val_loss: 0.1172 - val_mae: 0.3191
Epoch 61/5000
41/41 - 1s - loss: 0.0601 - mae: 0.1830 - val_loss: 0.1150 - val_mae: 0.3108
Epoch 62/5000
41/41 - 1s - loss: 0.0604 - mae: 0.1871 - val_loss: 0.1454 - val_mae: 0.3750
Epoch 63/5000
41/41 - 1s - loss: 0.0639 - mae: 0.1944 - val_loss: 0.1593 - val_mae: 0.3852
Epoch 64/5000
41/41 - 1s - loss: 0.0746 - mae: 0.2144 - val_loss: 0.1320 - val_mae: 0.3377
Epoch 65/5000
41/41 - 1s - loss: 0.0755 - mae: 0.2246 - val_loss: 0.1202 - val_mae: 0.2994
Epoch 66/5000
41/41 - 1s - loss: 0.0706 - mae: 0.2068 - val_loss: 0.1056 - val_mae: 0.2777
Epoch 67/5000
41/41 - 1s - loss: 0.0672 - mae: 0.2011 - val_loss: 0.1100 - val_mae: 0.3064
Epoch 68/5000
41/41 - 1s - loss: 0.0655 - mae: 0.1958 - val_loss: 0.1056 - val_mae: 0.2980
Epoch 69/5000
41/41 - 1s - loss: 0.0645 - mae: 0.1991 - val_loss: 0.0999 - val_mae: 0.2762
Epoch 70/5000
41/41 - 1s - loss: 0.0632 - mae: 0.1923 - val_loss: 0.1002 - val_mae: 0.2746
Epoch 71/5000
41/41 - 1s - loss: 0.0694 - mae: 0.2053 - val_loss: 0.0949 - val_mae: 0.2707
Epoch 72/5000
41/41 - 1s - loss: 0.0641 - mae: 0.1974 - val_loss: 0.0891 - val_mae: 0.2575
Epoch 73/5000
41/41 - 1s - loss: 0.0619 - mae: 0.1932 - val_loss: 0.0895 - val_mae: 0.2580
Epoch 74/5000
41/41 - 1s - loss: 0.0800 - mae: 0.2322 - val_loss: 0.0995 - val_mae: 0.2695
Epoch 75/5000
41/41 - 1s - loss: 0.0834 - mae: 0.2415 - val_loss: 0.1172 - val_mae: 0.2861
Epoch 76/5000
41/41 - 1s - loss: 0.0869 - mae: 0.2469 - val_loss: 0.1210 - val_mae: 0.2888
Epoch 77/5000
41/41 - 1s - loss: 0.0773 - mae: 0.2261 - val_loss: 0.1027 - val_mae: 0.2712
Epoch 78/5000
41/41 - 1s - loss: 0.0651 - mae: 0.1992 - val_loss: 0.1079 - val_mae: 0.2782
Epoch 79/5000
41/41 - 1s - loss: 0.0589 - mae: 0.1845 - val_loss: 0.1084 - val_mae: 0.2779
Epoch 80/5000
41/41 - 1s - loss: 0.0537 - mae: 0.1718 - val_loss: 0.1080 - val_mae: 0.2745
Epoch 81/5000
41/41 - 1s - loss: 0.0546 - mae: 0.1763 - val_loss: 0.1060 - val_mae: 0.2737
Epoch 82/5000
41/41 - 1s - loss: 0.0517 - mae: 0.1690 - val_loss: 0.1080 - val_mae: 0.2791
Epoch 83/5000
41/41 - 1s - loss: 0.0520 - mae: 0.1706 - val_loss: 0.1077 - val_mae: 0.2779
Epoch 84/5000
41/41 - 1s - loss: 0.0488 - mae: 0.1596 - val_loss: 0.0983 - val_mae: 0.2689
Epoch 85/5000
41/41 - 1s - loss: 0.0503 - mae: 0.1658 - val_loss: 0.1052 - val_mae: 0.2785
Epoch 86/5000
41/41 - 1s - loss: 0.0474 - mae: 0.1568 - val_loss: 0.1020 - val_mae: 0.2728
Epoch 87/5000
41/41 - 1s - loss: 0.0496 - mae: 0.1646 - val_loss: 0.0995 - val_mae: 0.2718
Epoch 88/5000
41/41 - 1s - loss: 0.0473 - mae: 0.1580 - val_loss: 0.1022 - val_mae: 0.2711
Epoch 89/5000
41/41 - 1s - loss: 0.0515 - mae: 0.1710 - val_loss: 0.1038 - val_mae: 0.2738
Epoch 90/5000
41/41 - 1s - loss: 0.0480 - mae: 0.1619 - val_loss: 0.1121 - val_mae: 0.2826
Epoch 91/5000
41/41 - 1s - loss: 0.0501 - mae: 0.1685 - val_loss: 0.1078 - val_mae: 0.2784
Epoch 92/5000
41/41 - 1s - loss: 0.0491 - mae: 0.1642 - val_loss: 0.1156 - val_mae: 0.2829
Epoch 93/5000
41/41 - 1s - loss: 0.0532 - mae: 0.1767 - val_loss: 0.0997 - val_mae: 0.2697
Epoch 94/5000
41/41 - 1s - loss: 0.0540 - mae: 0.1791 - val_loss: 0.1009 - val_mae: 0.2731
Epoch 95/5000
41/41 - 1s - loss: 0.0526 - mae: 0.1747 - val_loss: 0.1028 - val_mae: 0.2766
Epoch 96/5000
41/41 - 1s - loss: 0.0491 - mae: 0.1676 - val_loss: 0.1061 - val_mae: 0.2795
Epoch 97/5000
41/41 - 1s - loss: 0.0482 - mae: 0.1661 - val_loss: 0.1018 - val_mae: 0.2721
Epoch 98/5000
41/41 - 1s - loss: 0.0463 - mae: 0.1597 - val_loss: 0.1007 - val_mae: 0.2745
Epoch 99/5000
41/41 - 1s - loss: 0.0477 - mae: 0.1618 - val_loss: 0.1031 - val_mae: 0.2721
Epoch 100/5000
41/41 - 1s - loss: 0.0445 - mae: 0.1539 - val_loss: 0.1028 - val_mae: 0.2793
Epoch 101/5000
41/41 - 1s - loss: 0.0517 - mae: 0.1705 - val_loss: 0.1051 - val_mae: 0.2758
Epoch 102/5000
41/41 - 1s - loss: 0.0430 - mae: 0.1474 - val_loss: 0.1059 - val_mae: 0.2768
Epoch 103/5000
41/41 - 1s - loss: 0.0428 - mae: 0.1477 - val_loss: 0.1124 - val_mae: 0.2927
Epoch 104/5000
41/41 - 1s - loss: 0.0454 - mae: 0.1573 - val_loss: 0.1074 - val_mae: 0.2826
Epoch 105/5000
41/41 - 1s - loss: 0.0465 - mae: 0.1605 - val_loss: 0.1065 - val_mae: 0.2819
Epoch 106/5000
41/41 - 1s - loss: 0.0412 - mae: 0.1453 - val_loss: 0.1145 - val_mae: 0.2928
Epoch 107/5000
41/41 - 1s - loss: 0.0402 - mae: 0.1420 - val_loss: 0.1194 - val_mae: 0.3017
Epoch 108/5000
41/41 - 1s - loss: 0.0422 - mae: 0.1527 - val_loss: 0.1079 - val_mae: 0.2873
Epoch 109/5000
41/41 - 1s - loss: 0.0396 - mae: 0.1427 - val_loss: 0.1038 - val_mae: 0.2761
Epoch 110/5000
41/41 - 1s - loss: 0.0413 - mae: 0.1498 - val_loss: 0.0978 - val_mae: 0.2746
Epoch 111/5000
41/41 - 1s - loss: 0.0400 - mae: 0.1429 - val_loss: 0.1261 - val_mae: 0.3238
Epoch 112/5000
41/41 - 1s - loss: 0.0476 - mae: 0.1646 - val_loss: 0.0880 - val_mae: 0.2635
Epoch 113/5000
41/41 - 1s - loss: 0.0467 - mae: 0.1592 - val_loss: 0.1080 - val_mae: 0.2946
Epoch 114/5000
41/41 - 1s - loss: 0.0406 - mae: 0.1441 - val_loss: 0.0986 - val_mae: 0.2737
Epoch 115/5000
41/41 - 1s - loss: 0.0366 - mae: 0.1344 - val_loss: 0.0995 - val_mae: 0.2712
Epoch 116/5000
41/41 - 1s - loss: 0.0357 - mae: 0.1330 - val_loss: 0.1088 - val_mae: 0.2867
Epoch 117/5000
41/41 - 1s - loss: 0.0402 - mae: 0.1436 - val_loss: 0.0896 - val_mae: 0.2602
Epoch 118/5000
41/41 - 1s - loss: 0.0407 - mae: 0.1478 - val_loss: 0.1016 - val_mae: 0.2725
Epoch 119/5000
41/41 - 1s - loss: 0.0367 - mae: 0.1363 - val_loss: 0.1127 - val_mae: 0.2850
Epoch 120/5000
41/41 - 1s - loss: 0.0361 - mae: 0.1330 - val_loss: 0.1054 - val_mae: 0.2792
Epoch 121/5000
41/41 - 1s - loss: 0.0380 - mae: 0.1381 - val_loss: 0.0975 - val_mae: 0.2652
Epoch 122/5000
41/41 - 1s - loss: 0.0431 - mae: 0.1547 - val_loss: 0.1028 - val_mae: 0.2723
Epoch 123/5000
41/41 - 1s - loss: 0.0349 - mae: 0.1310 - val_loss: 0.0977 - val_mae: 0.2659
Epoch 124/5000
41/41 - 1s - loss: 0.0348 - mae: 0.1261 - val_loss: 0.0998 - val_mae: 0.2678
Epoch 125/5000
41/41 - 1s - loss: 0.0375 - mae: 0.1409 - val_loss: 0.1048 - val_mae: 0.2763
Epoch 126/5000
41/41 - 1s - loss: 0.0339 - mae: 0.1283 - val_loss: 0.0998 - val_mae: 0.2670
Epoch 127/5000
41/41 - 1s - loss: 0.0372 - mae: 0.1357 - val_loss: 0.0925 - val_mae: 0.2593
Epoch 128/5000
41/41 - 1s - loss: 0.0407 - mae: 0.1450 - val_loss: 0.0994 - val_mae: 0.2692
Epoch 129/5000
41/41 - 1s - loss: 0.0404 - mae: 0.1487 - val_loss: 0.1062 - val_mae: 0.2695
Epoch 130/5000
41/41 - 1s - loss: 0.0380 - mae: 0.1370 - val_loss: 0.0850 - val_mae: 0.2448
Epoch 131/5000
41/41 - 1s - loss: 0.0401 - mae: 0.1476 - val_loss: 0.1062 - val_mae: 0.2736
Epoch 132/5000
41/41 - 1s - loss: 0.0342 - mae: 0.1308 - val_loss: 0.1045 - val_mae: 0.2775
Epoch 133/5000
41/41 - 1s - loss: 0.0343 - mae: 0.1272 - val_loss: 0.1038 - val_mae: 0.2726
Epoch 134/5000
41/41 - 1s - loss: 0.0340 - mae: 0.1305 - val_loss: 0.1051 - val_mae: 0.2740
Epoch 135/5000
41/41 - 1s - loss: 0.0369 - mae: 0.1359 - val_loss: 0.0889 - val_mae: 0.2533
Epoch 136/5000
41/41 - 1s - loss: 0.0356 - mae: 0.1346 - val_loss: 0.1074 - val_mae: 0.2759
Epoch 137/5000
41/41 - 1s - loss: 0.0316 - mae: 0.1234 - val_loss: 0.1020 - val_mae: 0.2655
Epoch 138/5000
41/41 - 1s - loss: 0.0337 - mae: 0.1301 - val_loss: 0.0973 - val_mae: 0.2595
Epoch 139/5000
41/41 - 1s - loss: 0.0340 - mae: 0.1310 - val_loss: 0.1000 - val_mae: 0.2716
Epoch 140/5000
41/41 - 1s - loss: 0.0360 - mae: 0.1378 - val_loss: 0.1012 - val_mae: 0.2609
Epoch 141/5000
41/41 - 1s - loss: 0.0333 - mae: 0.1266 - val_loss: 0.0996 - val_mae: 0.2631
Epoch 142/5000
41/41 - 1s - loss: 0.0317 - mae: 0.1247 - val_loss: 0.1116 - val_mae: 0.2824
Epoch 143/5000
41/41 - 1s - loss: 0.0364 - mae: 0.1382 - val_loss: 0.0913 - val_mae: 0.2510
Epoch 144/5000
41/41 - 1s - loss: 0.0337 - mae: 0.1291 - val_loss: 0.1186 - val_mae: 0.2953
Epoch 145/5000
41/41 - 1s - loss: 0.0327 - mae: 0.1310 - val_loss: 0.0997 - val_mae: 0.2684
Epoch 146/5000
41/41 - 1s - loss: 0.0334 - mae: 0.1303 - val_loss: 0.1053 - val_mae: 0.2758
Epoch 147/5000
41/41 - 1s - loss: 0.0327 - mae: 0.1275 - val_loss: 0.1312 - val_mae: 0.3203
Epoch 148/5000
41/41 - 1s - loss: 0.0408 - mae: 0.1518 - val_loss: 0.0932 - val_mae: 0.2641
Epoch 149/5000
41/41 - 1s - loss: 0.0308 - mae: 0.1226 - val_loss: 0.1325 - val_mae: 0.3196
Epoch 150/5000
41/41 - 1s - loss: 0.0365 - mae: 0.1433 - val_loss: 0.1056 - val_mae: 0.2842
Epoch 151/5000
41/41 - 1s - loss: 0.0310 - mae: 0.1227 - val_loss: 0.1317 - val_mae: 0.3168
Epoch 152/5000
41/41 - 1s - loss: 0.0328 - mae: 0.1305 - val_loss: 0.1252 - val_mae: 0.3117
Epoch 153/5000
41/41 - 1s - loss: 0.0309 - mae: 0.1237 - val_loss: 0.1397 - val_mae: 0.3402
Epoch 154/5000
41/41 - 1s - loss: 0.0367 - mae: 0.1417 - val_loss: 0.0987 - val_mae: 0.2730
Epoch 155/5000
41/41 - 1s - loss: 0.0356 - mae: 0.1383 - val_loss: 0.1299 - val_mae: 0.3217
Epoch 156/5000
41/41 - 1s - loss: 0.0334 - mae: 0.1338 - val_loss: 0.1143 - val_mae: 0.2911
Epoch 157/5000
41/41 - 1s - loss: 0.0330 - mae: 0.1291 - val_loss: 0.1331 - val_mae: 0.3369
Epoch 158/5000
41/41 - 1s - loss: 0.0386 - mae: 0.1478 - val_loss: 0.1101 - val_mae: 0.2902
Epoch 159/5000
41/41 - 1s - loss: 0.0349 - mae: 0.1317 - val_loss: 0.1026 - val_mae: 0.2911
Epoch 160/5000
41/41 - 1s - loss: 0.0377 - mae: 0.1469 - val_loss: 0.0950 - val_mae: 0.2720
Epoch 161/5000
41/41 - 1s - loss: 0.0325 - mae: 0.1333 - val_loss: 0.0824 - val_mae: 0.2443
Epoch 162/5000
41/41 - 1s - loss: 0.0333 - mae: 0.1410 - val_loss: 0.1012 - val_mae: 0.2679
Epoch 163/5000
41/41 - 1s - loss: 0.0310 - mae: 0.1278 - val_loss: 0.0791 - val_mae: 0.2374
Epoch 164/5000
41/41 - 1s - loss: 0.0324 - mae: 0.1332 - val_loss: 0.0840 - val_mae: 0.2511
Epoch 165/5000
41/41 - 1s - loss: 0.0340 - mae: 0.1375 - val_loss: 0.0837 - val_mae: 0.2475
Epoch 166/5000
41/41 - 1s - loss: 0.0354 - mae: 0.1377 - val_loss: 0.0803 - val_mae: 0.2459
Epoch 167/5000
41/41 - 1s - loss: 0.0326 - mae: 0.1286 - val_loss: 0.0925 - val_mae: 0.2597
Epoch 168/5000
41/41 - 1s - loss: 0.0301 - mae: 0.1206 - val_loss: 0.0834 - val_mae: 0.2517
Epoch 169/5000
41/41 - 1s - loss: 0.0289 - mae: 0.1172 - val_loss: 0.0936 - val_mae: 0.2560
Epoch 170/5000
41/41 - 1s - loss: 0.0252 - mae: 0.1121 - val_loss: 0.0908 - val_mae: 0.2551
Epoch 171/5000
41/41 - 1s - loss: 0.0291 - mae: 0.1216 - val_loss: 0.0930 - val_mae: 0.2588
Epoch 172/5000
41/41 - 1s - loss: 0.0264 - mae: 0.1115 - val_loss: 0.1106 - val_mae: 0.2787
Epoch 173/5000
41/41 - 1s - loss: 0.0287 - mae: 0.1259 - val_loss: 0.1139 - val_mae: 0.2911
Epoch 174/5000
41/41 - 1s - loss: 0.0259 - mae: 0.1137 - val_loss: 0.1285 - val_mae: 0.3146
Epoch 175/5000
41/41 - 1s - loss: 0.0327 - mae: 0.1363 - val_loss: 0.1192 - val_mae: 0.3071
Epoch 176/5000
41/41 - 1s - loss: 0.0271 - mae: 0.1151 - val_loss: 0.1392 - val_mae: 0.3325
Epoch 177/5000
41/41 - 1s - loss: 0.0385 - mae: 0.1471 - val_loss: 0.1406 - val_mae: 0.3535
Epoch 178/5000
41/41 - 1s - loss: 0.0279 - mae: 0.1192 - val_loss: 0.1306 - val_mae: 0.3189
Epoch 179/5000
41/41 - 1s - loss: 0.0301 - mae: 0.1262 - val_loss: 0.1060 - val_mae: 0.2914
Epoch 180/5000
41/41 - 1s - loss: 0.0294 - mae: 0.1228 - val_loss: 0.0991 - val_mae: 0.2776
Epoch 181/5000
41/41 - 1s - loss: 0.0283 - mae: 0.1228 - val_loss: 0.0901 - val_mae: 0.2524
Epoch 182/5000
41/41 - 1s - loss: 0.0269 - mae: 0.1218 - val_loss: 0.0897 - val_mae: 0.2524
Epoch 183/5000
41/41 - 1s - loss: 0.0234 - mae: 0.1119 - val_loss: 0.0809 - val_mae: 0.2411
Epoch 184/5000
41/41 - 1s - loss: 0.0232 - mae: 0.1132 - val_loss: 0.0887 - val_mae: 0.2513
Epoch 185/5000
41/41 - 1s - loss: 0.0222 - mae: 0.1120 - val_loss: 0.1063 - val_mae: 0.2677
Epoch 186/5000
41/41 - 1s - loss: 0.0232 - mae: 0.1100 - val_loss: 0.1371 - val_mae: 0.3214
Epoch 187/5000
41/41 - 1s - loss: 0.0281 - mae: 0.1178 - val_loss: 0.1245 - val_mae: 0.2997
Epoch 188/5000
41/41 - 1s - loss: 0.0262 - mae: 0.1129 - val_loss: 0.1153 - val_mae: 0.3036
Epoch 189/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1097 - val_loss: 0.1130 - val_mae: 0.2886
Epoch 190/5000
41/41 - 1s - loss: 0.0238 - mae: 0.1051 - val_loss: 0.1075 - val_mae: 0.2877
Epoch 191/5000
41/41 - 1s - loss: 0.0202 - mae: 0.1008 - val_loss: 0.1282 - val_mae: 0.3145
Epoch 192/5000
41/41 - 1s - loss: 0.0236 - mae: 0.1035 - val_loss: 0.1002 - val_mae: 0.2733
Epoch 193/5000
41/41 - 1s - loss: 0.0229 - mae: 0.1028 - val_loss: 0.1118 - val_mae: 0.2981
Epoch 194/5000
41/41 - 1s - loss: 0.0177 - mae: 0.0940 - val_loss: 0.1077 - val_mae: 0.2830
Epoch 195/5000
41/41 - 1s - loss: 0.0177 - mae: 0.0940 - val_loss: 0.1055 - val_mae: 0.2803
Epoch 196/5000
41/41 - 1s - loss: 0.0162 - mae: 0.0912 - val_loss: 0.0945 - val_mae: 0.2566
Epoch 197/5000
41/41 - 1s - loss: 0.0193 - mae: 0.1026 - val_loss: 0.1104 - val_mae: 0.2823
Epoch 198/5000
41/41 - 1s - loss: 0.0196 - mae: 0.1009 - val_loss: 0.1105 - val_mae: 0.2763
Epoch 199/5000
41/41 - 1s - loss: 0.0208 - mae: 0.0992 - val_loss: 0.0944 - val_mae: 0.2640
Epoch 200/5000
41/41 - 1s - loss: 0.0226 - mae: 0.1032 - val_loss: 0.1060 - val_mae: 0.2745
Epoch 201/5000
41/41 - 1s - loss: 0.0201 - mae: 0.1004 - val_loss: 0.1245 - val_mae: 0.3109
Epoch 202/5000
41/41 - 1s - loss: 0.0174 - mae: 0.0973 - val_loss: 0.1119 - val_mae: 0.2844
Epoch 203/5000
41/41 - 1s - loss: 0.0197 - mae: 0.0993 - val_loss: 0.0948 - val_mae: 0.2649
Epoch 204/5000
41/41 - 1s - loss: 0.0259 - mae: 0.1134 - val_loss: 0.0952 - val_mae: 0.2696
Epoch 205/5000
41/41 - 1s - loss: 0.0219 - mae: 0.1101 - val_loss: 0.1169 - val_mae: 0.2955
Epoch 206/5000
41/41 - 1s - loss: 0.0227 - mae: 0.1034 - val_loss: 0.1163 - val_mae: 0.2931
Epoch 207/5000
41/41 - 1s - loss: 0.0239 - mae: 0.1116 - val_loss: 0.1135 - val_mae: 0.2871
Epoch 208/5000
41/41 - 1s - loss: 0.0214 - mae: 0.1094 - val_loss: 0.1304 - val_mae: 0.3216
Epoch 209/5000
41/41 - 1s - loss: 0.0215 - mae: 0.1117 - val_loss: 0.1164 - val_mae: 0.2982
Epoch 210/5000
41/41 - 1s - loss: 0.0203 - mae: 0.1001 - val_loss: 0.1109 - val_mae: 0.2923
Epoch 211/5000
41/41 - 1s - loss: 0.0198 - mae: 0.0986 - val_loss: 0.1056 - val_mae: 0.2828
Epoch 212/5000
41/41 - 1s - loss: 0.0171 - mae: 0.0947 - val_loss: 0.1241 - val_mae: 0.3125
Epoch 213/5000
41/41 - 1s - loss: 0.0167 - mae: 0.0912 - val_loss: 0.1220 - val_mae: 0.3060
Epoch 214/5000
41/41 - 1s - loss: 0.0145 - mae: 0.0865 - val_loss: 0.1121 - val_mae: 0.2897
Epoch 215/5000
41/41 - 1s - loss: 0.0177 - mae: 0.0974 - val_loss: 0.0894 - val_mae: 0.2607
Epoch 216/5000
41/41 - 1s - loss: 0.0198 - mae: 0.1112 - val_loss: 0.1110 - val_mae: 0.2906
Epoch 217/5000
41/41 - 1s - loss: 0.0169 - mae: 0.0978 - val_loss: 0.1070 - val_mae: 0.2774
Epoch 218/5000
41/41 - 1s - loss: 0.0144 - mae: 0.0927 - val_loss: 0.0902 - val_mae: 0.2599
Epoch 219/5000
41/41 - 1s - loss: 0.0180 - mae: 0.1059 - val_loss: 0.0994 - val_mae: 0.2694
Epoch 220/5000
41/41 - 1s - loss: 0.0158 - mae: 0.0974 - val_loss: 0.0911 - val_mae: 0.2501
Epoch 221/5000
41/41 - 1s - loss: 0.0140 - mae: 0.0884 - val_loss: 0.1014 - val_mae: 0.2682
Epoch 222/5000
41/41 - 1s - loss: 0.0131 - mae: 0.0880 - val_loss: 0.0980 - val_mae: 0.2639
Epoch 223/5000
41/41 - 1s - loss: 0.0150 - mae: 0.0954 - val_loss: 0.1125 - val_mae: 0.2838
Epoch 224/5000
41/41 - 1s - loss: 0.0154 - mae: 0.0994 - val_loss: 0.1050 - val_mae: 0.2723
Epoch 225/5000
41/41 - 1s - loss: 0.0190 - mae: 0.1094 - val_loss: 0.0981 - val_mae: 0.2696
Epoch 226/5000
41/41 - 1s - loss: 0.0169 - mae: 0.1042 - val_loss: 0.1073 - val_mae: 0.2806
Epoch 227/5000
41/41 - 1s - loss: 0.0183 - mae: 0.1126 - val_loss: 0.1088 - val_mae: 0.2851
Epoch 228/5000
41/41 - 1s - loss: 0.0196 - mae: 0.1071 - val_loss: 0.1359 - val_mae: 0.3272
Epoch 229/5000
41/41 - 1s - loss: 0.0296 - mae: 0.1340 - val_loss: 0.1275 - val_mae: 0.3271
Epoch 230/5000
41/41 - 1s - loss: 0.0213 - mae: 0.1154 - val_loss: 0.1319 - val_mae: 0.3283
Epoch 231/5000
41/41 - 1s - loss: 0.0216 - mae: 0.1121 - val_loss: 0.1359 - val_mae: 0.3272
Epoch 232/5000
41/41 - 1s - loss: 0.0211 - mae: 0.1125 - val_loss: 0.0992 - val_mae: 0.2907
Epoch 233/5000
41/41 - 1s - loss: 0.0241 - mae: 0.1194 - val_loss: 0.0942 - val_mae: 0.2738
Epoch 234/5000
41/41 - 1s - loss: 0.0212 - mae: 0.1213 - val_loss: 0.0908 - val_mae: 0.2725
Epoch 235/5000
41/41 - 1s - loss: 0.0222 - mae: 0.1193 - val_loss: 0.0903 - val_mae: 0.2668
Epoch 236/5000
41/41 - 1s - loss: 0.0215 - mae: 0.1272 - val_loss: 0.0814 - val_mae: 0.2465
Epoch 237/5000
41/41 - 1s - loss: 0.0152 - mae: 0.1051 - val_loss: 0.0953 - val_mae: 0.2629
Epoch 238/5000
41/41 - 1s - loss: 0.0160 - mae: 0.1042 - val_loss: 0.1001 - val_mae: 0.2648
Epoch 239/5000
41/41 - 1s - loss: 0.0154 - mae: 0.1084 - val_loss: 0.1028 - val_mae: 0.2824
Epoch 240/5000
41/41 - 1s - loss: 0.0141 - mae: 0.0971 - val_loss: 0.1027 - val_mae: 0.2893
Epoch 241/5000
41/41 - 1s - loss: 0.0169 - mae: 0.1077 - val_loss: 0.1086 - val_mae: 0.3015
Epoch 242/5000
41/41 - 1s - loss: 0.0172 - mae: 0.1065 - val_loss: 0.0882 - val_mae: 0.2634
Epoch 243/5000
41/41 - 1s - loss: 0.0163 - mae: 0.1046 - val_loss: 0.0800 - val_mae: 0.2433
Epoch 244/5000
41/41 - 1s - loss: 0.0150 - mae: 0.0999 - val_loss: 0.1004 - val_mae: 0.2655
Epoch 245/5000
41/41 - 1s - loss: 0.0137 - mae: 0.1005 - val_loss: 0.1082 - val_mae: 0.2779
Epoch 246/5000
41/41 - 1s - loss: 0.0136 - mae: 0.0964 - val_loss: 0.0966 - val_mae: 0.2840
Epoch 247/5000
41/41 - 1s - loss: 0.0158 - mae: 0.1052 - val_loss: 0.1001 - val_mae: 0.2912
Epoch 248/5000
41/41 - 1s - loss: 0.0155 - mae: 0.0986 - val_loss: 0.0810 - val_mae: 0.2478
Epoch 249/5000
41/41 - 1s - loss: 0.0139 - mae: 0.0972 - val_loss: 0.0980 - val_mae: 0.2604
Epoch 250/5000
41/41 - 1s - loss: 0.0112 - mae: 0.0883 - val_loss: 0.0971 - val_mae: 0.2622
Epoch 251/5000
41/41 - 1s - loss: 0.0118 - mae: 0.0863 - val_loss: 0.0881 - val_mae: 0.2623
Epoch 252/5000
41/41 - 1s - loss: 0.0111 - mae: 0.0868 - val_loss: 0.1068 - val_mae: 0.2836
Epoch 253/5000
41/41 - 1s - loss: 0.0125 - mae: 0.0848 - val_loss: 0.0821 - val_mae: 0.2570
Epoch 254/5000
41/41 - 1s - loss: 0.0182 - mae: 0.0953 - val_loss: 0.0970 - val_mae: 0.2684
Epoch 255/5000
41/41 - 1s - loss: 0.0136 - mae: 0.0875 - val_loss: 0.1142 - val_mae: 0.2865
Epoch 256/5000
41/41 - 1s - loss: 0.0218 - mae: 0.1020 - val_loss: 0.0969 - val_mae: 0.2696
Epoch 257/5000
41/41 - 1s - loss: 0.0152 - mae: 0.0885 - val_loss: 0.0833 - val_mae: 0.2534
Epoch 258/5000
41/41 - 1s - loss: 0.0121 - mae: 0.0810 - val_loss: 0.0939 - val_mae: 0.2682
Epoch 259/5000
41/41 - 1s - loss: 0.0132 - mae: 0.0825 - val_loss: 0.1043 - val_mae: 0.2781
Epoch 260/5000
41/41 - 1s - loss: 0.0088 - mae: 0.0743 - val_loss: 0.0959 - val_mae: 0.2657
Epoch 261/5000
41/41 - 1s - loss: 0.0094 - mae: 0.0772 - val_loss: 0.0843 - val_mae: 0.2465
Epoch 262/5000
41/41 - 1s - loss: 0.0127 - mae: 0.0945 - val_loss: 0.1007 - val_mae: 0.2671
Epoch 263/5000
41/41 - 1s - loss: 0.0122 - mae: 0.0931 - val_loss: 0.0865 - val_mae: 0.2608
Epoch 264/5000
41/41 - 1s - loss: 0.0099 - mae: 0.0780 - val_loss: 0.0944 - val_mae: 0.2631
Restoring model weights from the end of the best epoch.
Epoch 00264: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_5..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 6

Generating graphs from SMILES..

Setting up training set.
Size: 2058

Setting up validation set.
Size: 228

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_34"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_6 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_6 (PartitionP (None, None, 64)     0           message_passing_6[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_6[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_6 (Masking)             (None, None, 64)     0           partition_padding_6[0][0]        
                                                                 partition_padding_6[1][0]        
__________________________________________________________________________________________________
transformer_encoder_6 (Transfor (None, None, 64)     199040      masking_6[0][0]                  
                                                                 masking_6[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_6 (Glo (None, 64)           0           transformer_encoder_6[0][0]      
                                                                 transformer_encoder_6[1][0]      
__________________________________________________________________________________________________
dense_106 (Dense)               (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_104 (Dense)               (None, 512)          33280       global_average_pooling1d_6[0][0] 
                                                                 global_average_pooling1d_6[1][0] 
__________________________________________________________________________________________________
dense_107 (Dense)               (None, 10)           110         dense_106[0][0]                  
__________________________________________________________________________________________________
dense_105 (Dense)               (None, 450)          230850      dense_104[0][0]                  
                                                                 dense_104[1][0]                  
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 5)            55          dense_107[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 905)          0           dense_105[0][0]                  
                                                                 dense_105[1][0]                  
                                                                 dense_108[0][0]                  
__________________________________________________________________________________________________
dense_109 (Dense)               (None, 700)          634200      concatenate_6[0][0]              
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 560)          392560      dense_109[0][0]                  
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 373)          209253      dense_113[0][0]                  
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 187)          69938       dense_114[0][0]                  
__________________________________________________________________________________________________
dense_116 (Dense)               (None, 1)            188         dense_115[0][0]                  
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
41/41 - 6s - loss: 0.2922 - mae: 0.5865 - val_loss: 0.1942 - val_mae: 0.4314
Epoch 2/5000
41/41 - 1s - loss: 0.1621 - mae: 0.4064 - val_loss: 0.1966 - val_mae: 0.4146
Epoch 3/5000
41/41 - 1s - loss: 0.1605 - mae: 0.4035 - val_loss: 0.1967 - val_mae: 0.4154
Epoch 4/5000
41/41 - 1s - loss: 0.1600 - mae: 0.4033 - val_loss: 0.1930 - val_mae: 0.4442
Epoch 5/5000
41/41 - 1s - loss: 0.1576 - mae: 0.3984 - val_loss: 0.1997 - val_mae: 0.4828
Epoch 6/5000
41/41 - 1s - loss: 0.1583 - mae: 0.3988 - val_loss: 0.2101 - val_mae: 0.5135
Epoch 7/5000
41/41 - 1s - loss: 0.1575 - mae: 0.3958 - val_loss: 0.2142 - val_mae: 0.5256
Epoch 8/5000
41/41 - 1s - loss: 0.1559 - mae: 0.3953 - val_loss: 0.2072 - val_mae: 0.5058
Epoch 9/5000
41/41 - 1s - loss: 0.1549 - mae: 0.3929 - val_loss: 0.2107 - val_mae: 0.5159
Epoch 10/5000
41/41 - 1s - loss: 0.1540 - mae: 0.3906 - val_loss: 0.2065 - val_mae: 0.5038
Epoch 11/5000
41/41 - 1s - loss: 0.1533 - mae: 0.3896 - val_loss: 0.2024 - val_mae: 0.4924
Epoch 12/5000
41/41 - 1s - loss: 0.1536 - mae: 0.3882 - val_loss: 0.2082 - val_mae: 0.5092
Epoch 13/5000
41/41 - 1s - loss: 0.1536 - mae: 0.3892 - val_loss: 0.2076 - val_mae: 0.5059
Epoch 14/5000
41/41 - 1s - loss: 0.1523 - mae: 0.3875 - val_loss: 0.1932 - val_mae: 0.4597
Epoch 15/5000
41/41 - 1s - loss: 0.1507 - mae: 0.3830 - val_loss: 0.1920 - val_mae: 0.4518
Epoch 16/5000
41/41 - 1s - loss: 0.1513 - mae: 0.3831 - val_loss: 0.1941 - val_mae: 0.4615
Epoch 17/5000
41/41 - 1s - loss: 0.1500 - mae: 0.3812 - val_loss: 0.1939 - val_mae: 0.4594
Epoch 18/5000
41/41 - 1s - loss: 0.1490 - mae: 0.3789 - val_loss: 0.1863 - val_mae: 0.4264
Epoch 19/5000
41/41 - 1s - loss: 0.1463 - mae: 0.3720 - val_loss: 0.1879 - val_mae: 0.4167
Epoch 20/5000
41/41 - 1s - loss: 0.1458 - mae: 0.3704 - val_loss: 0.1862 - val_mae: 0.4101
Epoch 21/5000
41/41 - 1s - loss: 0.1476 - mae: 0.3741 - val_loss: 0.1922 - val_mae: 0.4403
Epoch 22/5000
41/41 - 1s - loss: 0.1479 - mae: 0.3773 - val_loss: 0.1860 - val_mae: 0.4275
Epoch 23/5000
41/41 - 1s - loss: 0.1447 - mae: 0.3682 - val_loss: 0.1843 - val_mae: 0.4041
Epoch 24/5000
41/41 - 1s - loss: 0.1454 - mae: 0.3688 - val_loss: 0.1846 - val_mae: 0.4116
Epoch 25/5000
41/41 - 1s - loss: 0.1425 - mae: 0.3626 - val_loss: 0.1816 - val_mae: 0.4203
Epoch 26/5000
41/41 - 1s - loss: 0.1455 - mae: 0.3708 - val_loss: 0.1883 - val_mae: 0.4419
Epoch 27/5000
41/41 - 1s - loss: 0.1442 - mae: 0.3682 - val_loss: 0.1825 - val_mae: 0.3951
Epoch 28/5000
41/41 - 1s - loss: 0.1461 - mae: 0.3688 - val_loss: 0.1958 - val_mae: 0.4743
Epoch 29/5000
41/41 - 1s - loss: 0.1437 - mae: 0.3703 - val_loss: 0.1812 - val_mae: 0.4014
Epoch 30/5000
41/41 - 1s - loss: 0.1468 - mae: 0.3671 - val_loss: 0.1969 - val_mae: 0.4860
Epoch 31/5000
41/41 - 1s - loss: 0.1435 - mae: 0.3698 - val_loss: 0.1786 - val_mae: 0.4141
Epoch 32/5000
41/41 - 1s - loss: 0.1459 - mae: 0.3663 - val_loss: 0.1965 - val_mae: 0.4899
Epoch 33/5000
41/41 - 1s - loss: 0.1415 - mae: 0.3631 - val_loss: 0.1843 - val_mae: 0.4434
Epoch 34/5000
41/41 - 1s - loss: 0.1379 - mae: 0.3510 - val_loss: 0.1793 - val_mae: 0.3970
Epoch 35/5000
41/41 - 1s - loss: 0.1427 - mae: 0.3643 - val_loss: 0.1810 - val_mae: 0.4243
Epoch 36/5000
41/41 - 1s - loss: 0.1424 - mae: 0.3616 - val_loss: 0.1832 - val_mae: 0.4333
Epoch 37/5000
41/41 - 1s - loss: 0.1450 - mae: 0.3621 - val_loss: 0.1992 - val_mae: 0.4955
Epoch 38/5000
41/41 - 1s - loss: 0.1419 - mae: 0.3614 - val_loss: 0.1780 - val_mae: 0.4093
Epoch 39/5000
41/41 - 1s - loss: 0.1425 - mae: 0.3621 - val_loss: 0.1873 - val_mae: 0.4549
Epoch 40/5000
41/41 - 1s - loss: 0.1438 - mae: 0.3619 - val_loss: 0.1899 - val_mae: 0.4689
Epoch 41/5000
41/41 - 1s - loss: 0.1373 - mae: 0.3535 - val_loss: 0.1760 - val_mae: 0.3867
Epoch 42/5000
41/41 - 1s - loss: 0.1424 - mae: 0.3542 - val_loss: 0.1855 - val_mae: 0.4331
Epoch 43/5000
41/41 - 1s - loss: 0.1368 - mae: 0.3569 - val_loss: 0.1746 - val_mae: 0.3878
Epoch 44/5000
41/41 - 1s - loss: 0.1352 - mae: 0.3460 - val_loss: 0.1797 - val_mae: 0.3907
Epoch 45/5000
41/41 - 1s - loss: 0.1378 - mae: 0.3493 - val_loss: 0.1797 - val_mae: 0.4204
Epoch 46/5000
41/41 - 1s - loss: 0.1361 - mae: 0.3484 - val_loss: 0.1754 - val_mae: 0.3846
Epoch 47/5000
41/41 - 1s - loss: 0.1353 - mae: 0.3454 - val_loss: 0.1742 - val_mae: 0.3995
Epoch 48/5000
41/41 - 1s - loss: 0.1372 - mae: 0.3450 - val_loss: 0.1857 - val_mae: 0.4618
Epoch 49/5000
41/41 - 1s - loss: 0.1359 - mae: 0.3514 - val_loss: 0.1726 - val_mae: 0.3708
Epoch 50/5000
41/41 - 1s - loss: 0.1329 - mae: 0.3385 - val_loss: 0.1723 - val_mae: 0.3809
Epoch 51/5000
41/41 - 1s - loss: 0.1322 - mae: 0.3368 - val_loss: 0.1716 - val_mae: 0.3823
Epoch 52/5000
41/41 - 1s - loss: 0.1335 - mae: 0.3386 - val_loss: 0.1703 - val_mae: 0.3889
Epoch 53/5000
41/41 - 1s - loss: 0.1383 - mae: 0.3446 - val_loss: 0.1914 - val_mae: 0.4821
Epoch 54/5000
41/41 - 1s - loss: 0.1347 - mae: 0.3517 - val_loss: 0.1700 - val_mae: 0.3696
Epoch 55/5000
41/41 - 1s - loss: 0.1387 - mae: 0.3434 - val_loss: 0.1817 - val_mae: 0.4386
Epoch 56/5000
41/41 - 1s - loss: 0.1372 - mae: 0.3503 - val_loss: 0.1840 - val_mae: 0.4589
Epoch 57/5000
41/41 - 1s - loss: 0.1317 - mae: 0.3426 - val_loss: 0.1655 - val_mae: 0.3637
Epoch 58/5000
41/41 - 1s - loss: 0.1296 - mae: 0.3287 - val_loss: 0.1692 - val_mae: 0.3814
Epoch 59/5000
41/41 - 1s - loss: 0.1339 - mae: 0.3367 - val_loss: 0.1965 - val_mae: 0.4949
Epoch 60/5000
41/41 - 1s - loss: 0.1367 - mae: 0.3503 - val_loss: 0.1795 - val_mae: 0.4348
Epoch 61/5000
41/41 - 1s - loss: 0.1352 - mae: 0.3413 - val_loss: 0.1855 - val_mae: 0.4564
Epoch 62/5000
41/41 - 1s - loss: 0.1350 - mae: 0.3404 - val_loss: 0.2055 - val_mae: 0.5116
Epoch 63/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3444 - val_loss: 0.1934 - val_mae: 0.4777
Epoch 64/5000
41/41 - 1s - loss: 0.1354 - mae: 0.3376 - val_loss: 0.1839 - val_mae: 0.4518
Epoch 65/5000
41/41 - 1s - loss: 0.1337 - mae: 0.3437 - val_loss: 0.1925 - val_mae: 0.4731
Epoch 66/5000
41/41 - 1s - loss: 0.1333 - mae: 0.3360 - val_loss: 0.2001 - val_mae: 0.4969
Epoch 67/5000
41/41 - 1s - loss: 0.1330 - mae: 0.3369 - val_loss: 0.2015 - val_mae: 0.4993
Epoch 68/5000
41/41 - 1s - loss: 0.1324 - mae: 0.3355 - val_loss: 0.1947 - val_mae: 0.4811
Epoch 69/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3337 - val_loss: 0.2030 - val_mae: 0.5060
Epoch 70/5000
41/41 - 1s - loss: 0.1320 - mae: 0.3361 - val_loss: 0.1824 - val_mae: 0.4425
Epoch 71/5000
41/41 - 1s - loss: 0.1334 - mae: 0.3311 - val_loss: 0.1794 - val_mae: 0.4318
Epoch 72/5000
41/41 - 1s - loss: 0.1318 - mae: 0.3392 - val_loss: 0.1882 - val_mae: 0.4621
Epoch 73/5000
41/41 - 1s - loss: 0.1323 - mae: 0.3355 - val_loss: 0.1965 - val_mae: 0.4858
Epoch 74/5000
41/41 - 1s - loss: 0.1309 - mae: 0.3327 - val_loss: 0.1956 - val_mae: 0.4823
Epoch 75/5000
41/41 - 1s - loss: 0.1320 - mae: 0.3295 - val_loss: 0.1798 - val_mae: 0.4369
Epoch 76/5000
41/41 - 1s - loss: 0.1302 - mae: 0.3322 - val_loss: 0.2044 - val_mae: 0.5051
Epoch 77/5000
41/41 - 1s - loss: 0.1301 - mae: 0.3315 - val_loss: 0.1918 - val_mae: 0.4684
Epoch 78/5000
41/41 - 1s - loss: 0.1316 - mae: 0.3271 - val_loss: 0.1838 - val_mae: 0.4515
Epoch 79/5000
41/41 - 1s - loss: 0.1306 - mae: 0.3357 - val_loss: 0.2016 - val_mae: 0.4979
Epoch 80/5000
41/41 - 1s - loss: 0.1305 - mae: 0.3281 - val_loss: 0.1980 - val_mae: 0.4897
Epoch 81/5000
41/41 - 1s - loss: 0.1300 - mae: 0.3307 - val_loss: 0.2017 - val_mae: 0.4935
Epoch 82/5000
41/41 - 1s - loss: 0.1293 - mae: 0.3257 - val_loss: 0.2054 - val_mae: 0.5018
Epoch 83/5000
41/41 - 1s - loss: 0.1296 - mae: 0.3281 - val_loss: 0.1961 - val_mae: 0.4809
Epoch 84/5000
41/41 - 1s - loss: 0.1292 - mae: 0.3251 - val_loss: 0.2075 - val_mae: 0.5132
Epoch 85/5000
41/41 - 1s - loss: 0.1290 - mae: 0.3274 - val_loss: 0.1904 - val_mae: 0.4638
Epoch 86/5000
41/41 - 1s - loss: 0.1280 - mae: 0.3215 - val_loss: 0.2045 - val_mae: 0.5030
Epoch 87/5000
41/41 - 1s - loss: 0.1292 - mae: 0.3268 - val_loss: 0.1985 - val_mae: 0.4866
Epoch 88/5000
41/41 - 1s - loss: 0.1275 - mae: 0.3219 - val_loss: 0.2052 - val_mae: 0.5033
Epoch 89/5000
41/41 - 1s - loss: 0.1280 - mae: 0.3231 - val_loss: 0.1981 - val_mae: 0.4819
Epoch 90/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3193 - val_loss: 0.2006 - val_mae: 0.4882
Epoch 91/5000
41/41 - 1s - loss: 0.1268 - mae: 0.3194 - val_loss: 0.2001 - val_mae: 0.4910
Epoch 92/5000
41/41 - 1s - loss: 0.1274 - mae: 0.3227 - val_loss: 0.1947 - val_mae: 0.4761
Epoch 93/5000
41/41 - 1s - loss: 0.1276 - mae: 0.3190 - val_loss: 0.2010 - val_mae: 0.4959
Epoch 94/5000
41/41 - 1s - loss: 0.1294 - mae: 0.3294 - val_loss: 0.1876 - val_mae: 0.4584
Epoch 95/5000
41/41 - 1s - loss: 0.1267 - mae: 0.3184 - val_loss: 0.1943 - val_mae: 0.4788
Epoch 96/5000
41/41 - 1s - loss: 0.1271 - mae: 0.3237 - val_loss: 0.1651 - val_mae: 0.3729
Epoch 97/5000
41/41 - 1s - loss: 0.1267 - mae: 0.3205 - val_loss: 0.1844 - val_mae: 0.4525
Epoch 98/5000
41/41 - 1s - loss: 0.1263 - mae: 0.3216 - val_loss: 0.1899 - val_mae: 0.4657
Epoch 99/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3197 - val_loss: 0.2018 - val_mae: 0.4957
Epoch 100/5000
41/41 - 1s - loss: 0.1281 - mae: 0.3232 - val_loss: 0.2034 - val_mae: 0.4989
Epoch 101/5000
41/41 - 1s - loss: 0.1295 - mae: 0.3305 - val_loss: 0.2007 - val_mae: 0.4865
Epoch 102/5000
41/41 - 1s - loss: 0.1256 - mae: 0.3198 - val_loss: 0.1945 - val_mae: 0.4736
Epoch 103/5000
41/41 - 1s - loss: 0.1259 - mae: 0.3178 - val_loss: 0.2090 - val_mae: 0.5067
Epoch 104/5000
41/41 - 1s - loss: 0.1261 - mae: 0.3196 - val_loss: 0.1975 - val_mae: 0.4807
Epoch 105/5000
41/41 - 1s - loss: 0.1255 - mae: 0.3190 - val_loss: 0.1915 - val_mae: 0.4629
Epoch 106/5000
41/41 - 1s - loss: 0.1247 - mae: 0.3133 - val_loss: 0.2020 - val_mae: 0.4947
Epoch 107/5000
41/41 - 1s - loss: 0.1261 - mae: 0.3217 - val_loss: 0.1923 - val_mae: 0.4652
Epoch 108/5000
41/41 - 1s - loss: 0.1244 - mae: 0.3126 - val_loss: 0.1966 - val_mae: 0.4806
Epoch 109/5000
41/41 - 1s - loss: 0.1260 - mae: 0.3216 - val_loss: 0.1853 - val_mae: 0.4442
Epoch 110/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3106 - val_loss: 0.1978 - val_mae: 0.4843
Epoch 111/5000
41/41 - 1s - loss: 0.1258 - mae: 0.3225 - val_loss: 0.1839 - val_mae: 0.4380
Epoch 112/5000
41/41 - 1s - loss: 0.1254 - mae: 0.3143 - val_loss: 0.1962 - val_mae: 0.4788
Epoch 113/5000
41/41 - 1s - loss: 0.1247 - mae: 0.3175 - val_loss: 0.1986 - val_mae: 0.4823
Epoch 114/5000
41/41 - 1s - loss: 0.1233 - mae: 0.3137 - val_loss: 0.1942 - val_mae: 0.4718
Epoch 115/5000
41/41 - 1s - loss: 0.1238 - mae: 0.3152 - val_loss: 0.2038 - val_mae: 0.4960
Epoch 116/5000
41/41 - 1s - loss: 0.1236 - mae: 0.3123 - val_loss: 0.2010 - val_mae: 0.4909
Epoch 117/5000
41/41 - 1s - loss: 0.1256 - mae: 0.3215 - val_loss: 0.1929 - val_mae: 0.4672
Epoch 118/5000
41/41 - 1s - loss: 0.1257 - mae: 0.3144 - val_loss: 0.1766 - val_mae: 0.4287
Epoch 119/5000
41/41 - 1s - loss: 0.1283 - mae: 0.3302 - val_loss: 0.1822 - val_mae: 0.4427
Epoch 120/5000
41/41 - 1s - loss: 0.1247 - mae: 0.3145 - val_loss: 0.1948 - val_mae: 0.4780
Epoch 121/5000
41/41 - 1s - loss: 0.1263 - mae: 0.3225 - val_loss: 0.1842 - val_mae: 0.4438
Epoch 122/5000
41/41 - 1s - loss: 0.1231 - mae: 0.3149 - val_loss: 0.1970 - val_mae: 0.4744
Epoch 123/5000
41/41 - 1s - loss: 0.1226 - mae: 0.3117 - val_loss: 0.1960 - val_mae: 0.4707
Epoch 124/5000
41/41 - 1s - loss: 0.1212 - mae: 0.3094 - val_loss: 0.1988 - val_mae: 0.4785
Epoch 125/5000
41/41 - 1s - loss: 0.1238 - mae: 0.3130 - val_loss: 0.1913 - val_mae: 0.4590
Epoch 126/5000
41/41 - 1s - loss: 0.1226 - mae: 0.3108 - val_loss: 0.1945 - val_mae: 0.4726
Epoch 127/5000
41/41 - 1s - loss: 0.1244 - mae: 0.3193 - val_loss: 0.2069 - val_mae: 0.5006
Epoch 128/5000
41/41 - 1s - loss: 0.1231 - mae: 0.3137 - val_loss: 0.1901 - val_mae: 0.4581
Epoch 129/5000
41/41 - 1s - loss: 0.1234 - mae: 0.3151 - val_loss: 0.1921 - val_mae: 0.4597
Epoch 130/5000
41/41 - 1s - loss: 0.1255 - mae: 0.3216 - val_loss: 0.1858 - val_mae: 0.4460
Epoch 131/5000
41/41 - 1s - loss: 0.1228 - mae: 0.3136 - val_loss: 0.1912 - val_mae: 0.4583
Epoch 132/5000
41/41 - 1s - loss: 0.1231 - mae: 0.3152 - val_loss: 0.2065 - val_mae: 0.4910
Epoch 133/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3160 - val_loss: 0.1905 - val_mae: 0.4529
Epoch 134/5000
41/41 - 1s - loss: 0.1255 - mae: 0.3199 - val_loss: 0.1896 - val_mae: 0.4475
Epoch 135/5000
41/41 - 1s - loss: 0.1218 - mae: 0.3085 - val_loss: 0.2099 - val_mae: 0.4961
Epoch 136/5000
41/41 - 1s - loss: 0.1240 - mae: 0.3141 - val_loss: 0.1866 - val_mae: 0.4485
Epoch 137/5000
41/41 - 1s - loss: 0.1323 - mae: 0.3351 - val_loss: 0.1843 - val_mae: 0.3902
Epoch 138/5000
41/41 - 1s - loss: 0.1278 - mae: 0.3270 - val_loss: 0.1789 - val_mae: 0.3935
Epoch 139/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3304 - val_loss: 0.1741 - val_mae: 0.3868
Epoch 140/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3190 - val_loss: 0.1799 - val_mae: 0.4268
Epoch 141/5000
41/41 - 1s - loss: 0.1248 - mae: 0.3204 - val_loss: 0.1774 - val_mae: 0.4144
Epoch 142/5000
41/41 - 1s - loss: 0.1235 - mae: 0.3136 - val_loss: 0.1688 - val_mae: 0.3812
Epoch 143/5000
41/41 - 1s - loss: 0.1308 - mae: 0.3354 - val_loss: 0.1835 - val_mae: 0.4455
Epoch 144/5000
41/41 - 1s - loss: 0.1264 - mae: 0.3207 - val_loss: 0.1777 - val_mae: 0.3852
Epoch 145/5000
41/41 - 1s - loss: 0.1291 - mae: 0.3301 - val_loss: 0.1753 - val_mae: 0.3815
Epoch 146/5000
41/41 - 1s - loss: 0.1289 - mae: 0.3318 - val_loss: 0.1735 - val_mae: 0.3917
Epoch 147/5000
41/41 - 1s - loss: 0.1241 - mae: 0.3169 - val_loss: 0.1725 - val_mae: 0.3804
Epoch 148/5000
41/41 - 1s - loss: 0.1241 - mae: 0.3155 - val_loss: 0.1725 - val_mae: 0.3895
Epoch 149/5000
41/41 - 1s - loss: 0.1227 - mae: 0.3132 - val_loss: 0.1794 - val_mae: 0.3842
Epoch 150/5000
41/41 - 1s - loss: 0.1282 - mae: 0.3242 - val_loss: 0.1781 - val_mae: 0.3936
Epoch 151/5000
41/41 - 1s - loss: 0.1256 - mae: 0.3192 - val_loss: 0.1851 - val_mae: 0.3918
Epoch 152/5000
41/41 - 1s - loss: 0.1279 - mae: 0.3255 - val_loss: 0.1795 - val_mae: 0.3826
Epoch 153/5000
41/41 - 1s - loss: 0.1273 - mae: 0.3265 - val_loss: 0.1716 - val_mae: 0.3780
Epoch 154/5000
41/41 - 1s - loss: 0.1263 - mae: 0.3204 - val_loss: 0.1869 - val_mae: 0.3945
Epoch 155/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3241 - val_loss: 0.1835 - val_mae: 0.3912
Epoch 156/5000
41/41 - 1s - loss: 0.1260 - mae: 0.3206 - val_loss: 0.1713 - val_mae: 0.3833
Epoch 157/5000
41/41 - 1s - loss: 0.1229 - mae: 0.3153 - val_loss: 0.1708 - val_mae: 0.3803
Epoch 158/5000
41/41 - 1s - loss: 0.1216 - mae: 0.3111 - val_loss: 0.1732 - val_mae: 0.3864
Restoring model weights from the end of the best epoch.
Epoch 00158: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_6..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_34"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_6 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_6 (PartitionP (None, None, 64)     0           message_passing_6[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_6[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_6 (Masking)             (None, None, 64)     0           partition_padding_6[0][0]        
                                                                 partition_padding_6[1][0]        
__________________________________________________________________________________________________
transformer_encoder_6 (Transfor (None, None, 64)     199040      masking_6[0][0]                  
                                                                 masking_6[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_6 (Glo (None, 64)           0           transformer_encoder_6[0][0]      
                                                                 transformer_encoder_6[1][0]      
__________________________________________________________________________________________________
dense_106 (Dense)               (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_104 (Dense)               (None, 512)          33280       global_average_pooling1d_6[0][0] 
                                                                 global_average_pooling1d_6[1][0] 
__________________________________________________________________________________________________
dense_107 (Dense)               (None, 10)           110         dense_106[0][0]                  
__________________________________________________________________________________________________
dense_105 (Dense)               (None, 450)          230850      dense_104[0][0]                  
                                                                 dense_104[1][0]                  
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 5)            55          dense_107[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 905)          0           dense_105[0][0]                  
                                                                 dense_105[1][0]                  
                                                                 dense_108[0][0]                  
__________________________________________________________________________________________________
dense_109 (Dense)               (None, 700)          634200      concatenate_6[0][0]              
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 560)          392560      dense_109[0][0]                  
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 373)          209253      dense_113[0][0]                  
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 187)          69938       dense_114[0][0]                  
__________________________________________________________________________________________________
dense_116 (Dense)               (None, 1)            188         dense_115[0][0]                  
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
41/41 - 6s - loss: 0.1326 - mae: 0.3281 - val_loss: 0.1699 - val_mae: 0.3558
Epoch 2/5000
41/41 - 1s - loss: 0.1216 - mae: 0.3117 - val_loss: 0.1631 - val_mae: 0.3542
Epoch 3/5000
41/41 - 1s - loss: 0.1150 - mae: 0.2960 - val_loss: 0.1649 - val_mae: 0.3714
Epoch 4/5000
41/41 - 1s - loss: 0.1120 - mae: 0.2864 - val_loss: 0.1692 - val_mae: 0.3887
Epoch 5/5000
41/41 - 1s - loss: 0.1098 - mae: 0.2807 - val_loss: 0.1731 - val_mae: 0.3989
Epoch 6/5000
41/41 - 1s - loss: 0.1077 - mae: 0.2762 - val_loss: 0.1715 - val_mae: 0.3952
Epoch 7/5000
41/41 - 1s - loss: 0.1057 - mae: 0.2719 - val_loss: 0.1704 - val_mae: 0.3930
Epoch 8/5000
41/41 - 1s - loss: 0.1042 - mae: 0.2686 - val_loss: 0.1741 - val_mae: 0.4101
Epoch 9/5000
41/41 - 1s - loss: 0.1030 - mae: 0.2663 - val_loss: 0.1749 - val_mae: 0.4159
Epoch 10/5000
41/41 - 1s - loss: 0.1012 - mae: 0.2621 - val_loss: 0.1738 - val_mae: 0.4116
Epoch 11/5000
41/41 - 1s - loss: 0.0998 - mae: 0.2592 - val_loss: 0.1792 - val_mae: 0.4288
Epoch 12/5000
41/41 - 1s - loss: 0.0983 - mae: 0.2559 - val_loss: 0.1788 - val_mae: 0.4271
Epoch 13/5000
41/41 - 1s - loss: 0.0998 - mae: 0.2588 - val_loss: 0.1670 - val_mae: 0.3872
Epoch 14/5000
41/41 - 1s - loss: 0.0983 - mae: 0.2578 - val_loss: 0.1634 - val_mae: 0.3756
Epoch 15/5000
41/41 - 1s - loss: 0.0949 - mae: 0.2486 - val_loss: 0.1644 - val_mae: 0.3867
Epoch 16/5000
41/41 - 1s - loss: 0.0923 - mae: 0.2421 - val_loss: 0.1646 - val_mae: 0.3861
Epoch 17/5000
41/41 - 1s - loss: 0.0911 - mae: 0.2394 - val_loss: 0.1639 - val_mae: 0.3795
Epoch 18/5000
41/41 - 1s - loss: 0.0908 - mae: 0.2392 - val_loss: 0.1624 - val_mae: 0.3713
Epoch 19/5000
41/41 - 1s - loss: 0.0900 - mae: 0.2386 - val_loss: 0.1609 - val_mae: 0.3652
Epoch 20/5000
41/41 - 1s - loss: 0.0889 - mae: 0.2359 - val_loss: 0.1591 - val_mae: 0.3535
Epoch 21/5000
41/41 - 1s - loss: 0.0878 - mae: 0.2339 - val_loss: 0.1589 - val_mae: 0.3523
Epoch 22/5000
41/41 - 1s - loss: 0.0868 - mae: 0.2328 - val_loss: 0.1650 - val_mae: 0.3657
Epoch 23/5000
41/41 - 1s - loss: 0.0858 - mae: 0.2313 - val_loss: 0.1686 - val_mae: 0.3736
Epoch 24/5000
41/41 - 1s - loss: 0.0865 - mae: 0.2328 - val_loss: 0.1687 - val_mae: 0.3766
Epoch 25/5000
41/41 - 1s - loss: 0.0909 - mae: 0.2426 - val_loss: 0.1607 - val_mae: 0.3551
Epoch 26/5000
41/41 - 1s - loss: 0.1016 - mae: 0.2710 - val_loss: 0.1655 - val_mae: 0.3433
Epoch 27/5000
41/41 - 1s - loss: 0.0940 - mae: 0.2506 - val_loss: 0.1562 - val_mae: 0.3280
Epoch 28/5000
41/41 - 1s - loss: 0.0863 - mae: 0.2301 - val_loss: 0.1530 - val_mae: 0.3210
Epoch 29/5000
41/41 - 1s - loss: 0.0841 - mae: 0.2251 - val_loss: 0.1539 - val_mae: 0.3224
Epoch 30/5000
41/41 - 1s - loss: 0.0827 - mae: 0.2226 - val_loss: 0.1539 - val_mae: 0.3233
Epoch 31/5000
41/41 - 1s - loss: 0.0813 - mae: 0.2193 - val_loss: 0.1548 - val_mae: 0.3240
Epoch 32/5000
41/41 - 1s - loss: 0.0796 - mae: 0.2147 - val_loss: 0.1521 - val_mae: 0.3198
Epoch 33/5000
41/41 - 1s - loss: 0.0787 - mae: 0.2132 - val_loss: 0.1521 - val_mae: 0.3194
Epoch 34/5000
41/41 - 1s - loss: 0.0778 - mae: 0.2125 - val_loss: 0.1538 - val_mae: 0.3211
Epoch 35/5000
41/41 - 1s - loss: 0.0775 - mae: 0.2130 - val_loss: 0.1543 - val_mae: 0.3219
Epoch 36/5000
41/41 - 1s - loss: 0.0762 - mae: 0.2088 - val_loss: 0.1550 - val_mae: 0.3244
Epoch 37/5000
41/41 - 1s - loss: 0.0752 - mae: 0.2067 - val_loss: 0.1544 - val_mae: 0.3256
Epoch 38/5000
41/41 - 1s - loss: 0.0744 - mae: 0.2043 - val_loss: 0.1535 - val_mae: 0.3299
Epoch 39/5000
41/41 - 1s - loss: 0.0751 - mae: 0.2058 - val_loss: 0.1564 - val_mae: 0.3371
Epoch 40/5000
41/41 - 1s - loss: 0.0739 - mae: 0.2020 - val_loss: 0.1532 - val_mae: 0.3270
Epoch 41/5000
41/41 - 1s - loss: 0.0722 - mae: 0.1989 - val_loss: 0.1538 - val_mae: 0.3230
Epoch 42/5000
41/41 - 1s - loss: 0.0700 - mae: 0.1947 - val_loss: 0.1517 - val_mae: 0.3228
Epoch 43/5000
41/41 - 1s - loss: 0.0696 - mae: 0.1947 - val_loss: 0.1515 - val_mae: 0.3251
Epoch 44/5000
41/41 - 1s - loss: 0.0705 - mae: 0.1994 - val_loss: 0.1574 - val_mae: 0.3378
Epoch 45/5000
41/41 - 1s - loss: 0.0718 - mae: 0.2028 - val_loss: 0.1582 - val_mae: 0.3430
Epoch 46/5000
41/41 - 1s - loss: 0.0719 - mae: 0.2030 - val_loss: 0.1645 - val_mae: 0.3592
Epoch 47/5000
41/41 - 1s - loss: 0.0739 - mae: 0.2094 - val_loss: 0.1665 - val_mae: 0.3735
Epoch 48/5000
41/41 - 1s - loss: 0.0799 - mae: 0.2217 - val_loss: 0.1601 - val_mae: 0.3746
Epoch 49/5000
41/41 - 1s - loss: 0.0827 - mae: 0.2345 - val_loss: 0.1467 - val_mae: 0.3179
Epoch 50/5000
41/41 - 1s - loss: 0.0705 - mae: 0.2023 - val_loss: 0.1467 - val_mae: 0.3167
Epoch 51/5000
41/41 - 1s - loss: 0.0627 - mae: 0.1818 - val_loss: 0.1490 - val_mae: 0.3283
Epoch 52/5000
41/41 - 1s - loss: 0.0611 - mae: 0.1781 - val_loss: 0.1488 - val_mae: 0.3286
Epoch 53/5000
41/41 - 1s - loss: 0.0608 - mae: 0.1783 - val_loss: 0.1525 - val_mae: 0.3374
Epoch 54/5000
41/41 - 1s - loss: 0.0607 - mae: 0.1804 - val_loss: 0.1581 - val_mae: 0.3473
Epoch 55/5000
41/41 - 1s - loss: 0.0627 - mae: 0.1863 - val_loss: 0.1565 - val_mae: 0.3375
Epoch 56/5000
41/41 - 1s - loss: 0.0624 - mae: 0.1874 - val_loss: 0.1594 - val_mae: 0.3456
Epoch 57/5000
41/41 - 1s - loss: 0.0609 - mae: 0.1827 - val_loss: 0.1586 - val_mae: 0.3518
Epoch 58/5000
41/41 - 1s - loss: 0.0638 - mae: 0.1914 - val_loss: 0.1587 - val_mae: 0.3561
Epoch 59/5000
41/41 - 1s - loss: 0.0697 - mae: 0.2048 - val_loss: 0.1518 - val_mae: 0.3346
Epoch 60/5000
41/41 - 1s - loss: 0.0639 - mae: 0.1935 - val_loss: 0.1574 - val_mae: 0.3584
Epoch 61/5000
41/41 - 1s - loss: 0.0632 - mae: 0.1914 - val_loss: 0.1823 - val_mae: 0.4268
Epoch 62/5000
41/41 - 1s - loss: 0.0660 - mae: 0.1999 - val_loss: 0.1635 - val_mae: 0.3766
Epoch 63/5000
41/41 - 1s - loss: 0.0596 - mae: 0.1830 - val_loss: 0.1553 - val_mae: 0.3456
Epoch 64/5000
41/41 - 1s - loss: 0.0605 - mae: 0.1851 - val_loss: 0.1540 - val_mae: 0.3463
Epoch 65/5000
41/41 - 1s - loss: 0.0632 - mae: 0.1932 - val_loss: 0.1397 - val_mae: 0.3081
Epoch 66/5000
41/41 - 1s - loss: 0.0636 - mae: 0.1961 - val_loss: 0.1431 - val_mae: 0.3003
Epoch 67/5000
41/41 - 1s - loss: 0.0616 - mae: 0.1872 - val_loss: 0.1424 - val_mae: 0.3044
Epoch 68/5000
41/41 - 1s - loss: 0.0686 - mae: 0.2067 - val_loss: 0.1599 - val_mae: 0.3741
Epoch 69/5000
41/41 - 1s - loss: 0.0599 - mae: 0.1893 - val_loss: 0.1678 - val_mae: 0.3796
Epoch 70/5000
41/41 - 1s - loss: 0.0582 - mae: 0.1806 - val_loss: 0.1423 - val_mae: 0.3058
Epoch 71/5000
41/41 - 1s - loss: 0.0545 - mae: 0.1708 - val_loss: 0.1437 - val_mae: 0.3115
Epoch 72/5000
41/41 - 1s - loss: 0.0516 - mae: 0.1675 - val_loss: 0.1699 - val_mae: 0.3682
Epoch 73/5000
41/41 - 1s - loss: 0.0533 - mae: 0.1697 - val_loss: 0.1696 - val_mae: 0.3707
Epoch 74/5000
41/41 - 1s - loss: 0.0550 - mae: 0.1761 - val_loss: 0.1501 - val_mae: 0.3259
Epoch 75/5000
41/41 - 1s - loss: 0.0565 - mae: 0.1775 - val_loss: 0.1451 - val_mae: 0.3068
Epoch 76/5000
41/41 - 1s - loss: 0.0534 - mae: 0.1702 - val_loss: 0.1493 - val_mae: 0.3133
Epoch 77/5000
41/41 - 1s - loss: 0.0564 - mae: 0.1829 - val_loss: 0.1627 - val_mae: 0.3544
Epoch 78/5000
41/41 - 1s - loss: 0.0549 - mae: 0.1754 - val_loss: 0.1625 - val_mae: 0.3551
Epoch 79/5000
41/41 - 1s - loss: 0.0536 - mae: 0.1718 - val_loss: 0.1479 - val_mae: 0.3127
Epoch 80/5000
41/41 - 1s - loss: 0.0474 - mae: 0.1547 - val_loss: 0.1488 - val_mae: 0.3146
Epoch 81/5000
41/41 - 1s - loss: 0.0458 - mae: 0.1546 - val_loss: 0.1502 - val_mae: 0.3239
Epoch 82/5000
41/41 - 1s - loss: 0.0478 - mae: 0.1620 - val_loss: 0.1592 - val_mae: 0.3415
Epoch 83/5000
41/41 - 1s - loss: 0.0473 - mae: 0.1574 - val_loss: 0.1659 - val_mae: 0.3519
Epoch 84/5000
41/41 - 1s - loss: 0.0484 - mae: 0.1554 - val_loss: 0.1489 - val_mae: 0.3102
Epoch 85/5000
41/41 - 1s - loss: 0.0465 - mae: 0.1526 - val_loss: 0.1471 - val_mae: 0.3063
Epoch 86/5000
41/41 - 1s - loss: 0.0481 - mae: 0.1613 - val_loss: 0.1488 - val_mae: 0.3186
Epoch 87/5000
41/41 - 1s - loss: 0.0463 - mae: 0.1537 - val_loss: 0.1532 - val_mae: 0.3257
Epoch 88/5000
41/41 - 1s - loss: 0.0448 - mae: 0.1492 - val_loss: 0.1532 - val_mae: 0.3281
Epoch 89/5000
41/41 - 1s - loss: 0.0477 - mae: 0.1564 - val_loss: 0.1483 - val_mae: 0.3138
Epoch 90/5000
41/41 - 1s - loss: 0.0450 - mae: 0.1498 - val_loss: 0.1446 - val_mae: 0.3087
Epoch 91/5000
41/41 - 1s - loss: 0.0446 - mae: 0.1534 - val_loss: 0.1500 - val_mae: 0.3182
Epoch 92/5000
41/41 - 1s - loss: 0.0457 - mae: 0.1554 - val_loss: 0.1529 - val_mae: 0.3207
Epoch 93/5000
41/41 - 1s - loss: 0.0441 - mae: 0.1502 - val_loss: 0.1536 - val_mae: 0.3235
Epoch 94/5000
41/41 - 1s - loss: 0.0440 - mae: 0.1483 - val_loss: 0.1462 - val_mae: 0.3071
Epoch 95/5000
41/41 - 1s - loss: 0.0463 - mae: 0.1576 - val_loss: 0.1473 - val_mae: 0.3101
Epoch 96/5000
41/41 - 1s - loss: 0.0465 - mae: 0.1590 - val_loss: 0.1443 - val_mae: 0.3064
Epoch 97/5000
41/41 - 1s - loss: 0.0473 - mae: 0.1619 - val_loss: 0.1446 - val_mae: 0.3111
Epoch 98/5000
41/41 - 1s - loss: 0.0539 - mae: 0.1771 - val_loss: 0.1456 - val_mae: 0.3084
Epoch 99/5000
41/41 - 1s - loss: 0.0558 - mae: 0.1796 - val_loss: 0.1406 - val_mae: 0.2946
Epoch 100/5000
41/41 - 1s - loss: 0.0485 - mae: 0.1629 - val_loss: 0.1500 - val_mae: 0.3111
Epoch 101/5000
41/41 - 1s - loss: 0.0514 - mae: 0.1744 - val_loss: 0.1428 - val_mae: 0.3029
Epoch 102/5000
41/41 - 1s - loss: 0.0526 - mae: 0.1734 - val_loss: 0.1413 - val_mae: 0.2973
Epoch 103/5000
41/41 - 1s - loss: 0.0548 - mae: 0.1785 - val_loss: 0.1513 - val_mae: 0.3133
Epoch 104/5000
41/41 - 1s - loss: 0.0559 - mae: 0.1848 - val_loss: 0.1503 - val_mae: 0.3119
Epoch 105/5000
41/41 - 1s - loss: 0.0524 - mae: 0.1809 - val_loss: 0.1477 - val_mae: 0.3046
Epoch 106/5000
41/41 - 1s - loss: 0.0577 - mae: 0.1899 - val_loss: 0.1493 - val_mae: 0.3084
Epoch 107/5000
41/41 - 1s - loss: 0.0551 - mae: 0.1862 - val_loss: 0.1532 - val_mae: 0.3125
Epoch 108/5000
41/41 - 1s - loss: 0.0704 - mae: 0.2205 - val_loss: 0.1489 - val_mae: 0.3151
Epoch 109/5000
41/41 - 1s - loss: 0.0669 - mae: 0.2083 - val_loss: 0.1521 - val_mae: 0.3266
Epoch 110/5000
41/41 - 1s - loss: 0.0509 - mae: 0.1713 - val_loss: 0.1560 - val_mae: 0.3200
Epoch 111/5000
41/41 - 1s - loss: 0.0487 - mae: 0.1679 - val_loss: 0.1570 - val_mae: 0.3179
Epoch 112/5000
41/41 - 1s - loss: 0.0457 - mae: 0.1609 - val_loss: 0.1566 - val_mae: 0.3202
Epoch 113/5000
41/41 - 1s - loss: 0.0423 - mae: 0.1544 - val_loss: 0.1690 - val_mae: 0.3461
Epoch 114/5000
41/41 - 1s - loss: 0.0422 - mae: 0.1508 - val_loss: 0.1666 - val_mae: 0.3426
Epoch 115/5000
41/41 - 1s - loss: 0.0426 - mae: 0.1514 - val_loss: 0.1597 - val_mae: 0.3285
Epoch 116/5000
41/41 - 1s - loss: 0.0392 - mae: 0.1402 - val_loss: 0.1618 - val_mae: 0.3364
Epoch 117/5000
41/41 - 1s - loss: 0.0383 - mae: 0.1403 - val_loss: 0.1564 - val_mae: 0.3244
Epoch 118/5000
41/41 - 1s - loss: 0.0372 - mae: 0.1371 - val_loss: 0.1610 - val_mae: 0.3337
Epoch 119/5000
41/41 - 1s - loss: 0.0371 - mae: 0.1382 - val_loss: 0.1577 - val_mae: 0.3234
Epoch 120/5000
41/41 - 1s - loss: 0.0359 - mae: 0.1353 - val_loss: 0.1633 - val_mae: 0.3344
Epoch 121/5000
41/41 - 1s - loss: 0.0394 - mae: 0.1433 - val_loss: 0.1700 - val_mae: 0.3451
Epoch 122/5000
41/41 - 1s - loss: 0.0416 - mae: 0.1426 - val_loss: 0.1595 - val_mae: 0.3236
Epoch 123/5000
41/41 - 1s - loss: 0.0398 - mae: 0.1417 - val_loss: 0.1500 - val_mae: 0.3122
Epoch 124/5000
41/41 - 1s - loss: 0.0352 - mae: 0.1285 - val_loss: 0.1519 - val_mae: 0.3135
Epoch 125/5000
41/41 - 1s - loss: 0.0358 - mae: 0.1325 - val_loss: 0.1491 - val_mae: 0.3082
Epoch 126/5000
41/41 - 1s - loss: 0.0353 - mae: 0.1285 - val_loss: 0.1495 - val_mae: 0.3059
Epoch 127/5000
41/41 - 1s - loss: 0.0328 - mae: 0.1222 - val_loss: 0.1549 - val_mae: 0.3164
Epoch 128/5000
41/41 - 1s - loss: 0.0324 - mae: 0.1230 - val_loss: 0.1558 - val_mae: 0.3156
Epoch 129/5000
41/41 - 1s - loss: 0.0334 - mae: 0.1266 - val_loss: 0.1518 - val_mae: 0.3077
Epoch 130/5000
41/41 - 1s - loss: 0.0342 - mae: 0.1229 - val_loss: 0.1528 - val_mae: 0.3129
Epoch 131/5000
41/41 - 1s - loss: 0.0326 - mae: 0.1271 - val_loss: 0.1551 - val_mae: 0.3124
Epoch 132/5000
41/41 - 1s - loss: 0.0321 - mae: 0.1210 - val_loss: 0.1508 - val_mae: 0.3057
Epoch 133/5000
41/41 - 1s - loss: 0.0349 - mae: 0.1269 - val_loss: 0.1482 - val_mae: 0.3026
Epoch 134/5000
41/41 - 1s - loss: 0.0333 - mae: 0.1255 - val_loss: 0.1517 - val_mae: 0.3077
Epoch 135/5000
41/41 - 1s - loss: 0.0343 - mae: 0.1305 - val_loss: 0.1499 - val_mae: 0.3087
Epoch 136/5000
41/41 - 1s - loss: 0.0288 - mae: 0.1151 - val_loss: 0.1547 - val_mae: 0.3119
Epoch 137/5000
41/41 - 1s - loss: 0.0347 - mae: 0.1325 - val_loss: 0.1496 - val_mae: 0.3024
Epoch 138/5000
41/41 - 1s - loss: 0.0389 - mae: 0.1432 - val_loss: 0.1472 - val_mae: 0.3033
Epoch 139/5000
41/41 - 1s - loss: 0.0356 - mae: 0.1349 - val_loss: 0.1503 - val_mae: 0.3092
Epoch 140/5000
41/41 - 1s - loss: 0.0301 - mae: 0.1199 - val_loss: 0.1588 - val_mae: 0.3151
Epoch 141/5000
41/41 - 1s - loss: 0.0347 - mae: 0.1371 - val_loss: 0.1473 - val_mae: 0.2996
Epoch 142/5000
41/41 - 1s - loss: 0.0307 - mae: 0.1207 - val_loss: 0.1554 - val_mae: 0.3125
Epoch 143/5000
41/41 - 1s - loss: 0.0283 - mae: 0.1150 - val_loss: 0.1589 - val_mae: 0.3221
Epoch 144/5000
41/41 - 1s - loss: 0.0284 - mae: 0.1166 - val_loss: 0.1502 - val_mae: 0.3024
Epoch 145/5000
41/41 - 1s - loss: 0.0298 - mae: 0.1232 - val_loss: 0.1581 - val_mae: 0.3238
Epoch 146/5000
41/41 - 1s - loss: 0.0275 - mae: 0.1122 - val_loss: 0.1495 - val_mae: 0.3036
Epoch 147/5000
41/41 - 1s - loss: 0.0291 - mae: 0.1233 - val_loss: 0.1568 - val_mae: 0.3159
Epoch 148/5000
41/41 - 1s - loss: 0.0321 - mae: 0.1291 - val_loss: 0.1519 - val_mae: 0.3040
Epoch 149/5000
41/41 - 1s - loss: 0.0286 - mae: 0.1210 - val_loss: 0.1690 - val_mae: 0.3457
Epoch 150/5000
41/41 - 1s - loss: 0.0290 - mae: 0.1206 - val_loss: 0.1799 - val_mae: 0.3675
Epoch 151/5000
41/41 - 1s - loss: 0.0369 - mae: 0.1402 - val_loss: 0.1508 - val_mae: 0.3089
Epoch 152/5000
41/41 - 1s - loss: 0.0331 - mae: 0.1337 - val_loss: 0.1763 - val_mae: 0.3665
Epoch 153/5000
41/41 - 1s - loss: 0.0374 - mae: 0.1441 - val_loss: 0.1613 - val_mae: 0.3265
Epoch 154/5000
41/41 - 1s - loss: 0.0317 - mae: 0.1287 - val_loss: 0.1593 - val_mae: 0.3342
Epoch 155/5000
41/41 - 1s - loss: 0.0316 - mae: 0.1288 - val_loss: 0.1511 - val_mae: 0.3053
Epoch 156/5000
41/41 - 1s - loss: 0.0371 - mae: 0.1455 - val_loss: 0.1492 - val_mae: 0.3120
Epoch 157/5000
41/41 - 1s - loss: 0.0310 - mae: 0.1251 - val_loss: 0.1457 - val_mae: 0.2958
Epoch 158/5000
41/41 - 1s - loss: 0.0359 - mae: 0.1403 - val_loss: 0.1469 - val_mae: 0.3037
Epoch 159/5000
41/41 - 1s - loss: 0.0295 - mae: 0.1234 - val_loss: 0.1440 - val_mae: 0.2988
Epoch 160/5000
41/41 - 1s - loss: 0.0320 - mae: 0.1310 - val_loss: 0.1438 - val_mae: 0.2983
Epoch 161/5000
41/41 - 1s - loss: 0.0270 - mae: 0.1144 - val_loss: 0.1445 - val_mae: 0.3005
Epoch 162/5000
41/41 - 1s - loss: 0.0261 - mae: 0.1141 - val_loss: 0.1514 - val_mae: 0.3119
Epoch 163/5000
41/41 - 1s - loss: 0.0267 - mae: 0.1096 - val_loss: 0.1467 - val_mae: 0.3039
Epoch 164/5000
41/41 - 1s - loss: 0.0241 - mae: 0.1056 - val_loss: 0.1486 - val_mae: 0.3044
Epoch 165/5000
41/41 - 1s - loss: 0.0236 - mae: 0.1063 - val_loss: 0.1532 - val_mae: 0.3108
Epoch 166/5000
41/41 - 1s - loss: 0.0240 - mae: 0.1103 - val_loss: 0.1538 - val_mae: 0.3083
Epoch 167/5000
41/41 - 1s - loss: 0.0231 - mae: 0.1068 - val_loss: 0.1519 - val_mae: 0.3047
Epoch 168/5000
41/41 - 1s - loss: 0.0232 - mae: 0.1073 - val_loss: 0.1536 - val_mae: 0.3072
Epoch 169/5000
41/41 - 1s - loss: 0.0256 - mae: 0.1138 - val_loss: 0.1524 - val_mae: 0.3085
Epoch 170/5000
41/41 - 1s - loss: 0.0270 - mae: 0.1213 - val_loss: 0.1616 - val_mae: 0.3345
Epoch 171/5000
41/41 - 1s - loss: 0.0232 - mae: 0.1121 - val_loss: 0.1577 - val_mae: 0.3150
Epoch 172/5000
41/41 - 1s - loss: 0.0260 - mae: 0.1132 - val_loss: 0.1545 - val_mae: 0.3062
Epoch 173/5000
41/41 - 1s - loss: 0.0261 - mae: 0.1134 - val_loss: 0.1688 - val_mae: 0.3486
Epoch 174/5000
41/41 - 1s - loss: 0.0247 - mae: 0.1128 - val_loss: 0.1649 - val_mae: 0.3280
Epoch 175/5000
41/41 - 1s - loss: 0.0249 - mae: 0.1098 - val_loss: 0.1659 - val_mae: 0.3277
Epoch 176/5000
41/41 - 1s - loss: 0.0217 - mae: 0.1025 - val_loss: 0.1744 - val_mae: 0.3515
Epoch 177/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1147 - val_loss: 0.1691 - val_mae: 0.3394
Epoch 178/5000
41/41 - 1s - loss: 0.0270 - mae: 0.1173 - val_loss: 0.1787 - val_mae: 0.3491
Epoch 179/5000
41/41 - 1s - loss: 0.0293 - mae: 0.1233 - val_loss: 0.1517 - val_mae: 0.3234
Epoch 180/5000
41/41 - 1s - loss: 0.0336 - mae: 0.1398 - val_loss: 0.1522 - val_mae: 0.3065
Epoch 181/5000
41/41 - 1s - loss: 0.0335 - mae: 0.1347 - val_loss: 0.1456 - val_mae: 0.3033
Epoch 182/5000
41/41 - 1s - loss: 0.0352 - mae: 0.1481 - val_loss: 0.1462 - val_mae: 0.3041
Epoch 183/5000
41/41 - 1s - loss: 0.0308 - mae: 0.1328 - val_loss: 0.1453 - val_mae: 0.3089
Epoch 184/5000
41/41 - 1s - loss: 0.0283 - mae: 0.1266 - val_loss: 0.1480 - val_mae: 0.2996
Epoch 185/5000
41/41 - 1s - loss: 0.0247 - mae: 0.1178 - val_loss: 0.1493 - val_mae: 0.3053
Epoch 186/5000
41/41 - 1s - loss: 0.0253 - mae: 0.1190 - val_loss: 0.1533 - val_mae: 0.3116
Epoch 187/5000
41/41 - 1s - loss: 0.0223 - mae: 0.1084 - val_loss: 0.1508 - val_mae: 0.3073
Epoch 188/5000
41/41 - 1s - loss: 0.0239 - mae: 0.1082 - val_loss: 0.1514 - val_mae: 0.3057
Epoch 189/5000
41/41 - 1s - loss: 0.0230 - mae: 0.1099 - val_loss: 0.1546 - val_mae: 0.3091
Epoch 190/5000
41/41 - 1s - loss: 0.0239 - mae: 0.1117 - val_loss: 0.1590 - val_mae: 0.3185
Epoch 191/5000
41/41 - 1s - loss: 0.0209 - mae: 0.0981 - val_loss: 0.1602 - val_mae: 0.3248
Epoch 192/5000
41/41 - 1s - loss: 0.0198 - mae: 0.1002 - val_loss: 0.1602 - val_mae: 0.3194
Epoch 193/5000
41/41 - 1s - loss: 0.0199 - mae: 0.0982 - val_loss: 0.1647 - val_mae: 0.3212
Epoch 194/5000
41/41 - 1s - loss: 0.0195 - mae: 0.1011 - val_loss: 0.1550 - val_mae: 0.3076
Epoch 195/5000
41/41 - 1s - loss: 0.0226 - mae: 0.1106 - val_loss: 0.1547 - val_mae: 0.3108
Epoch 196/5000
41/41 - 1s - loss: 0.0189 - mae: 0.0994 - val_loss: 0.1541 - val_mae: 0.3088
Epoch 197/5000
41/41 - 1s - loss: 0.0186 - mae: 0.1018 - val_loss: 0.1496 - val_mae: 0.3076
Epoch 198/5000
41/41 - 1s - loss: 0.0196 - mae: 0.1051 - val_loss: 0.1546 - val_mae: 0.3126
Epoch 199/5000
41/41 - 1s - loss: 0.0190 - mae: 0.1010 - val_loss: 0.1554 - val_mae: 0.3138
Epoch 200/5000
41/41 - 1s - loss: 0.0219 - mae: 0.1067 - val_loss: 0.1518 - val_mae: 0.3102
Restoring model weights from the end of the best epoch.
Epoch 00200: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_6..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 7

Generating graphs from SMILES..

Setting up training set.
Size: 2058

Setting up validation set.
Size: 228

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_39"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_7 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_7 (PartitionP (None, None, 64)     0           message_passing_7[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_7[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_7 (Masking)             (None, None, 64)     0           partition_padding_7[0][0]        
                                                                 partition_padding_7[1][0]        
__________________________________________________________________________________________________
transformer_encoder_7 (Transfor (None, None, 64)     199040      masking_7[0][0]                  
                                                                 masking_7[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_7 (Glo (None, 64)           0           transformer_encoder_7[0][0]      
                                                                 transformer_encoder_7[1][0]      
__________________________________________________________________________________________________
dense_123 (Dense)               (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_121 (Dense)               (None, 512)          33280       global_average_pooling1d_7[0][0] 
                                                                 global_average_pooling1d_7[1][0] 
__________________________________________________________________________________________________
dense_124 (Dense)               (None, 10)           110         dense_123[0][0]                  
__________________________________________________________________________________________________
dense_122 (Dense)               (None, 450)          230850      dense_121[0][0]                  
                                                                 dense_121[1][0]                  
__________________________________________________________________________________________________
dense_125 (Dense)               (None, 5)            55          dense_124[0][0]                  
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 905)          0           dense_122[0][0]                  
                                                                 dense_122[1][0]                  
                                                                 dense_125[0][0]                  
__________________________________________________________________________________________________
dense_126 (Dense)               (None, 700)          634200      concatenate_7[0][0]              
__________________________________________________________________________________________________
dense_130 (Dense)               (None, 560)          392560      dense_126[0][0]                  
__________________________________________________________________________________________________
dense_131 (Dense)               (None, 373)          209253      dense_130[0][0]                  
__________________________________________________________________________________________________
dense_132 (Dense)               (None, 187)          69938       dense_131[0][0]                  
__________________________________________________________________________________________________
dense_133 (Dense)               (None, 1)            188         dense_132[0][0]                  
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
41/41 - 5s - loss: 0.3192 - mae: 0.6391 - val_loss: 0.0885 - val_mae: 0.3356
Epoch 2/5000
41/41 - 1s - loss: 0.1611 - mae: 0.4058 - val_loss: 0.0884 - val_mae: 0.3369
Epoch 3/5000
41/41 - 1s - loss: 0.1597 - mae: 0.4017 - val_loss: 0.0866 - val_mae: 0.3343
Epoch 4/5000
41/41 - 1s - loss: 0.1597 - mae: 0.4005 - val_loss: 0.0830 - val_mae: 0.3193
Epoch 5/5000
41/41 - 1s - loss: 0.1580 - mae: 0.3966 - val_loss: 0.0832 - val_mae: 0.3243
Epoch 6/5000
41/41 - 1s - loss: 0.1569 - mae: 0.3944 - val_loss: 0.0847 - val_mae: 0.3327
Epoch 7/5000
41/41 - 1s - loss: 0.1558 - mae: 0.3923 - val_loss: 0.0877 - val_mae: 0.3464
Epoch 8/5000
41/41 - 1s - loss: 0.1551 - mae: 0.3899 - val_loss: 0.0876 - val_mae: 0.3466
Epoch 9/5000
41/41 - 1s - loss: 0.1539 - mae: 0.3869 - val_loss: 0.0828 - val_mae: 0.3295
Epoch 10/5000
41/41 - 1s - loss: 0.1523 - mae: 0.3834 - val_loss: 0.0823 - val_mae: 0.3303
Epoch 11/5000
41/41 - 1s - loss: 0.1518 - mae: 0.3815 - val_loss: 0.0814 - val_mae: 0.3258
Epoch 12/5000
41/41 - 1s - loss: 0.1496 - mae: 0.3773 - val_loss: 0.0880 - val_mae: 0.3513
Epoch 13/5000
41/41 - 1s - loss: 0.1490 - mae: 0.3757 - val_loss: 0.0824 - val_mae: 0.3303
Epoch 14/5000
41/41 - 1s - loss: 0.1487 - mae: 0.3747 - val_loss: 0.0747 - val_mae: 0.2970
Epoch 15/5000
41/41 - 1s - loss: 0.1467 - mae: 0.3716 - val_loss: 0.0814 - val_mae: 0.3286
Epoch 16/5000
41/41 - 1s - loss: 0.1469 - mae: 0.3699 - val_loss: 0.0746 - val_mae: 0.3011
Epoch 17/5000
41/41 - 1s - loss: 0.1447 - mae: 0.3661 - val_loss: 0.0859 - val_mae: 0.3467
Epoch 18/5000
41/41 - 1s - loss: 0.1446 - mae: 0.3665 - val_loss: 0.0870 - val_mae: 0.3483
Epoch 19/5000
41/41 - 1s - loss: 0.1439 - mae: 0.3640 - val_loss: 0.0755 - val_mae: 0.3046
Epoch 20/5000
41/41 - 1s - loss: 0.1428 - mae: 0.3616 - val_loss: 0.0844 - val_mae: 0.3400
Epoch 21/5000
41/41 - 1s - loss: 0.1422 - mae: 0.3627 - val_loss: 0.0796 - val_mae: 0.3239
Epoch 22/5000
41/41 - 1s - loss: 0.1413 - mae: 0.3575 - val_loss: 0.0804 - val_mae: 0.3254
Epoch 23/5000
41/41 - 1s - loss: 0.1417 - mae: 0.3611 - val_loss: 0.0708 - val_mae: 0.2776
Epoch 24/5000
41/41 - 1s - loss: 0.1391 - mae: 0.3543 - val_loss: 0.0899 - val_mae: 0.3546
Epoch 25/5000
41/41 - 1s - loss: 0.1408 - mae: 0.3583 - val_loss: 0.0937 - val_mae: 0.3680
Epoch 26/5000
41/41 - 1s - loss: 0.1385 - mae: 0.3524 - val_loss: 0.0879 - val_mae: 0.3491
Epoch 27/5000
41/41 - 1s - loss: 0.1402 - mae: 0.3564 - val_loss: 0.0685 - val_mae: 0.2629
Epoch 28/5000
41/41 - 1s - loss: 0.1376 - mae: 0.3501 - val_loss: 0.0752 - val_mae: 0.3044
Epoch 29/5000
41/41 - 1s - loss: 0.1365 - mae: 0.3480 - val_loss: 0.0792 - val_mae: 0.3180
Epoch 30/5000
41/41 - 1s - loss: 0.1362 - mae: 0.3464 - val_loss: 0.0748 - val_mae: 0.2999
Epoch 31/5000
41/41 - 1s - loss: 0.1367 - mae: 0.3496 - val_loss: 0.0766 - val_mae: 0.3041
Epoch 32/5000
41/41 - 1s - loss: 0.1352 - mae: 0.3442 - val_loss: 0.0762 - val_mae: 0.3028
Epoch 33/5000
41/41 - 1s - loss: 0.1394 - mae: 0.3566 - val_loss: 0.0883 - val_mae: 0.3544
Epoch 34/5000
41/41 - 1s - loss: 0.1396 - mae: 0.3549 - val_loss: 0.0700 - val_mae: 0.2620
Epoch 35/5000
41/41 - 1s - loss: 0.1387 - mae: 0.3544 - val_loss: 0.0810 - val_mae: 0.3303
Epoch 36/5000
41/41 - 1s - loss: 0.1382 - mae: 0.3494 - val_loss: 0.0729 - val_mae: 0.2896
Epoch 37/5000
41/41 - 1s - loss: 0.1354 - mae: 0.3464 - val_loss: 0.0704 - val_mae: 0.2699
Epoch 38/5000
41/41 - 1s - loss: 0.1341 - mae: 0.3407 - val_loss: 0.0699 - val_mae: 0.2717
Epoch 39/5000
41/41 - 1s - loss: 0.1337 - mae: 0.3405 - val_loss: 0.0715 - val_mae: 0.2795
Epoch 40/5000
41/41 - 1s - loss: 0.1353 - mae: 0.3454 - val_loss: 0.0717 - val_mae: 0.2830
Epoch 41/5000
41/41 - 1s - loss: 0.1411 - mae: 0.3562 - val_loss: 0.0985 - val_mae: 0.3785
Epoch 42/5000
41/41 - 1s - loss: 0.1416 - mae: 0.3571 - val_loss: 0.0803 - val_mae: 0.3102
Epoch 43/5000
41/41 - 1s - loss: 0.1328 - mae: 0.3385 - val_loss: 0.0770 - val_mae: 0.2956
Epoch 44/5000
41/41 - 1s - loss: 0.1316 - mae: 0.3348 - val_loss: 0.0738 - val_mae: 0.2784
Epoch 45/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3408 - val_loss: 0.0850 - val_mae: 0.3318
Epoch 46/5000
41/41 - 1s - loss: 0.1400 - mae: 0.3541 - val_loss: 0.0867 - val_mae: 0.3450
Epoch 47/5000
41/41 - 1s - loss: 0.1386 - mae: 0.3480 - val_loss: 0.0838 - val_mae: 0.3278
Epoch 48/5000
41/41 - 1s - loss: 0.1347 - mae: 0.3415 - val_loss: 0.0818 - val_mae: 0.3086
Epoch 49/5000
41/41 - 1s - loss: 0.1344 - mae: 0.3377 - val_loss: 0.0832 - val_mae: 0.3299
Epoch 50/5000
41/41 - 1s - loss: 0.1361 - mae: 0.3446 - val_loss: 0.0781 - val_mae: 0.2893
Epoch 51/5000
41/41 - 1s - loss: 0.1324 - mae: 0.3313 - val_loss: 0.0731 - val_mae: 0.2778
Epoch 52/5000
41/41 - 1s - loss: 0.1367 - mae: 0.3449 - val_loss: 0.0993 - val_mae: 0.3793
Epoch 53/5000
41/41 - 1s - loss: 0.1352 - mae: 0.3446 - val_loss: 0.0770 - val_mae: 0.2849
Epoch 54/5000
41/41 - 1s - loss: 0.1315 - mae: 0.3317 - val_loss: 0.0735 - val_mae: 0.2698
Epoch 55/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3296 - val_loss: 0.0735 - val_mae: 0.2671
Epoch 56/5000
41/41 - 1s - loss: 0.1326 - mae: 0.3321 - val_loss: 0.1049 - val_mae: 0.3758
Epoch 57/5000
41/41 - 1s - loss: 0.1324 - mae: 0.3346 - val_loss: 0.0781 - val_mae: 0.2896
Epoch 58/5000
41/41 - 1s - loss: 0.1313 - mae: 0.3336 - val_loss: 0.0837 - val_mae: 0.2983
Epoch 59/5000
41/41 - 1s - loss: 0.1290 - mae: 0.3250 - val_loss: 0.0811 - val_mae: 0.3026
Epoch 60/5000
41/41 - 1s - loss: 0.1284 - mae: 0.3227 - val_loss: 0.0724 - val_mae: 0.2670
Epoch 61/5000
41/41 - 1s - loss: 0.1334 - mae: 0.3328 - val_loss: 0.1014 - val_mae: 0.3808
Epoch 62/5000
41/41 - 1s - loss: 0.1339 - mae: 0.3392 - val_loss: 0.0793 - val_mae: 0.2936
Epoch 63/5000
41/41 - 1s - loss: 0.1288 - mae: 0.3231 - val_loss: 0.0777 - val_mae: 0.2950
Epoch 64/5000
41/41 - 1s - loss: 0.1303 - mae: 0.3311 - val_loss: 0.0837 - val_mae: 0.3038
Epoch 65/5000
41/41 - 1s - loss: 0.1283 - mae: 0.3228 - val_loss: 0.0831 - val_mae: 0.3187
Epoch 66/5000
41/41 - 1s - loss: 0.1328 - mae: 0.3348 - val_loss: 0.0845 - val_mae: 0.3112
Epoch 67/5000
41/41 - 1s - loss: 0.1288 - mae: 0.3234 - val_loss: 0.0777 - val_mae: 0.2902
Epoch 68/5000
41/41 - 1s - loss: 0.1332 - mae: 0.3369 - val_loss: 0.0807 - val_mae: 0.2965
Epoch 69/5000
41/41 - 1s - loss: 0.1277 - mae: 0.3202 - val_loss: 0.0808 - val_mae: 0.3005
Epoch 70/5000
41/41 - 1s - loss: 0.1311 - mae: 0.3308 - val_loss: 0.0743 - val_mae: 0.2792
Epoch 71/5000
41/41 - 1s - loss: 0.1299 - mae: 0.3296 - val_loss: 0.0783 - val_mae: 0.2774
Epoch 72/5000
41/41 - 1s - loss: 0.1276 - mae: 0.3204 - val_loss: 0.0815 - val_mae: 0.2977
Epoch 73/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3298 - val_loss: 0.0909 - val_mae: 0.3126
Epoch 74/5000
41/41 - 1s - loss: 0.1248 - mae: 0.3154 - val_loss: 0.0764 - val_mae: 0.2689
Epoch 75/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3194 - val_loss: 0.0794 - val_mae: 0.2857
Epoch 76/5000
41/41 - 1s - loss: 0.1265 - mae: 0.3174 - val_loss: 0.0758 - val_mae: 0.2823
Epoch 77/5000
41/41 - 1s - loss: 0.1324 - mae: 0.3332 - val_loss: 0.0924 - val_mae: 0.3165
Epoch 78/5000
41/41 - 1s - loss: 0.1253 - mae: 0.3164 - val_loss: 0.0749 - val_mae: 0.2646
Epoch 79/5000
41/41 - 1s - loss: 0.1339 - mae: 0.3406 - val_loss: 0.0848 - val_mae: 0.3036
Epoch 80/5000
41/41 - 1s - loss: 0.1245 - mae: 0.3161 - val_loss: 0.0784 - val_mae: 0.2703
Epoch 81/5000
41/41 - 1s - loss: 0.1249 - mae: 0.3163 - val_loss: 0.0793 - val_mae: 0.2852
Epoch 82/5000
41/41 - 1s - loss: 0.1257 - mae: 0.3149 - val_loss: 0.0753 - val_mae: 0.2778
Epoch 83/5000
41/41 - 1s - loss: 0.1371 - mae: 0.3467 - val_loss: 0.0849 - val_mae: 0.3199
Epoch 84/5000
41/41 - 1s - loss: 0.1263 - mae: 0.3227 - val_loss: 0.0769 - val_mae: 0.2863
Epoch 85/5000
41/41 - 1s - loss: 0.1283 - mae: 0.3277 - val_loss: 0.0881 - val_mae: 0.3085
Epoch 86/5000
41/41 - 1s - loss: 0.1240 - mae: 0.3140 - val_loss: 0.0797 - val_mae: 0.2869
Epoch 87/5000
41/41 - 1s - loss: 0.1272 - mae: 0.3212 - val_loss: 0.0812 - val_mae: 0.2994
Epoch 88/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3362 - val_loss: 0.0836 - val_mae: 0.2967
Epoch 89/5000
41/41 - 1s - loss: 0.1283 - mae: 0.3251 - val_loss: 0.0737 - val_mae: 0.2531
Epoch 90/5000
41/41 - 1s - loss: 0.1376 - mae: 0.3476 - val_loss: 0.1064 - val_mae: 0.3760
Epoch 91/5000
41/41 - 1s - loss: 0.1264 - mae: 0.3208 - val_loss: 0.0855 - val_mae: 0.2977
Epoch 92/5000
41/41 - 1s - loss: 0.1306 - mae: 0.3310 - val_loss: 0.0976 - val_mae: 0.3479
Epoch 93/5000
41/41 - 1s - loss: 0.1278 - mae: 0.3236 - val_loss: 0.1002 - val_mae: 0.3544
Epoch 94/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3120 - val_loss: 0.0787 - val_mae: 0.2666
Epoch 95/5000
41/41 - 1s - loss: 0.1290 - mae: 0.3258 - val_loss: 0.1048 - val_mae: 0.3565
Epoch 96/5000
41/41 - 1s - loss: 0.1275 - mae: 0.3249 - val_loss: 0.0891 - val_mae: 0.3006
Epoch 97/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3216 - val_loss: 0.0925 - val_mae: 0.3150
Epoch 98/5000
41/41 - 1s - loss: 0.1252 - mae: 0.3174 - val_loss: 0.1011 - val_mae: 0.3472
Epoch 99/5000
41/41 - 1s - loss: 0.1255 - mae: 0.3162 - val_loss: 0.0931 - val_mae: 0.3294
Epoch 100/5000
41/41 - 1s - loss: 0.1293 - mae: 0.3283 - val_loss: 0.1109 - val_mae: 0.3791
Epoch 101/5000
41/41 - 1s - loss: 0.1272 - mae: 0.3229 - val_loss: 0.1028 - val_mae: 0.3533
Epoch 102/5000
41/41 - 1s - loss: 0.1236 - mae: 0.3116 - val_loss: 0.0957 - val_mae: 0.3342
Epoch 103/5000
41/41 - 1s - loss: 0.1267 - mae: 0.3228 - val_loss: 0.1141 - val_mae: 0.3750
Epoch 104/5000
41/41 - 1s - loss: 0.1267 - mae: 0.3213 - val_loss: 0.1150 - val_mae: 0.3839
Epoch 105/5000
41/41 - 1s - loss: 0.1253 - mae: 0.3175 - val_loss: 0.1055 - val_mae: 0.3649
Epoch 106/5000
41/41 - 1s - loss: 0.1240 - mae: 0.3124 - val_loss: 0.1030 - val_mae: 0.3601
Epoch 107/5000
41/41 - 1s - loss: 0.1240 - mae: 0.3153 - val_loss: 0.0994 - val_mae: 0.3364
Epoch 108/5000
41/41 - 1s - loss: 0.1220 - mae: 0.3071 - val_loss: 0.0991 - val_mae: 0.3490
Epoch 109/5000
41/41 - 1s - loss: 0.1302 - mae: 0.3291 - val_loss: 0.1230 - val_mae: 0.4026
Epoch 110/5000
41/41 - 1s - loss: 0.1300 - mae: 0.3271 - val_loss: 0.1309 - val_mae: 0.4260
Epoch 111/5000
41/41 - 1s - loss: 0.1281 - mae: 0.3240 - val_loss: 0.1271 - val_mae: 0.4141
Epoch 112/5000
41/41 - 1s - loss: 0.1267 - mae: 0.3206 - val_loss: 0.1396 - val_mae: 0.4406
Epoch 113/5000
41/41 - 1s - loss: 0.1264 - mae: 0.3196 - val_loss: 0.1322 - val_mae: 0.4228
Epoch 114/5000
41/41 - 1s - loss: 0.1247 - mae: 0.3165 - val_loss: 0.1202 - val_mae: 0.3915
Epoch 115/5000
41/41 - 1s - loss: 0.1238 - mae: 0.3138 - val_loss: 0.1155 - val_mae: 0.3807
Epoch 116/5000
41/41 - 1s - loss: 0.1239 - mae: 0.3148 - val_loss: 0.1168 - val_mae: 0.3796
Epoch 117/5000
41/41 - 1s - loss: 0.1227 - mae: 0.3110 - val_loss: 0.1122 - val_mae: 0.3773
Epoch 118/5000
41/41 - 1s - loss: 0.1214 - mae: 0.3074 - val_loss: 0.1123 - val_mae: 0.3736
Epoch 119/5000
41/41 - 1s - loss: 0.1225 - mae: 0.3107 - val_loss: 0.1153 - val_mae: 0.3771
Epoch 120/5000
41/41 - 1s - loss: 0.1211 - mae: 0.3062 - val_loss: 0.1070 - val_mae: 0.3557
Epoch 121/5000
41/41 - 1s - loss: 0.1260 - mae: 0.3183 - val_loss: 0.1377 - val_mae: 0.4265
Epoch 122/5000
41/41 - 1s - loss: 0.1278 - mae: 0.3240 - val_loss: 0.1471 - val_mae: 0.4519
Epoch 123/5000
41/41 - 1s - loss: 0.1307 - mae: 0.3305 - val_loss: 0.1066 - val_mae: 0.3725
Epoch 124/5000
41/41 - 1s - loss: 0.1230 - mae: 0.3116 - val_loss: 0.1148 - val_mae: 0.3723
Epoch 125/5000
41/41 - 1s - loss: 0.1216 - mae: 0.3085 - val_loss: 0.1157 - val_mae: 0.3817
Epoch 126/5000
41/41 - 1s - loss: 0.1211 - mae: 0.3072 - val_loss: 0.1178 - val_mae: 0.3863
Epoch 127/5000
41/41 - 1s - loss: 0.1236 - mae: 0.3125 - val_loss: 0.1278 - val_mae: 0.4080
Epoch 128/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3149 - val_loss: 0.1489 - val_mae: 0.4576
Epoch 129/5000
41/41 - 1s - loss: 0.1278 - mae: 0.3230 - val_loss: 0.1404 - val_mae: 0.4410
Epoch 130/5000
41/41 - 1s - loss: 0.1269 - mae: 0.3218 - val_loss: 0.1277 - val_mae: 0.4143
Epoch 131/5000
41/41 - 1s - loss: 0.1228 - mae: 0.3118 - val_loss: 0.1327 - val_mae: 0.4198
Epoch 132/5000
41/41 - 1s - loss: 0.1224 - mae: 0.3113 - val_loss: 0.1336 - val_mae: 0.4200
Epoch 133/5000
41/41 - 1s - loss: 0.1231 - mae: 0.3132 - val_loss: 0.1353 - val_mae: 0.4178
Epoch 134/5000
41/41 - 1s - loss: 0.1212 - mae: 0.3071 - val_loss: 0.1362 - val_mae: 0.4206
Epoch 135/5000
41/41 - 1s - loss: 0.1239 - mae: 0.3144 - val_loss: 0.1487 - val_mae: 0.4501
Epoch 136/5000
41/41 - 1s - loss: 0.1251 - mae: 0.3180 - val_loss: 0.1261 - val_mae: 0.4104
Epoch 137/5000
41/41 - 1s - loss: 0.1208 - mae: 0.3071 - val_loss: 0.1162 - val_mae: 0.3799
Epoch 138/5000
41/41 - 1s - loss: 0.1216 - mae: 0.3072 - val_loss: 0.1273 - val_mae: 0.4043
Epoch 139/5000
41/41 - 1s - loss: 0.1200 - mae: 0.3047 - val_loss: 0.1390 - val_mae: 0.4287
Epoch 140/5000
41/41 - 1s - loss: 0.1207 - mae: 0.3063 - val_loss: 0.1344 - val_mae: 0.4180
Epoch 141/5000
41/41 - 1s - loss: 0.1197 - mae: 0.3024 - val_loss: 0.1442 - val_mae: 0.4431
Epoch 142/5000
41/41 - 1s - loss: 0.1232 - mae: 0.3113 - val_loss: 0.1458 - val_mae: 0.4575
Epoch 143/5000
41/41 - 1s - loss: 0.1257 - mae: 0.3187 - val_loss: 0.1232 - val_mae: 0.3994
Epoch 144/5000
41/41 - 1s - loss: 0.1235 - mae: 0.3130 - val_loss: 0.1225 - val_mae: 0.4123
Epoch 145/5000
41/41 - 1s - loss: 0.1277 - mae: 0.3250 - val_loss: 0.1013 - val_mae: 0.3441
Epoch 146/5000
41/41 - 1s - loss: 0.1176 - mae: 0.2979 - val_loss: 0.1368 - val_mae: 0.4465
Epoch 147/5000
41/41 - 1s - loss: 0.1230 - mae: 0.3126 - val_loss: 0.1089 - val_mae: 0.3630
Epoch 148/5000
41/41 - 1s - loss: 0.1170 - mae: 0.2949 - val_loss: 0.1264 - val_mae: 0.4182
Epoch 149/5000
41/41 - 1s - loss: 0.1194 - mae: 0.3033 - val_loss: 0.1324 - val_mae: 0.4227
Epoch 150/5000
41/41 - 1s - loss: 0.1198 - mae: 0.3041 - val_loss: 0.1288 - val_mae: 0.4258
Epoch 151/5000
41/41 - 1s - loss: 0.1195 - mae: 0.3025 - val_loss: 0.1500 - val_mae: 0.4634
Epoch 152/5000
41/41 - 1s - loss: 0.1253 - mae: 0.3162 - val_loss: 0.1402 - val_mae: 0.4377
Epoch 153/5000
41/41 - 1s - loss: 0.1262 - mae: 0.3210 - val_loss: 0.1137 - val_mae: 0.3760
Epoch 154/5000
41/41 - 1s - loss: 0.1202 - mae: 0.3053 - val_loss: 0.1411 - val_mae: 0.4436
Epoch 155/5000
41/41 - 1s - loss: 0.1218 - mae: 0.3100 - val_loss: 0.1365 - val_mae: 0.4325
Epoch 156/5000
41/41 - 1s - loss: 0.1215 - mae: 0.3069 - val_loss: 0.1302 - val_mae: 0.4130
Epoch 157/5000
41/41 - 1s - loss: 0.1188 - mae: 0.3019 - val_loss: 0.1294 - val_mae: 0.4158
Epoch 158/5000
41/41 - 1s - loss: 0.1180 - mae: 0.2990 - val_loss: 0.1417 - val_mae: 0.4341
Epoch 159/5000
41/41 - 1s - loss: 0.1198 - mae: 0.3031 - val_loss: 0.1490 - val_mae: 0.4527
Epoch 160/5000
41/41 - 1s - loss: 0.1216 - mae: 0.3089 - val_loss: 0.1472 - val_mae: 0.4436
Epoch 161/5000
41/41 - 1s - loss: 0.1220 - mae: 0.3085 - val_loss: 0.1386 - val_mae: 0.4246
Epoch 162/5000
41/41 - 1s - loss: 0.1196 - mae: 0.3029 - val_loss: 0.1458 - val_mae: 0.4485
Epoch 163/5000
41/41 - 1s - loss: 0.1221 - mae: 0.3100 - val_loss: 0.1363 - val_mae: 0.4274
Epoch 164/5000
41/41 - 1s - loss: 0.1249 - mae: 0.3180 - val_loss: 0.1179 - val_mae: 0.3858
Epoch 165/5000
41/41 - 1s - loss: 0.1162 - mae: 0.2958 - val_loss: 0.1251 - val_mae: 0.4025
Epoch 166/5000
41/41 - 1s - loss: 0.1182 - mae: 0.3000 - val_loss: 0.1452 - val_mae: 0.4556
Epoch 167/5000
41/41 - 1s - loss: 0.1232 - mae: 0.3117 - val_loss: 0.1196 - val_mae: 0.4046
Epoch 168/5000
41/41 - 1s - loss: 0.1250 - mae: 0.3152 - val_loss: 0.1187 - val_mae: 0.3877
Epoch 169/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3183 - val_loss: 0.0811 - val_mae: 0.3157
Epoch 170/5000
41/41 - 1s - loss: 0.1246 - mae: 0.3156 - val_loss: 0.0998 - val_mae: 0.3653
Epoch 171/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3160 - val_loss: 0.1170 - val_mae: 0.3819
Epoch 172/5000
41/41 - 1s - loss: 0.1212 - mae: 0.3058 - val_loss: 0.1108 - val_mae: 0.3758
Epoch 173/5000
41/41 - 1s - loss: 0.1227 - mae: 0.3126 - val_loss: 0.1177 - val_mae: 0.3891
Epoch 174/5000
41/41 - 1s - loss: 0.1230 - mae: 0.3095 - val_loss: 0.0867 - val_mae: 0.3229
Epoch 175/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3364 - val_loss: 0.1144 - val_mae: 0.4079
Epoch 176/5000
41/41 - 1s - loss: 0.1234 - mae: 0.3140 - val_loss: 0.1047 - val_mae: 0.3607
Epoch 177/5000
41/41 - 1s - loss: 0.1232 - mae: 0.3124 - val_loss: 0.0976 - val_mae: 0.3443
Epoch 178/5000
41/41 - 1s - loss: 0.1199 - mae: 0.3049 - val_loss: 0.1053 - val_mae: 0.3551
Epoch 179/5000
41/41 - 1s - loss: 0.1198 - mae: 0.3046 - val_loss: 0.1156 - val_mae: 0.3758
Epoch 180/5000
41/41 - 1s - loss: 0.1202 - mae: 0.3050 - val_loss: 0.1088 - val_mae: 0.3659
Epoch 181/5000
41/41 - 1s - loss: 0.1194 - mae: 0.3013 - val_loss: 0.1129 - val_mae: 0.3696
Epoch 182/5000
41/41 - 1s - loss: 0.1198 - mae: 0.3032 - val_loss: 0.0949 - val_mae: 0.3192
Epoch 183/5000
41/41 - 1s - loss: 0.1202 - mae: 0.3039 - val_loss: 0.1061 - val_mae: 0.3497
Epoch 184/5000
41/41 - 1s - loss: 0.1186 - mae: 0.3006 - val_loss: 0.1138 - val_mae: 0.3603
Epoch 185/5000
41/41 - 1s - loss: 0.1164 - mae: 0.2951 - val_loss: 0.1314 - val_mae: 0.4004
Epoch 186/5000
41/41 - 1s - loss: 0.1177 - mae: 0.2996 - val_loss: 0.1208 - val_mae: 0.3874
Epoch 187/5000
41/41 - 1s - loss: 0.1185 - mae: 0.3009 - val_loss: 0.1277 - val_mae: 0.3979
Epoch 188/5000
41/41 - 1s - loss: 0.1175 - mae: 0.3000 - val_loss: 0.1411 - val_mae: 0.4130
Epoch 189/5000
41/41 - 1s - loss: 0.1162 - mae: 0.2964 - val_loss: 0.1211 - val_mae: 0.3860
Epoch 190/5000
41/41 - 1s - loss: 0.1138 - mae: 0.2913 - val_loss: 0.1413 - val_mae: 0.4129
Restoring model weights from the end of the best epoch.
Epoch 00190: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_7..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_39"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_7 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_7 (PartitionP (None, None, 64)     0           message_passing_7[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_7[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_7 (Masking)             (None, None, 64)     0           partition_padding_7[0][0]        
                                                                 partition_padding_7[1][0]        
__________________________________________________________________________________________________
transformer_encoder_7 (Transfor (None, None, 64)     199040      masking_7[0][0]                  
                                                                 masking_7[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_7 (Glo (None, 64)           0           transformer_encoder_7[0][0]      
                                                                 transformer_encoder_7[1][0]      
__________________________________________________________________________________________________
dense_123 (Dense)               (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_121 (Dense)               (None, 512)          33280       global_average_pooling1d_7[0][0] 
                                                                 global_average_pooling1d_7[1][0] 
__________________________________________________________________________________________________
dense_124 (Dense)               (None, 10)           110         dense_123[0][0]                  
__________________________________________________________________________________________________
dense_122 (Dense)               (None, 450)          230850      dense_121[0][0]                  
                                                                 dense_121[1][0]                  
__________________________________________________________________________________________________
dense_125 (Dense)               (None, 5)            55          dense_124[0][0]                  
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 905)          0           dense_122[0][0]                  
                                                                 dense_122[1][0]                  
                                                                 dense_125[0][0]                  
__________________________________________________________________________________________________
dense_126 (Dense)               (None, 700)          634200      concatenate_7[0][0]              
__________________________________________________________________________________________________
dense_130 (Dense)               (None, 560)          392560      dense_126[0][0]                  
__________________________________________________________________________________________________
dense_131 (Dense)               (None, 373)          209253      dense_130[0][0]                  
__________________________________________________________________________________________________
dense_132 (Dense)               (None, 187)          69938       dense_131[0][0]                  
__________________________________________________________________________________________________
dense_133 (Dense)               (None, 1)            188         dense_132[0][0]                  
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
41/41 - 7s - loss: 0.1430 - mae: 0.3515 - val_loss: 0.0768 - val_mae: 0.2745
Epoch 2/5000
41/41 - 1s - loss: 0.1201 - mae: 0.3083 - val_loss: 0.0879 - val_mae: 0.3083
Epoch 3/5000
41/41 - 1s - loss: 0.1149 - mae: 0.2954 - val_loss: 0.1040 - val_mae: 0.3531
Epoch 4/5000
41/41 - 1s - loss: 0.1121 - mae: 0.2868 - val_loss: 0.1065 - val_mae: 0.3565
Epoch 5/5000
41/41 - 1s - loss: 0.1090 - mae: 0.2797 - val_loss: 0.1127 - val_mae: 0.3689
Epoch 6/5000
41/41 - 1s - loss: 0.1067 - mae: 0.2743 - val_loss: 0.1204 - val_mae: 0.3828
Epoch 7/5000
41/41 - 1s - loss: 0.1053 - mae: 0.2706 - val_loss: 0.1250 - val_mae: 0.3909
Epoch 8/5000
41/41 - 1s - loss: 0.1063 - mae: 0.2718 - val_loss: 0.1022 - val_mae: 0.3408
Epoch 9/5000
41/41 - 1s - loss: 0.1075 - mae: 0.2771 - val_loss: 0.0796 - val_mae: 0.2869
Epoch 10/5000
41/41 - 1s - loss: 0.0996 - mae: 0.2604 - val_loss: 0.1017 - val_mae: 0.3384
Epoch 11/5000
41/41 - 1s - loss: 0.0982 - mae: 0.2565 - val_loss: 0.1232 - val_mae: 0.3812
Epoch 12/5000
41/41 - 1s - loss: 0.0961 - mae: 0.2520 - val_loss: 0.1266 - val_mae: 0.3929
Epoch 13/5000
41/41 - 1s - loss: 0.0958 - mae: 0.2507 - val_loss: 0.1384 - val_mae: 0.4113
Epoch 14/5000
41/41 - 1s - loss: 0.0981 - mae: 0.2556 - val_loss: 0.1225 - val_mae: 0.3835
Epoch 15/5000
41/41 - 1s - loss: 0.1026 - mae: 0.2659 - val_loss: 0.0843 - val_mae: 0.2894
Epoch 16/5000
41/41 - 1s - loss: 0.0960 - mae: 0.2527 - val_loss: 0.0960 - val_mae: 0.3251
Epoch 17/5000
41/41 - 1s - loss: 0.0903 - mae: 0.2387 - val_loss: 0.1229 - val_mae: 0.3776
Epoch 18/5000
41/41 - 1s - loss: 0.0905 - mae: 0.2376 - val_loss: 0.1352 - val_mae: 0.3998
Epoch 19/5000
41/41 - 1s - loss: 0.0925 - mae: 0.2432 - val_loss: 0.1272 - val_mae: 0.3774
Epoch 20/5000
41/41 - 1s - loss: 0.0955 - mae: 0.2515 - val_loss: 0.0872 - val_mae: 0.2897
Epoch 21/5000
41/41 - 1s - loss: 0.0924 - mae: 0.2453 - val_loss: 0.0800 - val_mae: 0.2773
Epoch 22/5000
41/41 - 1s - loss: 0.0857 - mae: 0.2295 - val_loss: 0.0945 - val_mae: 0.3057
Epoch 23/5000
41/41 - 1s - loss: 0.0836 - mae: 0.2228 - val_loss: 0.1071 - val_mae: 0.3319
Epoch 24/5000
41/41 - 1s - loss: 0.0812 - mae: 0.2172 - val_loss: 0.1068 - val_mae: 0.3287
Epoch 25/5000
41/41 - 1s - loss: 0.0800 - mae: 0.2154 - val_loss: 0.1084 - val_mae: 0.3325
Epoch 26/5000
41/41 - 1s - loss: 0.0783 - mae: 0.2131 - val_loss: 0.1122 - val_mae: 0.3382
Epoch 27/5000
41/41 - 1s - loss: 0.0767 - mae: 0.2110 - val_loss: 0.1142 - val_mae: 0.3330
Epoch 28/5000
41/41 - 1s - loss: 0.0758 - mae: 0.2088 - val_loss: 0.1309 - val_mae: 0.3646
Epoch 29/5000
41/41 - 1s - loss: 0.0754 - mae: 0.2076 - val_loss: 0.1240 - val_mae: 0.3444
Epoch 30/5000
41/41 - 1s - loss: 0.0752 - mae: 0.2092 - val_loss: 0.1123 - val_mae: 0.3158
Epoch 31/5000
41/41 - 1s - loss: 0.0768 - mae: 0.2170 - val_loss: 0.1094 - val_mae: 0.3127
Epoch 32/5000
41/41 - 1s - loss: 0.0817 - mae: 0.2267 - val_loss: 0.1383 - val_mae: 0.3918
Epoch 33/5000
41/41 - 1s - loss: 0.0818 - mae: 0.2219 - val_loss: 0.1366 - val_mae: 0.3799
Epoch 34/5000
41/41 - 1s - loss: 0.0883 - mae: 0.2391 - val_loss: 0.1056 - val_mae: 0.3180
Epoch 35/5000
41/41 - 1s - loss: 0.0868 - mae: 0.2366 - val_loss: 0.0820 - val_mae: 0.2570
Epoch 36/5000
41/41 - 1s - loss: 0.0776 - mae: 0.2178 - val_loss: 0.0972 - val_mae: 0.2885
Epoch 37/5000
41/41 - 1s - loss: 0.0714 - mae: 0.2004 - val_loss: 0.1207 - val_mae: 0.3356
Epoch 38/5000
41/41 - 1s - loss: 0.0691 - mae: 0.1936 - val_loss: 0.1290 - val_mae: 0.3396
Epoch 39/5000
41/41 - 1s - loss: 0.0689 - mae: 0.1936 - val_loss: 0.1263 - val_mae: 0.3361
Epoch 40/5000
41/41 - 1s - loss: 0.0703 - mae: 0.1978 - val_loss: 0.1076 - val_mae: 0.3054
Epoch 41/5000
41/41 - 1s - loss: 0.0759 - mae: 0.2161 - val_loss: 0.0738 - val_mae: 0.2292
Epoch 42/5000
41/41 - 1s - loss: 0.0747 - mae: 0.2148 - val_loss: 0.0863 - val_mae: 0.2652
Epoch 43/5000
41/41 - 1s - loss: 0.0735 - mae: 0.2111 - val_loss: 0.1290 - val_mae: 0.3496
Epoch 44/5000
41/41 - 1s - loss: 0.0661 - mae: 0.1901 - val_loss: 0.1128 - val_mae: 0.3125
Epoch 45/5000
41/41 - 1s - loss: 0.0649 - mae: 0.1888 - val_loss: 0.0928 - val_mae: 0.2782
Epoch 46/5000
41/41 - 1s - loss: 0.0633 - mae: 0.1871 - val_loss: 0.0997 - val_mae: 0.2926
Epoch 47/5000
41/41 - 1s - loss: 0.0617 - mae: 0.1826 - val_loss: 0.1080 - val_mae: 0.3052
Epoch 48/5000
41/41 - 1s - loss: 0.0607 - mae: 0.1802 - val_loss: 0.1042 - val_mae: 0.2937
Epoch 49/5000
41/41 - 1s - loss: 0.0598 - mae: 0.1803 - val_loss: 0.1167 - val_mae: 0.3112
Epoch 50/5000
41/41 - 1s - loss: 0.0603 - mae: 0.1833 - val_loss: 0.1300 - val_mae: 0.3264
Epoch 51/5000
41/41 - 1s - loss: 0.0622 - mae: 0.1888 - val_loss: 0.1334 - val_mae: 0.3316
Epoch 52/5000
41/41 - 1s - loss: 0.0679 - mae: 0.2003 - val_loss: 0.1219 - val_mae: 0.3283
Epoch 53/5000
41/41 - 1s - loss: 0.0808 - mae: 0.2297 - val_loss: 0.1183 - val_mae: 0.3229
Epoch 54/5000
41/41 - 1s - loss: 0.0635 - mae: 0.1936 - val_loss: 0.1302 - val_mae: 0.3532
Epoch 55/5000
41/41 - 1s - loss: 0.0682 - mae: 0.2049 - val_loss: 0.1616 - val_mae: 0.4193
Epoch 56/5000
41/41 - 1s - loss: 0.0744 - mae: 0.2189 - val_loss: 0.1547 - val_mae: 0.4036
Epoch 57/5000
41/41 - 1s - loss: 0.0822 - mae: 0.2413 - val_loss: 0.1035 - val_mae: 0.2959
Epoch 58/5000
41/41 - 1s - loss: 0.0692 - mae: 0.2110 - val_loss: 0.1197 - val_mae: 0.3282
Epoch 59/5000
41/41 - 1s - loss: 0.0579 - mae: 0.1831 - val_loss: 0.1242 - val_mae: 0.3351
Epoch 60/5000
41/41 - 1s - loss: 0.0555 - mae: 0.1791 - val_loss: 0.1437 - val_mae: 0.3694
Epoch 61/5000
41/41 - 1s - loss: 0.0543 - mae: 0.1763 - val_loss: 0.1388 - val_mae: 0.3596
Epoch 62/5000
41/41 - 1s - loss: 0.0581 - mae: 0.1884 - val_loss: 0.1543 - val_mae: 0.3832
Epoch 63/5000
41/41 - 1s - loss: 0.0535 - mae: 0.1758 - val_loss: 0.1554 - val_mae: 0.4011
Epoch 64/5000
41/41 - 1s - loss: 0.0565 - mae: 0.1846 - val_loss: 0.1048 - val_mae: 0.2968
Epoch 65/5000
41/41 - 1s - loss: 0.0640 - mae: 0.2031 - val_loss: 0.1038 - val_mae: 0.2903
Epoch 66/5000
41/41 - 1s - loss: 0.0579 - mae: 0.1871 - val_loss: 0.0901 - val_mae: 0.2619
Epoch 67/5000
41/41 - 1s - loss: 0.0513 - mae: 0.1737 - val_loss: 0.0848 - val_mae: 0.2472
Epoch 68/5000
41/41 - 1s - loss: 0.0520 - mae: 0.1777 - val_loss: 0.0849 - val_mae: 0.2600
Epoch 69/5000
41/41 - 1s - loss: 0.0588 - mae: 0.1899 - val_loss: 0.0813 - val_mae: 0.2544
Epoch 70/5000
41/41 - 1s - loss: 0.0531 - mae: 0.1788 - val_loss: 0.0957 - val_mae: 0.2848
Epoch 71/5000
41/41 - 1s - loss: 0.0549 - mae: 0.1829 - val_loss: 0.1199 - val_mae: 0.3383
Epoch 72/5000
41/41 - 1s - loss: 0.0610 - mae: 0.1992 - val_loss: 0.1438 - val_mae: 0.3930
Epoch 73/5000
41/41 - 1s - loss: 0.0632 - mae: 0.2034 - val_loss: 0.0916 - val_mae: 0.2848
Epoch 74/5000
41/41 - 1s - loss: 0.0551 - mae: 0.1860 - val_loss: 0.0955 - val_mae: 0.2768
Epoch 75/5000
41/41 - 1s - loss: 0.0543 - mae: 0.1831 - val_loss: 0.1022 - val_mae: 0.2747
Epoch 76/5000
41/41 - 1s - loss: 0.0493 - mae: 0.1702 - val_loss: 0.0818 - val_mae: 0.2345
Epoch 77/5000
41/41 - 1s - loss: 0.0475 - mae: 0.1671 - val_loss: 0.0783 - val_mae: 0.2300
Epoch 78/5000
41/41 - 1s - loss: 0.0588 - mae: 0.1888 - val_loss: 0.0911 - val_mae: 0.2551
Epoch 79/5000
41/41 - 1s - loss: 0.0652 - mae: 0.2046 - val_loss: 0.0930 - val_mae: 0.3129
Epoch 80/5000
41/41 - 1s - loss: 0.0612 - mae: 0.2035 - val_loss: 0.0982 - val_mae: 0.2814
Epoch 81/5000
41/41 - 1s - loss: 0.0523 - mae: 0.1820 - val_loss: 0.0851 - val_mae: 0.2470
Epoch 82/5000
41/41 - 1s - loss: 0.0445 - mae: 0.1628 - val_loss: 0.0889 - val_mae: 0.2423
Epoch 83/5000
41/41 - 1s - loss: 0.0535 - mae: 0.1818 - val_loss: 0.1446 - val_mae: 0.3536
Epoch 84/5000
41/41 - 1s - loss: 0.0550 - mae: 0.1844 - val_loss: 0.1034 - val_mae: 0.2897
Epoch 85/5000
41/41 - 1s - loss: 0.0512 - mae: 0.1816 - val_loss: 0.0936 - val_mae: 0.2574
Epoch 86/5000
41/41 - 1s - loss: 0.0519 - mae: 0.1817 - val_loss: 0.0906 - val_mae: 0.2438
Epoch 87/5000
41/41 - 1s - loss: 0.0487 - mae: 0.1701 - val_loss: 0.0805 - val_mae: 0.2345
Epoch 88/5000
41/41 - 1s - loss: 0.0611 - mae: 0.1983 - val_loss: 0.0757 - val_mae: 0.2469
Epoch 89/5000
41/41 - 1s - loss: 0.0554 - mae: 0.1909 - val_loss: 0.0839 - val_mae: 0.2433
Epoch 90/5000
41/41 - 1s - loss: 0.0448 - mae: 0.1654 - val_loss: 0.0896 - val_mae: 0.2445
Epoch 91/5000
41/41 - 1s - loss: 0.0465 - mae: 0.1664 - val_loss: 0.0908 - val_mae: 0.2597
Epoch 92/5000
41/41 - 1s - loss: 0.0450 - mae: 0.1642 - val_loss: 0.0905 - val_mae: 0.2481
Epoch 93/5000
41/41 - 1s - loss: 0.0410 - mae: 0.1547 - val_loss: 0.0874 - val_mae: 0.2417
Epoch 94/5000
41/41 - 1s - loss: 0.0390 - mae: 0.1490 - val_loss: 0.0882 - val_mae: 0.2450
Epoch 95/5000
41/41 - 1s - loss: 0.0398 - mae: 0.1482 - val_loss: 0.0905 - val_mae: 0.2493
Epoch 96/5000
41/41 - 1s - loss: 0.0380 - mae: 0.1448 - val_loss: 0.0913 - val_mae: 0.2535
Epoch 97/5000
41/41 - 1s - loss: 0.0397 - mae: 0.1475 - val_loss: 0.0897 - val_mae: 0.2467
Epoch 98/5000
41/41 - 1s - loss: 0.0424 - mae: 0.1545 - val_loss: 0.0743 - val_mae: 0.2242
Epoch 99/5000
41/41 - 1s - loss: 0.0421 - mae: 0.1579 - val_loss: 0.0803 - val_mae: 0.2276
Epoch 100/5000
41/41 - 1s - loss: 0.0453 - mae: 0.1641 - val_loss: 0.0750 - val_mae: 0.2241
Epoch 101/5000
41/41 - 1s - loss: 0.0468 - mae: 0.1698 - val_loss: 0.0763 - val_mae: 0.2405
Epoch 102/5000
41/41 - 1s - loss: 0.0434 - mae: 0.1621 - val_loss: 0.0756 - val_mae: 0.2234
Epoch 103/5000
41/41 - 1s - loss: 0.0398 - mae: 0.1528 - val_loss: 0.0743 - val_mae: 0.2188
Epoch 104/5000
41/41 - 1s - loss: 0.0374 - mae: 0.1485 - val_loss: 0.0746 - val_mae: 0.2223
Epoch 105/5000
41/41 - 1s - loss: 0.0408 - mae: 0.1575 - val_loss: 0.0812 - val_mae: 0.2380
Epoch 106/5000
41/41 - 1s - loss: 0.0391 - mae: 0.1515 - val_loss: 0.0860 - val_mae: 0.2404
Epoch 107/5000
41/41 - 1s - loss: 0.0385 - mae: 0.1499 - val_loss: 0.0756 - val_mae: 0.2234
Epoch 108/5000
41/41 - 1s - loss: 0.0376 - mae: 0.1480 - val_loss: 0.0768 - val_mae: 0.2249
Epoch 109/5000
41/41 - 1s - loss: 0.0369 - mae: 0.1476 - val_loss: 0.0726 - val_mae: 0.2156
Epoch 110/5000
41/41 - 1s - loss: 0.0406 - mae: 0.1559 - val_loss: 0.0730 - val_mae: 0.2208
Epoch 111/5000
41/41 - 1s - loss: 0.0398 - mae: 0.1562 - val_loss: 0.0827 - val_mae: 0.2364
Epoch 112/5000
41/41 - 1s - loss: 0.0423 - mae: 0.1635 - val_loss: 0.0738 - val_mae: 0.2236
Epoch 113/5000
41/41 - 1s - loss: 0.0426 - mae: 0.1612 - val_loss: 0.0735 - val_mae: 0.2149
Epoch 114/5000
41/41 - 1s - loss: 0.0414 - mae: 0.1594 - val_loss: 0.0744 - val_mae: 0.2208
Epoch 115/5000
41/41 - 1s - loss: 0.0453 - mae: 0.1675 - val_loss: 0.0749 - val_mae: 0.2223
Epoch 116/5000
41/41 - 1s - loss: 0.0448 - mae: 0.1708 - val_loss: 0.0750 - val_mae: 0.2202
Epoch 117/5000
41/41 - 1s - loss: 0.0391 - mae: 0.1578 - val_loss: 0.0776 - val_mae: 0.2303
Epoch 118/5000
41/41 - 1s - loss: 0.0377 - mae: 0.1548 - val_loss: 0.0732 - val_mae: 0.2183
Epoch 119/5000
41/41 - 1s - loss: 0.0385 - mae: 0.1548 - val_loss: 0.0759 - val_mae: 0.2239
Epoch 120/5000
41/41 - 1s - loss: 0.0439 - mae: 0.1713 - val_loss: 0.0892 - val_mae: 0.2519
Epoch 121/5000
41/41 - 1s - loss: 0.0520 - mae: 0.1828 - val_loss: 0.0822 - val_mae: 0.2452
Epoch 122/5000
41/41 - 1s - loss: 0.0400 - mae: 0.1532 - val_loss: 0.0794 - val_mae: 0.2356
Epoch 123/5000
41/41 - 1s - loss: 0.0413 - mae: 0.1608 - val_loss: 0.1174 - val_mae: 0.2950
Epoch 124/5000
41/41 - 1s - loss: 0.0528 - mae: 0.1816 - val_loss: 0.1124 - val_mae: 0.3037
Epoch 125/5000
41/41 - 1s - loss: 0.0391 - mae: 0.1522 - val_loss: 0.1084 - val_mae: 0.2869
Epoch 126/5000
41/41 - 1s - loss: 0.0378 - mae: 0.1506 - val_loss: 0.1055 - val_mae: 0.2808
Epoch 127/5000
41/41 - 1s - loss: 0.0362 - mae: 0.1464 - val_loss: 0.1183 - val_mae: 0.3055
Epoch 128/5000
41/41 - 1s - loss: 0.0400 - mae: 0.1589 - val_loss: 0.1075 - val_mae: 0.2827
Epoch 129/5000
41/41 - 1s - loss: 0.0439 - mae: 0.1663 - val_loss: 0.0910 - val_mae: 0.2561
Epoch 130/5000
41/41 - 1s - loss: 0.0407 - mae: 0.1542 - val_loss: 0.1221 - val_mae: 0.3207
Epoch 131/5000
41/41 - 1s - loss: 0.0404 - mae: 0.1590 - val_loss: 0.1360 - val_mae: 0.3301
Epoch 132/5000
41/41 - 1s - loss: 0.0440 - mae: 0.1669 - val_loss: 0.1513 - val_mae: 0.3460
Epoch 133/5000
41/41 - 1s - loss: 0.0333 - mae: 0.1387 - val_loss: 0.1721 - val_mae: 0.3855
Epoch 134/5000
41/41 - 1s - loss: 0.0468 - mae: 0.1707 - val_loss: 0.1668 - val_mae: 0.3868
Epoch 135/5000
41/41 - 1s - loss: 0.0358 - mae: 0.1458 - val_loss: 0.1152 - val_mae: 0.3040
Epoch 136/5000
41/41 - 1s - loss: 0.0372 - mae: 0.1474 - val_loss: 0.1370 - val_mae: 0.3407
Epoch 137/5000
41/41 - 1s - loss: 0.0315 - mae: 0.1316 - val_loss: 0.1049 - val_mae: 0.2935
Epoch 138/5000
41/41 - 1s - loss: 0.0352 - mae: 0.1424 - val_loss: 0.1016 - val_mae: 0.2884
Epoch 139/5000
41/41 - 1s - loss: 0.0319 - mae: 0.1339 - val_loss: 0.0834 - val_mae: 0.2578
Epoch 140/5000
41/41 - 1s - loss: 0.0314 - mae: 0.1333 - val_loss: 0.0835 - val_mae: 0.2554
Epoch 141/5000
41/41 - 1s - loss: 0.0279 - mae: 0.1230 - val_loss: 0.0879 - val_mae: 0.2519
Epoch 142/5000
41/41 - 1s - loss: 0.0280 - mae: 0.1217 - val_loss: 0.0974 - val_mae: 0.2708
Epoch 143/5000
41/41 - 1s - loss: 0.0280 - mae: 0.1213 - val_loss: 0.0827 - val_mae: 0.2518
Epoch 144/5000
41/41 - 1s - loss: 0.0260 - mae: 0.1162 - val_loss: 0.0839 - val_mae: 0.2429
Epoch 145/5000
41/41 - 1s - loss: 0.0240 - mae: 0.1114 - val_loss: 0.0814 - val_mae: 0.2416
Epoch 146/5000
41/41 - 1s - loss: 0.0249 - mae: 0.1148 - val_loss: 0.1014 - val_mae: 0.2736
Epoch 147/5000
41/41 - 1s - loss: 0.0289 - mae: 0.1253 - val_loss: 0.0869 - val_mae: 0.2520
Epoch 148/5000
41/41 - 1s - loss: 0.0266 - mae: 0.1173 - val_loss: 0.0827 - val_mae: 0.2415
Epoch 149/5000
41/41 - 1s - loss: 0.0312 - mae: 0.1305 - val_loss: 0.1076 - val_mae: 0.2889
Epoch 150/5000
41/41 - 1s - loss: 0.0319 - mae: 0.1347 - val_loss: 0.1084 - val_mae: 0.2862
Epoch 151/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1141 - val_loss: 0.0993 - val_mae: 0.2717
Epoch 152/5000
41/41 - 1s - loss: 0.0254 - mae: 0.1161 - val_loss: 0.1187 - val_mae: 0.3063
Epoch 153/5000
41/41 - 1s - loss: 0.0293 - mae: 0.1285 - val_loss: 0.1284 - val_mae: 0.3165
Epoch 154/5000
41/41 - 1s - loss: 0.0235 - mae: 0.1104 - val_loss: 0.1512 - val_mae: 0.3559
Epoch 155/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1139 - val_loss: 0.1344 - val_mae: 0.3260
Epoch 156/5000
41/41 - 1s - loss: 0.0249 - mae: 0.1149 - val_loss: 0.1333 - val_mae: 0.3336
Epoch 157/5000
41/41 - 1s - loss: 0.0235 - mae: 0.1086 - val_loss: 0.1608 - val_mae: 0.3722
Epoch 158/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1157 - val_loss: 0.1514 - val_mae: 0.3602
Epoch 159/5000
41/41 - 1s - loss: 0.0262 - mae: 0.1191 - val_loss: 0.1509 - val_mae: 0.3552
Epoch 160/5000
41/41 - 1s - loss: 0.0274 - mae: 0.1199 - val_loss: 0.1886 - val_mae: 0.4255
Epoch 161/5000
41/41 - 1s - loss: 0.0312 - mae: 0.1331 - val_loss: 0.1085 - val_mae: 0.3162
Epoch 162/5000
41/41 - 1s - loss: 0.0331 - mae: 0.1380 - val_loss: 0.1353 - val_mae: 0.3371
Epoch 163/5000
41/41 - 1s - loss: 0.0357 - mae: 0.1378 - val_loss: 0.0696 - val_mae: 0.2422
Epoch 164/5000
41/41 - 1s - loss: 0.0413 - mae: 0.1609 - val_loss: 0.0663 - val_mae: 0.2169
Epoch 165/5000
41/41 - 1s - loss: 0.0329 - mae: 0.1417 - val_loss: 0.0725 - val_mae: 0.2283
Epoch 166/5000
41/41 - 1s - loss: 0.0301 - mae: 0.1284 - val_loss: 0.0690 - val_mae: 0.2121
Epoch 167/5000
41/41 - 1s - loss: 0.0274 - mae: 0.1228 - val_loss: 0.0713 - val_mae: 0.2146
Epoch 168/5000
41/41 - 1s - loss: 0.0252 - mae: 0.1166 - val_loss: 0.0736 - val_mae: 0.2195
Epoch 169/5000
41/41 - 1s - loss: 0.0273 - mae: 0.1234 - val_loss: 0.0769 - val_mae: 0.2302
Epoch 170/5000
41/41 - 1s - loss: 0.0279 - mae: 0.1294 - val_loss: 0.0873 - val_mae: 0.2504
Epoch 171/5000
41/41 - 1s - loss: 0.0279 - mae: 0.1287 - val_loss: 0.1012 - val_mae: 0.2717
Epoch 172/5000
41/41 - 1s - loss: 0.0259 - mae: 0.1245 - val_loss: 0.1085 - val_mae: 0.2850
Epoch 173/5000
41/41 - 1s - loss: 0.0295 - mae: 0.1337 - val_loss: 0.1210 - val_mae: 0.3025
Epoch 174/5000
41/41 - 1s - loss: 0.0275 - mae: 0.1225 - val_loss: 0.1517 - val_mae: 0.3487
Epoch 175/5000
41/41 - 1s - loss: 0.0269 - mae: 0.1230 - val_loss: 0.1309 - val_mae: 0.3378
Epoch 176/5000
41/41 - 1s - loss: 0.0332 - mae: 0.1344 - val_loss: 0.1496 - val_mae: 0.3684
Epoch 177/5000
41/41 - 1s - loss: 0.0303 - mae: 0.1277 - val_loss: 0.0789 - val_mae: 0.2508
Epoch 178/5000
41/41 - 1s - loss: 0.0286 - mae: 0.1294 - val_loss: 0.0844 - val_mae: 0.2585
Epoch 179/5000
41/41 - 1s - loss: 0.0245 - mae: 0.1101 - val_loss: 0.0797 - val_mae: 0.2461
Epoch 180/5000
41/41 - 1s - loss: 0.0249 - mae: 0.1118 - val_loss: 0.0792 - val_mae: 0.2384
Epoch 181/5000
41/41 - 1s - loss: 0.0224 - mae: 0.1045 - val_loss: 0.0771 - val_mae: 0.2378
Epoch 182/5000
41/41 - 1s - loss: 0.0238 - mae: 0.1042 - val_loss: 0.0889 - val_mae: 0.2541
Epoch 183/5000
41/41 - 1s - loss: 0.0212 - mae: 0.1032 - val_loss: 0.0858 - val_mae: 0.2535
Epoch 184/5000
41/41 - 1s - loss: 0.0207 - mae: 0.0975 - val_loss: 0.0977 - val_mae: 0.2714
Epoch 185/5000
41/41 - 1s - loss: 0.0193 - mae: 0.0961 - val_loss: 0.0979 - val_mae: 0.2748
Epoch 186/5000
41/41 - 1s - loss: 0.0225 - mae: 0.1050 - val_loss: 0.1059 - val_mae: 0.2839
Epoch 187/5000
41/41 - 1s - loss: 0.0216 - mae: 0.1042 - val_loss: 0.1287 - val_mae: 0.3270
Epoch 188/5000
41/41 - 1s - loss: 0.0213 - mae: 0.1007 - val_loss: 0.1032 - val_mae: 0.2923
Epoch 189/5000
41/41 - 1s - loss: 0.0251 - mae: 0.1120 - val_loss: 0.1264 - val_mae: 0.3273
Epoch 190/5000
41/41 - 1s - loss: 0.0236 - mae: 0.1037 - val_loss: 0.0808 - val_mae: 0.2560
Epoch 191/5000
41/41 - 1s - loss: 0.0240 - mae: 0.1121 - val_loss: 0.1023 - val_mae: 0.2872
Epoch 192/5000
41/41 - 1s - loss: 0.0205 - mae: 0.0959 - val_loss: 0.0970 - val_mae: 0.2797
Epoch 193/5000
41/41 - 1s - loss: 0.0201 - mae: 0.0954 - val_loss: 0.0963 - val_mae: 0.2761
Epoch 194/5000
41/41 - 1s - loss: 0.0210 - mae: 0.0967 - val_loss: 0.0891 - val_mae: 0.2698
Epoch 195/5000
41/41 - 1s - loss: 0.0214 - mae: 0.1020 - val_loss: 0.0796 - val_mae: 0.2458
Epoch 196/5000
41/41 - 1s - loss: 0.0238 - mae: 0.1042 - val_loss: 0.0942 - val_mae: 0.2690
Epoch 197/5000
41/41 - 1s - loss: 0.0234 - mae: 0.1107 - val_loss: 0.0733 - val_mae: 0.2352
Epoch 198/5000
41/41 - 1s - loss: 0.0217 - mae: 0.1020 - val_loss: 0.0833 - val_mae: 0.2484
Epoch 199/5000
41/41 - 1s - loss: 0.0202 - mae: 0.0956 - val_loss: 0.1016 - val_mae: 0.2736
Epoch 200/5000
41/41 - 1s - loss: 0.0176 - mae: 0.0915 - val_loss: 0.0852 - val_mae: 0.2508
Epoch 201/5000
41/41 - 1s - loss: 0.0190 - mae: 0.0916 - val_loss: 0.0716 - val_mae: 0.2196
Epoch 202/5000
41/41 - 1s - loss: 0.0198 - mae: 0.0988 - val_loss: 0.0924 - val_mae: 0.2653
Epoch 203/5000
41/41 - 1s - loss: 0.0228 - mae: 0.1091 - val_loss: 0.0853 - val_mae: 0.2543
Epoch 204/5000
41/41 - 1s - loss: 0.0241 - mae: 0.1112 - val_loss: 0.0853 - val_mae: 0.2533
Epoch 205/5000
41/41 - 1s - loss: 0.0192 - mae: 0.0950 - val_loss: 0.1030 - val_mae: 0.2779
Epoch 206/5000
41/41 - 1s - loss: 0.0187 - mae: 0.0982 - val_loss: 0.0868 - val_mae: 0.2565
Epoch 207/5000
41/41 - 1s - loss: 0.0207 - mae: 0.1028 - val_loss: 0.0960 - val_mae: 0.2682
Epoch 208/5000
41/41 - 1s - loss: 0.0197 - mae: 0.0992 - val_loss: 0.1082 - val_mae: 0.2958
Epoch 209/5000
41/41 - 1s - loss: 0.0188 - mae: 0.0971 - val_loss: 0.0945 - val_mae: 0.2750
Epoch 210/5000
41/41 - 1s - loss: 0.0171 - mae: 0.0918 - val_loss: 0.1141 - val_mae: 0.2975
Epoch 211/5000
41/41 - 1s - loss: 0.0163 - mae: 0.0899 - val_loss: 0.1198 - val_mae: 0.3173
Epoch 212/5000
41/41 - 1s - loss: 0.0186 - mae: 0.0971 - val_loss: 0.1176 - val_mae: 0.3105
Epoch 213/5000
41/41 - 1s - loss: 0.0181 - mae: 0.0982 - val_loss: 0.1364 - val_mae: 0.3399
Epoch 214/5000
41/41 - 1s - loss: 0.0167 - mae: 0.0922 - val_loss: 0.1239 - val_mae: 0.3342
Epoch 215/5000
41/41 - 1s - loss: 0.0158 - mae: 0.0899 - val_loss: 0.1322 - val_mae: 0.3322
Epoch 216/5000
41/41 - 1s - loss: 0.0208 - mae: 0.1041 - val_loss: 0.1581 - val_mae: 0.3742
Epoch 217/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1119 - val_loss: 0.0752 - val_mae: 0.2609
Epoch 218/5000
41/41 - 1s - loss: 0.0279 - mae: 0.1288 - val_loss: 0.0916 - val_mae: 0.2735
Epoch 219/5000
41/41 - 1s - loss: 0.0215 - mae: 0.1063 - val_loss: 0.0923 - val_mae: 0.2794
Epoch 220/5000
41/41 - 1s - loss: 0.0233 - mae: 0.1137 - val_loss: 0.0807 - val_mae: 0.2511
Epoch 221/5000
41/41 - 1s - loss: 0.0258 - mae: 0.1191 - val_loss: 0.0671 - val_mae: 0.2201
Epoch 222/5000
41/41 - 1s - loss: 0.0258 - mae: 0.1307 - val_loss: 0.0654 - val_mae: 0.2047
Epoch 223/5000
41/41 - 1s - loss: 0.0263 - mae: 0.1307 - val_loss: 0.0673 - val_mae: 0.2046
Epoch 224/5000
41/41 - 1s - loss: 0.0258 - mae: 0.1292 - val_loss: 0.0789 - val_mae: 0.2306
Epoch 225/5000
41/41 - 1s - loss: 0.0312 - mae: 0.1426 - val_loss: 0.0996 - val_mae: 0.2701
Epoch 226/5000
41/41 - 1s - loss: 0.0230 - mae: 0.1207 - val_loss: 0.1309 - val_mae: 0.3203
Epoch 227/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1164 - val_loss: 0.1026 - val_mae: 0.2975
Epoch 228/5000
41/41 - 1s - loss: 0.0182 - mae: 0.0955 - val_loss: 0.0985 - val_mae: 0.2766
Epoch 229/5000
41/41 - 1s - loss: 0.0176 - mae: 0.0951 - val_loss: 0.0983 - val_mae: 0.2735
Epoch 230/5000
41/41 - 1s - loss: 0.0177 - mae: 0.0947 - val_loss: 0.0876 - val_mae: 0.2565
Epoch 231/5000
41/41 - 1s - loss: 0.0185 - mae: 0.0983 - val_loss: 0.0688 - val_mae: 0.2176
Epoch 232/5000
41/41 - 1s - loss: 0.0152 - mae: 0.0980 - val_loss: 0.0729 - val_mae: 0.2148
Epoch 233/5000
41/41 - 1s - loss: 0.0146 - mae: 0.0938 - val_loss: 0.0846 - val_mae: 0.2390
Epoch 234/5000
41/41 - 1s - loss: 0.0159 - mae: 0.0977 - val_loss: 0.0885 - val_mae: 0.2540
Epoch 235/5000
41/41 - 1s - loss: 0.0141 - mae: 0.0958 - val_loss: 0.1029 - val_mae: 0.2775
Epoch 236/5000
41/41 - 1s - loss: 0.0145 - mae: 0.0882 - val_loss: 0.0998 - val_mae: 0.2819
Epoch 237/5000
41/41 - 1s - loss: 0.0197 - mae: 0.0965 - val_loss: 0.0997 - val_mae: 0.2798
Epoch 238/5000
41/41 - 1s - loss: 0.0134 - mae: 0.0867 - val_loss: 0.0834 - val_mae: 0.2506
Epoch 239/5000
41/41 - 1s - loss: 0.0159 - mae: 0.0868 - val_loss: 0.1018 - val_mae: 0.2757
Epoch 240/5000
41/41 - 1s - loss: 0.0187 - mae: 0.0944 - val_loss: 0.0714 - val_mae: 0.2266
Epoch 241/5000
41/41 - 1s - loss: 0.0143 - mae: 0.0917 - val_loss: 0.0736 - val_mae: 0.2278
Epoch 242/5000
41/41 - 1s - loss: 0.0146 - mae: 0.0873 - val_loss: 0.0774 - val_mae: 0.2311
Epoch 243/5000
41/41 - 1s - loss: 0.0174 - mae: 0.0965 - val_loss: 0.0798 - val_mae: 0.2352
Epoch 244/5000
41/41 - 1s - loss: 0.0125 - mae: 0.0887 - val_loss: 0.0854 - val_mae: 0.2481
Epoch 245/5000
41/41 - 1s - loss: 0.0110 - mae: 0.0770 - val_loss: 0.0808 - val_mae: 0.2339
Epoch 246/5000
41/41 - 1s - loss: 0.0109 - mae: 0.0839 - val_loss: 0.0990 - val_mae: 0.2697
Epoch 247/5000
41/41 - 1s - loss: 0.0123 - mae: 0.0830 - val_loss: 0.0826 - val_mae: 0.2570
Epoch 248/5000
41/41 - 1s - loss: 0.0157 - mae: 0.0846 - val_loss: 0.0933 - val_mae: 0.2673
Epoch 249/5000
41/41 - 1s - loss: 0.0172 - mae: 0.0899 - val_loss: 0.0922 - val_mae: 0.2694
Epoch 250/5000
41/41 - 1s - loss: 0.0155 - mae: 0.0904 - val_loss: 0.0735 - val_mae: 0.2297
Epoch 251/5000
41/41 - 1s - loss: 0.0116 - mae: 0.0796 - val_loss: 0.0891 - val_mae: 0.2527
Epoch 252/5000
41/41 - 1s - loss: 0.0110 - mae: 0.0784 - val_loss: 0.0748 - val_mae: 0.2315
Epoch 253/5000
41/41 - 1s - loss: 0.0110 - mae: 0.0786 - val_loss: 0.0738 - val_mae: 0.2227
Epoch 254/5000
41/41 - 1s - loss: 0.0152 - mae: 0.0886 - val_loss: 0.0864 - val_mae: 0.2576
Epoch 255/5000
41/41 - 1s - loss: 0.0169 - mae: 0.0885 - val_loss: 0.0806 - val_mae: 0.2399
Epoch 256/5000
41/41 - 1s - loss: 0.0151 - mae: 0.0872 - val_loss: 0.0849 - val_mae: 0.2465
Epoch 257/5000
41/41 - 1s - loss: 0.0107 - mae: 0.0840 - val_loss: 0.0967 - val_mae: 0.2708
Epoch 258/5000
41/41 - 1s - loss: 0.0099 - mae: 0.0776 - val_loss: 0.0852 - val_mae: 0.2509
Epoch 259/5000
41/41 - 1s - loss: 0.0105 - mae: 0.0802 - val_loss: 0.1130 - val_mae: 0.2948
Epoch 260/5000
41/41 - 1s - loss: 0.0082 - mae: 0.0699 - val_loss: 0.0833 - val_mae: 0.2518
Epoch 261/5000
41/41 - 1s - loss: 0.0097 - mae: 0.0748 - val_loss: 0.1010 - val_mae: 0.2774
Epoch 262/5000
41/41 - 1s - loss: 0.0092 - mae: 0.0732 - val_loss: 0.0729 - val_mae: 0.2293
Epoch 263/5000
41/41 - 1s - loss: 0.0138 - mae: 0.0896 - val_loss: 0.0718 - val_mae: 0.2220
Epoch 264/5000
41/41 - 1s - loss: 0.0130 - mae: 0.0935 - val_loss: 0.0662 - val_mae: 0.2069
Epoch 265/5000
41/41 - 1s - loss: 0.0099 - mae: 0.0786 - val_loss: 0.0744 - val_mae: 0.2218
Epoch 266/5000
41/41 - 1s - loss: 0.0119 - mae: 0.0877 - val_loss: 0.0722 - val_mae: 0.2168
Epoch 267/5000
41/41 - 1s - loss: 0.0091 - mae: 0.0738 - val_loss: 0.0795 - val_mae: 0.2316
Epoch 268/5000
41/41 - 1s - loss: 0.0102 - mae: 0.0801 - val_loss: 0.0860 - val_mae: 0.2432
Epoch 269/5000
41/41 - 1s - loss: 0.0107 - mae: 0.0834 - val_loss: 0.0886 - val_mae: 0.2573
Epoch 270/5000
41/41 - 1s - loss: 0.0086 - mae: 0.0743 - val_loss: 0.0988 - val_mae: 0.2763
Epoch 271/5000
41/41 - 1s - loss: 0.0099 - mae: 0.0763 - val_loss: 0.0807 - val_mae: 0.2446
Epoch 272/5000
41/41 - 1s - loss: 0.0104 - mae: 0.0781 - val_loss: 0.0903 - val_mae: 0.2600
Epoch 273/5000
41/41 - 1s - loss: 0.0085 - mae: 0.0705 - val_loss: 0.0752 - val_mae: 0.2348
Epoch 274/5000
41/41 - 1s - loss: 0.0087 - mae: 0.0738 - val_loss: 0.0808 - val_mae: 0.2337
Epoch 275/5000
41/41 - 1s - loss: 0.0081 - mae: 0.0689 - val_loss: 0.0739 - val_mae: 0.2248
Epoch 276/5000
41/41 - 1s - loss: 0.0098 - mae: 0.0732 - val_loss: 0.0780 - val_mae: 0.2226
Epoch 277/5000
41/41 - 1s - loss: 0.0086 - mae: 0.0707 - val_loss: 0.0707 - val_mae: 0.2150
Epoch 278/5000
41/41 - 1s - loss: 0.0090 - mae: 0.0714 - val_loss: 0.0750 - val_mae: 0.2205
Epoch 279/5000
41/41 - 1s - loss: 0.0080 - mae: 0.0735 - val_loss: 0.0768 - val_mae: 0.2273
Epoch 280/5000
41/41 - 1s - loss: 0.0087 - mae: 0.0719 - val_loss: 0.0804 - val_mae: 0.2340
Epoch 281/5000
41/41 - 1s - loss: 0.0102 - mae: 0.0849 - val_loss: 0.0955 - val_mae: 0.2692
Epoch 282/5000
41/41 - 1s - loss: 0.0097 - mae: 0.0773 - val_loss: 0.0885 - val_mae: 0.2541
Epoch 283/5000
41/41 - 1s - loss: 0.0131 - mae: 0.0877 - val_loss: 0.1073 - val_mae: 0.2945
Epoch 284/5000
41/41 - 1s - loss: 0.0186 - mae: 0.0921 - val_loss: 0.0913 - val_mae: 0.2700
Epoch 285/5000
41/41 - 1s - loss: 0.0242 - mae: 0.1089 - val_loss: 0.0910 - val_mae: 0.2758
Epoch 286/5000
41/41 - 1s - loss: 0.0129 - mae: 0.0903 - val_loss: 0.0952 - val_mae: 0.2680
Epoch 287/5000
41/41 - 1s - loss: 0.0168 - mae: 0.0891 - val_loss: 0.0819 - val_mae: 0.2597
Epoch 288/5000
41/41 - 1s - loss: 0.0151 - mae: 0.0908 - val_loss: 0.0758 - val_mae: 0.2334
Epoch 289/5000
41/41 - 1s - loss: 0.0125 - mae: 0.0867 - val_loss: 0.0806 - val_mae: 0.2409
Epoch 290/5000
41/41 - 1s - loss: 0.0096 - mae: 0.0790 - val_loss: 0.0699 - val_mae: 0.2121
Epoch 291/5000
41/41 - 1s - loss: 0.0112 - mae: 0.0825 - val_loss: 0.0694 - val_mae: 0.2070
Epoch 292/5000
41/41 - 1s - loss: 0.0124 - mae: 0.0950 - val_loss: 0.0694 - val_mae: 0.2158
Epoch 293/5000
41/41 - 1s - loss: 0.0113 - mae: 0.0892 - val_loss: 0.0764 - val_mae: 0.2286
Epoch 294/5000
41/41 - 1s - loss: 0.0114 - mae: 0.0849 - val_loss: 0.0876 - val_mae: 0.2564
Epoch 295/5000
41/41 - 1s - loss: 0.0097 - mae: 0.0791 - val_loss: 0.0935 - val_mae: 0.2680
Epoch 296/5000
41/41 - 1s - loss: 0.0075 - mae: 0.0703 - val_loss: 0.0834 - val_mae: 0.2462
Epoch 297/5000
41/41 - 1s - loss: 0.0111 - mae: 0.0790 - val_loss: 0.0706 - val_mae: 0.2194
Epoch 298/5000
41/41 - 1s - loss: 0.0095 - mae: 0.0804 - val_loss: 0.0730 - val_mae: 0.2163
Epoch 299/5000
41/41 - 1s - loss: 0.0068 - mae: 0.0677 - val_loss: 0.0741 - val_mae: 0.2244
Epoch 300/5000
41/41 - 1s - loss: 0.0080 - mae: 0.0699 - val_loss: 0.0826 - val_mae: 0.2389
Epoch 301/5000
41/41 - 1s - loss: 0.0083 - mae: 0.0735 - val_loss: 0.0892 - val_mae: 0.2586
Epoch 302/5000
41/41 - 1s - loss: 0.0070 - mae: 0.0669 - val_loss: 0.0792 - val_mae: 0.2327
Epoch 303/5000
41/41 - 1s - loss: 0.0093 - mae: 0.0711 - val_loss: 0.0737 - val_mae: 0.2221
Epoch 304/5000
41/41 - 1s - loss: 0.0084 - mae: 0.0736 - val_loss: 0.0732 - val_mae: 0.2163
Epoch 305/5000
41/41 - 1s - loss: 0.0062 - mae: 0.0630 - val_loss: 0.0749 - val_mae: 0.2222
Epoch 306/5000
41/41 - 1s - loss: 0.0069 - mae: 0.0639 - val_loss: 0.0804 - val_mae: 0.2370
Epoch 307/5000
41/41 - 1s - loss: 0.0075 - mae: 0.0681 - val_loss: 0.0794 - val_mae: 0.2390
Epoch 308/5000
41/41 - 1s - loss: 0.0089 - mae: 0.0702 - val_loss: 0.0849 - val_mae: 0.2454
Epoch 309/5000
41/41 - 1s - loss: 0.0087 - mae: 0.0730 - val_loss: 0.0840 - val_mae: 0.2520
Epoch 310/5000
41/41 - 1s - loss: 0.0074 - mae: 0.0643 - val_loss: 0.0736 - val_mae: 0.2212
Epoch 311/5000
41/41 - 1s - loss: 0.0097 - mae: 0.0693 - val_loss: 0.0853 - val_mae: 0.2439
Epoch 312/5000
41/41 - 1s - loss: 0.0176 - mae: 0.0839 - val_loss: 0.0755 - val_mae: 0.2289
Epoch 313/5000
41/41 - 1s - loss: 0.0201 - mae: 0.0938 - val_loss: 0.0815 - val_mae: 0.2423
Epoch 314/5000
41/41 - 1s - loss: 0.0109 - mae: 0.0747 - val_loss: 0.0784 - val_mae: 0.2342
Epoch 315/5000
41/41 - 1s - loss: 0.0098 - mae: 0.0725 - val_loss: 0.0704 - val_mae: 0.2110
Epoch 316/5000
41/41 - 1s - loss: 0.0077 - mae: 0.0653 - val_loss: 0.0734 - val_mae: 0.2184
Epoch 317/5000
41/41 - 1s - loss: 0.0074 - mae: 0.0666 - val_loss: 0.0866 - val_mae: 0.2466
Epoch 318/5000
41/41 - 1s - loss: 0.0062 - mae: 0.0636 - val_loss: 0.0791 - val_mae: 0.2391
Epoch 319/5000
41/41 - 1s - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0823 - val_mae: 0.2385
Epoch 320/5000
41/41 - 1s - loss: 0.0063 - mae: 0.0611 - val_loss: 0.0761 - val_mae: 0.2371
Epoch 321/5000
41/41 - 1s - loss: 0.0058 - mae: 0.0595 - val_loss: 0.0738 - val_mae: 0.2189
Epoch 322/5000
41/41 - 1s - loss: 0.0057 - mae: 0.0548 - val_loss: 0.0733 - val_mae: 0.2226
Epoch 323/5000
41/41 - 1s - loss: 0.0059 - mae: 0.0566 - val_loss: 0.0696 - val_mae: 0.2075
Epoch 324/5000
41/41 - 1s - loss: 0.0060 - mae: 0.0568 - val_loss: 0.0762 - val_mae: 0.2259
Restoring model weights from the end of the best epoch.
Epoch 00324: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_7..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 8

Generating graphs from SMILES..

Setting up training set.
Size: 2058

Setting up validation set.
Size: 228

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_44"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_8 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_8 (PartitionP (None, None, 64)     0           message_passing_8[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_8[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_8 (Masking)             (None, None, 64)     0           partition_padding_8[0][0]        
                                                                 partition_padding_8[1][0]        
__________________________________________________________________________________________________
transformer_encoder_8 (Transfor (None, None, 64)     199040      masking_8[0][0]                  
                                                                 masking_8[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_8 (Glo (None, 64)           0           transformer_encoder_8[0][0]      
                                                                 transformer_encoder_8[1][0]      
__________________________________________________________________________________________________
dense_140 (Dense)               (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_138 (Dense)               (None, 512)          33280       global_average_pooling1d_8[0][0] 
                                                                 global_average_pooling1d_8[1][0] 
__________________________________________________________________________________________________
dense_141 (Dense)               (None, 10)           110         dense_140[0][0]                  
__________________________________________________________________________________________________
dense_139 (Dense)               (None, 450)          230850      dense_138[0][0]                  
                                                                 dense_138[1][0]                  
__________________________________________________________________________________________________
dense_142 (Dense)               (None, 5)            55          dense_141[0][0]                  
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 905)          0           dense_139[0][0]                  
                                                                 dense_139[1][0]                  
                                                                 dense_142[0][0]                  
__________________________________________________________________________________________________
dense_143 (Dense)               (None, 700)          634200      concatenate_8[0][0]              
__________________________________________________________________________________________________
dense_147 (Dense)               (None, 560)          392560      dense_143[0][0]                  
__________________________________________________________________________________________________
dense_148 (Dense)               (None, 373)          209253      dense_147[0][0]                  
__________________________________________________________________________________________________
dense_149 (Dense)               (None, 187)          69938       dense_148[0][0]                  
__________________________________________________________________________________________________
dense_150 (Dense)               (None, 1)            188         dense_149[0][0]                  
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
41/41 - 6s - loss: 0.2770 - mae: 0.5919 - val_loss: 0.2287 - val_mae: 0.5009
Epoch 2/5000
41/41 - 1s - loss: 0.1540 - mae: 0.3919 - val_loss: 0.2253 - val_mae: 0.4998
Epoch 3/5000
41/41 - 1s - loss: 0.1515 - mae: 0.3859 - val_loss: 0.2237 - val_mae: 0.5138
Epoch 4/5000
41/41 - 1s - loss: 0.1511 - mae: 0.3864 - val_loss: 0.2233 - val_mae: 0.5191
Epoch 5/5000
41/41 - 1s - loss: 0.1496 - mae: 0.3837 - val_loss: 0.2214 - val_mae: 0.5161
Epoch 6/5000
41/41 - 1s - loss: 0.1489 - mae: 0.3800 - val_loss: 0.2194 - val_mae: 0.5056
Epoch 7/5000
41/41 - 1s - loss: 0.1487 - mae: 0.3776 - val_loss: 0.2179 - val_mae: 0.4869
Epoch 8/5000
41/41 - 1s - loss: 0.1474 - mae: 0.3756 - val_loss: 0.2174 - val_mae: 0.4734
Epoch 9/5000
41/41 - 1s - loss: 0.1457 - mae: 0.3719 - val_loss: 0.2169 - val_mae: 0.4652
Epoch 10/5000
41/41 - 1s - loss: 0.1441 - mae: 0.3685 - val_loss: 0.2141 - val_mae: 0.4660
Epoch 11/5000
41/41 - 1s - loss: 0.1428 - mae: 0.3662 - val_loss: 0.2128 - val_mae: 0.4616
Epoch 12/5000
41/41 - 1s - loss: 0.1423 - mae: 0.3645 - val_loss: 0.2083 - val_mae: 0.4676
Epoch 13/5000
41/41 - 1s - loss: 0.1417 - mae: 0.3644 - val_loss: 0.2070 - val_mae: 0.4703
Epoch 14/5000
41/41 - 1s - loss: 0.1411 - mae: 0.3626 - val_loss: 0.2065 - val_mae: 0.4598
Epoch 15/5000
41/41 - 1s - loss: 0.1406 - mae: 0.3619 - val_loss: 0.2066 - val_mae: 0.4628
Epoch 16/5000
41/41 - 1s - loss: 0.1399 - mae: 0.3614 - val_loss: 0.2109 - val_mae: 0.4394
Epoch 17/5000
41/41 - 1s - loss: 0.1380 - mae: 0.3554 - val_loss: 0.2085 - val_mae: 0.4426
Epoch 18/5000
41/41 - 1s - loss: 0.1371 - mae: 0.3544 - val_loss: 0.2077 - val_mae: 0.4424
Epoch 19/5000
41/41 - 1s - loss: 0.1370 - mae: 0.3533 - val_loss: 0.2052 - val_mae: 0.4403
Epoch 20/5000
41/41 - 1s - loss: 0.1373 - mae: 0.3555 - val_loss: 0.2124 - val_mae: 0.4366
Epoch 21/5000
41/41 - 1s - loss: 0.1386 - mae: 0.3567 - val_loss: 0.2055 - val_mae: 0.4579
Epoch 22/5000
41/41 - 1s - loss: 0.1363 - mae: 0.3487 - val_loss: 0.2023 - val_mae: 0.4410
Epoch 23/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3465 - val_loss: 0.2019 - val_mae: 0.4398
Epoch 24/5000
41/41 - 1s - loss: 0.1365 - mae: 0.3541 - val_loss: 0.2086 - val_mae: 0.4392
Epoch 25/5000
41/41 - 1s - loss: 0.1368 - mae: 0.3501 - val_loss: 0.2028 - val_mae: 0.4673
Epoch 26/5000
41/41 - 1s - loss: 0.1359 - mae: 0.3493 - val_loss: 0.2087 - val_mae: 0.4293
Epoch 27/5000
41/41 - 1s - loss: 0.1351 - mae: 0.3455 - val_loss: 0.2011 - val_mae: 0.4337
Epoch 28/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3463 - val_loss: 0.2075 - val_mae: 0.4978
Epoch 29/5000
41/41 - 1s - loss: 0.1342 - mae: 0.3464 - val_loss: 0.2028 - val_mae: 0.4271
Epoch 30/5000
41/41 - 1s - loss: 0.1343 - mae: 0.3428 - val_loss: 0.2034 - val_mae: 0.4806
Epoch 31/5000
41/41 - 1s - loss: 0.1330 - mae: 0.3453 - val_loss: 0.2021 - val_mae: 0.4417
Epoch 32/5000
41/41 - 1s - loss: 0.1341 - mae: 0.3430 - val_loss: 0.2030 - val_mae: 0.4799
Epoch 33/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3416 - val_loss: 0.1999 - val_mae: 0.4606
Epoch 34/5000
41/41 - 1s - loss: 0.1315 - mae: 0.3390 - val_loss: 0.2002 - val_mae: 0.4478
Epoch 35/5000
41/41 - 1s - loss: 0.1331 - mae: 0.3412 - val_loss: 0.2021 - val_mae: 0.4746
Epoch 36/5000
41/41 - 1s - loss: 0.1367 - mae: 0.3495 - val_loss: 0.2008 - val_mae: 0.4617
Epoch 37/5000
41/41 - 1s - loss: 0.1355 - mae: 0.3466 - val_loss: 0.2076 - val_mae: 0.4450
Epoch 38/5000
41/41 - 1s - loss: 0.1341 - mae: 0.3435 - val_loss: 0.2024 - val_mae: 0.4527
Epoch 39/5000
41/41 - 1s - loss: 0.1357 - mae: 0.3484 - val_loss: 0.2286 - val_mae: 0.5573
Epoch 40/5000
41/41 - 1s - loss: 0.1350 - mae: 0.3475 - val_loss: 0.2082 - val_mae: 0.4182
Epoch 41/5000
41/41 - 1s - loss: 0.1334 - mae: 0.3405 - val_loss: 0.2145 - val_mae: 0.5177
Epoch 42/5000
41/41 - 1s - loss: 0.1359 - mae: 0.3508 - val_loss: 0.2036 - val_mae: 0.4737
Epoch 43/5000
41/41 - 1s - loss: 0.1327 - mae: 0.3392 - val_loss: 0.2085 - val_mae: 0.4171
Epoch 44/5000
41/41 - 1s - loss: 0.1305 - mae: 0.3342 - val_loss: 0.2015 - val_mae: 0.4604
Epoch 45/5000
41/41 - 1s - loss: 0.1361 - mae: 0.3454 - val_loss: 0.2118 - val_mae: 0.5142
Epoch 46/5000
41/41 - 1s - loss: 0.1330 - mae: 0.3419 - val_loss: 0.2040 - val_mae: 0.4120
Epoch 47/5000
41/41 - 1s - loss: 0.1316 - mae: 0.3340 - val_loss: 0.2182 - val_mae: 0.5284
Epoch 48/5000
41/41 - 1s - loss: 0.1343 - mae: 0.3465 - val_loss: 0.2004 - val_mae: 0.4559
Epoch 49/5000
41/41 - 1s - loss: 0.1317 - mae: 0.3363 - val_loss: 0.2029 - val_mae: 0.4142
Epoch 50/5000
41/41 - 1s - loss: 0.1297 - mae: 0.3318 - val_loss: 0.1996 - val_mae: 0.4424
Epoch 51/5000
41/41 - 1s - loss: 0.1313 - mae: 0.3355 - val_loss: 0.2042 - val_mae: 0.4150
Epoch 52/5000
41/41 - 1s - loss: 0.1335 - mae: 0.3383 - val_loss: 0.2185 - val_mae: 0.5366
Epoch 53/5000
41/41 - 1s - loss: 0.1325 - mae: 0.3395 - val_loss: 0.1951 - val_mae: 0.4415
Epoch 54/5000
41/41 - 1s - loss: 0.1294 - mae: 0.3304 - val_loss: 0.2107 - val_mae: 0.5072
Epoch 55/5000
41/41 - 1s - loss: 0.1310 - mae: 0.3360 - val_loss: 0.1958 - val_mae: 0.4219
Epoch 56/5000
41/41 - 1s - loss: 0.1315 - mae: 0.3336 - val_loss: 0.2183 - val_mae: 0.5334
Epoch 57/5000
41/41 - 1s - loss: 0.1313 - mae: 0.3363 - val_loss: 0.1938 - val_mae: 0.4438
Epoch 58/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3250 - val_loss: 0.1994 - val_mae: 0.4684
Epoch 59/5000
41/41 - 1s - loss: 0.1292 - mae: 0.3317 - val_loss: 0.2027 - val_mae: 0.4821
Epoch 60/5000
41/41 - 1s - loss: 0.1306 - mae: 0.3343 - val_loss: 0.1993 - val_mae: 0.4075
Epoch 61/5000
41/41 - 1s - loss: 0.1301 - mae: 0.3317 - val_loss: 0.2008 - val_mae: 0.4103
Epoch 62/5000
41/41 - 1s - loss: 0.1263 - mae: 0.3196 - val_loss: 0.1980 - val_mae: 0.4655
Epoch 63/5000
41/41 - 1s - loss: 0.1316 - mae: 0.3343 - val_loss: 0.2108 - val_mae: 0.5021
Epoch 64/5000
41/41 - 1s - loss: 0.1278 - mae: 0.3329 - val_loss: 0.1969 - val_mae: 0.4065
Epoch 65/5000
41/41 - 1s - loss: 0.1251 - mae: 0.3191 - val_loss: 0.1987 - val_mae: 0.4658
Epoch 66/5000
41/41 - 1s - loss: 0.1294 - mae: 0.3303 - val_loss: 0.2078 - val_mae: 0.4968
Epoch 67/5000
41/41 - 1s - loss: 0.1292 - mae: 0.3305 - val_loss: 0.1941 - val_mae: 0.4402
Epoch 68/5000
41/41 - 1s - loss: 0.1282 - mae: 0.3273 - val_loss: 0.1913 - val_mae: 0.4377
Epoch 69/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3332 - val_loss: 0.1922 - val_mae: 0.4244
Epoch 70/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3271 - val_loss: 0.2055 - val_mae: 0.4989
Epoch 71/5000
41/41 - 1s - loss: 0.1288 - mae: 0.3330 - val_loss: 0.1965 - val_mae: 0.4140
Epoch 72/5000
41/41 - 1s - loss: 0.1303 - mae: 0.3279 - val_loss: 0.2040 - val_mae: 0.4961
Epoch 73/5000
41/41 - 1s - loss: 0.1298 - mae: 0.3333 - val_loss: 0.1923 - val_mae: 0.4208
Epoch 74/5000
41/41 - 1s - loss: 0.1291 - mae: 0.3288 - val_loss: 0.2097 - val_mae: 0.5082
Epoch 75/5000
41/41 - 1s - loss: 0.1301 - mae: 0.3328 - val_loss: 0.1976 - val_mae: 0.4581
Epoch 76/5000
41/41 - 1s - loss: 0.1281 - mae: 0.3252 - val_loss: 0.2165 - val_mae: 0.5155
Epoch 77/5000
41/41 - 1s - loss: 0.1271 - mae: 0.3293 - val_loss: 0.1929 - val_mae: 0.4127
Epoch 78/5000
41/41 - 1s - loss: 0.1256 - mae: 0.3206 - val_loss: 0.2088 - val_mae: 0.5027
Epoch 79/5000
41/41 - 1s - loss: 0.1283 - mae: 0.3284 - val_loss: 0.1931 - val_mae: 0.4325
Epoch 80/5000
41/41 - 1s - loss: 0.1268 - mae: 0.3233 - val_loss: 0.1875 - val_mae: 0.4098
Epoch 81/5000
41/41 - 1s - loss: 0.1294 - mae: 0.3250 - val_loss: 0.2026 - val_mae: 0.4921
Epoch 82/5000
41/41 - 1s - loss: 0.1271 - mae: 0.3274 - val_loss: 0.1908 - val_mae: 0.4374
Epoch 83/5000
41/41 - 1s - loss: 0.1273 - mae: 0.3235 - val_loss: 0.2036 - val_mae: 0.4986
Epoch 84/5000
41/41 - 1s - loss: 0.1274 - mae: 0.3269 - val_loss: 0.1952 - val_mae: 0.4565
Epoch 85/5000
41/41 - 1s - loss: 0.1259 - mae: 0.3207 - val_loss: 0.2037 - val_mae: 0.4938
Epoch 86/5000
41/41 - 1s - loss: 0.1259 - mae: 0.3224 - val_loss: 0.1936 - val_mae: 0.4472
Epoch 87/5000
41/41 - 1s - loss: 0.1264 - mae: 0.3197 - val_loss: 0.2069 - val_mae: 0.5063
Epoch 88/5000
41/41 - 1s - loss: 0.1267 - mae: 0.3268 - val_loss: 0.1885 - val_mae: 0.4230
Epoch 89/5000
41/41 - 1s - loss: 0.1234 - mae: 0.3157 - val_loss: 0.2047 - val_mae: 0.4859
Epoch 90/5000
41/41 - 1s - loss: 0.1261 - mae: 0.3222 - val_loss: 0.2017 - val_mae: 0.4821
Epoch 91/5000
41/41 - 1s - loss: 0.1248 - mae: 0.3194 - val_loss: 0.1931 - val_mae: 0.4451
Epoch 92/5000
41/41 - 1s - loss: 0.1235 - mae: 0.3156 - val_loss: 0.1911 - val_mae: 0.4362
Epoch 93/5000
41/41 - 1s - loss: 0.1234 - mae: 0.3136 - val_loss: 0.2004 - val_mae: 0.4811
Epoch 94/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3170 - val_loss: 0.1925 - val_mae: 0.4383
Epoch 95/5000
41/41 - 1s - loss: 0.1235 - mae: 0.3136 - val_loss: 0.2068 - val_mae: 0.4982
Epoch 96/5000
41/41 - 1s - loss: 0.1253 - mae: 0.3199 - val_loss: 0.1961 - val_mae: 0.4523
Epoch 97/5000
41/41 - 1s - loss: 0.1238 - mae: 0.3164 - val_loss: 0.1979 - val_mae: 0.4707
Epoch 98/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3172 - val_loss: 0.1944 - val_mae: 0.4447
Epoch 99/5000
41/41 - 1s - loss: 0.1231 - mae: 0.3149 - val_loss: 0.2112 - val_mae: 0.5113
Epoch 100/5000
41/41 - 1s - loss: 0.1251 - mae: 0.3219 - val_loss: 0.2009 - val_mae: 0.4665
Epoch 101/5000
41/41 - 1s - loss: 0.1221 - mae: 0.3135 - val_loss: 0.1932 - val_mae: 0.4499
Epoch 102/5000
41/41 - 1s - loss: 0.1221 - mae: 0.3123 - val_loss: 0.1948 - val_mae: 0.4433
Epoch 103/5000
41/41 - 1s - loss: 0.1215 - mae: 0.3095 - val_loss: 0.1950 - val_mae: 0.4559
Epoch 104/5000
41/41 - 1s - loss: 0.1226 - mae: 0.3133 - val_loss: 0.1943 - val_mae: 0.4375
Epoch 105/5000
41/41 - 1s - loss: 0.1209 - mae: 0.3085 - val_loss: 0.1956 - val_mae: 0.4584
Epoch 106/5000
41/41 - 1s - loss: 0.1220 - mae: 0.3105 - val_loss: 0.1962 - val_mae: 0.4594
Epoch 107/5000
41/41 - 1s - loss: 0.1233 - mae: 0.3139 - val_loss: 0.2005 - val_mae: 0.4661
Epoch 108/5000
41/41 - 1s - loss: 0.1212 - mae: 0.3108 - val_loss: 0.1999 - val_mae: 0.4678
Epoch 109/5000
41/41 - 1s - loss: 0.1228 - mae: 0.3138 - val_loss: 0.1963 - val_mae: 0.4498
Epoch 110/5000
41/41 - 1s - loss: 0.1211 - mae: 0.3112 - val_loss: 0.1965 - val_mae: 0.4634
Epoch 111/5000
41/41 - 1s - loss: 0.1222 - mae: 0.3112 - val_loss: 0.1944 - val_mae: 0.4409
Epoch 112/5000
41/41 - 1s - loss: 0.1207 - mae: 0.3086 - val_loss: 0.2176 - val_mae: 0.5195
Epoch 113/5000
41/41 - 1s - loss: 0.1248 - mae: 0.3219 - val_loss: 0.1994 - val_mae: 0.4676
Epoch 114/5000
41/41 - 1s - loss: 0.1205 - mae: 0.3084 - val_loss: 0.2017 - val_mae: 0.4758
Epoch 115/5000
41/41 - 1s - loss: 0.1221 - mae: 0.3133 - val_loss: 0.2040 - val_mae: 0.4687
Epoch 116/5000
41/41 - 1s - loss: 0.1195 - mae: 0.3063 - val_loss: 0.2054 - val_mae: 0.4783
Epoch 117/5000
41/41 - 1s - loss: 0.1210 - mae: 0.3110 - val_loss: 0.1954 - val_mae: 0.4467
Epoch 118/5000
41/41 - 1s - loss: 0.1193 - mae: 0.3043 - val_loss: 0.1979 - val_mae: 0.4559
Epoch 119/5000
41/41 - 1s - loss: 0.1184 - mae: 0.3040 - val_loss: 0.1955 - val_mae: 0.4461
Epoch 120/5000
41/41 - 1s - loss: 0.1196 - mae: 0.3069 - val_loss: 0.2101 - val_mae: 0.4924
Epoch 121/5000
41/41 - 1s - loss: 0.1222 - mae: 0.3125 - val_loss: 0.1971 - val_mae: 0.4504
Epoch 122/5000
41/41 - 1s - loss: 0.1199 - mae: 0.3068 - val_loss: 0.2137 - val_mae: 0.5088
Epoch 123/5000
41/41 - 1s - loss: 0.1227 - mae: 0.3150 - val_loss: 0.2004 - val_mae: 0.4569
Epoch 124/5000
41/41 - 1s - loss: 0.1184 - mae: 0.3045 - val_loss: 0.2050 - val_mae: 0.4821
Epoch 125/5000
41/41 - 1s - loss: 0.1217 - mae: 0.3118 - val_loss: 0.2040 - val_mae: 0.4660
Epoch 126/5000
41/41 - 1s - loss: 0.1189 - mae: 0.3064 - val_loss: 0.2045 - val_mae: 0.4838
Epoch 127/5000
41/41 - 1s - loss: 0.1212 - mae: 0.3121 - val_loss: 0.2007 - val_mae: 0.4498
Epoch 128/5000
41/41 - 1s - loss: 0.1170 - mae: 0.3015 - val_loss: 0.2091 - val_mae: 0.4837
Epoch 129/5000
41/41 - 1s - loss: 0.1203 - mae: 0.3081 - val_loss: 0.2119 - val_mae: 0.5004
Epoch 130/5000
41/41 - 1s - loss: 0.1256 - mae: 0.3219 - val_loss: 0.2190 - val_mae: 0.5061
Epoch 131/5000
41/41 - 1s - loss: 0.1240 - mae: 0.3174 - val_loss: 0.1980 - val_mae: 0.4461
Epoch 132/5000
41/41 - 1s - loss: 0.1175 - mae: 0.3028 - val_loss: 0.2177 - val_mae: 0.5131
Epoch 133/5000
41/41 - 1s - loss: 0.1226 - mae: 0.3162 - val_loss: 0.2087 - val_mae: 0.4867
Epoch 134/5000
41/41 - 1s - loss: 0.1202 - mae: 0.3106 - val_loss: 0.2088 - val_mae: 0.4839
Epoch 135/5000
41/41 - 1s - loss: 0.1216 - mae: 0.3132 - val_loss: 0.1949 - val_mae: 0.4349
Epoch 136/5000
41/41 - 1s - loss: 0.1182 - mae: 0.3041 - val_loss: 0.2001 - val_mae: 0.4659
Epoch 137/5000
41/41 - 1s - loss: 0.1187 - mae: 0.3052 - val_loss: 0.2210 - val_mae: 0.5233
Epoch 138/5000
41/41 - 1s - loss: 0.1223 - mae: 0.3141 - val_loss: 0.2069 - val_mae: 0.4827
Epoch 139/5000
41/41 - 1s - loss: 0.1194 - mae: 0.3074 - val_loss: 0.2038 - val_mae: 0.4592
Epoch 140/5000
41/41 - 1s - loss: 0.1160 - mae: 0.2990 - val_loss: 0.2114 - val_mae: 0.4934
Epoch 141/5000
41/41 - 1s - loss: 0.1199 - mae: 0.3099 - val_loss: 0.2072 - val_mae: 0.4660
Epoch 142/5000
41/41 - 1s - loss: 0.1156 - mae: 0.2979 - val_loss: 0.2167 - val_mae: 0.5137
Epoch 143/5000
41/41 - 1s - loss: 0.1207 - mae: 0.3110 - val_loss: 0.2212 - val_mae: 0.5088
Epoch 144/5000
41/41 - 1s - loss: 0.1199 - mae: 0.3102 - val_loss: 0.2053 - val_mae: 0.4681
Epoch 145/5000
41/41 - 1s - loss: 0.1193 - mae: 0.3099 - val_loss: 0.2082 - val_mae: 0.4748
Epoch 146/5000
41/41 - 1s - loss: 0.1170 - mae: 0.3022 - val_loss: 0.2127 - val_mae: 0.4900
Epoch 147/5000
41/41 - 1s - loss: 0.1228 - mae: 0.3165 - val_loss: 0.2161 - val_mae: 0.4887
Epoch 148/5000
41/41 - 1s - loss: 0.1234 - mae: 0.3199 - val_loss: 0.2019 - val_mae: 0.4688
Epoch 149/5000
41/41 - 1s - loss: 0.1195 - mae: 0.3092 - val_loss: 0.2090 - val_mae: 0.4853
Epoch 150/5000
41/41 - 1s - loss: 0.1176 - mae: 0.3058 - val_loss: 0.2128 - val_mae: 0.4959
Epoch 151/5000
41/41 - 1s - loss: 0.1190 - mae: 0.3075 - val_loss: 0.2134 - val_mae: 0.4977
Epoch 152/5000
41/41 - 1s - loss: 0.1208 - mae: 0.3137 - val_loss: 0.2071 - val_mae: 0.4755
Epoch 153/5000
41/41 - 1s - loss: 0.1176 - mae: 0.3047 - val_loss: 0.2134 - val_mae: 0.5029
Epoch 154/5000
41/41 - 1s - loss: 0.1180 - mae: 0.3047 - val_loss: 0.2008 - val_mae: 0.4555
Epoch 155/5000
41/41 - 1s - loss: 0.1174 - mae: 0.3037 - val_loss: 0.2070 - val_mae: 0.4835
Epoch 156/5000
41/41 - 1s - loss: 0.1162 - mae: 0.2994 - val_loss: 0.2129 - val_mae: 0.4986
Epoch 157/5000
41/41 - 1s - loss: 0.1207 - mae: 0.3109 - val_loss: 0.2099 - val_mae: 0.4782
Epoch 158/5000
41/41 - 1s - loss: 0.1209 - mae: 0.3122 - val_loss: 0.2093 - val_mae: 0.4773
Epoch 159/5000
41/41 - 1s - loss: 0.1223 - mae: 0.3212 - val_loss: 0.2094 - val_mae: 0.4781
Epoch 160/5000
41/41 - 1s - loss: 0.1168 - mae: 0.3017 - val_loss: 0.2145 - val_mae: 0.4951
Epoch 161/5000
41/41 - 1s - loss: 0.1218 - mae: 0.3142 - val_loss: 0.2026 - val_mae: 0.4551
Epoch 162/5000
41/41 - 1s - loss: 0.1271 - mae: 0.3249 - val_loss: 0.2080 - val_mae: 0.4366
Epoch 163/5000
41/41 - 1s - loss: 0.1206 - mae: 0.3148 - val_loss: 0.2030 - val_mae: 0.4728
Epoch 164/5000
41/41 - 1s - loss: 0.1188 - mae: 0.3075 - val_loss: 0.1974 - val_mae: 0.4376
Epoch 165/5000
41/41 - 1s - loss: 0.1240 - mae: 0.3210 - val_loss: 0.2086 - val_mae: 0.4304
Restoring model weights from the end of the best epoch.
Epoch 00165: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_8..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_44"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_8 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_8 (PartitionP (None, None, 64)     0           message_passing_8[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_8[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_8 (Masking)             (None, None, 64)     0           partition_padding_8[0][0]        
                                                                 partition_padding_8[1][0]        
__________________________________________________________________________________________________
transformer_encoder_8 (Transfor (None, None, 64)     199040      masking_8[0][0]                  
                                                                 masking_8[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_8 (Glo (None, 64)           0           transformer_encoder_8[0][0]      
                                                                 transformer_encoder_8[1][0]      
__________________________________________________________________________________________________
dense_140 (Dense)               (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_138 (Dense)               (None, 512)          33280       global_average_pooling1d_8[0][0] 
                                                                 global_average_pooling1d_8[1][0] 
__________________________________________________________________________________________________
dense_141 (Dense)               (None, 10)           110         dense_140[0][0]                  
__________________________________________________________________________________________________
dense_139 (Dense)               (None, 450)          230850      dense_138[0][0]                  
                                                                 dense_138[1][0]                  
__________________________________________________________________________________________________
dense_142 (Dense)               (None, 5)            55          dense_141[0][0]                  
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 905)          0           dense_139[0][0]                  
                                                                 dense_139[1][0]                  
                                                                 dense_142[0][0]                  
__________________________________________________________________________________________________
dense_143 (Dense)               (None, 700)          634200      concatenate_8[0][0]              
__________________________________________________________________________________________________
dense_147 (Dense)               (None, 560)          392560      dense_143[0][0]                  
__________________________________________________________________________________________________
dense_148 (Dense)               (None, 373)          209253      dense_147[0][0]                  
__________________________________________________________________________________________________
dense_149 (Dense)               (None, 187)          69938       dense_148[0][0]                  
__________________________________________________________________________________________________
dense_150 (Dense)               (None, 1)            188         dense_149[0][0]                  
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
41/41 - 6s - loss: 0.1259 - mae: 0.3190 - val_loss: 0.1904 - val_mae: 0.4255
Epoch 2/5000
41/41 - 1s - loss: 0.1174 - mae: 0.3025 - val_loss: 0.1857 - val_mae: 0.4177
Epoch 3/5000
41/41 - 1s - loss: 0.1123 - mae: 0.2896 - val_loss: 0.1830 - val_mae: 0.4041
Epoch 4/5000
41/41 - 1s - loss: 0.1086 - mae: 0.2811 - val_loss: 0.1838 - val_mae: 0.4060
Epoch 5/5000
41/41 - 1s - loss: 0.1057 - mae: 0.2747 - val_loss: 0.1837 - val_mae: 0.4048
Epoch 6/5000
41/41 - 1s - loss: 0.1030 - mae: 0.2686 - val_loss: 0.1860 - val_mae: 0.4086
Epoch 7/5000
41/41 - 1s - loss: 0.1008 - mae: 0.2630 - val_loss: 0.1885 - val_mae: 0.4137
Epoch 8/5000
41/41 - 1s - loss: 0.0994 - mae: 0.2602 - val_loss: 0.1897 - val_mae: 0.4135
Epoch 9/5000
41/41 - 1s - loss: 0.0986 - mae: 0.2586 - val_loss: 0.1885 - val_mae: 0.4102
Epoch 10/5000
41/41 - 1s - loss: 0.0997 - mae: 0.2614 - val_loss: 0.1835 - val_mae: 0.3967
Epoch 11/5000
41/41 - 1s - loss: 0.0997 - mae: 0.2614 - val_loss: 0.1810 - val_mae: 0.3920
Epoch 12/5000
41/41 - 1s - loss: 0.0953 - mae: 0.2517 - val_loss: 0.1911 - val_mae: 0.4149
Epoch 13/5000
41/41 - 1s - loss: 0.0927 - mae: 0.2461 - val_loss: 0.1987 - val_mae: 0.4373
Epoch 14/5000
41/41 - 1s - loss: 0.0956 - mae: 0.2543 - val_loss: 0.1975 - val_mae: 0.4250
Epoch 15/5000
41/41 - 1s - loss: 0.0940 - mae: 0.2512 - val_loss: 0.1957 - val_mae: 0.4274
Epoch 16/5000
41/41 - 1s - loss: 0.0910 - mae: 0.2442 - val_loss: 0.2005 - val_mae: 0.4399
Epoch 17/5000
41/41 - 1s - loss: 0.0897 - mae: 0.2423 - val_loss: 0.2030 - val_mae: 0.4507
Epoch 18/5000
41/41 - 1s - loss: 0.0911 - mae: 0.2457 - val_loss: 0.2059 - val_mae: 0.4588
Epoch 19/5000
41/41 - 1s - loss: 0.0916 - mae: 0.2476 - val_loss: 0.2112 - val_mae: 0.4719
Epoch 20/5000
41/41 - 1s - loss: 0.0948 - mae: 0.2547 - val_loss: 0.1947 - val_mae: 0.4337
Epoch 21/5000
41/41 - 1s - loss: 0.0956 - mae: 0.2572 - val_loss: 0.1832 - val_mae: 0.3987
Epoch 22/5000
41/41 - 1s - loss: 0.0941 - mae: 0.2518 - val_loss: 0.1832 - val_mae: 0.3900
Epoch 23/5000
41/41 - 1s - loss: 0.0903 - mae: 0.2440 - val_loss: 0.1861 - val_mae: 0.3859
Epoch 24/5000
41/41 - 1s - loss: 0.0874 - mae: 0.2380 - val_loss: 0.1848 - val_mae: 0.3818
Epoch 25/5000
41/41 - 1s - loss: 0.0850 - mae: 0.2309 - val_loss: 0.1851 - val_mae: 0.3771
Epoch 26/5000
41/41 - 1s - loss: 0.0824 - mae: 0.2246 - val_loss: 0.1864 - val_mae: 0.3798
Epoch 27/5000
41/41 - 1s - loss: 0.0810 - mae: 0.2219 - val_loss: 0.1876 - val_mae: 0.3802
Epoch 28/5000
41/41 - 1s - loss: 0.0791 - mae: 0.2176 - val_loss: 0.1888 - val_mae: 0.3882
Epoch 29/5000
41/41 - 1s - loss: 0.0774 - mae: 0.2125 - val_loss: 0.1889 - val_mae: 0.3914
Epoch 30/5000
41/41 - 1s - loss: 0.0766 - mae: 0.2102 - val_loss: 0.1924 - val_mae: 0.3945
Epoch 31/5000
41/41 - 1s - loss: 0.0751 - mae: 0.2072 - val_loss: 0.1935 - val_mae: 0.3964
Epoch 32/5000
41/41 - 1s - loss: 0.0740 - mae: 0.2046 - val_loss: 0.1944 - val_mae: 0.3961
Epoch 33/5000
41/41 - 1s - loss: 0.0730 - mae: 0.2032 - val_loss: 0.1932 - val_mae: 0.3965
Epoch 34/5000
41/41 - 1s - loss: 0.0715 - mae: 0.2002 - val_loss: 0.1921 - val_mae: 0.3941
Epoch 35/5000
41/41 - 1s - loss: 0.0705 - mae: 0.1976 - val_loss: 0.1922 - val_mae: 0.3921
Epoch 36/5000
41/41 - 1s - loss: 0.0701 - mae: 0.1976 - val_loss: 0.1908 - val_mae: 0.3867
Epoch 37/5000
41/41 - 1s - loss: 0.0696 - mae: 0.1973 - val_loss: 0.1887 - val_mae: 0.3768
Epoch 38/5000
41/41 - 1s - loss: 0.0697 - mae: 0.1997 - val_loss: 0.1913 - val_mae: 0.3854
Epoch 39/5000
41/41 - 1s - loss: 0.0688 - mae: 0.1977 - val_loss: 0.1956 - val_mae: 0.3987
Epoch 40/5000
41/41 - 1s - loss: 0.0678 - mae: 0.1968 - val_loss: 0.2072 - val_mae: 0.4192
Epoch 41/5000
41/41 - 1s - loss: 0.0669 - mae: 0.1965 - val_loss: 0.2069 - val_mae: 0.4217
Epoch 42/5000
41/41 - 1s - loss: 0.0654 - mae: 0.1932 - val_loss: 0.2074 - val_mae: 0.4198
Epoch 43/5000
41/41 - 1s - loss: 0.0660 - mae: 0.1942 - val_loss: 0.1990 - val_mae: 0.4105
Epoch 44/5000
41/41 - 1s - loss: 0.0690 - mae: 0.2036 - val_loss: 0.1941 - val_mae: 0.3848
Epoch 45/5000
41/41 - 1s - loss: 0.0659 - mae: 0.1953 - val_loss: 0.1936 - val_mae: 0.3915
Epoch 46/5000
41/41 - 1s - loss: 0.0604 - mae: 0.1824 - val_loss: 0.1995 - val_mae: 0.4094
Epoch 47/5000
41/41 - 1s - loss: 0.0583 - mae: 0.1774 - val_loss: 0.2040 - val_mae: 0.4213
Epoch 48/5000
41/41 - 1s - loss: 0.0573 - mae: 0.1759 - val_loss: 0.2042 - val_mae: 0.4235
Epoch 49/5000
41/41 - 1s - loss: 0.0578 - mae: 0.1789 - val_loss: 0.2014 - val_mae: 0.4153
Epoch 50/5000
41/41 - 1s - loss: 0.0587 - mae: 0.1815 - val_loss: 0.2071 - val_mae: 0.4173
Epoch 51/5000
41/41 - 1s - loss: 0.0578 - mae: 0.1799 - val_loss: 0.2044 - val_mae: 0.4131
Epoch 52/5000
41/41 - 1s - loss: 0.0572 - mae: 0.1821 - val_loss: 0.2043 - val_mae: 0.3946
Epoch 53/5000
41/41 - 1s - loss: 0.0596 - mae: 0.1892 - val_loss: 0.2053 - val_mae: 0.3969
Epoch 54/5000
41/41 - 1s - loss: 0.0626 - mae: 0.1956 - val_loss: 0.2058 - val_mae: 0.4113
Epoch 55/5000
41/41 - 1s - loss: 0.0581 - mae: 0.1875 - val_loss: 0.2115 - val_mae: 0.4276
Epoch 56/5000
41/41 - 1s - loss: 0.0565 - mae: 0.1830 - val_loss: 0.2082 - val_mae: 0.4077
Epoch 57/5000
41/41 - 1s - loss: 0.0566 - mae: 0.1846 - val_loss: 0.2155 - val_mae: 0.4092
Epoch 58/5000
41/41 - 1s - loss: 0.0548 - mae: 0.1821 - val_loss: 0.2143 - val_mae: 0.4075
Epoch 59/5000
41/41 - 1s - loss: 0.0583 - mae: 0.1896 - val_loss: 0.2129 - val_mae: 0.4021
Epoch 60/5000
41/41 - 1s - loss: 0.0760 - mae: 0.2277 - val_loss: 0.2247 - val_mae: 0.4652
Epoch 61/5000
41/41 - 1s - loss: 0.0794 - mae: 0.2376 - val_loss: 0.2163 - val_mae: 0.4189
Epoch 62/5000
41/41 - 1s - loss: 0.0616 - mae: 0.1982 - val_loss: 0.2110 - val_mae: 0.4256
Epoch 63/5000
41/41 - 1s - loss: 0.0584 - mae: 0.1902 - val_loss: 0.2130 - val_mae: 0.4144
Epoch 64/5000
41/41 - 1s - loss: 0.0545 - mae: 0.1838 - val_loss: 0.2285 - val_mae: 0.4636
Epoch 65/5000
41/41 - 1s - loss: 0.0585 - mae: 0.1917 - val_loss: 0.2269 - val_mae: 0.4652
Epoch 66/5000
41/41 - 1s - loss: 0.0536 - mae: 0.1835 - val_loss: 0.2207 - val_mae: 0.4291
Epoch 67/5000
41/41 - 1s - loss: 0.0469 - mae: 0.1670 - val_loss: 0.2266 - val_mae: 0.4398
Epoch 68/5000
41/41 - 1s - loss: 0.0514 - mae: 0.1774 - val_loss: 0.2287 - val_mae: 0.4315
Epoch 69/5000
41/41 - 1s - loss: 0.0497 - mae: 0.1718 - val_loss: 0.2229 - val_mae: 0.4236
Epoch 70/5000
41/41 - 1s - loss: 0.0515 - mae: 0.1755 - val_loss: 0.2384 - val_mae: 0.4388
Epoch 71/5000
41/41 - 1s - loss: 0.0497 - mae: 0.1703 - val_loss: 0.2235 - val_mae: 0.4145
Epoch 72/5000
41/41 - 1s - loss: 0.0476 - mae: 0.1693 - val_loss: 0.2187 - val_mae: 0.4069
Epoch 73/5000
41/41 - 1s - loss: 0.0469 - mae: 0.1678 - val_loss: 0.2232 - val_mae: 0.4094
Epoch 74/5000
41/41 - 1s - loss: 0.0518 - mae: 0.1813 - val_loss: 0.2547 - val_mae: 0.4590
Epoch 75/5000
41/41 - 1s - loss: 0.0552 - mae: 0.1869 - val_loss: 0.2435 - val_mae: 0.4440
Epoch 76/5000
41/41 - 1s - loss: 0.0435 - mae: 0.1637 - val_loss: 0.2370 - val_mae: 0.4369
Epoch 77/5000
41/41 - 1s - loss: 0.0425 - mae: 0.1591 - val_loss: 0.2151 - val_mae: 0.4019
Epoch 78/5000
41/41 - 1s - loss: 0.0435 - mae: 0.1624 - val_loss: 0.2368 - val_mae: 0.4296
Epoch 79/5000
41/41 - 1s - loss: 0.0485 - mae: 0.1716 - val_loss: 0.2454 - val_mae: 0.4385
Epoch 80/5000
41/41 - 1s - loss: 0.0387 - mae: 0.1523 - val_loss: 0.2269 - val_mae: 0.4221
Epoch 81/5000
41/41 - 1s - loss: 0.0433 - mae: 0.1607 - val_loss: 0.2261 - val_mae: 0.4093
Epoch 82/5000
41/41 - 1s - loss: 0.0436 - mae: 0.1691 - val_loss: 0.2538 - val_mae: 0.4382
Epoch 83/5000
41/41 - 1s - loss: 0.0415 - mae: 0.1583 - val_loss: 0.2474 - val_mae: 0.4471
Epoch 84/5000
41/41 - 1s - loss: 0.0409 - mae: 0.1598 - val_loss: 0.2434 - val_mae: 0.4469
Epoch 85/5000
41/41 - 1s - loss: 0.0415 - mae: 0.1612 - val_loss: 0.2359 - val_mae: 0.4229
Epoch 86/5000
41/41 - 1s - loss: 0.0434 - mae: 0.1649 - val_loss: 0.2485 - val_mae: 0.4420
Epoch 87/5000
41/41 - 1s - loss: 0.0385 - mae: 0.1549 - val_loss: 0.2317 - val_mae: 0.4198
Epoch 88/5000
41/41 - 1s - loss: 0.0461 - mae: 0.1689 - val_loss: 0.2485 - val_mae: 0.4361
Epoch 89/5000
41/41 - 1s - loss: 0.0517 - mae: 0.1853 - val_loss: 0.2564 - val_mae: 0.4429
Epoch 90/5000
41/41 - 1s - loss: 0.0384 - mae: 0.1568 - val_loss: 0.2262 - val_mae: 0.4095
Epoch 91/5000
41/41 - 1s - loss: 0.0386 - mae: 0.1566 - val_loss: 0.2348 - val_mae: 0.4169
Epoch 92/5000
41/41 - 1s - loss: 0.0376 - mae: 0.1566 - val_loss: 0.2446 - val_mae: 0.4286
Epoch 93/5000
41/41 - 1s - loss: 0.0386 - mae: 0.1561 - val_loss: 0.2422 - val_mae: 0.4213
Epoch 94/5000
41/41 - 1s - loss: 0.0390 - mae: 0.1643 - val_loss: 0.2366 - val_mae: 0.4200
Epoch 95/5000
41/41 - 1s - loss: 0.0424 - mae: 0.1691 - val_loss: 0.2500 - val_mae: 0.4302
Epoch 96/5000
41/41 - 1s - loss: 0.0405 - mae: 0.1679 - val_loss: 0.2522 - val_mae: 0.4352
Epoch 97/5000
41/41 - 1s - loss: 0.0452 - mae: 0.1761 - val_loss: 0.2453 - val_mae: 0.4308
Epoch 98/5000
41/41 - 1s - loss: 0.0464 - mae: 0.1737 - val_loss: 0.2577 - val_mae: 0.4446
Epoch 99/5000
41/41 - 1s - loss: 0.0464 - mae: 0.1774 - val_loss: 0.2569 - val_mae: 0.4468
Epoch 100/5000
41/41 - 1s - loss: 0.0521 - mae: 0.1898 - val_loss: 0.2563 - val_mae: 0.4456
Epoch 101/5000
41/41 - 1s - loss: 0.0536 - mae: 0.1930 - val_loss: 0.2551 - val_mae: 0.4451
Epoch 102/5000
41/41 - 1s - loss: 0.0555 - mae: 0.1997 - val_loss: 0.2515 - val_mae: 0.4403
Epoch 103/5000
41/41 - 1s - loss: 0.0468 - mae: 0.1845 - val_loss: 0.2761 - val_mae: 0.4723
Epoch 104/5000
41/41 - 1s - loss: 0.0432 - mae: 0.1743 - val_loss: 0.2688 - val_mae: 0.4758
Epoch 105/5000
41/41 - 1s - loss: 0.0328 - mae: 0.1535 - val_loss: 0.2654 - val_mae: 0.4578
Epoch 106/5000
41/41 - 1s - loss: 0.0309 - mae: 0.1401 - val_loss: 0.2557 - val_mae: 0.4479
Epoch 107/5000
41/41 - 1s - loss: 0.0321 - mae: 0.1452 - val_loss: 0.2608 - val_mae: 0.4485
Epoch 108/5000
41/41 - 1s - loss: 0.0283 - mae: 0.1337 - val_loss: 0.2603 - val_mae: 0.4454
Epoch 109/5000
41/41 - 1s - loss: 0.0274 - mae: 0.1306 - val_loss: 0.2642 - val_mae: 0.4487
Epoch 110/5000
41/41 - 1s - loss: 0.0267 - mae: 0.1315 - val_loss: 0.2610 - val_mae: 0.4455
Epoch 111/5000
41/41 - 1s - loss: 0.0256 - mae: 0.1279 - val_loss: 0.2508 - val_mae: 0.4427
Epoch 112/5000
41/41 - 1s - loss: 0.0277 - mae: 0.1332 - val_loss: 0.2685 - val_mae: 0.4520
Epoch 113/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1250 - val_loss: 0.2520 - val_mae: 0.4346
Epoch 114/5000
41/41 - 1s - loss: 0.0294 - mae: 0.1365 - val_loss: 0.2670 - val_mae: 0.4462
Epoch 115/5000
41/41 - 1s - loss: 0.0262 - mae: 0.1301 - val_loss: 0.2562 - val_mae: 0.4423
Epoch 116/5000
41/41 - 1s - loss: 0.0246 - mae: 0.1242 - val_loss: 0.2708 - val_mae: 0.4529
Epoch 117/5000
41/41 - 1s - loss: 0.0233 - mae: 0.1219 - val_loss: 0.2679 - val_mae: 0.4491
Epoch 118/5000
41/41 - 1s - loss: 0.0246 - mae: 0.1230 - val_loss: 0.2774 - val_mae: 0.4615
Epoch 119/5000
41/41 - 1s - loss: 0.0241 - mae: 0.1219 - val_loss: 0.2661 - val_mae: 0.4575
Epoch 120/5000
41/41 - 1s - loss: 0.0237 - mae: 0.1199 - val_loss: 0.2782 - val_mae: 0.4687
Epoch 121/5000
41/41 - 1s - loss: 0.0226 - mae: 0.1182 - val_loss: 0.2716 - val_mae: 0.4580
Epoch 122/5000
41/41 - 1s - loss: 0.0238 - mae: 0.1193 - val_loss: 0.2761 - val_mae: 0.4654
Epoch 123/5000
41/41 - 1s - loss: 0.0222 - mae: 0.1164 - val_loss: 0.2522 - val_mae: 0.4376
Epoch 124/5000
41/41 - 1s - loss: 0.0238 - mae: 0.1217 - val_loss: 0.2747 - val_mae: 0.4692
Epoch 125/5000
41/41 - 1s - loss: 0.0212 - mae: 0.1150 - val_loss: 0.2576 - val_mae: 0.4469
Epoch 126/5000
41/41 - 1s - loss: 0.0203 - mae: 0.1096 - val_loss: 0.2812 - val_mae: 0.4648
Epoch 127/5000
41/41 - 1s - loss: 0.0218 - mae: 0.1170 - val_loss: 0.2532 - val_mae: 0.4391
Epoch 128/5000
41/41 - 1s - loss: 0.0218 - mae: 0.1141 - val_loss: 0.2716 - val_mae: 0.4677
Epoch 129/5000
41/41 - 1s - loss: 0.0217 - mae: 0.1156 - val_loss: 0.2671 - val_mae: 0.4594
Epoch 130/5000
41/41 - 1s - loss: 0.0230 - mae: 0.1190 - val_loss: 0.2849 - val_mae: 0.4740
Epoch 131/5000
41/41 - 1s - loss: 0.0263 - mae: 0.1291 - val_loss: 0.2499 - val_mae: 0.4409
Epoch 132/5000
41/41 - 1s - loss: 0.0232 - mae: 0.1176 - val_loss: 0.2819 - val_mae: 0.4720
Epoch 133/5000
41/41 - 1s - loss: 0.0199 - mae: 0.1099 - val_loss: 0.2728 - val_mae: 0.4682
Epoch 134/5000
41/41 - 1s - loss: 0.0201 - mae: 0.1082 - val_loss: 0.2907 - val_mae: 0.4831
Epoch 135/5000
41/41 - 1s - loss: 0.0205 - mae: 0.1121 - val_loss: 0.2608 - val_mae: 0.4551
Epoch 136/5000
41/41 - 1s - loss: 0.0214 - mae: 0.1111 - val_loss: 0.3042 - val_mae: 0.5089
Epoch 137/5000
41/41 - 1s - loss: 0.0224 - mae: 0.1181 - val_loss: 0.2922 - val_mae: 0.4912
Epoch 138/5000
41/41 - 1s - loss: 0.0204 - mae: 0.1126 - val_loss: 0.2798 - val_mae: 0.4729
Restoring model weights from the end of the best epoch.
Epoch 00138: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_8..
££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££££
WORKING ON CV SPLIT 9

Generating graphs from SMILES..

Setting up training set.
Size: 2058

Setting up validation set.
Size: 228

Building model..
Loading model weights from process/trained_model_weights/weights..
Replacing last n layers with untrained FCNN layers..
Model: "model_49"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_9 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_9 (PartitionP (None, None, 64)     0           message_passing_9[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_9[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_9 (Masking)             (None, None, 64)     0           partition_padding_9[0][0]        
                                                                 partition_padding_9[1][0]        
__________________________________________________________________________________________________
transformer_encoder_9 (Transfor (None, None, 64)     199040      masking_9[0][0]                  
                                                                 masking_9[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_9 (Glo (None, 64)           0           transformer_encoder_9[0][0]      
                                                                 transformer_encoder_9[1][0]      
__________________________________________________________________________________________________
dense_157 (Dense)               (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_155 (Dense)               (None, 512)          33280       global_average_pooling1d_9[0][0] 
                                                                 global_average_pooling1d_9[1][0] 
__________________________________________________________________________________________________
dense_158 (Dense)               (None, 10)           110         dense_157[0][0]                  
__________________________________________________________________________________________________
dense_156 (Dense)               (None, 450)          230850      dense_155[0][0]                  
                                                                 dense_155[1][0]                  
__________________________________________________________________________________________________
dense_159 (Dense)               (None, 5)            55          dense_158[0][0]                  
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 905)          0           dense_156[0][0]                  
                                                                 dense_156[1][0]                  
                                                                 dense_159[0][0]                  
__________________________________________________________________________________________________
dense_160 (Dense)               (None, 700)          634200      concatenate_9[0][0]              
__________________________________________________________________________________________________
dense_164 (Dense)               (None, 560)          392560      dense_160[0][0]                  
__________________________________________________________________________________________________
dense_165 (Dense)               (None, 373)          209253      dense_164[0][0]                  
__________________________________________________________________________________________________
dense_166 (Dense)               (None, 187)          69938       dense_165[0][0]                  
__________________________________________________________________________________________________
dense_167 (Dense)               (None, 1)            188         dense_166[0][0]                  
==================================================================================================
Total params: 1,827,712
Trainable params: 671,939
Non-trainable params: 1,155,773
__________________________________________________________________________________________________
None
Fitting transferred model..
Epoch 1/5000
41/41 - 6s - loss: 0.2958 - mae: 0.6008 - val_loss: 0.2132 - val_mae: 0.5125
Epoch 2/5000
41/41 - 1s - loss: 0.1592 - mae: 0.4039 - val_loss: 0.2053 - val_mae: 0.4786
Epoch 3/5000
41/41 - 1s - loss: 0.1579 - mae: 0.4011 - val_loss: 0.2033 - val_mae: 0.4732
Epoch 4/5000
41/41 - 1s - loss: 0.1569 - mae: 0.3988 - val_loss: 0.2010 - val_mae: 0.4635
Epoch 5/5000
41/41 - 1s - loss: 0.1563 - mae: 0.3970 - val_loss: 0.2000 - val_mae: 0.4577
Epoch 6/5000
41/41 - 1s - loss: 0.1552 - mae: 0.3939 - val_loss: 0.1984 - val_mae: 0.4545
Epoch 7/5000
41/41 - 1s - loss: 0.1541 - mae: 0.3919 - val_loss: 0.1981 - val_mae: 0.4444
Epoch 8/5000
41/41 - 1s - loss: 0.1536 - mae: 0.3902 - val_loss: 0.1976 - val_mae: 0.4430
Epoch 9/5000
41/41 - 1s - loss: 0.1521 - mae: 0.3868 - val_loss: 0.1965 - val_mae: 0.4342
Epoch 10/5000
41/41 - 1s - loss: 0.1505 - mae: 0.3834 - val_loss: 0.1947 - val_mae: 0.4360
Epoch 11/5000
41/41 - 1s - loss: 0.1492 - mae: 0.3793 - val_loss: 0.1967 - val_mae: 0.4516
Epoch 12/5000
41/41 - 1s - loss: 0.1494 - mae: 0.3799 - val_loss: 0.1946 - val_mae: 0.4411
Epoch 13/5000
41/41 - 1s - loss: 0.1492 - mae: 0.3786 - val_loss: 0.1920 - val_mae: 0.4244
Epoch 14/5000
41/41 - 1s - loss: 0.1466 - mae: 0.3728 - val_loss: 0.1930 - val_mae: 0.4401
Epoch 15/5000
41/41 - 1s - loss: 0.1476 - mae: 0.3756 - val_loss: 0.1906 - val_mae: 0.4070
Epoch 16/5000
41/41 - 1s - loss: 0.1454 - mae: 0.3707 - val_loss: 0.1887 - val_mae: 0.4106
Epoch 17/5000
41/41 - 1s - loss: 0.1447 - mae: 0.3691 - val_loss: 0.1876 - val_mae: 0.3982
Epoch 18/5000
41/41 - 1s - loss: 0.1441 - mae: 0.3687 - val_loss: 0.1877 - val_mae: 0.3960
Epoch 19/5000
41/41 - 1s - loss: 0.1421 - mae: 0.3636 - val_loss: 0.1862 - val_mae: 0.4048
Epoch 20/5000
41/41 - 1s - loss: 0.1443 - mae: 0.3707 - val_loss: 0.1875 - val_mae: 0.3939
Epoch 21/5000
41/41 - 1s - loss: 0.1412 - mae: 0.3597 - val_loss: 0.1847 - val_mae: 0.4053
Epoch 22/5000
41/41 - 1s - loss: 0.1388 - mae: 0.3552 - val_loss: 0.1886 - val_mae: 0.4436
Epoch 23/5000
41/41 - 1s - loss: 0.1376 - mae: 0.3541 - val_loss: 0.1862 - val_mae: 0.4369
Epoch 24/5000
41/41 - 1s - loss: 0.1363 - mae: 0.3504 - val_loss: 0.1859 - val_mae: 0.4355
Epoch 25/5000
41/41 - 1s - loss: 0.1404 - mae: 0.3616 - val_loss: 0.1858 - val_mae: 0.4182
Epoch 26/5000
41/41 - 1s - loss: 0.1393 - mae: 0.3559 - val_loss: 0.1822 - val_mae: 0.3963
Epoch 27/5000
41/41 - 1s - loss: 0.1372 - mae: 0.3550 - val_loss: 0.1836 - val_mae: 0.3804
Epoch 28/5000
41/41 - 1s - loss: 0.1397 - mae: 0.3569 - val_loss: 0.1970 - val_mae: 0.4700
Epoch 29/5000
41/41 - 1s - loss: 0.1395 - mae: 0.3569 - val_loss: 0.1841 - val_mae: 0.4194
Epoch 30/5000
41/41 - 1s - loss: 0.1374 - mae: 0.3527 - val_loss: 0.1822 - val_mae: 0.3939
Epoch 31/5000
41/41 - 1s - loss: 0.1347 - mae: 0.3451 - val_loss: 0.1818 - val_mae: 0.4015
Epoch 32/5000
41/41 - 1s - loss: 0.1369 - mae: 0.3514 - val_loss: 0.1853 - val_mae: 0.3876
Epoch 33/5000
41/41 - 1s - loss: 0.1362 - mae: 0.3495 - val_loss: 0.1840 - val_mae: 0.3906
Epoch 34/5000
41/41 - 1s - loss: 0.1359 - mae: 0.3464 - val_loss: 0.1853 - val_mae: 0.4274
Epoch 35/5000
41/41 - 1s - loss: 0.1382 - mae: 0.3539 - val_loss: 0.1887 - val_mae: 0.4420
Epoch 36/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3449 - val_loss: 0.1820 - val_mae: 0.3701
Epoch 37/5000
41/41 - 1s - loss: 0.1339 - mae: 0.3420 - val_loss: 0.1901 - val_mae: 0.4456
Epoch 38/5000
41/41 - 1s - loss: 0.1358 - mae: 0.3486 - val_loss: 0.1803 - val_mae: 0.4013
Epoch 39/5000
41/41 - 1s - loss: 0.1333 - mae: 0.3411 - val_loss: 0.1825 - val_mae: 0.3858
Epoch 40/5000
41/41 - 1s - loss: 0.1366 - mae: 0.3469 - val_loss: 0.1822 - val_mae: 0.3897
Epoch 41/5000
41/41 - 1s - loss: 0.1332 - mae: 0.3381 - val_loss: 0.1813 - val_mae: 0.3688
Epoch 42/5000
41/41 - 1s - loss: 0.1301 - mae: 0.3331 - val_loss: 0.1800 - val_mae: 0.3731
Epoch 43/5000
41/41 - 1s - loss: 0.1315 - mae: 0.3346 - val_loss: 0.1866 - val_mae: 0.4206
Epoch 44/5000
41/41 - 1s - loss: 0.1356 - mae: 0.3482 - val_loss: 0.1798 - val_mae: 0.3673
Epoch 45/5000
41/41 - 1s - loss: 0.1357 - mae: 0.3434 - val_loss: 0.2009 - val_mae: 0.4942
Epoch 46/5000
41/41 - 1s - loss: 0.1372 - mae: 0.3513 - val_loss: 0.1895 - val_mae: 0.4481
Epoch 47/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3371 - val_loss: 0.1802 - val_mae: 0.3727
Epoch 48/5000
41/41 - 1s - loss: 0.1282 - mae: 0.3293 - val_loss: 0.1808 - val_mae: 0.3801
Epoch 49/5000
41/41 - 1s - loss: 0.1290 - mae: 0.3280 - val_loss: 0.1824 - val_mae: 0.4060
Epoch 50/5000
41/41 - 1s - loss: 0.1353 - mae: 0.3453 - val_loss: 0.1829 - val_mae: 0.4198
Epoch 51/5000
41/41 - 1s - loss: 0.1313 - mae: 0.3366 - val_loss: 0.1818 - val_mae: 0.3950
Epoch 52/5000
41/41 - 1s - loss: 0.1297 - mae: 0.3316 - val_loss: 0.1812 - val_mae: 0.3883
Epoch 53/5000
41/41 - 1s - loss: 0.1285 - mae: 0.3287 - val_loss: 0.1841 - val_mae: 0.4038
Epoch 54/5000
41/41 - 1s - loss: 0.1323 - mae: 0.3381 - val_loss: 0.1822 - val_mae: 0.3604
Epoch 55/5000
41/41 - 1s - loss: 0.1288 - mae: 0.3302 - val_loss: 0.1801 - val_mae: 0.3887
Epoch 56/5000
41/41 - 1s - loss: 0.1278 - mae: 0.3265 - val_loss: 0.1779 - val_mae: 0.3795
Epoch 57/5000
41/41 - 1s - loss: 0.1260 - mae: 0.3221 - val_loss: 0.1783 - val_mae: 0.3825
Epoch 58/5000
41/41 - 1s - loss: 0.1259 - mae: 0.3204 - val_loss: 0.1831 - val_mae: 0.3961
Epoch 59/5000
41/41 - 1s - loss: 0.1258 - mae: 0.3199 - val_loss: 0.1790 - val_mae: 0.3916
Epoch 60/5000
41/41 - 1s - loss: 0.1271 - mae: 0.3253 - val_loss: 0.1777 - val_mae: 0.3679
Epoch 61/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3186 - val_loss: 0.1789 - val_mae: 0.3609
Epoch 62/5000
41/41 - 1s - loss: 0.1238 - mae: 0.3167 - val_loss: 0.1777 - val_mae: 0.3699
Epoch 63/5000
41/41 - 1s - loss: 0.1236 - mae: 0.3154 - val_loss: 0.1776 - val_mae: 0.3614
Epoch 64/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3165 - val_loss: 0.1761 - val_mae: 0.3606
Epoch 65/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3156 - val_loss: 0.1776 - val_mae: 0.3542
Epoch 66/5000
41/41 - 1s - loss: 0.1243 - mae: 0.3180 - val_loss: 0.1777 - val_mae: 0.3608
Epoch 67/5000
41/41 - 1s - loss: 0.1233 - mae: 0.3160 - val_loss: 0.1776 - val_mae: 0.3748
Epoch 68/5000
41/41 - 1s - loss: 0.1233 - mae: 0.3140 - val_loss: 0.1785 - val_mae: 0.3865
Epoch 69/5000
41/41 - 1s - loss: 0.1256 - mae: 0.3200 - val_loss: 0.1760 - val_mae: 0.3758
Epoch 70/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3156 - val_loss: 0.1759 - val_mae: 0.3674
Epoch 71/5000
41/41 - 1s - loss: 0.1246 - mae: 0.3174 - val_loss: 0.1807 - val_mae: 0.3928
Epoch 72/5000
41/41 - 1s - loss: 0.1241 - mae: 0.3164 - val_loss: 0.1819 - val_mae: 0.4028
Epoch 73/5000
41/41 - 1s - loss: 0.1265 - mae: 0.3252 - val_loss: 0.1774 - val_mae: 0.3605
Epoch 74/5000
41/41 - 1s - loss: 0.1215 - mae: 0.3120 - val_loss: 0.1796 - val_mae: 0.3538
Epoch 75/5000
41/41 - 1s - loss: 0.1401 - mae: 0.3536 - val_loss: 0.1771 - val_mae: 0.3983
Epoch 76/5000
41/41 - 1s - loss: 0.1308 - mae: 0.3413 - val_loss: 0.1740 - val_mae: 0.3700
Epoch 77/5000
41/41 - 1s - loss: 0.1255 - mae: 0.3215 - val_loss: 0.1812 - val_mae: 0.4075
Epoch 78/5000
41/41 - 1s - loss: 0.1312 - mae: 0.3409 - val_loss: 0.1768 - val_mae: 0.3668
Epoch 79/5000
41/41 - 1s - loss: 0.1255 - mae: 0.3223 - val_loss: 0.1781 - val_mae: 0.3907
Epoch 80/5000
41/41 - 1s - loss: 0.1240 - mae: 0.3196 - val_loss: 0.1769 - val_mae: 0.3633
Epoch 81/5000
41/41 - 1s - loss: 0.1222 - mae: 0.3149 - val_loss: 0.1751 - val_mae: 0.3582
Epoch 82/5000
41/41 - 1s - loss: 0.1206 - mae: 0.3103 - val_loss: 0.1767 - val_mae: 0.3685
Epoch 83/5000
41/41 - 1s - loss: 0.1214 - mae: 0.3102 - val_loss: 0.1748 - val_mae: 0.3573
Epoch 84/5000
41/41 - 1s - loss: 0.1224 - mae: 0.3141 - val_loss: 0.1797 - val_mae: 0.3810
Epoch 85/5000
41/41 - 1s - loss: 0.1205 - mae: 0.3100 - val_loss: 0.1751 - val_mae: 0.3586
Epoch 86/5000
41/41 - 1s - loss: 0.1207 - mae: 0.3089 - val_loss: 0.1760 - val_mae: 0.3692
Epoch 87/5000
41/41 - 1s - loss: 0.1206 - mae: 0.3093 - val_loss: 0.1750 - val_mae: 0.3542
Epoch 88/5000
41/41 - 1s - loss: 0.1197 - mae: 0.3071 - val_loss: 0.1773 - val_mae: 0.3490
Epoch 89/5000
41/41 - 1s - loss: 0.1208 - mae: 0.3085 - val_loss: 0.1756 - val_mae: 0.3671
Epoch 90/5000
41/41 - 1s - loss: 0.1193 - mae: 0.3061 - val_loss: 0.1758 - val_mae: 0.3591
Epoch 91/5000
41/41 - 1s - loss: 0.1194 - mae: 0.3055 - val_loss: 0.1758 - val_mae: 0.3523
Epoch 92/5000
41/41 - 1s - loss: 0.1204 - mae: 0.3085 - val_loss: 0.1746 - val_mae: 0.3642
Epoch 93/5000
41/41 - 1s - loss: 0.1195 - mae: 0.3060 - val_loss: 0.1804 - val_mae: 0.3550
Epoch 94/5000
41/41 - 1s - loss: 0.1205 - mae: 0.3096 - val_loss: 0.1762 - val_mae: 0.3612
Epoch 95/5000
41/41 - 1s - loss: 0.1249 - mae: 0.3199 - val_loss: 0.1764 - val_mae: 0.3876
Epoch 96/5000
41/41 - 1s - loss: 0.1273 - mae: 0.3272 - val_loss: 0.1805 - val_mae: 0.3923
Epoch 97/5000
41/41 - 1s - loss: 0.1213 - mae: 0.3129 - val_loss: 0.1771 - val_mae: 0.3539
Epoch 98/5000
41/41 - 1s - loss: 0.1185 - mae: 0.3042 - val_loss: 0.1768 - val_mae: 0.3636
Epoch 99/5000
41/41 - 1s - loss: 0.1185 - mae: 0.3053 - val_loss: 0.1769 - val_mae: 0.3537
Epoch 100/5000
41/41 - 1s - loss: 0.1183 - mae: 0.3046 - val_loss: 0.1753 - val_mae: 0.3551
Epoch 101/5000
41/41 - 1s - loss: 0.1239 - mae: 0.3150 - val_loss: 0.1758 - val_mae: 0.3627
Epoch 102/5000
41/41 - 1s - loss: 0.1298 - mae: 0.3337 - val_loss: 0.1748 - val_mae: 0.3652
Epoch 103/5000
41/41 - 1s - loss: 0.1406 - mae: 0.3553 - val_loss: 0.1760 - val_mae: 0.3707
Epoch 104/5000
41/41 - 1s - loss: 0.1330 - mae: 0.3435 - val_loss: 0.1835 - val_mae: 0.4447
Epoch 105/5000
41/41 - 1s - loss: 0.1302 - mae: 0.3328 - val_loss: 0.1736 - val_mae: 0.3795
Epoch 106/5000
41/41 - 1s - loss: 0.1286 - mae: 0.3301 - val_loss: 0.1759 - val_mae: 0.3848
Epoch 107/5000
41/41 - 1s - loss: 0.1204 - mae: 0.3104 - val_loss: 0.1743 - val_mae: 0.3558
Epoch 108/5000
41/41 - 1s - loss: 0.1184 - mae: 0.3033 - val_loss: 0.1741 - val_mae: 0.3602
Epoch 109/5000
41/41 - 1s - loss: 0.1182 - mae: 0.3043 - val_loss: 0.1755 - val_mae: 0.3512
Epoch 110/5000
41/41 - 1s - loss: 0.1180 - mae: 0.3024 - val_loss: 0.1775 - val_mae: 0.3492
Epoch 111/5000
41/41 - 1s - loss: 0.1190 - mae: 0.3052 - val_loss: 0.1757 - val_mae: 0.3552
Epoch 112/5000
41/41 - 1s - loss: 0.1177 - mae: 0.3025 - val_loss: 0.1748 - val_mae: 0.3528
Epoch 113/5000
41/41 - 1s - loss: 0.1175 - mae: 0.3018 - val_loss: 0.1744 - val_mae: 0.3510
Epoch 114/5000
41/41 - 1s - loss: 0.1179 - mae: 0.3023 - val_loss: 0.1766 - val_mae: 0.3467
Epoch 115/5000
41/41 - 1s - loss: 0.1471 - mae: 0.3692 - val_loss: 0.1973 - val_mae: 0.4853
Epoch 116/5000
41/41 - 1s - loss: 0.1348 - mae: 0.3458 - val_loss: 0.1744 - val_mae: 0.4007
Epoch 117/5000
41/41 - 1s - loss: 0.1305 - mae: 0.3397 - val_loss: 0.1751 - val_mae: 0.4018
Epoch 118/5000
41/41 - 1s - loss: 0.1259 - mae: 0.3227 - val_loss: 0.1832 - val_mae: 0.4198
Epoch 119/5000
41/41 - 1s - loss: 0.1308 - mae: 0.3396 - val_loss: 0.1765 - val_mae: 0.3765
Epoch 120/5000
41/41 - 1s - loss: 0.1227 - mae: 0.3174 - val_loss: 0.1752 - val_mae: 0.3616
Epoch 121/5000
41/41 - 1s - loss: 0.1209 - mae: 0.3100 - val_loss: 0.1793 - val_mae: 0.3869
Epoch 122/5000
41/41 - 1s - loss: 0.1219 - mae: 0.3134 - val_loss: 0.1855 - val_mae: 0.4215
Epoch 123/5000
41/41 - 1s - loss: 0.1262 - mae: 0.3290 - val_loss: 0.1800 - val_mae: 0.3549
Epoch 124/5000
41/41 - 1s - loss: 0.1211 - mae: 0.3098 - val_loss: 0.1746 - val_mae: 0.3570
Epoch 125/5000
41/41 - 1s - loss: 0.1201 - mae: 0.3115 - val_loss: 0.1765 - val_mae: 0.3477
Epoch 126/5000
41/41 - 1s - loss: 0.1195 - mae: 0.3069 - val_loss: 0.1747 - val_mae: 0.3523
Epoch 127/5000
41/41 - 1s - loss: 0.1186 - mae: 0.3041 - val_loss: 0.1737 - val_mae: 0.3544
Epoch 128/5000
41/41 - 1s - loss: 0.1210 - mae: 0.3088 - val_loss: 0.1775 - val_mae: 0.3530
Epoch 129/5000
41/41 - 1s - loss: 0.1314 - mae: 0.3381 - val_loss: 0.1773 - val_mae: 0.3504
Epoch 130/5000
41/41 - 1s - loss: 0.1390 - mae: 0.3550 - val_loss: 0.1921 - val_mae: 0.4493
Epoch 131/5000
41/41 - 1s - loss: 0.1323 - mae: 0.3349 - val_loss: 0.1836 - val_mae: 0.4340
Epoch 132/5000
41/41 - 1s - loss: 0.1333 - mae: 0.3427 - val_loss: 0.2078 - val_mae: 0.4890
Epoch 133/5000
41/41 - 1s - loss: 0.1249 - mae: 0.3240 - val_loss: 0.1792 - val_mae: 0.3978
Epoch 134/5000
41/41 - 1s - loss: 0.1293 - mae: 0.3294 - val_loss: 0.1976 - val_mae: 0.4682
Epoch 135/5000
41/41 - 1s - loss: 0.1304 - mae: 0.3300 - val_loss: 0.2116 - val_mae: 0.5082
Epoch 136/5000
41/41 - 1s - loss: 0.1276 - mae: 0.3296 - val_loss: 0.1961 - val_mae: 0.4531
Epoch 137/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3225 - val_loss: 0.2205 - val_mae: 0.5199
Epoch 138/5000
41/41 - 1s - loss: 0.1266 - mae: 0.3244 - val_loss: 0.2128 - val_mae: 0.5184
Epoch 139/5000
41/41 - 1s - loss: 0.1257 - mae: 0.3212 - val_loss: 0.1936 - val_mae: 0.4442
Epoch 140/5000
41/41 - 1s - loss: 0.1267 - mae: 0.3232 - val_loss: 0.1989 - val_mae: 0.4704
Epoch 141/5000
41/41 - 1s - loss: 0.1255 - mae: 0.3223 - val_loss: 0.2171 - val_mae: 0.5104
Epoch 142/5000
41/41 - 1s - loss: 0.1244 - mae: 0.3187 - val_loss: 0.2179 - val_mae: 0.5102
Epoch 143/5000
41/41 - 1s - loss: 0.1260 - mae: 0.3250 - val_loss: 0.1985 - val_mae: 0.4572
Epoch 144/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3149 - val_loss: 0.2144 - val_mae: 0.5077
Epoch 145/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3188 - val_loss: 0.2103 - val_mae: 0.4864
Epoch 146/5000
41/41 - 1s - loss: 0.1235 - mae: 0.3140 - val_loss: 0.2116 - val_mae: 0.4959
Epoch 147/5000
41/41 - 1s - loss: 0.1237 - mae: 0.3179 - val_loss: 0.1923 - val_mae: 0.4367
Epoch 148/5000
41/41 - 1s - loss: 0.1231 - mae: 0.3134 - val_loss: 0.2125 - val_mae: 0.4983
Epoch 149/5000
41/41 - 1s - loss: 0.1245 - mae: 0.3195 - val_loss: 0.2045 - val_mae: 0.4769
Epoch 150/5000
41/41 - 1s - loss: 0.1226 - mae: 0.3145 - val_loss: 0.2002 - val_mae: 0.4594
Epoch 151/5000
41/41 - 1s - loss: 0.1204 - mae: 0.3080 - val_loss: 0.2053 - val_mae: 0.4758
Epoch 152/5000
41/41 - 1s - loss: 0.1221 - mae: 0.3113 - val_loss: 0.2170 - val_mae: 0.5085
Epoch 153/5000
41/41 - 1s - loss: 0.1213 - mae: 0.3123 - val_loss: 0.2059 - val_mae: 0.4761
Epoch 154/5000
41/41 - 1s - loss: 0.1223 - mae: 0.3121 - val_loss: 0.2194 - val_mae: 0.5113
Epoch 155/5000
41/41 - 1s - loss: 0.1235 - mae: 0.3181 - val_loss: 0.1852 - val_mae: 0.4119
Epoch 156/5000
41/41 - 1s - loss: 0.1197 - mae: 0.3072 - val_loss: 0.2090 - val_mae: 0.4841
Epoch 157/5000
41/41 - 1s - loss: 0.1212 - mae: 0.3120 - val_loss: 0.2112 - val_mae: 0.4942
Epoch 158/5000
41/41 - 1s - loss: 0.1216 - mae: 0.3106 - val_loss: 0.2131 - val_mae: 0.4946
Epoch 159/5000
41/41 - 1s - loss: 0.1229 - mae: 0.3159 - val_loss: 0.1883 - val_mae: 0.4214
Epoch 160/5000
41/41 - 1s - loss: 0.1218 - mae: 0.3104 - val_loss: 0.2138 - val_mae: 0.4997
Epoch 161/5000
41/41 - 1s - loss: 0.1223 - mae: 0.3150 - val_loss: 0.2013 - val_mae: 0.4574
Epoch 162/5000
41/41 - 1s - loss: 0.1190 - mae: 0.3045 - val_loss: 0.2019 - val_mae: 0.4659
Epoch 163/5000
41/41 - 1s - loss: 0.1187 - mae: 0.3040 - val_loss: 0.2015 - val_mae: 0.4605
Epoch 164/5000
41/41 - 1s - loss: 0.1188 - mae: 0.3034 - val_loss: 0.2127 - val_mae: 0.4950
Epoch 165/5000
41/41 - 1s - loss: 0.1205 - mae: 0.3106 - val_loss: 0.2028 - val_mae: 0.4610
Epoch 166/5000
41/41 - 1s - loss: 0.1182 - mae: 0.3021 - val_loss: 0.2042 - val_mae: 0.4687
Epoch 167/5000
41/41 - 1s - loss: 0.1190 - mae: 0.3056 - val_loss: 0.2043 - val_mae: 0.4744
Epoch 168/5000
41/41 - 1s - loss: 0.1196 - mae: 0.3057 - val_loss: 0.2219 - val_mae: 0.5176
Epoch 169/5000
41/41 - 1s - loss: 0.1233 - mae: 0.3148 - val_loss: 0.2015 - val_mae: 0.4612
Epoch 170/5000
41/41 - 1s - loss: 0.1191 - mae: 0.3048 - val_loss: 0.2114 - val_mae: 0.4972
Epoch 171/5000
41/41 - 1s - loss: 0.1221 - mae: 0.3136 - val_loss: 0.2036 - val_mae: 0.4640
Epoch 172/5000
41/41 - 1s - loss: 0.1193 - mae: 0.3056 - val_loss: 0.2043 - val_mae: 0.4651
Epoch 173/5000
41/41 - 1s - loss: 0.1191 - mae: 0.3040 - val_loss: 0.1970 - val_mae: 0.4503
Epoch 174/5000
41/41 - 1s - loss: 0.1179 - mae: 0.3032 - val_loss: 0.2065 - val_mae: 0.4698
Epoch 175/5000
41/41 - 1s - loss: 0.1188 - mae: 0.3031 - val_loss: 0.2065 - val_mae: 0.4799
Epoch 176/5000
41/41 - 1s - loss: 0.1217 - mae: 0.3151 - val_loss: 0.1832 - val_mae: 0.3917
Epoch 177/5000
41/41 - 1s - loss: 0.1139 - mae: 0.2917 - val_loss: 0.1937 - val_mae: 0.4343
Epoch 178/5000
41/41 - 1s - loss: 0.1170 - mae: 0.2994 - val_loss: 0.2079 - val_mae: 0.4829
Epoch 179/5000
41/41 - 1s - loss: 0.1170 - mae: 0.3014 - val_loss: 0.1948 - val_mae: 0.4495
Epoch 180/5000
41/41 - 1s - loss: 0.1163 - mae: 0.3002 - val_loss: 0.2023 - val_mae: 0.4595
Epoch 181/5000
41/41 - 1s - loss: 0.1162 - mae: 0.2983 - val_loss: 0.1958 - val_mae: 0.4442
Epoch 182/5000
41/41 - 1s - loss: 0.1151 - mae: 0.2942 - val_loss: 0.2031 - val_mae: 0.4645
Epoch 183/5000
41/41 - 1s - loss: 0.1147 - mae: 0.2959 - val_loss: 0.2012 - val_mae: 0.4600
Epoch 184/5000
41/41 - 1s - loss: 0.1147 - mae: 0.2952 - val_loss: 0.1959 - val_mae: 0.4383
Epoch 185/5000
41/41 - 1s - loss: 0.1150 - mae: 0.2936 - val_loss: 0.2039 - val_mae: 0.4683
Epoch 186/5000
41/41 - 1s - loss: 0.1177 - mae: 0.3005 - val_loss: 0.2006 - val_mae: 0.4577
Epoch 187/5000
41/41 - 1s - loss: 0.1153 - mae: 0.2953 - val_loss: 0.1894 - val_mae: 0.4229
Epoch 188/5000
41/41 - 1s - loss: 0.1146 - mae: 0.2926 - val_loss: 0.1970 - val_mae: 0.4463
Epoch 189/5000
41/41 - 1s - loss: 0.1157 - mae: 0.2961 - val_loss: 0.1933 - val_mae: 0.4355
Epoch 190/5000
41/41 - 1s - loss: 0.1136 - mae: 0.2921 - val_loss: 0.1924 - val_mae: 0.4299
Epoch 191/5000
41/41 - 1s - loss: 0.1130 - mae: 0.2901 - val_loss: 0.1925 - val_mae: 0.4300
Epoch 192/5000
41/41 - 1s - loss: 0.1142 - mae: 0.2922 - val_loss: 0.1909 - val_mae: 0.4273
Epoch 193/5000
41/41 - 1s - loss: 0.1119 - mae: 0.2884 - val_loss: 0.1897 - val_mae: 0.4234
Epoch 194/5000
41/41 - 1s - loss: 0.1137 - mae: 0.2938 - val_loss: 0.1909 - val_mae: 0.4260
Epoch 195/5000
41/41 - 1s - loss: 0.1189 - mae: 0.3055 - val_loss: 0.1986 - val_mae: 0.4437
Epoch 196/5000
41/41 - 1s - loss: 0.1179 - mae: 0.3040 - val_loss: 0.2125 - val_mae: 0.4820
Epoch 197/5000
41/41 - 1s - loss: 0.1195 - mae: 0.3099 - val_loss: 0.2005 - val_mae: 0.4496
Epoch 198/5000
41/41 - 1s - loss: 0.1173 - mae: 0.3043 - val_loss: 0.2235 - val_mae: 0.5142
Epoch 199/5000
41/41 - 1s - loss: 0.1192 - mae: 0.3093 - val_loss: 0.2109 - val_mae: 0.4807
Epoch 200/5000
41/41 - 1s - loss: 0.1158 - mae: 0.3000 - val_loss: 0.2076 - val_mae: 0.4660
Epoch 201/5000
41/41 - 1s - loss: 0.1160 - mae: 0.2990 - val_loss: 0.2160 - val_mae: 0.4930
Epoch 202/5000
41/41 - 1s - loss: 0.1211 - mae: 0.3134 - val_loss: 0.1871 - val_mae: 0.4130
Epoch 203/5000
41/41 - 1s - loss: 0.1122 - mae: 0.2902 - val_loss: 0.2012 - val_mae: 0.4377
Epoch 204/5000
41/41 - 1s - loss: 0.1157 - mae: 0.2986 - val_loss: 0.1998 - val_mae: 0.4404
Epoch 205/5000
41/41 - 1s - loss: 0.1165 - mae: 0.3009 - val_loss: 0.1951 - val_mae: 0.4298
Epoch 206/5000
41/41 - 1s - loss: 0.1167 - mae: 0.3023 - val_loss: 0.1860 - val_mae: 0.3899
Epoch 207/5000
41/41 - 1s - loss: 0.1118 - mae: 0.2878 - val_loss: 0.1834 - val_mae: 0.3815
Epoch 208/5000
41/41 - 1s - loss: 0.1119 - mae: 0.2879 - val_loss: 0.2046 - val_mae: 0.4426
Epoch 209/5000
41/41 - 1s - loss: 0.1112 - mae: 0.2880 - val_loss: 0.2015 - val_mae: 0.4408
Epoch 210/5000
41/41 - 1s - loss: 0.1103 - mae: 0.2864 - val_loss: 0.2034 - val_mae: 0.4457
Epoch 211/5000
41/41 - 1s - loss: 0.1135 - mae: 0.2941 - val_loss: 0.1870 - val_mae: 0.3947
Epoch 212/5000
41/41 - 1s - loss: 0.1123 - mae: 0.2912 - val_loss: 0.1882 - val_mae: 0.4109
Epoch 213/5000
41/41 - 1s - loss: 0.1126 - mae: 0.2931 - val_loss: 0.1895 - val_mae: 0.4152
Epoch 214/5000
41/41 - 1s - loss: 0.1128 - mae: 0.2920 - val_loss: 0.1845 - val_mae: 0.3915
Epoch 215/5000
41/41 - 1s - loss: 0.1132 - mae: 0.2926 - val_loss: 0.1876 - val_mae: 0.4240
Restoring model weights from the end of the best epoch.
Epoch 00215: early stopping
Saving training information..
Saving model weights to process/trained_model_weights/weights_transfer_9..

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Fine-tuning.
Model: "model_49"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
atom_features_0 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_0 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_0 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
atom_features_1 (InputLayer)    [(None, 29)]         0                                            
__________________________________________________________________________________________________
bond_features_1 (InputLayer)    [(None, 7)]          0                                            
__________________________________________________________________________________________________
pair_indices_1 (InputLayer)     [(None, 2)]          0                                            
__________________________________________________________________________________________________
message_passing_9 (MessagePassi (None, 64)           57728       atom_features_0[0][0]            
                                                                 bond_features_0[0][0]            
                                                                 pair_indices_0[0][0]             
                                                                 atom_features_1[0][0]            
                                                                 bond_features_1[0][0]            
                                                                 pair_indices_1[0][0]             
__________________________________________________________________________________________________
atom_partition_indices_0 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
atom_partition_indices_1 (Input [(None,)]            0                                            
__________________________________________________________________________________________________
partition_padding_9 (PartitionP (None, None, 64)     0           message_passing_9[0][0]          
                                                                 atom_partition_indices_0[0][0]   
                                                                 message_passing_9[1][0]          
                                                                 atom_partition_indices_1[0][0]   
__________________________________________________________________________________________________
masking_9 (Masking)             (None, None, 64)     0           partition_padding_9[0][0]        
                                                                 partition_padding_9[1][0]        
__________________________________________________________________________________________________
transformer_encoder_9 (Transfor (None, None, 64)     199040      masking_9[0][0]                  
                                                                 masking_9[1][0]                  
__________________________________________________________________________________________________
r_group_mapping (InputLayer)    [(None, 50)]         0                                            
__________________________________________________________________________________________________
global_average_pooling1d_9 (Glo (None, 64)           0           transformer_encoder_9[0][0]      
                                                                 transformer_encoder_9[1][0]      
__________________________________________________________________________________________________
dense_157 (Dense)               (None, 10)           510         r_group_mapping[0][0]            
__________________________________________________________________________________________________
dense_155 (Dense)               (None, 512)          33280       global_average_pooling1d_9[0][0] 
                                                                 global_average_pooling1d_9[1][0] 
__________________________________________________________________________________________________
dense_158 (Dense)               (None, 10)           110         dense_157[0][0]                  
__________________________________________________________________________________________________
dense_156 (Dense)               (None, 450)          230850      dense_155[0][0]                  
                                                                 dense_155[1][0]                  
__________________________________________________________________________________________________
dense_159 (Dense)               (None, 5)            55          dense_158[0][0]                  
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 905)          0           dense_156[0][0]                  
                                                                 dense_156[1][0]                  
                                                                 dense_159[0][0]                  
__________________________________________________________________________________________________
dense_160 (Dense)               (None, 700)          634200      concatenate_9[0][0]              
__________________________________________________________________________________________________
dense_164 (Dense)               (None, 560)          392560      dense_160[0][0]                  
__________________________________________________________________________________________________
dense_165 (Dense)               (None, 373)          209253      dense_164[0][0]                  
__________________________________________________________________________________________________
dense_166 (Dense)               (None, 187)          69938       dense_165[0][0]                  
__________________________________________________________________________________________________
dense_167 (Dense)               (None, 1)            188         dense_166[0][0]                  
==================================================================================================
Total params: 1,827,712
Trainable params: 1,827,712
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/5000
41/41 - 6s - loss: 0.1414 - mae: 0.3432 - val_loss: 0.1714 - val_mae: 0.3771
Epoch 2/5000
41/41 - 1s - loss: 0.1203 - mae: 0.3113 - val_loss: 0.1685 - val_mae: 0.3529
Epoch 3/5000
41/41 - 1s - loss: 0.1149 - mae: 0.3012 - val_loss: 0.1684 - val_mae: 0.3552
Epoch 4/5000
41/41 - 1s - loss: 0.1112 - mae: 0.2908 - val_loss: 0.1700 - val_mae: 0.3599
Epoch 5/5000
41/41 - 1s - loss: 0.1076 - mae: 0.2819 - val_loss: 0.1698 - val_mae: 0.3613
Epoch 6/5000
41/41 - 1s - loss: 0.1053 - mae: 0.2767 - val_loss: 0.1671 - val_mae: 0.3587
Epoch 7/5000
41/41 - 1s - loss: 0.1023 - mae: 0.2705 - val_loss: 0.1688 - val_mae: 0.3694
Epoch 8/5000
41/41 - 1s - loss: 0.1007 - mae: 0.2663 - val_loss: 0.1726 - val_mae: 0.3829
Epoch 9/5000
41/41 - 1s - loss: 0.0995 - mae: 0.2627 - val_loss: 0.1777 - val_mae: 0.4018
Epoch 10/5000
41/41 - 1s - loss: 0.0988 - mae: 0.2613 - val_loss: 0.1716 - val_mae: 0.3807
Epoch 11/5000
41/41 - 1s - loss: 0.0991 - mae: 0.2632 - val_loss: 0.1681 - val_mae: 0.3552
Epoch 12/5000
41/41 - 1s - loss: 0.0977 - mae: 0.2614 - val_loss: 0.1670 - val_mae: 0.3530
Epoch 13/5000
41/41 - 1s - loss: 0.0951 - mae: 0.2570 - val_loss: 0.1686 - val_mae: 0.3544
Epoch 14/5000
41/41 - 1s - loss: 0.0916 - mae: 0.2482 - val_loss: 0.1789 - val_mae: 0.3875
Epoch 15/5000
41/41 - 1s - loss: 0.0901 - mae: 0.2438 - val_loss: 0.1965 - val_mae: 0.4318
Epoch 16/5000
41/41 - 1s - loss: 0.0886 - mae: 0.2409 - val_loss: 0.2117 - val_mae: 0.4577
Epoch 17/5000
41/41 - 1s - loss: 0.0891 - mae: 0.2410 - val_loss: 0.2121 - val_mae: 0.4578
Epoch 18/5000
41/41 - 1s - loss: 0.0932 - mae: 0.2505 - val_loss: 0.1733 - val_mae: 0.3659
Epoch 19/5000
41/41 - 1s - loss: 0.0904 - mae: 0.2457 - val_loss: 0.1620 - val_mae: 0.3492
Epoch 20/5000
41/41 - 1s - loss: 0.0873 - mae: 0.2393 - val_loss: 0.1635 - val_mae: 0.3458
Epoch 21/5000
41/41 - 1s - loss: 0.0832 - mae: 0.2312 - val_loss: 0.1725 - val_mae: 0.3739
Epoch 22/5000
41/41 - 1s - loss: 0.0807 - mae: 0.2236 - val_loss: 0.1752 - val_mae: 0.3723
Epoch 23/5000
41/41 - 1s - loss: 0.0799 - mae: 0.2213 - val_loss: 0.1720 - val_mae: 0.3637
Epoch 24/5000
41/41 - 1s - loss: 0.0784 - mae: 0.2202 - val_loss: 0.1717 - val_mae: 0.3569
Epoch 25/5000
41/41 - 1s - loss: 0.0785 - mae: 0.2217 - val_loss: 0.1765 - val_mae: 0.3639
Epoch 26/5000
41/41 - 1s - loss: 0.0805 - mae: 0.2268 - val_loss: 0.1654 - val_mae: 0.3369
Epoch 27/5000
41/41 - 1s - loss: 0.0800 - mae: 0.2295 - val_loss: 0.1620 - val_mae: 0.3393
Epoch 28/5000
41/41 - 1s - loss: 0.0780 - mae: 0.2290 - val_loss: 0.1734 - val_mae: 0.3647
Epoch 29/5000
41/41 - 1s - loss: 0.0768 - mae: 0.2237 - val_loss: 0.1891 - val_mae: 0.4035
Epoch 30/5000
41/41 - 1s - loss: 0.0762 - mae: 0.2244 - val_loss: 0.1674 - val_mae: 0.3544
Epoch 31/5000
41/41 - 1s - loss: 0.0767 - mae: 0.2229 - val_loss: 0.1663 - val_mae: 0.3449
Epoch 32/5000
41/41 - 1s - loss: 0.0767 - mae: 0.2242 - val_loss: 0.1635 - val_mae: 0.3300
Epoch 33/5000
41/41 - 1s - loss: 0.0777 - mae: 0.2271 - val_loss: 0.1640 - val_mae: 0.3259
Epoch 34/5000
41/41 - 1s - loss: 0.0848 - mae: 0.2409 - val_loss: 0.1616 - val_mae: 0.3240
Epoch 35/5000
41/41 - 1s - loss: 0.0769 - mae: 0.2256 - val_loss: 0.1600 - val_mae: 0.3259
Epoch 36/5000
41/41 - 1s - loss: 0.0764 - mae: 0.2234 - val_loss: 0.1696 - val_mae: 0.3273
Epoch 37/5000
41/41 - 1s - loss: 0.0814 - mae: 0.2355 - val_loss: 0.1624 - val_mae: 0.3419
Epoch 38/5000
41/41 - 1s - loss: 0.0779 - mae: 0.2275 - val_loss: 0.1993 - val_mae: 0.4346
Epoch 39/5000
41/41 - 1s - loss: 0.0696 - mae: 0.2086 - val_loss: 0.1893 - val_mae: 0.4016
Epoch 40/5000
41/41 - 1s - loss: 0.0642 - mae: 0.1957 - val_loss: 0.1649 - val_mae: 0.3364
Epoch 41/5000
41/41 - 1s - loss: 0.0645 - mae: 0.1962 - val_loss: 0.1576 - val_mae: 0.3219
Epoch 42/5000
41/41 - 1s - loss: 0.0596 - mae: 0.1857 - val_loss: 0.1615 - val_mae: 0.3231
Epoch 43/5000
41/41 - 1s - loss: 0.0637 - mae: 0.1986 - val_loss: 0.1615 - val_mae: 0.3252
Epoch 44/5000
41/41 - 1s - loss: 0.0628 - mae: 0.1950 - val_loss: 0.1559 - val_mae: 0.3168
Epoch 45/5000
41/41 - 1s - loss: 0.0618 - mae: 0.1926 - val_loss: 0.1558 - val_mae: 0.3210
Epoch 46/5000
41/41 - 1s - loss: 0.0664 - mae: 0.2059 - val_loss: 0.1632 - val_mae: 0.3497
Epoch 47/5000
41/41 - 1s - loss: 0.0734 - mae: 0.2180 - val_loss: 0.1974 - val_mae: 0.4405
Epoch 48/5000
41/41 - 1s - loss: 0.0759 - mae: 0.2239 - val_loss: 0.1714 - val_mae: 0.3649
Epoch 49/5000
41/41 - 1s - loss: 0.0618 - mae: 0.1964 - val_loss: 0.1669 - val_mae: 0.3510
Epoch 50/5000
41/41 - 1s - loss: 0.0579 - mae: 0.1842 - val_loss: 0.1581 - val_mae: 0.3258
Epoch 51/5000
41/41 - 1s - loss: 0.0587 - mae: 0.1870 - val_loss: 0.1593 - val_mae: 0.3354
Epoch 52/5000
41/41 - 1s - loss: 0.0598 - mae: 0.1910 - val_loss: 0.1768 - val_mae: 0.3660
Epoch 53/5000
41/41 - 1s - loss: 0.0636 - mae: 0.1983 - val_loss: 0.2082 - val_mae: 0.4442
Epoch 54/5000
41/41 - 1s - loss: 0.0626 - mae: 0.1979 - val_loss: 0.2154 - val_mae: 0.4342
Epoch 55/5000
41/41 - 1s - loss: 0.0614 - mae: 0.1968 - val_loss: 0.1888 - val_mae: 0.3890
Epoch 56/5000
41/41 - 1s - loss: 0.0660 - mae: 0.2072 - val_loss: 0.1559 - val_mae: 0.3140
Epoch 57/5000
41/41 - 1s - loss: 0.0629 - mae: 0.2011 - val_loss: 0.1589 - val_mae: 0.3124
Epoch 58/5000
41/41 - 1s - loss: 0.0664 - mae: 0.2090 - val_loss: 0.1736 - val_mae: 0.3724
Epoch 59/5000
41/41 - 1s - loss: 0.0643 - mae: 0.2017 - val_loss: 0.1769 - val_mae: 0.3687
Epoch 60/5000
41/41 - 1s - loss: 0.0666 - mae: 0.2123 - val_loss: 0.1570 - val_mae: 0.3133
Epoch 61/5000
41/41 - 1s - loss: 0.0604 - mae: 0.1958 - val_loss: 0.1691 - val_mae: 0.3352
Epoch 62/5000
41/41 - 1s - loss: 0.0576 - mae: 0.1885 - val_loss: 0.1723 - val_mae: 0.3501
Epoch 63/5000
41/41 - 1s - loss: 0.0604 - mae: 0.1938 - val_loss: 0.1591 - val_mae: 0.3136
Epoch 64/5000
41/41 - 1s - loss: 0.0539 - mae: 0.1772 - val_loss: 0.1571 - val_mae: 0.3094
Epoch 65/5000
41/41 - 1s - loss: 0.0620 - mae: 0.1981 - val_loss: 0.1613 - val_mae: 0.3234
Epoch 66/5000
41/41 - 1s - loss: 0.0618 - mae: 0.1958 - val_loss: 0.1649 - val_mae: 0.3376
Epoch 67/5000
41/41 - 1s - loss: 0.0594 - mae: 0.1913 - val_loss: 0.1560 - val_mae: 0.3107
Epoch 68/5000
41/41 - 1s - loss: 0.0538 - mae: 0.1798 - val_loss: 0.1560 - val_mae: 0.3161
Epoch 69/5000
41/41 - 1s - loss: 0.0552 - mae: 0.1810 - val_loss: 0.1568 - val_mae: 0.3293
Epoch 70/5000
41/41 - 1s - loss: 0.0532 - mae: 0.1771 - val_loss: 0.1617 - val_mae: 0.3325
Epoch 71/5000
41/41 - 1s - loss: 0.0500 - mae: 0.1696 - val_loss: 0.1576 - val_mae: 0.3204
Epoch 72/5000
41/41 - 1s - loss: 0.0477 - mae: 0.1634 - val_loss: 0.1563 - val_mae: 0.3141
Epoch 73/5000
41/41 - 1s - loss: 0.0478 - mae: 0.1654 - val_loss: 0.1758 - val_mae: 0.3559
Epoch 74/5000
41/41 - 1s - loss: 0.0561 - mae: 0.1833 - val_loss: 0.1675 - val_mae: 0.3356
Epoch 75/5000
41/41 - 1s - loss: 0.0538 - mae: 0.1783 - val_loss: 0.1555 - val_mae: 0.3078
Epoch 76/5000
41/41 - 1s - loss: 0.0476 - mae: 0.1650 - val_loss: 0.1548 - val_mae: 0.3056
Epoch 77/5000
41/41 - 1s - loss: 0.0531 - mae: 0.1789 - val_loss: 0.1624 - val_mae: 0.3273
Epoch 78/5000
41/41 - 1s - loss: 0.0548 - mae: 0.1792 - val_loss: 0.1590 - val_mae: 0.3174
Epoch 79/5000
41/41 - 1s - loss: 0.0530 - mae: 0.1798 - val_loss: 0.1558 - val_mae: 0.3082
Epoch 80/5000
41/41 - 1s - loss: 0.0505 - mae: 0.1748 - val_loss: 0.1548 - val_mae: 0.3085
Epoch 81/5000
41/41 - 1s - loss: 0.0557 - mae: 0.1859 - val_loss: 0.1571 - val_mae: 0.3126
Epoch 82/5000
41/41 - 1s - loss: 0.0535 - mae: 0.1793 - val_loss: 0.1552 - val_mae: 0.3037
Epoch 83/5000
41/41 - 1s - loss: 0.0486 - mae: 0.1697 - val_loss: 0.1553 - val_mae: 0.3037
Epoch 84/5000
41/41 - 1s - loss: 0.0561 - mae: 0.1890 - val_loss: 0.1588 - val_mae: 0.3109
Epoch 85/5000
41/41 - 1s - loss: 0.0513 - mae: 0.1782 - val_loss: 0.1586 - val_mae: 0.3059
Epoch 86/5000
41/41 - 1s - loss: 0.0487 - mae: 0.1717 - val_loss: 0.1594 - val_mae: 0.3074
Epoch 87/5000
41/41 - 1s - loss: 0.0522 - mae: 0.1809 - val_loss: 0.1586 - val_mae: 0.3068
Epoch 88/5000
41/41 - 1s - loss: 0.0526 - mae: 0.1821 - val_loss: 0.1555 - val_mae: 0.3037
Epoch 89/5000
41/41 - 1s - loss: 0.0581 - mae: 0.1945 - val_loss: 0.1613 - val_mae: 0.3121
Epoch 90/5000
41/41 - 1s - loss: 0.0561 - mae: 0.1907 - val_loss: 0.1618 - val_mae: 0.3145
Epoch 91/5000
41/41 - 1s - loss: 0.0605 - mae: 0.1980 - val_loss: 0.1565 - val_mae: 0.3083
Epoch 92/5000
41/41 - 1s - loss: 0.0599 - mae: 0.1977 - val_loss: 0.1552 - val_mae: 0.3218
Epoch 93/5000
41/41 - 1s - loss: 0.0590 - mae: 0.1992 - val_loss: 0.1572 - val_mae: 0.3377
Epoch 94/5000
41/41 - 1s - loss: 0.0566 - mae: 0.1926 - val_loss: 0.1568 - val_mae: 0.3296
Epoch 95/5000
41/41 - 1s - loss: 0.0529 - mae: 0.1848 - val_loss: 0.1567 - val_mae: 0.3199
Epoch 96/5000
41/41 - 1s - loss: 0.0560 - mae: 0.1930 - val_loss: 0.1686 - val_mae: 0.3733
Epoch 97/5000
41/41 - 1s - loss: 0.0542 - mae: 0.1874 - val_loss: 0.1894 - val_mae: 0.4261
Epoch 98/5000
41/41 - 1s - loss: 0.0598 - mae: 0.1975 - val_loss: 0.1720 - val_mae: 0.3862
Epoch 99/5000
41/41 - 1s - loss: 0.0488 - mae: 0.1691 - val_loss: 0.1688 - val_mae: 0.3663
Epoch 100/5000
41/41 - 1s - loss: 0.0445 - mae: 0.1619 - val_loss: 0.1704 - val_mae: 0.3574
Epoch 101/5000
41/41 - 1s - loss: 0.0422 - mae: 0.1519 - val_loss: 0.1560 - val_mae: 0.3204
Epoch 102/5000
41/41 - 1s - loss: 0.0396 - mae: 0.1463 - val_loss: 0.1687 - val_mae: 0.3474
Epoch 103/5000
41/41 - 1s - loss: 0.0382 - mae: 0.1420 - val_loss: 0.1681 - val_mae: 0.3456
Epoch 104/5000
41/41 - 1s - loss: 0.0370 - mae: 0.1353 - val_loss: 0.1615 - val_mae: 0.3298
Epoch 105/5000
41/41 - 1s - loss: 0.0367 - mae: 0.1363 - val_loss: 0.1602 - val_mae: 0.3307
Epoch 106/5000
41/41 - 1s - loss: 0.0367 - mae: 0.1342 - val_loss: 0.1561 - val_mae: 0.3226
Epoch 107/5000
41/41 - 1s - loss: 0.0360 - mae: 0.1321 - val_loss: 0.1575 - val_mae: 0.3242
Epoch 108/5000
41/41 - 1s - loss: 0.0348 - mae: 0.1292 - val_loss: 0.1664 - val_mae: 0.3426
Epoch 109/5000
41/41 - 1s - loss: 0.0357 - mae: 0.1315 - val_loss: 0.1551 - val_mae: 0.3199
Epoch 110/5000
41/41 - 1s - loss: 0.0346 - mae: 0.1292 - val_loss: 0.1505 - val_mae: 0.3083
Epoch 111/5000
41/41 - 1s - loss: 0.0346 - mae: 0.1286 - val_loss: 0.1556 - val_mae: 0.3191
Epoch 112/5000
41/41 - 1s - loss: 0.0340 - mae: 0.1274 - val_loss: 0.1635 - val_mae: 0.3369
Epoch 113/5000
41/41 - 1s - loss: 0.0350 - mae: 0.1294 - val_loss: 0.1677 - val_mae: 0.3485
Epoch 114/5000
41/41 - 1s - loss: 0.0340 - mae: 0.1281 - val_loss: 0.1539 - val_mae: 0.3132
Epoch 115/5000
41/41 - 1s - loss: 0.0342 - mae: 0.1269 - val_loss: 0.1486 - val_mae: 0.2996
Epoch 116/5000
41/41 - 1s - loss: 0.0354 - mae: 0.1347 - val_loss: 0.1484 - val_mae: 0.2981
Epoch 117/5000
41/41 - 1s - loss: 0.0359 - mae: 0.1364 - val_loss: 0.1740 - val_mae: 0.3796
Epoch 118/5000
41/41 - 1s - loss: 0.0363 - mae: 0.1349 - val_loss: 0.1842 - val_mae: 0.3892
Epoch 119/5000
41/41 - 1s - loss: 0.0373 - mae: 0.1415 - val_loss: 0.1601 - val_mae: 0.3296
Epoch 120/5000
41/41 - 1s - loss: 0.0365 - mae: 0.1391 - val_loss: 0.1481 - val_mae: 0.2987
Epoch 121/5000
41/41 - 1s - loss: 0.0375 - mae: 0.1413 - val_loss: 0.1547 - val_mae: 0.3263
Epoch 122/5000
41/41 - 1s - loss: 0.0351 - mae: 0.1338 - val_loss: 0.1946 - val_mae: 0.4126
Epoch 123/5000
41/41 - 1s - loss: 0.0368 - mae: 0.1384 - val_loss: 0.1657 - val_mae: 0.3393
Epoch 124/5000
41/41 - 1s - loss: 0.0334 - mae: 0.1294 - val_loss: 0.1534 - val_mae: 0.3176
Epoch 125/5000
41/41 - 1s - loss: 0.0317 - mae: 0.1219 - val_loss: 0.1539 - val_mae: 0.3232
Epoch 126/5000
41/41 - 1s - loss: 0.0306 - mae: 0.1211 - val_loss: 0.1810 - val_mae: 0.3784
Epoch 127/5000
41/41 - 1s - loss: 0.0338 - mae: 0.1283 - val_loss: 0.1838 - val_mae: 0.3859
Epoch 128/5000
41/41 - 1s - loss: 0.0381 - mae: 0.1465 - val_loss: 0.1497 - val_mae: 0.3108
Epoch 129/5000
41/41 - 1s - loss: 0.0331 - mae: 0.1278 - val_loss: 0.1575 - val_mae: 0.3365
Epoch 130/5000
41/41 - 1s - loss: 0.0313 - mae: 0.1225 - val_loss: 0.1768 - val_mae: 0.3787
Epoch 131/5000
41/41 - 1s - loss: 0.0316 - mae: 0.1220 - val_loss: 0.1976 - val_mae: 0.4139
Epoch 132/5000
41/41 - 1s - loss: 0.0332 - mae: 0.1284 - val_loss: 0.1759 - val_mae: 0.3674
Epoch 133/5000
41/41 - 1s - loss: 0.0352 - mae: 0.1379 - val_loss: 0.1506 - val_mae: 0.3151
Epoch 134/5000
41/41 - 1s - loss: 0.0337 - mae: 0.1306 - val_loss: 0.1509 - val_mae: 0.3127
Epoch 135/5000
41/41 - 1s - loss: 0.0334 - mae: 0.1315 - val_loss: 0.1667 - val_mae: 0.3525
Epoch 136/5000
41/41 - 1s - loss: 0.0319 - mae: 0.1241 - val_loss: 0.2032 - val_mae: 0.4270
Epoch 137/5000
41/41 - 1s - loss: 0.0347 - mae: 0.1364 - val_loss: 0.1600 - val_mae: 0.3288
Epoch 138/5000
41/41 - 1s - loss: 0.0301 - mae: 0.1229 - val_loss: 0.1698 - val_mae: 0.3595
Epoch 139/5000
41/41 - 1s - loss: 0.0311 - mae: 0.1247 - val_loss: 0.2092 - val_mae: 0.4461
Epoch 140/5000
41/41 - 1s - loss: 0.0299 - mae: 0.1213 - val_loss: 0.1733 - val_mae: 0.3630
Epoch 141/5000
41/41 - 1s - loss: 0.0277 - mae: 0.1169 - val_loss: 0.1656 - val_mae: 0.3545
Epoch 142/5000
41/41 - 1s - loss: 0.0299 - mae: 0.1223 - val_loss: 0.1513 - val_mae: 0.3250
Epoch 143/5000
41/41 - 1s - loss: 0.0306 - mae: 0.1256 - val_loss: 0.1502 - val_mae: 0.3144
Epoch 144/5000
41/41 - 1s - loss: 0.0350 - mae: 0.1379 - val_loss: 0.1614 - val_mae: 0.3560
Epoch 145/5000
41/41 - 1s - loss: 0.0343 - mae: 0.1348 - val_loss: 0.1878 - val_mae: 0.4056
Epoch 146/5000
41/41 - 1s - loss: 0.0351 - mae: 0.1389 - val_loss: 0.1657 - val_mae: 0.3407
Epoch 147/5000
41/41 - 1s - loss: 0.0397 - mae: 0.1504 - val_loss: 0.2078 - val_mae: 0.4284
Epoch 148/5000
41/41 - 1s - loss: 0.0328 - mae: 0.1326 - val_loss: 0.1715 - val_mae: 0.3656
Epoch 149/5000
41/41 - 1s - loss: 0.0356 - mae: 0.1394 - val_loss: 0.1921 - val_mae: 0.4026
Epoch 150/5000
41/41 - 1s - loss: 0.0327 - mae: 0.1328 - val_loss: 0.1614 - val_mae: 0.3428
Epoch 151/5000
41/41 - 1s - loss: 0.0370 - mae: 0.1448 - val_loss: 0.1585 - val_mae: 0.3266
Epoch 152/5000
41/41 - 1s - loss: 0.0387 - mae: 0.1429 - val_loss: 0.1610 - val_mae: 0.3362
Epoch 153/5000
41/41 - 1s - loss: 0.0361 - mae: 0.1439 - val_loss: 0.1659 - val_mae: 0.3295
Epoch 154/5000
41/41 - 1s - loss: 0.0330 - mae: 0.1294 - val_loss: 0.1567 - val_mae: 0.3148
Epoch 155/5000
41/41 - 1s - loss: 0.0366 - mae: 0.1432 - val_loss: 0.1579 - val_mae: 0.3107
Epoch 156/5000
41/41 - 1s - loss: 0.0369 - mae: 0.1462 - val_loss: 0.1594 - val_mae: 0.3095
Epoch 157/5000
41/41 - 1s - loss: 0.0377 - mae: 0.1457 - val_loss: 0.1576 - val_mae: 0.3069
Epoch 158/5000
41/41 - 1s - loss: 0.0418 - mae: 0.1564 - val_loss: 0.1591 - val_mae: 0.3072
Epoch 159/5000
41/41 - 1s - loss: 0.0483 - mae: 0.1756 - val_loss: 0.1639 - val_mae: 0.3161
Epoch 160/5000
41/41 - 1s - loss: 0.0557 - mae: 0.1918 - val_loss: 0.1648 - val_mae: 0.3252
Epoch 161/5000
41/41 - 1s - loss: 0.0550 - mae: 0.1913 - val_loss: 0.1631 - val_mae: 0.3298
Epoch 162/5000
41/41 - 1s - loss: 0.0439 - mae: 0.1623 - val_loss: 0.1754 - val_mae: 0.3563
Epoch 163/5000
41/41 - 1s - loss: 0.0333 - mae: 0.1360 - val_loss: 0.1717 - val_mae: 0.3495
Epoch 164/5000
41/41 - 1s - loss: 0.0298 - mae: 0.1284 - val_loss: 0.1644 - val_mae: 0.3346
Epoch 165/5000
41/41 - 1s - loss: 0.0279 - mae: 0.1203 - val_loss: 0.1715 - val_mae: 0.3466
Epoch 166/5000
41/41 - 1s - loss: 0.0328 - mae: 0.1373 - val_loss: 0.1588 - val_mae: 0.3345
Epoch 167/5000
41/41 - 1s - loss: 0.0268 - mae: 0.1195 - val_loss: 0.1593 - val_mae: 0.3357
Epoch 168/5000
41/41 - 1s - loss: 0.0254 - mae: 0.1153 - val_loss: 0.1585 - val_mae: 0.3328
Epoch 169/5000
41/41 - 1s - loss: 0.0240 - mae: 0.1082 - val_loss: 0.1548 - val_mae: 0.3212
Epoch 170/5000
41/41 - 1s - loss: 0.0226 - mae: 0.1039 - val_loss: 0.1688 - val_mae: 0.3460
Epoch 171/5000
41/41 - 1s - loss: 0.0227 - mae: 0.1019 - val_loss: 0.1670 - val_mae: 0.3396
Epoch 172/5000
41/41 - 1s - loss: 0.0230 - mae: 0.1038 - val_loss: 0.1558 - val_mae: 0.3169
Epoch 173/5000
41/41 - 1s - loss: 0.0242 - mae: 0.1073 - val_loss: 0.1593 - val_mae: 0.3266
Epoch 174/5000
41/41 - 1s - loss: 0.0250 - mae: 0.1100 - val_loss: 0.1696 - val_mae: 0.3535
Epoch 175/5000
41/41 - 1s - loss: 0.0239 - mae: 0.1076 - val_loss: 0.1553 - val_mae: 0.3171
Epoch 176/5000
41/41 - 1s - loss: 0.0241 - mae: 0.1058 - val_loss: 0.1570 - val_mae: 0.3242
Epoch 177/5000
41/41 - 1s - loss: 0.0230 - mae: 0.1027 - val_loss: 0.1641 - val_mae: 0.3378
Epoch 178/5000
41/41 - 1s - loss: 0.0235 - mae: 0.1036 - val_loss: 0.1557 - val_mae: 0.3151
Epoch 179/5000
41/41 - 1s - loss: 0.0234 - mae: 0.1048 - val_loss: 0.1531 - val_mae: 0.3091
Epoch 180/5000
41/41 - 1s - loss: 0.0284 - mae: 0.1203 - val_loss: 0.1646 - val_mae: 0.3340
Epoch 181/5000
41/41 - 1s - loss: 0.0248 - mae: 0.1118 - val_loss: 0.1611 - val_mae: 0.3260
Epoch 182/5000
41/41 - 1s - loss: 0.0242 - mae: 0.1092 - val_loss: 0.1546 - val_mae: 0.3048
Epoch 183/5000
41/41 - 1s - loss: 0.0249 - mae: 0.1118 - val_loss: 0.1561 - val_mae: 0.3132
Epoch 184/5000
41/41 - 1s - loss: 0.0276 - mae: 0.1232 - val_loss: 0.1763 - val_mae: 0.3468
Epoch 185/5000
41/41 - 1s - loss: 0.0260 - mae: 0.1181 - val_loss: 0.1565 - val_mae: 0.3094
Epoch 186/5000
41/41 - 1s - loss: 0.0266 - mae: 0.1183 - val_loss: 0.1606 - val_mae: 0.3164
Epoch 187/5000
41/41 - 1s - loss: 0.0262 - mae: 0.1210 - val_loss: 0.1639 - val_mae: 0.3274
Epoch 188/5000
41/41 - 1s - loss: 0.0265 - mae: 0.1182 - val_loss: 0.1598 - val_mae: 0.3133
Epoch 189/5000
41/41 - 1s - loss: 0.0295 - mae: 0.1245 - val_loss: 0.1640 - val_mae: 0.3242
Epoch 190/5000
41/41 - 1s - loss: 0.0224 - mae: 0.1128 - val_loss: 0.1582 - val_mae: 0.3102
Epoch 191/5000
41/41 - 1s - loss: 0.0258 - mae: 0.1207 - val_loss: 0.1595 - val_mae: 0.3142
Epoch 192/5000
41/41 - 1s - loss: 0.0327 - mae: 0.1381 - val_loss: 0.1635 - val_mae: 0.3339
Epoch 193/5000
41/41 - 1s - loss: 0.0255 - mae: 0.1259 - val_loss: 0.1667 - val_mae: 0.3312
Epoch 194/5000
41/41 - 1s - loss: 0.0270 - mae: 0.1263 - val_loss: 0.1697 - val_mae: 0.3415
Epoch 195/5000
41/41 - 1s - loss: 0.0331 - mae: 0.1444 - val_loss: 0.1752 - val_mae: 0.3664
Epoch 196/5000
41/41 - 1s - loss: 0.0343 - mae: 0.1460 - val_loss: 0.2004 - val_mae: 0.4288
Epoch 197/5000
41/41 - 1s - loss: 0.0368 - mae: 0.1447 - val_loss: 0.2013 - val_mae: 0.4203
Epoch 198/5000
41/41 - 1s - loss: 0.0354 - mae: 0.1457 - val_loss: 0.1835 - val_mae: 0.3765
Epoch 199/5000
41/41 - 1s - loss: 0.0296 - mae: 0.1279 - val_loss: 0.1679 - val_mae: 0.3443
Epoch 200/5000
41/41 - 1s - loss: 0.0259 - mae: 0.1249 - val_loss: 0.1597 - val_mae: 0.3191
Epoch 201/5000
41/41 - 1s - loss: 0.0215 - mae: 0.1117 - val_loss: 0.1578 - val_mae: 0.3141
Epoch 202/5000
41/41 - 1s - loss: 0.0231 - mae: 0.1100 - val_loss: 0.1652 - val_mae: 0.3271
Epoch 203/5000
41/41 - 1s - loss: 0.0220 - mae: 0.1068 - val_loss: 0.1629 - val_mae: 0.3365
Epoch 204/5000
41/41 - 1s - loss: 0.0241 - mae: 0.1092 - val_loss: 0.1568 - val_mae: 0.3242
Epoch 205/5000
41/41 - 1s - loss: 0.0191 - mae: 0.1005 - val_loss: 0.1631 - val_mae: 0.3395
Epoch 206/5000
41/41 - 1s - loss: 0.0187 - mae: 0.0999 - val_loss: 0.1639 - val_mae: 0.3411
Epoch 207/5000
41/41 - 1s - loss: 0.0179 - mae: 0.0953 - val_loss: 0.1739 - val_mae: 0.3576
Epoch 208/5000
41/41 - 1s - loss: 0.0171 - mae: 0.0951 - val_loss: 0.1641 - val_mae: 0.3357
Epoch 209/5000
41/41 - 1s - loss: 0.0179 - mae: 0.0937 - val_loss: 0.1655 - val_mae: 0.3388
Epoch 210/5000
41/41 - 1s - loss: 0.0176 - mae: 0.0904 - val_loss: 0.1580 - val_mae: 0.3263
Epoch 211/5000
41/41 - 1s - loss: 0.0183 - mae: 0.0918 - val_loss: 0.1584 - val_mae: 0.3233
Epoch 212/5000
41/41 - 1s - loss: 0.0198 - mae: 0.0998 - val_loss: 0.1629 - val_mae: 0.3298
Epoch 213/5000
41/41 - 1s - loss: 0.0167 - mae: 0.0913 - val_loss: 0.1545 - val_mae: 0.3097
Epoch 214/5000
41/41 - 1s - loss: 0.0184 - mae: 0.0994 - val_loss: 0.1598 - val_mae: 0.3109
Epoch 215/5000
41/41 - 1s - loss: 0.0232 - mae: 0.1175 - val_loss: 0.1784 - val_mae: 0.3407
Epoch 216/5000
41/41 - 1s - loss: 0.0194 - mae: 0.1025 - val_loss: 0.1644 - val_mae: 0.3224
Epoch 217/5000
41/41 - 1s - loss: 0.0249 - mae: 0.1187 - val_loss: 0.1593 - val_mae: 0.3222
Restoring model weights from the end of the best epoch.
Epoch 00217: early stopping
Saving training information..
Finetuned model performs better than transfer-learned model.
Saving model weights to process/trained_model_weights/weights_finetuned_9..

Done.
